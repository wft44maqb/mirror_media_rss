<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>亚马逊AWS官方博客</title>
	<atom:link href="https://aws.amazon.com/cn/blogs/china/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/cn/blogs/china/</link>
	<description>Just another AWS Brew Blogs  site</description>
	<lastBuildDate>Fri, 03 Sep 2021 04:30:44 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>使用更具体的 Amazon VPC 路由检查子网到子网的流量</title>
		<link>https://aws.amazon.com/cn/blogs/china/inspect-subnet-to-subnet-traffic-with-amazon-vpc-more-specific-routing/</link>
				<pubDate>Fri, 03 Sep 2021 04:30:44 +0000</pubDate>
		<dc:creator><![CDATA[Sébastien Stormacq]]></dc:creator>
				<category><![CDATA[Announcements]]></category>

		<guid isPermaLink="false">308ee0fb555368909267bfb075f24cf12dbcb77e</guid>
				<description>自 2019 年 12 月以来，Amazon Virtual Private Cloud（VPC）允许您将所有进站流量（也称为南北流量）路由到特定网络接口。您可能出于多种原因使用此功能。例如，使用入侵检测系统（IDS）设备检测进站流量或将进站流量路由到防火墙。</description>
								<content:encoded>&lt;p&gt;自 2019 年 12 月以来，&lt;a title="" href="https://aws.amazon.com/vpc/"&gt;Amazon Virtual Private Cloud（VPC）&lt;/a&gt;允许您将所有进站流量（也称为&lt;a href="https://en.wikipedia.org/wiki/North-south_traffic"&gt;南北流量&lt;/a&gt;）路由到特定网络接口。您可能出于多种原因使用此功能。例如，使用入侵检测系统（IDS）设备检测进站流量或将进站流量路由到防火墙。&lt;/p&gt; 
&lt;p&gt;自我们推出此功能以来，许多用户要求我们提供类似的功能来分析从一个子网流向 VPC 内的另一个子网的流量，也称为&lt;a href="https://en.wikipedia.org/wiki/East-west_traffic"&gt;东西流量&lt;/a&gt;。到今天为止，这仍然是不可能的，因为路由表中的路由不能比默认本地路由更具体（有关更多详细信息，请查看&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html"&gt;VPC 文档&lt;/a&gt;）。简单地说，这意味着任何一个路由的目标使用的 &lt;a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing"&gt;CIDR&lt;/a&gt; 范围都不能小于默认本地路由（即整个 VPC 的 CIDR 范围）。例如，当 VPC 范围为 &lt;code&gt;10.0.0/16&lt;/code&gt; 且子网有 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 时，通向 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 的路由比通向 &lt;code&gt;10.0.0/16&lt;/code&gt; 的路由更具体。&lt;/p&gt; 
&lt;p&gt;路由表不再有此限制。路由表中的路由可以有比默认本地路由更具体的路由。您可以使用此类更具体的路由将所有流量发送到专用设备或服务，以检测、分析或过滤两个子网之间的所有流量（东西流量）。路由目标可以是连接到您构建或购买的设备的网络接口（ENI）、出于性能或高可用性原因将流量分配到多个设备的 &lt;a href="https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/"&gt;AWS 网关负载均衡器&lt;/a&gt;（GWLB）终端节点、&lt;a title="" href="https://aws.amazon.com/firewall-manager/"&gt;AWS Firewall Manager&lt;/a&gt; 终端节点或 &lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html"&gt;NAT 网关&lt;/a&gt;。它还允许在子网和 &lt;a href="https://aws.amazon.com/transit-gateway/"&gt;AWS Transit Gateway&lt;/a&gt; 之间插入设备。&lt;/p&gt; 
&lt;p&gt;可以将设备链接起来，以便在源子网和目标子网之间进行多种类型的分析。例如，您可能希望首先使用防火墙（AWS 托管防火墙或&lt;a href="https://aws.amazon.com/marketplace/solutions/security"&gt;第三方防火墙设备&lt;/a&gt;）筛选流量，然后将流量发送到&lt;a href="https://aws.amazon.com/marketplace/solutions/infrastructure-software/ids-ips"&gt;入侵检测和防御系统&lt;/a&gt;，最后，执行深度数据包检测。您可以从我们的 &lt;a href="https://aws.amazon.com/partners/"&gt;AWS 合作伙伴网络&lt;/a&gt;和 &lt;a href="https://aws.amazon.com/marketplace"&gt;AWS Marketplace&lt;/a&gt; 访问虚拟设备。&lt;/p&gt; 
&lt;p&gt;链接设备时，每个设备和每个终端节点都必须位于单独的子网中。&lt;/p&gt; 
&lt;p&gt;让我们动手试试这个新功能。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;工作原理&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 在本博客文章中，我们假设我有一个具有三个子网的 &lt;span title=""&gt;VPC&lt;/span&gt;。第一个子网是公有子网，有一个堡垒主机。它需要访问资源，例如 API 或第二个子网中的数据库。第二个子网是私有子网。它托管堡垒所需的资源。我写了&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;一个简单的 CDK 脚本&lt;/a&gt;来帮助您部署此设置。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/Slide1.png"&gt;&lt;img class="aligncenter wp-image-52363 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/Slide1-e1621855971954-1024x584.png" alt="更具体的 VPC 路由" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;出于合规性原因，我们公司要求此私有应用程序的流量流经入侵检测系统。&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;CDK 脚本&lt;/a&gt;还创建了第三个子网（私有子网）来托管网络设备。它提供了三个 &lt;a title="" href="https://aws.amazon.com/ec2/"&gt;Amazon Elastic Compute Cloud（Amazon EC2）&lt;/a&gt;实例：堡垒主机、应用程序实例和网络分析设备。该脚本还创建了 NAT 网关，允许引导应用程序实例并使用 &lt;a title="" href="https://aws.amazon.com/systems-manager/"&gt;AWS Systems Manager&lt;/a&gt; Session Manager （SSM）连接到三个实例。&lt;/p&gt; 
&lt;p&gt;因为这是一个演示，所以网络设备是配置为 IP 路由器的常规 Amazon Linux &lt;span title=""&gt;EC2&lt;/span&gt; 实例。在现实生活中，您可能要使用我们的合作伙伴在 &lt;a title="" href="https://aws.amazon.com/marketplace/"&gt;AWS Marketplace&lt;/a&gt; 上提供的众多设备之一，或者&lt;a href="https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/"&gt;网关负载均衡器&lt;/a&gt;终端节点或 Network Firewall。&lt;/p&gt; 
&lt;p&gt;让我们修改路由表以通过设备发送流量。&lt;/p&gt; 
&lt;p&gt;使用 &lt;a title="" href="https://console.aws.amazon.com"&gt;AWS 管理控制台&lt;/a&gt;或 &lt;a title="" href="https://aws.amazon.com/cli/"&gt;AWS 命令行界面（CLI）&lt;/a&gt;，我向 &lt;code&gt;10.0.0.0/24&lt;/code&gt; 和 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 子网路由表添加了更具体的路由。这些路由指向 &lt;code&gt;eni0&lt;/code&gt;，即流量检测设备的网络接口。&lt;/p&gt; 
&lt;p&gt;使用 CLI，我首先收集设备的 VPC ID、子网 ID、路由表 ID 和 ENI ID。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;VPC_ID=$(aws                                                    \
    --region $REGION cloudformation describe-stacks             \
    --stack-name SpecificRoutingDemoStack                       \
    --query "Stacks[].Outputs[?OutputKey=='VPCID'].OutputValue" \
    --output text)
echo $VPC_ID

APPLICATION_SUBNET_ID=$(aws                                                                      \
    --region $REGION ec2 describe-instances                                                      \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='application']].NetworkInterfaces[].SubnetId" \
    --output text)
echo $APPLICATION_SUBNET_ID

APPLICATION_SUBNET_ROUTE_TABLE=$(aws                                                             \
    --region $REGION  ec2 describe-route-tables                                                  \
    --query "RouteTables[?VpcId=='${VPC_ID}'] | [?Associations[?SubnetId=='${APPLICATION_SUBNET_ID}']].RouteTableId" \
    --output text)
echo $APPLICATION_SUBNET_ROUTE_TABLE

APPLIANCE_ENI_ID=$(aws                                                                           \
    --region $REGION ec2 describe-instances                                                      \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='appliance']].NetworkInterfaces[].NetworkInterfaceId" \
    --output text)
echo $APPLIANCE_ENI_ID

BASTION_SUBNET_ID=$(aws                                                                         \
    --region $REGION ec2 describe-instances                                                     \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='BastionHost']].NetworkInterfaces[].SubnetId" \
    --output text)
echo $BASTION_SUBNET_ID

BASTION_SUBNET_ROUTE_TABLE=$(aws \
 --region $REGION ec2 describe-route-tables \
 --query "RouteTables[?VpcId=='${VPC_ID}'] | [?Associations[?SubnetId=='${BASTION_SUBNET_ID}']].RouteTableId" \
 --output text)
echo $BASTION_SUBNET_ROUTE_TABLE&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接下来，我会添加两条更具体的路由。一条路由通过设备网络接口将来自堡垒公有子网的流量发送到应用程序私有子网。&amp;nbsp;第二条路由与路由回复的方向相反。它通过设备网络接口将更具体的流量从应用程序私有子网路由到堡垒公有子网。&amp;nbsp;感到困惑？ 让我们看看下图：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/illustration-1.png"&gt;&lt;img class="aligncenter wp-image-52368 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/illustration-1-1024x584.png" alt="更具体的 VPC 路由" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;首先，让我们修改堡垒路由表：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;aws ec2 create-route                                  \
     --region $REGION                                 \
     --route-table-id $BASTION_SUBNET_ROUTE_TABLE     \
     --destination-cidr-block 10.0.1.0/24             \
     --network-interface-id $APPLIANCE_ENI_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接下来，让我们修改应用程序路由表：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;aws ec2 create-route                                  \
    --region $REGION                                  \
    --route-table-id $APPLICATION_SUBNET_ROUTE_TABLE  \
    --destination-cidr-block 10.0.0.0/24              \
    --network-interface-id $APPLIANCE_ENI_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我还可以使用 Amazon VPC 控制台进行这些修改。只需从 Routes (路由) 选项卡中选择“Bastion”(堡垒) 路由表，然后单击 Edit routes (编辑路由) 即可。&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-33-52.png"&gt;&lt;img class="aligncenter size-large wp-image-52421" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-33-52-1024x584.png" alt="MSR：选择路由表" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我添加了一个路由，用于将 &lt;code&gt;10.0.1.0/24&lt;/code&gt;（应用程序子网）的流量发送到设备 ENI（&lt;code&gt;eni-055...&lt;/code&gt;）。&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-35-20.png"&gt;&lt;img class="aligncenter size-large wp-image-52422" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-35-20-1024x494.png" alt="MSR：创建路由" width="1024" height="494"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下一步是定义相反的回复路由，将 &lt;code&gt;10.0.0.0/24&lt;/code&gt; 的流量从应用程序子网发送到设备 ENI（&lt;code&gt;eni-05...&lt;/code&gt;）。&amp;nbsp;完成后，应用程序子网路由表应如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-36-34.png"&gt;&lt;img class="aligncenter size-large wp-image-52423" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-36-34-1024x559.png" alt="MSR：最终路由表" width="1024" height="559"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;配置设备实例&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 最后，我将设备实例配置为转发其接收的所有流量。您的软件设备通常会为您完成此操作。当您使用 &lt;a title="" href="https://aws.amazon.com/marketplace/"&gt;AWS Marketplace&lt;/a&gt; 设备或&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;我为此演示提供的 CDK 脚本&lt;/a&gt;创建的实例时，无需执行额外步骤。如果您使用的是普通 Linux 实例，请完成以下两个额外步骤：&lt;/p&gt; 
&lt;p&gt;1.连接到 &lt;span title=""&gt;EC2&lt;/span&gt; 设备实例并在内核中配置 IP 流量转发：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;sysctl -w net.ipv4.ip_forward=1
sysctl -w net.ipv6.conf.all.forwarding=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2.将 &lt;span title=""&gt;EC2&lt;/span&gt; 实例配置为接受除本身之外的其他目标的流量（称为&lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html#EIP_Disable_SrcDestCheck"&gt;源/目标检查&lt;/a&gt;）：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;APPLIANCE_ID=$(aws --region $REGION ec2 describe-instances                     \
     --filter "Name=tag:Name,Values=appliance"                                 \
     --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
     --output text)

aws ec2 modify-instance-attribute --region $REGION     \
                         --no-source-dest-check        \
                         --instance-id $APPLIANCE_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;测试设置&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 设备现已做好将流量转发到其他 &lt;span title=""&gt;EC2&lt;/span&gt; 实例的准备。&lt;/p&gt; 
&lt;p&gt;如果您使用的是&lt;a href="https://github.com/sebsto/cdkv2-vpc-example"&gt;演示设置&lt;/a&gt;，则堡垒主机上未安装 SSH 密钥。通过 &lt;a title="" href="https://aws.amazon.com/systems-manager/"&gt;AWS Systems Manager&lt;/a&gt; Session Manager 进行访问。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;BASTION_ID=$(aws --region $REGION ec2 describe-instances                      \
    --filter "Name=tag:Name,Values=BastionHost"                               \
    --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
    --output text)

aws --region $REGION ssm start-session --target $BASTION_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;连接到堡垒主机后，发出以下 &lt;code&gt;cURL&lt;/code&gt; 命令以连接到应用程序主机：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;sh-4.2$ curl -I 10.0.1.239 # use the private IP address of your application host
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Mon, 24 May 2021 10:00:22 GMT
Content-Type: text/html
Content-Length: 12338
Last-Modified: Mon, 24 May 2021 09:36:49 GMT
Connection: keep-alive
ETag: "60ab73b1-3032"
Accept-Ranges: bytes&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;要验证流量是否真正流经设备，您可以再次对实例启用源/目标检查。将 &lt;code&gt;--source-dest-check&lt;/code&gt; 参数与上面的 &lt;code&gt;modify-instance-attribute&lt;/code&gt; CLI 命令一起使用。当源/目标检查启用时，流量将受阻。&lt;/p&gt; 
&lt;p&gt;我还可以连接到设备主机并使用 &lt;code&gt;tcpdump&lt;/code&gt; 命令检测流量。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;(on your laptop)
APPLIANCE_ID=$(aws --region $REGION ec2 describe-instances     \
                   --filter "Name=tag:Name,Values=appliance" \
		   --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
  		   --output text)

aws --region $REGION ssm start-session --target $APPLIANCE_ID

(on the appliance host)
tcpdump -i eth0 host 10.0.0.16 # the private IP address of the bastion host

08:53:22.760055 IP ip-10-0-0-16.us-west-2.compute.internal.46934 &amp;gt; ip-10-0-1-104.us-west-2.compute.internal.http: Flags [S], seq 1077227105, win 26883, options [mss 8961,sackOK,TS val 1954932042 ecr 0,nop,wscale 6], length 0
08:53:22.760073 IP ip-10-0-0-16.us-west-2.compute.internal.46934 &amp;gt; ip-10-0-1-104.us-west-2.compute.internal.http: Flags [S], seq 1077227105, win 26883, options [mss 8961,sackOK,TS val 1954932042 ecr 0,nop,wscale 6], length 0
08:53:22.760322 IP ip-10-0-1-104.us-west-2.compute.internal.http &amp;gt; ip-10-0-0-16.us-west-2.compute.internal.46934: Flags [S.], seq 4152624111, ack 1077227106, win 26847, options [mss 8961,sackOK,TS val 4094021737 ecr 1954932042,nop,wscale 6], length 0
08:53:22.760329 IP ip-10-0-1-104.us-west-2.compute.internal.http &amp;gt; ip-10-0-0-16.us-west-2.compute.internal.46934: Flags [S.], seq 4152624111, ack 1077227106, win 26847, options [mss &lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;清理&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 如果您使用了&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;我为此博文提供的 CDK 脚本&lt;/a&gt;，请务必在完成后运行 &lt;code&gt;cdk destroy&lt;/code&gt;，这样就无需为我用于此演示的三个 EC2 实例和 NAT 网关付费。在 &lt;code&gt;us-west-2&lt;/code&gt; 中运行演示脚本的&lt;a href="https://calculator.aws/#/estimate?id=a460f21b3c6a0e271aae860ce4482c02389747bd"&gt;费用&lt;/a&gt;为每小时 0.062 美元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;注意事项。&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; 在使用更具体的 &lt;span title=""&gt;VPC&lt;/span&gt; 路由时，请记住以下几点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;您要向其发送流量的网络接口或服务终端节点必须位于专用子网中。它不能位于流量的源子网或目标子网中。&lt;/li&gt; 
 &lt;li&gt;您可以将设备链接起来。每台设备必须位于其专用子网中。&lt;/li&gt; 
 &lt;li&gt;您添加的每个子网都会占用一个 IP 地址块。&amp;nbsp;如果您使用的是 IPv4，请注意所用的 IP 地址数量（一个 /24 子网使用来自您的 VPC 的 256 个地址）。子网中允许的最小 CIDR 范围是 /28，它只使用 16 个 IP 地址。&lt;/li&gt; 
 &lt;li&gt;设备的安全组必须有规则接受所需端口上的传入流量。同样，应用程序的安全组必须授权来自设备安全组或 IP 地址的流量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此新功能在所有 AWS 区域均可使用，无需额外付费。&lt;/p&gt; 
&lt;p&gt;您可以立即开始使用。&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>Amazon Textract 更新：8 个亚马逊云科技区域的价格降幅达 32％，异步任务处理时间缩短近 50％</title>
		<link>https://aws.amazon.com/cn/blogs/china/amazon-textract-updates-up-to-32-price-reduction-in-8-aws-regions-and-up-to-50-reduction-in-asynchronous-job-processing-times/</link>
				<pubDate>Fri, 03 Sep 2021 04:28:17 +0000</pubDate>
		<dc:creator><![CDATA[Channy Yun]]></dc:creator>
				<category><![CDATA[Price Reduction]]></category>

		<guid isPermaLink="false">1d79dcc8d4d08e74c3b32607ec6ca943b1d1b3b6</guid>
				<description>在亚马逊云科技 re:Invent 2018 上推出的 Amazon Textract 是一项机器学习服务，它可以从扫描的文档中自动提取文本、手写和数据，并超越了简单的光学字符识别 (OCR) 来识别、理解和提取表单和表格中的数据。</description>
								<content:encoded>&lt;p&gt;在亚马逊云科技 re:Invent 2018 上推出的 &lt;a href="https://aws.amazon.com/textract/"&gt;Amazon Textract&lt;/a&gt; 是一项机器学习服务，它可以从扫描的文档中自动提取文本、手写和数据，并超越了简单的光学字符识别 (OCR) 来识别、理解和提取表单和表格中的数据。&lt;/p&gt; 
&lt;p&gt;在过去的几个月中，我们推出了处理&lt;a href="https://aws.amazon.com/blogs/machine-learning/announcing-expanded-support-for-extracting-data-from-invoices-and-receipts-using-amazon-textract/"&gt;发票和收据&lt;/a&gt;的专业技术支持，并提高了基础计算机视觉模型的质量，该模型支持&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/07/amazon-textract-announces-improvements-detection-handwritten-text-digits-dates-phone-numbers/"&gt;手写文本&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/06/amazon-textract-announces-quality-updates-to-its-forms-extraction-feature/"&gt;表单&lt;/a&gt;和&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-textract-announces-quality-update-table-extraction-feature/"&gt;表格&lt;/a&gt;的提取，并支持英语、西班牙语、德语、意大利语、葡萄牙语和法语的打印文本。&lt;/p&gt; 
&lt;p&gt;作为多个亚马逊云科技合规性计划的一部分，第三方审计员将评估 Amazon Textract 的安全性和合规性。我们还添加了 &lt;a href="https://aws.amazon.com/blogs/security/new-2021-h1-irap-report-is-now-available-on-aws-artifact-for-australian-customers/"&gt;IRAP&lt;/a&gt; 合规性技术支持并实现 &lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-textract-achieves-fedramp-compliance/"&gt;US FedRAMP&lt;/a&gt; 授权，以添加到现有的列表中，如 &lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/10/amazon-textract-is-now-a-hipaa-eligible-service/"&gt;HIPAA&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/12/amazon-textract-is-now-pci-dss-certified-and-extracts-even-more-data-from-tables-and-forms/"&gt;PCI DSS&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2020/06/amazon-textract-is-now-soc-and-iso-compliant/?nc1=h_ls"&gt;ISO SCO&lt;/a&gt; 和 &lt;a href="https://aws.amazon.com/blogs/security/aws-extends-its-mtcs-level-3-certification-scope-to-cover-united-states-regions/"&gt;MTCS&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-54262" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/24/2021-textract-price-reduction.png" alt="" width="2018" height="546"&gt;&lt;/p&gt; 
&lt;p&gt;客户使用 Amazon Textract 自动执行关键业务流程工作流（例如，在索赔和纳税表处理、贷款申请和应付账款方面）。这样可以缩短人工审核时间、提高准确性、降低成本并加快全球范围的创新步伐。与此同时，&lt;a href="https://aws.amazon.com/textract/customers/"&gt;Textract 客户&lt;/a&gt;告诉我们，我们可以做更多的工作来降低成本和改善延迟现象。&lt;/p&gt; 
&lt;p&gt;今天，我们很高兴地宣布对 Amazon Textract 的两项主要更新：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;8 个亚马逊云科技区域的价格降幅达 32%，帮助&lt;/strong&gt;全球客户通过 Textract 节省更多成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Textract 全球&lt;/strong&gt;异步操作的端到端任务处理时间减少近 50%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;8 个亚马逊云科技区域的价格降幅达 32％&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; 我们很高兴地宣布，8 个亚马逊云科技区域的价格降幅达 32％：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、加拿大（中部）、欧洲（法兰克福）、欧洲（伦敦）和欧洲（巴黎）。&lt;/p&gt; 
&lt;p&gt;这些亚马逊云科技区域中 &lt;code&gt;DetectDocumentText&lt;/code&gt; (OCR) 和 &lt;code&gt;AnalyzeDocument&lt;/code&gt;（表单和表格）的 API 定价现在与美国东部（弗吉尼亚北部）区域的定价相同。这些已确定区域的客户将看到 API 定价下降 9-32％。&lt;/p&gt; 
&lt;p&gt;在降价之前，客户对 &lt;code&gt;DetectDocumentText&lt;/code&gt; 和 &lt;code&gt;AnalyzeDocument&lt;/code&gt; API 的使用情况将按不同的费率、按区域及其使用套餐收费。无论从哪个亚马逊云科技商业区域 Textract 调用，现在都将按同样的费率向该客户收费。&lt;/p&gt; 
&lt;table style="width: 100%;border: 1px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto;text-align: right"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border: 1px solid black;background-color: #eee"&gt; 
   &lt;td style="text-align: center;border: 1px solid black" rowspan="2"&gt;&lt;strong&gt;亚马逊云科技区域&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="text-align: center;border: 1px solid black" colspan="3"&gt;&lt;strong&gt;DetectDocumentText API&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="text-align: center;border: 1px solid black" colspan="3"&gt;&lt;strong&gt;AnalyzeDocument API&lt;/strong&gt;&lt;strong&gt;（表单+表格）&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;原价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;新价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;减少&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;原价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;新价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;减少&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（孟买）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.830 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black" rowspan="8"&gt;1.50 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;18%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;79.30 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black" rowspan="8"&gt;65.0 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;18%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（首尔）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.845 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;19%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;79.95 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;19%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（新加坡）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;2.200 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;32%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;95.00 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;32%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（悉尼）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.950 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;23%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;84.50 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;23%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;加拿大（中部）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.655 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;9%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;72.15 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;10%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（法兰克福）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.875 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;20%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;81.25 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;20%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（伦敦）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.750 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;14%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;75.00 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;13%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（巴黎）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.755 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;15%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;76.05 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;15%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;此表显示了每 1,000 页的两个有效价格示例，用于在降价之前和之后处理前 100 万个按月填的页面。每月页面使用量超过 100 万个套餐的客户还会看到类似的价格下降信息，其详细信息位于 &lt;a href="https://aws.amazon.com/textract/pricing/"&gt;Amazon Textract 定价页面&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;新定价将于 &lt;strong&gt;2021 年 9 月 1 日&lt;/strong&gt;生效。新价格将自动应用于您的账单。此定价变更不适用于欧洲（爱尔兰）、美国商业区域和美国 GovCloud 区域。近期推出的 &lt;code&gt;AnalyzeExpense&lt;/code&gt; API 发票和收据的定价没有任何变化。&lt;/p&gt; 
&lt;p&gt;作为&lt;a href="https://aws.amazon.com/free/"&gt;亚马逊云科技免费套餐&lt;/a&gt;的一部分，您可以免费开始使用 Amazon Textract。&amp;nbsp;免费套餐持续 3 个月，新的 AWS 客户可以使用 Detect Document Text API 每月分析多达 1,000 页，使用 Analyze Document API 或 Analyze Expense API 每月可分析 100 页。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;端到端任务处理时间减少近 50％&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; 客户可以同步（在单页文档中）和异步（在多页文档中）调用 Textract 来检测打印和手写的行和单词（通过 &lt;code&gt;DetectDocumentText &lt;/code&gt;API）以及提取表单和表格（通过 &lt;code&gt;AnalyzeDocument&lt;/code&gt; API）。我们看到，如今绝大多数客户异步调用 Textract 来对他们的文档管道进行大规模处理。&lt;/p&gt; 
&lt;p&gt;根据客户反馈，我们对 Textract 的异步 API 操作进行了多项改善和提高，这些功能将端到端延迟减少了近 50％。具体而言，这些更新将 Textract 客户在全球异步操作中经历的端到端任务处理时间缩短了近 50％。处理时间越短，客户处理文档、实现规模和提高总体生产力的速度就越快。&lt;/p&gt; 
&lt;p&gt;要深入了解 Amazon Textract，请参阅本&lt;a href="https://aws.amazon.com/getting-started/hands-on/extract-text-with-amazon-textract/"&gt;教程中关于从文档&lt;/a&gt;中提取文本和结构性数据、GitHub 中的&lt;a href="https://github.com/aws-samples/amazon-textract-code-samples"&gt;此代码示例&lt;/a&gt;、&lt;a href="https://docs.aws.amazon.com/textract/"&gt;Amazon Textract 文档&lt;/a&gt;，以及 Amazon Web Services Machine Learning 博客&lt;a href="https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-textract/"&gt;中关于 Amazon Textract 的&lt;/a&gt;博客帖子。&lt;/p&gt; 
&lt;p&gt;– &lt;a href="https://twitter.com/channyun"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>Announcing the latest AWS Heroes – August 2021</title>
		<link>https://aws.amazon.com/cn/blogs/china/announcing-the-latest-aws-heroes-august-2021/</link>
				<pubDate>Fri, 03 Sep 2021 04:09:00 +0000</pubDate>
		<dc:creator><![CDATA[Ross Barich]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">07b49b3d09f57f003e99de21de38d56a06c40a92</guid>
				<description>AWS 勇士们不遗余力地与社群分享知识，并帮助其他人在 AWS 上更好、更快地进行构建。上个月，我们推出了 AWS 勇士内容库，这是一个资源汇集之地，构建者可以在这里找到灵感并从 AWS 勇士撰写的教学内容中学习，包括博客、视频、幻灯片演示、播客、开源项目等。随着技术社群的日益发展，新的勇士不断涌现，每个季度我们都会表彰来自世界各地的一群杰出人士，他们对社群知识的共享产生重大影响，并受到高度赞赏。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士们&lt;/a&gt;不遗余力地与社群分享知识，并帮助其他人在 AWS 上更好、更快地进行构建。上个月，我们推出了 &lt;a href="https://aws.amazon.com/developer/community/heroes/content-library/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士内容库&lt;/a&gt;，这是一个资源汇集之地，构建者可以在这里找到灵感并从 AWS 勇士撰写的教学内容中学习，包括博客、视频、幻灯片演示、播客、开源项目等。随着技术社群的日益发展，新的勇士不断涌现，每个季度我们都会表彰来自世界各地的一群杰出人士，他们对社群知识的共享产生重大影响，并受到高度赞赏。&lt;/p&gt; 
&lt;p&gt;今天，我们很高兴地介绍最新的 AWS 勇士们，包括位于喀麦隆和马来西亚的首批勇士：&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Denis Astahov – 加拿大温哥华&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/denis-astahov/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/denis-astahov.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士 &lt;a href="https://aws.amazon.com/developer/community/heroes/denis-astahov/" target="_blank" rel="noopener noreferrer"&gt;Denis Astahov&lt;/a&gt; 是 OpsGuru 的一名解决方案构架师，在那里，他使用 Terraform 利用基础设施即代码自动化和开发各种云解决方案。Denis 拥有 YouTube 频道 ADV-IT，他通过该频道向人们讲授各种 IT 知识，尤其是有关 DevOps 的话题，包括 AWS、Terraform、Kubernetes、Ansible、Jenkins、Git、Linux、Python 及许多其他主题。他的频道拥有 7 万多个订阅者和 700 多万观看次数，使其成为俄语社群中 AWS 和 DevOps 知识最受欢迎的免费来源之一。Denis 拥有 10 多项云认证，其中包括 7 项 AWS Certification。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Ivonne Roberts — 美国坦帕&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/ivonne-roberts/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/ivonne-roberts.jpg" width="175" height="263"&gt;&lt;/a&gt;无服务器勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/ivonne-roberts/" target="_blank" rel="noopener noreferrer"&gt; Ivonne Roberts&lt;/a&gt; 是一名首席软件工程师，拥有逾 15 年的软件开发经验，其中包括十年与 AWS 合作的经验以及五年以上构建无服务器应用程序的经验。近年来，Ivonne 已开始与范围更广的软件工程界分享这些行业知识。在其博客 ivonneroberts.com 和 YouTube 频道 DevWidgets 上，Ivonne 专注于揭开采用无服务器架构的神秘面纱并消除障碍，以及简化软件开发生命周期。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Kaushik Mohanraj — 马来西亚吉隆坡&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/kaushik-mohanraj/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/kaushik-mohanraj.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/kaushik-mohanraj/" target="_blank" rel="noopener noreferrer"&gt; Kaushik Mohanraj&lt;/a&gt; 是马来西亚一家名为 Blazeclan Technologies 的公司的董事。Kaushik 是一位狂热的云从业者，在评估架构良好的解决方案方面拥有丰富的经验，并且是云技术和数字化转型大使。Kaushik 持有 10 项有效的 AWS Certification，这有助于他提供最有针对性且且最佳的解决方案。Kaushik 热衷于打造一个他得以在其中充分发展的社群，因此在 2019 年作为联合组织者加入了马来西亚 AWS 用户组。他还是“大数据中的女性 — 马来西亚分会”的联合总监，旨在为科技领域的女性构建和提供一个平台。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Luc van Donkersgoed — 荷兰乌得勒支&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/luc-van-donkersgoed/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/luc-van-donkersgoed.jpg" width="175" height="263"&gt;&lt;/a&gt;DevTools 勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/luc-van-donkersgoed/" target="_blank" rel="noopener noreferrer"&gt; Luc van Donkersgoed&lt;/a&gt; 在内心里是一位技术狂热爱好者，他是一名解决方案构架师、软件开发人员，同时也是一位企业家。他着迷于尖端技术。不在 AWS 上设计和构建强大的应用程序时， Luc 很可能正在博客、文章、视频、会议、培训课程和 Twitter 上分享知识。他撰写了一个 共16 节课的 AWS 解决方案构架师专业课程，内容涉及各种主题，包括 AWS CDK 将如何助力新一代无服务器开发人员，他也曾出现在 AWS 开发人员播客中，同时他也在维护 AWS 博客 Twitter Bot。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Rick Hwang — 台湾台北市&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/rick-hwang/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/rick-hwang.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/rick-hwang/" target="_blank" rel="noopener noreferrer"&gt; Rick Hwang&lt;/a&gt; 是位于台湾的 91APP 的一名云与基础设施架构师。他为开发人员授课的热情已在内部通过年度 AWS 培训项目负责人的身份得以彰显，在外部又通过 SRE Taiwan 社群拥有者的身份得以证明。Rick 独立创办了 SRE Taiwan，在过去的 4 年里，通过点对点互动、不断分享内容和主办年度学习小组聚会，招募了 3,600 多名成员。Rick 乐于帮助人们加深对 AWS 和整个云的了解。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Rosius Ndimofor — 喀麦隆杜阿拉&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/rosius-ndimofor/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/23/rosius-ndimofor.jpg" width="175" height="263"&gt;&lt;/a&gt;无服务器勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/rosius-ndimofor/" target="_blank" rel="noopener noreferrer"&gt; Rosius Ndimo&lt;/a&gt; 是 Serverless Guru 的一名软件开发人员。8 年来，他始终在为各种客户构建桌面、Web 和移动应用程序。2020 年，Rosius 的朋友向他介绍了 AWS，他随即便被吸引住了，并开始尽可能地学习如何构建 AWS 无服务器应用程序。您会看到 Rosius 在当地每月一次的 AWS 聚会活动中发表演讲，或者从事他的强项：构建无服务器 Web 或移动应用程序并在其博客上记录整个过程。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Setia Budi — 印度尼西亚万隆&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/setia-budi/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/setia-budi.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/setia-budi/" target="_blank" rel="noopener noreferrer"&gt; Setia Budi&lt;/a&gt; 是一名来自印度尼西亚的学者。他经营着一个名为 Indonesia Belajar 的 YouTube 频道，该频道提供与计算机科学和云计算相关的学习资料（以印度尼西亚语提供）。他对 AWS 社区的热情还体现在他在 AWS DevAx Connect 上发表演讲，他正在积极构建一系列与 AWS 服务相关的学习材料，并每周直播 AWS 专家探论云计算的直播会议。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Vinicius Caridá — 巴西圣保罗&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/vinicius-carida/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/vinicius-carida.jpg" width="175" height="263"&gt;&lt;/a&gt;机器学习勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/vinicius-carida/" target="_blank" rel="noopener noreferrer"&gt; Vinicius Caridá（Vini）&lt;/a&gt;是一名计算机工程师，他相信技术、数据和人工智能可以影响人们，进而创造一个更公平、更进步的世界。他喜欢在社交媒体上、YouTube 频道上以及 AWS 圣保罗用户组（他是社群主管）等各种聚会上分享自己关于 AI、NLP 和 MLOps 的知识。Vini 还是开源机器学习框架 TensorFlow 圣保罗的社群主管。他定期参加会议，并为不同背景（学术界、科学界、技术界）和不同成熟程度（初级、中级和高级）的受众撰写文章。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如果您想了解有关这些新勇士的详情，或者与附近的勇士联系，请访问 &lt;a href="https://aws.amazon.com/developer/community/heroes/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士网站&lt;/a&gt;或浏览 &lt;a href="https://aws.amazon.com/developer/community/heroes/content-library/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士内容库&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://twitter.com/rossbarich" target="_blank" rel="noopener noreferrer"&gt;Ross&lt;/a&gt;；&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>通过亚马逊云科技Marketplace中合作伙伴（Zenlayer）的产品来加速Amazon S3的访问</title>
		<link>https://aws.amazon.com/cn/blogs/china/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace/</link>
				<pubDate>Fri, 03 Sep 2021 03:59:58 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Marketplace]]></category>

		<guid isPermaLink="false">19e4e87c516f11f5d35a00626639a9bb0cda9724</guid>
				<description>AWS Marketplace 是一个精挑细选的数字化产品目录，您可以使用它来查找、购买、部署和管理构建解决方案及运营业务所需的第三方软件、数据和服务。 AWS Marketplace 囊括了众多常见类别下的数千个软件名录，例如安全、联网、存储、机器学习、IoT、商业智能、数据库和开发运营。 AWS Marketplace 还提供灵活的定价选项和多种部署方法，从而简化了软件的许可和采购。此外, AWS Marketplace 包括 AWS Data Exchange 提供的数据产品。</description>
								<content:encoded>&lt;h2&gt;1.&amp;nbsp;&amp;nbsp; 相关服务及背景介绍&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Amazon S3&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Amazon Simple Storage Service (Amazon S3) 是一种面向 Internet 的存储服务。该服务旨在降低网络规模计算的难度。&lt;/p&gt; 
&lt;p&gt;Amazon S3 提供了一个简单 Web 服务接口，可用于随时在 Web 上的任何位置存储和检索任何数量的数据。此服务让所有开发人员都能访问同一个具备高扩展性、可靠性、安全性和快速价廉的数据存储基础设施，Amazon 用它来运行其全球的网站网络。此服务旨在为开发人员带来最大化的规模效益。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Amazon CloudFront&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Amazon CloudFront 是一项加快将静态和动态 Web 内容（例如 .html、.css、.js 和图像文件）分发给用户的速度的 Web 服务。CloudFront 通过全球数据中心（称作边缘站点）网络传输内容。当用户请求您用 CloudFront 提供的内容时，请求被路由到提供最低延迟（时间延迟）的边缘站点，从而以尽可能最佳的性能传送内容。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;亚马逊云科技&lt;/strong&gt;&lt;strong&gt;Marketplace&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AWS Marketplace 是一个精挑细选的数字化产品目录，您可以使用它来查找、购买、部署和管理构建解决方案及运营业务所需的第三方软件、数据和服务。 AWS Marketplace 囊括了众多常见类别下的数千个软件名录，例如安全、联网、存储、机器学习、IoT、商业智能、数据库和开发运营。 AWS Marketplace 还提供灵活的定价选项和多种部署方法，从而简化了软件的许可和采购。此外, AWS Marketplace 包括 AWS Data Exchange 提供的数据产品。&lt;/p&gt; 
&lt;p&gt;您只需几次单击即可快速启动预配置的软件，并可选择 Amazon 系统映像 (AMI) 和软件即服务 (SaaS) 格式以及其他格式的软件解决方案。此外，您还可以浏览和订阅数据产品。灵活的定价选项包括免费试用、每小时、每月、每年、多年和自带许可 (BYOL) 模式。所有这些定价选项都从一个来源计费。AWS 会处理账单和付款，费用将显示在您的 AWS 账单上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;应用系统或最终用户对于&lt;/strong&gt;&lt;strong&gt;S3对象的访问需求&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由于Amazon S3的灵活性与可靠性，亚马逊云科技的许多客户都使用S3用于对象的存储，Amazon S3可以用于多种用途，比如数据湖的底层存储、备份文件的存储、日志的收集存储等。&lt;/p&gt; 
&lt;p&gt;除此之外，许多应用系统也会使用S3作为底层的存储之一，比如一些在线商城系统或者社交系统，会将图片等静态文件存储在Amazon S3之中，而系统的架构设计可能需要最终访问用户通过联合认证后获得相应的角色权限去访问这些位于Amazon S3中的对象。&lt;/p&gt; 
&lt;p&gt;应用系统在进行全球化的布局过程中，往往需要适用于全球化的客户，这些客户的地理位置较为分散，尤其一些位于偏远或特殊区域的客户，他们可能离应用系统或者Amazon S3所处的区域较远或无法通过亚马逊云科技底层网络到达，这时广域化的互联网会造成较大的延迟和不稳定，这会导致部分用户的体验下降或应用程序无法正常运作。&lt;/p&gt; 
&lt;h2&gt;2.&amp;nbsp;&amp;nbsp; ZGA（Global Accelerator）功能介绍&lt;/h2&gt; 
&lt;p&gt;Zenlayer Global Accelerator为全球用户提高了应用程序的可用性和性能。即时加速用户对应用程序、网站和/或在线平台的访问，包括高动态内容（如实时流媒体和播放器操作）或安全操作（如用户身份验证和支付）。&lt;/p&gt; 
&lt;p&gt;我们的合作伙伴的平台利用180多个边缘位置、专用全球主干网和先进的智能路由技术实现与客户的高速连接，消除延迟和数据包丢失，即使在“最后一英里”也不例。ZGA拥有稳定的高速连接，安全的防护，并采用拥有骨干网络和智能路由技术的全球节点，使用户能够通过接入最近的节点来实现高速连接访问源站，消除跨境跨域访问过程里用户经常遇到的网页加载慢、通讯的延迟以及卡顿。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;联合解决方案优势 ：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;直接通过VBR对接亚马逊云科技源站，中间节点与节点之间全程骨干网络 ，回源更迅速稳定，隐私性+性能双保障。&lt;/li&gt; 
 &lt;li&gt;通过智能解析和全球调度系统为用户选取最优最近的接入方式 。&lt;/li&gt; 
 &lt;li&gt;支持IP/域名加速。支持http，https，WebSocket，WSS，FTP，SSH，TCP/UDP等多种协议。支持自定义端口及支持私有协议。&lt;/li&gt; 
 &lt;li&gt;支持源站负载均衡及实时监控，SSL加密传输，黑白名单及IP ALC等功能保护源站安全。&lt;/li&gt; 
 &lt;li&gt;操作简便，交付敏捷。通过亚马逊云科技Marketplace可以直接试用和购买合作伙伴的产品，加速平台配备了配置界面，只需几分钟就可以将客户接入加速。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3.&amp;nbsp;&amp;nbsp; ZGA优化Amazon S3常用架构&lt;/h2&gt; 
&lt;p&gt;客户在亚马逊云科技的某个Region上使用了S3服务，期望可以覆盖全球各地用户的访问&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; ZGA加速S3常用架构&lt;/p&gt; 
&lt;p&gt;对于可控的用户，固定办公场所可以安装网关就近连接到Zenlayer的边缘POP，获取S3的流量送到全球骨干进行加速。移动用户安装客户端，随时体验S3加速效果。&lt;/p&gt; 
&lt;p&gt;而对于无法安装硬件网关或客户端的用户，可以直接访问由Zenlayer提供的域名(如：www.xxx.com)替代S3原本的域名，通过Zenlayer全球智能DNS解析服务，自动将访问S3的流量牵引至就近POP，再通过全球骨干转发到距离S3源站最近的POP进行转发，实现对S3的加速.&lt;/p&gt; 
&lt;h2&gt;4.&amp;nbsp;&amp;nbsp; ZGA集成Amazon Cloudfront加速全球S3&lt;/h2&gt; 
&lt;p&gt;客户在亚马逊云科技上使用了Amazon S3服务，并在部分节点使用了Amazon CloudFront覆盖当地客户，但当最终用户的某些区域不在CloudFront覆盖范围内，无法让这些用户都快速的访问S3上的内容。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 例如：&lt;/p&gt; 
&lt;p&gt;用户在美国东部署了S3源站，通过CloudFront服务加速东南亚用户，CloudFront东南亚节点选择在新加坡，本地使用者访问质量得到了优化，但东南亚其它地区的使用者通过互联网访问到CloudFront新加坡节点时体验不佳，导致整体访问效果不好。&lt;/p&gt; 
&lt;p&gt;ZGA的方案会提供给用户一个额外的URL地址，客户在域名控制平台使用该地址替换CloudFront的CNAME地址，使用者在访问S3域名时，通过智能DNS的解析，会判断出CloudFront无法覆盖的地址，并将这些流量会返回Zenlayer边缘POP的IP地址，如泰国、菲律宾、印尼等，流量就近接入后再通过全球骨干送到新加坡的CloudFront节点，最终由CloudFront节点经亚马逊云科技转发到美国源站，动态快速的扩充了CloudFront的全球覆盖能力。&lt;/p&gt; 
&lt;h2&gt;5.&amp;nbsp;&amp;nbsp; ZGA加速S3在不同Region的传输&lt;/h2&gt; 
&lt;p&gt;用户在亚马逊云科技的多个Region都是用了Amazon S3的服务，不同Region间的S3需要做数据同步。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; Zenlayer向客户在亚马逊云科技中不同的Region发起DX连接，按照就近选择原则，通过最近的POP打通到客户不同Region的连接；&lt;/p&gt; 
&lt;p&gt;由于S3不属于Private服务，客户需要建立Public VIF并绑定到VGW，建立到Zenlayer骨干网的连接通道；&lt;/p&gt; 
&lt;p&gt;不同的Region通过BGP communities控制BGP宣告的路由信息，只发布本Region的所有public IP，Zenlayer通过DX连接将两个区域的路由同步；&lt;/p&gt; 
&lt;p&gt;使用亚马逊云科技的S3数据同步功能进行数据的复制时，会依据路由规则通过Zenlayer骨干完成传输；&lt;/p&gt; 
&lt;h2&gt;6.&amp;nbsp;&amp;nbsp; 如何通过亚马逊云科技Marketplace来交付ZGA&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;合约产品下单&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;步骤一: 打开 &lt;a href="https://aws.amazon.com/marketplace/pp/B08RNQC2WJ"&gt;https://aws.amazon.com/marketplace/pp/B08RNQC2WJ&lt;/a&gt; 后，点击 “Continue to Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤二: 选择合约期限和续约设置&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤三: 选择您所需要的带宽步骤二: 选择合约期限和续约设置&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤四: 点击“Create Contract” 按钮来创建合约&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤五: 支付此合约&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤六: 点击 “Setup your account“ 按钮设置您的账户，之后将会进入到Zenlayer的Portal网址&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤七: 开始注册Zenlayer账户，可继续遵循用户指导步骤&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;订阅产品下单&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;步骤一: 打开 &lt;a href="https://aws.amazon.com/marketplace/pp/B08S3F2PCF"&gt;https://aws.amazon.com/marketplace/pp/B08S3F2PCF&lt;/a&gt; 后，点击 “Continue to Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤二: 确认按流量收费价格后点击“Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤三: 点击“Setup your account“ 按钮进入到Zenlayer Portal网站设置您的账户步骤二: 确认按流量收费价格后点击“Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤四: 开始注册Zenlayer账户，可继续遵循用户指导步骤&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7.&amp;nbsp;&amp;nbsp; 小结步骤四: 开始注册Zenlayer账户，可继续遵循用户指导步骤&lt;/h2&gt; 
&lt;p&gt;通过本文的介绍，您应该初步了解了如何通过亚马逊云科技以及合作伙伴Zenlayer的联合解决方案来加速您的应用以及终端用户对于Amazon S3中对象的访问，以及如果通过亚马逊云科技Marketplace来对合作伙伴的产品进行试用和购买，如果您需要更多的信息，可以参考亚马逊云科技Marketplace官方文档以及合作伙伴官方网站。&lt;/p&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/mingyue.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;张明月&lt;/h3&gt; 
  &lt;p&gt;合作伙伴解决方案架构师&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/liubing.png" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;刘冰&lt;/h3&gt; 
  &lt;p&gt;Zenlayer，产品经理&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用Python语言实现Transcribe Streaming的websocket协议</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-python-language-to-implement-the-websocket-protocol-of-transcribe-streaming/</link>
				<pubDate>Fri, 03 Sep 2021 03:45:21 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon Transcribe]]></category>

		<guid isPermaLink="false">e21e52547928d10b376260b6094480799af5ab25</guid>
				<description>Amazon Transcribe是自动语音识别（ASR）服务，可让开发人员轻松地为其应用程序添加语音转文本功能，Transcribe支持文件和流式Streaming的两种音频输入方式，Transcribe Streaming可以应用在会议记录，语音控制交互，语言实时翻译等场景，Streaming方式支持HTTP/2和WebSocket两种协议。本文介绍使用Python语言实现Transcribe Streaming的WebSocket协议。</description>
								<content:encoded>&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;Amazon Transcribe是自动语音识别（ASR）服务，可让开发人员轻松地为其应用程序添加语音转文本功能，Transcribe支持文件和流式Streaming的两种音频输入方式，Transcribe Streaming可以应用在会议记录，语音控制交互，语言实时翻译等场景，Streaming方式支持HTTP/2和WebSocket两种协议。本文介绍使用Python语言实现Transcribe Streaming的WebSocket协议。&lt;/p&gt; 
&lt;h2&gt;Streaming transcription 接口介绍&lt;/h2&gt; 
&lt;p&gt;Streaming transcription 接口可以接收音频流并且实时转换为文字，然后将结果返回客户端，同时返回数据中包含partial值，用来标示句子是否结束。&lt;/p&gt; 
&lt;p&gt;Streaming的数据是被编码的，由prelude和data组成。编码格式详见：https://docs.aws.amazon.com/transcribe/latest/dg/event-stream.html&lt;/p&gt; 
&lt;h2&gt;Python语言的实现过程和示例&lt;/h2&gt; 
&lt;p&gt;Python示例程序的运行环境是Python 3.7.9版本。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加IAM Policy到你使用到的IAM user&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "transcribestreaming",
            "Effect": "Allow",
            "Action": "transcribe:StartStreamTranscriptionWebSocket",
            "Resource": "*"
        }
    ]
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;安装Python的程序包&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Python示例程序需要安装三个程序包websocket-client，boto3和amazon_transcribe；其中boto3是AWS SDK for Python，amazon_transcribe是Amazon Transcribe Streaming SDK，这两个SDK简化了和Amazon Transcribe Service的集成过程。amazon_transcribe的详细说明见：https://github.com/awslabs/amazon-transcribe-streaming-sdk&lt;/p&gt; 
&lt;p&gt;安装程序包的命令：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;pip3 install boto3
pip3 install amazon_transcribe
pip3 install websocket-client&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;Python程序的import部分：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import hashlib
import hmac
import urllib.parse
from datetime import datetime
import time
import ssl
import json
import websocket
import _thread
from amazon_transcribe.eventstream import EventStreamMessageSerializer
from amazon_transcribe.eventstream import EventStreamBuffer
from boto3.session import Session&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;创建签名URL的函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;URL签名说明详见：&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Python的实现示例：&lt;/p&gt; 
&lt;p&gt;下列代码中主体函数是create_pre_signed_url，它将生成访问Streaming transcription 接口的URL，其中包括必要的参数和签名，它需要传入4个参数:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;参数region代表将要调用的Amazon Web Service Region。可查看Streaming支持的region，详见Docs链接的Amazon Transcribe Streaming部分（&lt;a href="https://docs.aws.amazon.com/general/latest/gr/transcribe.html"&gt;https://docs.aws.amazon.com/general/latest/gr/transcribe.html&lt;/a&gt;）&lt;/li&gt; 
 &lt;li&gt;参数language_code, media_encoding, sample_rate是stream-transcription-websocket接口的参数，定义见https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def sign(key, msg):
    return hmac.new(key, msg.encode("utf-8"), hashlib.sha256).digest()

def getSignatureKey(key, dateStamp, region, serviceName):
    kDate = sign(("AWS4" + key).encode("utf-8"), dateStamp)
    kRegion = sign(kDate, region)
    kService = sign(kRegion, serviceName)
    kSigning = sign(kService, "aws4_request")
    return kSigning

def create_pre_signed_url(region, language_code, media_encoding, sample_rate):
    # 获得access key和secret key
    credentials = Session().get_credentials()
    access_key_id = credentials.access_key
    secret_access_key = credentials.secret_key

    method = "GET"
    service = "transcribe"
    endpoint = "wss://transcribestreaming." + region + ".amazonaws.com:8443"
    host = "transcribestreaming." + region + ".amazonaws.com:8443"
    algorithm = "AWS4-HMAC-SHA256"

    t = datetime.utcnow()
    amz_date =t.strftime('%Y%m%dT%H%M%SZ')
    datestamp =t.strftime('%Y%m%d')

    canonical_uri = "/stream-transcription-websocket"

    canonical_headers = "host:" + host + "\n"
    signed_headers = "host"

    credential_scope = datestamp + "/" + region + "/" + service + "/" + "aws4_request"

    canonical_querystring = "X-Amz-Algorithm=" + algorithm
    canonical_querystring += "&amp;amp;X-Amz-Credential=" + urllib.parse.quote_plus(access_key_id + "/" + credential_scope)
    canonical_querystring += "&amp;amp;X-Amz-Date=" + amz_date
    canonical_querystring += "&amp;amp;X-Amz-Expires=300"
    canonical_querystring += "&amp;amp;X-Amz-SignedHeaders=" + signed_headers
    canonical_querystring += "&amp;amp;language-code="+ language_code +"&amp;amp;media-encoding=" + media_encoding +"&amp;amp;sample-rate=" + sample_rate

    # Zero length string for connecting
    payload_hash = hashlib.sha256(("").encode('utf-8')).hexdigest()

    canonical_request = method + '\n' \
                        + canonical_uri + '\n' \
                        + canonical_querystring + '\n' \
                        + canonical_headers + '\n' \
                        + signed_headers + '\n' \
                        + payload_hash

    string_to_sign = algorithm + "\n" \
                     + amz_date + "\n" \
                     + credential_scope + "\n" \
                     + hashlib.sha256(canonical_request.encode("utf-8")).hexdigest()

    signing_key = getSignatureKey(secret_access_key, datestamp, region, service)

    signature = hmac.new(signing_key, string_to_sign.encode("utf-8"),
                         hashlib.sha256).hexdigest()

    canonical_querystring += "&amp;amp;X-Amz-Signature=" + signature

    request_url = endpoint + canonical_uri + "?" + canonical_querystring

    return request_url
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写main函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面代码中的loop_receiving和send_data函数，作用分别是从Amazon Transcribe Service接收消息，和向Amazon Transcribe Service发送消息。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def main():
    url = create_pre_signed_url("us-east-1", "en-US", "pcm", "16000")
    ws = websocket.create_connection(url, sslopt={"cert_reqs": ssl.CERT_NONE})

    _thread.start_new_thread(loop_receiving, (ws,))
    print("Receiving...")
    send_data(ws)

    while True:
        time.sleep(1)
main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写loop_receiving函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该函数位于main函数上方。它将接收Amazon Transcribe Streaming Service的返回数据，并且打印出来。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def loop_receiving(ws):
    try:
        while True:
            result = ws.recv()

            if result == '':
                continue

            eventStreamBuffer = EventStreamBuffer()

            eventStreamBuffer.add_data(result)
            eventStreamMessage = eventStreamBuffer.next()

            stream_payload = eventStreamMessage.payload

            transcript = json.loads(bytes.decode(stream_payload, "UTF-8"))

            print("response:",transcript)

            results = transcript['Transcript']['Results']
            if len(results)&amp;gt;0:
                for length in range(len(results)):
                    if 'IsPartial' in results[length]:
                        print('IsPartial:', results[length]['IsPartial'])

                    if 'Alternatives' in results[length]:
                        alternatives = results[length]['Alternatives']
                        if len(alternatives)&amp;gt;0:
                            for sublength in range(len(alternatives)):
                                if 'Transcript' in alternatives[sublength]:
                                    print('Transcript:', alternatives[sublength]['Transcript'])


    except Exception as e:
        if 'WebSocketConnectionClosedException' == e.__class__.__name__:
            print("Error: websocket connection is closed")
        else:
            print(f"Exception Name: {e.__class__.__name__}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写send_data函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该函数位于main函数上方。它将发送音频数据到Amazon Transcribe Streaming Service。其中testFile变量是测试音频文件地址，测试音频为pem格式，英语，采样率为16000。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def send_data(ws):

    testFile = "xxx.pem"

    bufferSize = 1024*16

    stream_headers = {
        ":message-type": "event",
        ":event-type": "AudioEvent",
        ":content-type": "application/octet-stream",
    }

    eventstream_serializer = EventStreamMessageSerializer()

    with open(testFile, "rb") as source:
        while True:
            audio_chunk = source.read(bufferSize)
            # 将音频数据进行编码
            event_bytes = eventstream_serializer.serialize(stream_headers, audio_chunk)

            ws.send(event_bytes, opcode = 0x2) # 0 x 2 send binary

            # end with b'' data bytes
            if len(audio_chunk) == 0:
                break&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;在这篇文章中，介绍了如何使用Python语言实现Transcribe Streaming的WebSocket协议，提供了Python的例子供参考，包括签名URL、数据编码、数据流的发送和接收等部分。完整代码见：https://github.com/xuemark/transcribe/blob/master/transcribe_streaming_websocket.py&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/transcribe"&gt;https://aws.amazon.com/transcribe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awslabs/amazon-transcribe-streaming-sdk"&gt;https://github.com/awslabs/amazon-transcribe-streaming-sdk&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/markxue.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;薛召兵&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责帮助客户进行上云架构的设计和咨询。同时致力于AWS容器服务、媒体服务和机器学习服务在国内和全球商业客户的应用和推广，推进企业服务迁移上云进程。有10年以上的软件开发、售前技术支持、系统架构设计等经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>基于 Nitro Enclave 构建安全的可信执行环境</title>
		<link>https://aws.amazon.com/cn/blogs/china/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave/</link>
				<pubDate>Thu, 02 Sep 2021 03:44:40 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Security, Identity, & Compliance]]></category>
		<category><![CDATA[Amazon EC2]]></category>
		<category><![CDATA[AWS Certificate Manager]]></category>
		<category><![CDATA[AWS KMS]]></category>

		<guid isPermaLink="false">fd8724fce745fd981e91ec04870e32556afb194e</guid>
				<description>Nitro Enclave 使用户可以在亚马逊云科技上，简便，安全地运行隔离的可信计算环境，用于处理私钥，PII等敏感数据，支持 Intel，AMD 芯片的计算实例，没有任何额外费用，具备更好的灵活性和成本效益，且与云原生的安全服务 KMS，ACM 直接集成，为用户提供更好的使用体验和安全性保障。</description>
								<content:encoded>&lt;h2&gt;前言&lt;/h2&gt; 
&lt;p&gt;随着移动通信和互联网技术的发展与应用，数据泄漏可能会造成直接的收入损失，并对业务、用户信任和企业声誉产生重大影响，如何在业务更加深入地数字化的同时，在计算环境中确保数据的机密性和完整性，将是企业面临的重大挑战，尤其是在公有云的环境中。&lt;/p&gt; 
&lt;p&gt;可信执行环境（TEE: Trusted Execution Environment）的提出，正是应对这样的需求。 可信执行环境在芯片层面单独划分出来的一个隔离空间，建立与本地操作系统（例如 Android 和 Microsoft Windows）并行运行的隔离执行环境，保证加载到内部的代码和数据在机密性和完整性方面受到保护，保护敏感代码和数据免受来自本地操作系统潜在漏洞的特权攻击。&lt;/p&gt; 
&lt;p&gt;可信执行环境典型的业务场景包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;私钥安全&lt;/strong&gt;： 用户可以在隔离的安全环境中使用和处理私钥，例如加密和签名，同时阻止父实例上的用户、应用程序查看和获取这些密钥。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;敏感数据处理&lt;/strong&gt;： 可以在隔离的安全区域内运行应用程序，将个人身份，信用卡号等 PII 敏感数据进行令牌化。同时加密的数据可以发送到安全区域进行解密并处理。在整个过程中，父 EC2 实例将无法查看或访问敏感数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;业界常见的可信执行环境的技术包括，Intel SGX 和 ARM TrustZone 等，这个隔离的空间，在 Intel SGX 中被称作 Enclave，而在 ARM TrustZone 中则被称为 Secure World。&lt;/p&gt; 
&lt;p&gt;亚马逊云科技作为公有云的技术领导者，也推出了 TEE 解决方案，&lt;a href="https://aws.amazon.com/cn/ec2/nitro/nitro-enclaves/"&gt;Nitro Enclave&lt;/a&gt;，使用 Nitro Hypervisor 技术，在 EC2 实例内部，提供 CPU 和内存隔离的一个计算环境。&lt;/p&gt; 
&lt;p&gt;Nitro Enclave 主要优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;隔离和安全的运行环境: 基于 Nitro Hypervisor 实现的完全隔离的 CPU，内存计算环境，无持久化存储，交互式访问和外部网络&lt;/li&gt; 
 &lt;li&gt;加密证明: Attestation 证明文件允许用户在外部服务中，授权 Enclave 访问权限，和验证 Enclave 中的代码完整性&lt;/li&gt; 
 &lt;li&gt;灵活: 不需要绑定 CPU 厂商，支持 Intel，AMD 芯片，和任何编程语言&lt;/li&gt; 
 &lt;li&gt;成本: Nitro Enclave 运行于 EC2 中，无任何额外费用&lt;/li&gt; 
 &lt;li&gt;云原生安全集成: 与云原生的 KMS，ACM 安全服务直接集成，提供更好的用户体验和安全保障&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;1. Nitro Enclave 介绍&lt;/h2&gt; 
&lt;h3&gt;1.1 Nitro Enclave 基础介绍&lt;/h3&gt; 
&lt;p&gt;Nitro Enclaves 是一项 Amazon EC2 功能，允许您从 Amazon EC2 实例创建隔离的执行环境，称为 enclave。 Enclave 是独立的、强化的且高度受限的虚拟机，基于 Nitro Hypervisor 虚拟化技术，确保父实例无法访问隔离的 vCPU 和 enclave 的内存。Enclave 没有持久存储、交互式访问或外部网络，仅支持与其父实例的安全 Socket 连接。 用户无法通过 SSH 进入 enclave，并且父实例的进程、应用程序或用户（root 或 admin）无法访问 enclave 内的数据和应用程序。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1.2 Attestation 证明文件&lt;/h3&gt; 
&lt;p&gt;在 Nitro Enclave 中运行程序，除了隔离环境带来的私密性之外，还提供额外的安全特性，加密证明(Cryptographic Attestation)。Attestation 是 Enclave 用来证明其身份并与外部服务建立信任的过程，以及保证数据通信的安全。&lt;/p&gt; 
&lt;p&gt;Attestation 的目的是根据在特定 enclave 中运行的代码和配置，证明 enclave 是值得信赖的实体。 Nitro Hypervisor 能够生成包含 enclave 详细信息的证明文档，包括 enclave 签名密钥、enclave 映像的哈希值、父实例 ID 的哈希值以及附加 IAM 角色的 ARN 的哈希值。&lt;/p&gt; 
&lt;p&gt;Enclave Attestation 功能是由 Nitro Hypervisor 中的 Nitro Secure Module (NSM) 组件实现。亚马逊云科技提供了&lt;a href="https://github.com/aws/aws-nitro-enclaves-nsm-api"&gt;一套 helper library&lt;/a&gt;，方便用户在开发 Enclave 程序时，与 NSM 交互， 查询 PCR 和请求 Attestation 证明文件。&lt;/p&gt; 
&lt;p&gt;关于 Nitro Enclave Attestation 生成的详细过程，可参考&lt;a href="https://github.com/aws/aws-nitro-enclaves-nsm-api/blob/main/docs/attestation_process.md"&gt;此文档&lt;/a&gt;。下面是一个 Attestation 证明文件的结构：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;AttestationDocument = {
    module_id: text,               ; issuing Nitro hypervisor module ID
    timestamp: uint .size 8,       ; UTC time when document was created, in
                                   ; milliseconds since UNIX epoch
    digest: digest,                ; the digest function used for calculating the
                                   ; register values
    pcrs: { + index =&amp;gt; pcr },      ; map of all locked PCRs at the moment the
                                   ; attestation document was generated
    certificate: cert,             ; the infrastucture certificate used to sign this
                                   ; document, DER encoded
    cabundle: [* cert],            ; issuing CA bundle for infrastructure certificate
    ? public_key: user_data,       ; an optional DER-encoded key the attestation
                                   ; consumer can use to encrypt data with
    ? user_data: user_data,        ; additional signed user data, defined by protocol
    ? nonce: user_data,            ; an optional cryptographic nonce provided by the
                                   ; aattestation consumer as a proof of authenticity
}

cert = bytes .size (1..1024)       ; DER encoded certificate
user_data = bytes .size (0..1024)
pcr = bytes .size (32/48/64)       ; PCR content
index = 0..31
digest = "SHA384"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在 Attestation 证明文件中，包含了一个 Public Key，当 Enclave 程序向外部服务发起请求时，带上证明文件，外部应用可以利用该 Public Key，对需要返回 Enclave 的 Response 进行加密， Enclave 收到该 Response 后使用 Private Key 进行解密，确保数据在传输过程中不会被嗅探，且只有发起服务请求的 Enclave 才能解密该 Response。&lt;/p&gt; 
&lt;p&gt;另外，Attestation 文件中还包括每个 Enclave 一系列属性的哈希值，被称为 PCR (Platform Configuration Registers) 。用户可以使用 PCR 的哈希值在外部服务中创建访问策略，以授予对服务请求的访问权限。 Enclave 有 6 个 PCR，分别对应 Enclave 不同的元数据，其中 PCR 0，1，2 与 Enclave 镜像文件相关，在 Enclave 创建时生成。&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PCR&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hash of&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR0&lt;/td&gt; 
   &lt;td&gt;Enclave image file&lt;/td&gt; 
   &lt;td&gt;A contiguous measure of the contents of the image file, without the section data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR1&lt;/td&gt; 
   &lt;td&gt;Linux kernel and bootstrap&lt;/td&gt; 
   &lt;td&gt;A contiguous measurement of the kernel and boot ramfs data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR2&lt;/td&gt; 
   &lt;td&gt;Application&lt;/td&gt; 
   &lt;td&gt;A contiguous, in-order measurement of the user applications, without the boot ramfs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR3&lt;/td&gt; 
   &lt;td&gt;IAM role assigned to the parent instance&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the parent instance has the correct IAM role.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR4&lt;/td&gt; 
   &lt;td&gt;Instance ID of the parent instance&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the parent instance has a specific instance ID.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR8&lt;/td&gt; 
   &lt;td&gt;Enclave image file signing certificate&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the enclave was booted from an enclave image file signed by a specific certificate.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Attestation 证明文件生成后，还将会由受信任Nitro Hypervisor Attestation Public Key Infrastructure (PKI) ，基于一个 ACM PCA 的根证书进行签署，有效期为 30 年。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CN=aws.nitro-enclaves, C=US, O=Amazon, OU=AWS&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;用户可以下载该&lt;a href="https://aws-nitro-enclaves.amazonaws.com/AWS_NitroEnclaves_Root-G1.zip"&gt;根证书&lt;/a&gt;，导入到您的任何外部服务中，当 Enclave 中运行的程序需要请求外部服务时，可向 Nitro Hypervisor 申请并签署证明文件，外部服务通过导入的根证书，来验证 Enclave 证明文件的有效性，确保服务请求是来自于特定的 Enclave，从而建立信任。&lt;/p&gt; 
&lt;p&gt;目前 Amazon Key Management Service (KMS) 和 Amazon Certificate Manager (ACM) 支持与 Nitro Enclave 以及 Attestation 原生集成，Enclave 可借助 vsock 以及父实例上的代理，向 KMS 或 ACM 发起 API 请求，进行加密，解密，和证书申请，更新等操作，同时 KMS 和 ACM 支持对 Enclave 签名的证明文件进行验证，并可将 API Response 用证明文件中的 Public Key 进行加密，确保数据隐私安全。&lt;/p&gt; 
&lt;p&gt;适用于 Nitro Enclaves 的 ACM 允许您将公有和私有 SSL/TLS 证书与在带有 Nitro Enclaves 的 EC2 实例上运行的 Web 应用一起使用。 亚马逊云科技提供了一个打包好的 ACM for Nitro Enclaves 程序，作为服务(aws-nitro-enclaves-acm) 运行在父实例 Linux 操作系统中，该服务将自动创建和运行 Enclave，与 ACM 交互创建安全私钥，将证书及其私钥分发到 enclave，并管理证书续订，证书的私钥在 enclave 中保持隔离，防止父实例及其用户访问它。 具体部署过程可参照&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html"&gt;官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;目前，ACM for Nitro Enclaves 支持与运行在 Amazon EC2 实例上的 NGINX 配合使用，以安装证书并无缝替换过期证书，以提供 HTTPS 服务，未来将添加对其他 Web 服务（Apache HTTP）的支持。&lt;/p&gt; 
&lt;h3&gt;1.3 Nitro Enclave Attestation 与 KMS 集成&lt;/h3&gt; 
&lt;p&gt;Amazon KMS 是一项云原生的密钥管理服务，用来创建和管理密钥，支持使用密钥进行 Server-side 的加密，解密，签名，验证等操作，还支持生成用于 client-side 加密的密钥。 KMS 内置原生支持 Nitro Enclaves，能够验证来自 Enclave 请求中携带的 Attestation 证明文件，并可以根据证明文件中的 PCR 值，定义密钥策略，来授予对特定 Enclave 的访问权限。&lt;/p&gt; 
&lt;p&gt;可以在 KMS Policy 中定义的 Condition Key ，对来自 Enclave 发起的以下三个 API 请求，进行 Attestation 验证和 API 请求授权，例如只允许来自指定 Enclave 的 KMS Decrypt API 请求。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;kms:GenerateRandom： 生成随机字符串&lt;/li&gt; 
 &lt;li&gt;kms:GenerateDataKey： 生成 Data Key，用于 Client-Side 加密&lt;/li&gt; 
 &lt;li&gt;kms:Decrypt： 对文本或 Data Key 进行解密&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  "Version": "2012-10-17",
  "Statement": [{
    "Sid" : "Enable enclave data processing",
    "Effect" : "Allow",
    "Principal" : {
      "AWS" : "arn:aws:iam::123456789012:role/data-processing"
    },
    "Action": [
      "kms:Decrypt",
      "kms:GenerateDataKey",
      "kms:GenerateRandom"
    ],
    "Resource": "*",
    "Condition": {
      "StringEqualsIgnoreCase": {
        "kms:RecipientAttestation:ImageSha384":"EXAMPLE8abcdef7abcdef6abcdef5abcdef4abcdef3abcdef2abcdef1abcdef1abcdef0abcdef1abcdEXAMPLE",
        "kms:RecipientAttestation:PCR0":"EXAMPLEbc2ecbb68ed99a13d7122abfc0666b926a79d5379bc58b9445c84217f59cfdd36c08b2c79552928702EXAMPLE",
        "kms:RecipientAttestation:PCR1":"EXAMPLE050abf6b993c915505f3220e2d82b51aff830ad14cbecc2eec1bf0b4ae749d311c663f464cde9f718aEXAMPLE", 
        "kms:RecipientAttestation:PCR2":"EXAMPLEc300289e872e6ac4d19b0b5ac4a9b020c98295643ff3978610750ce6a86f7edff24e3c0a4a445f2ff8EXAMPLE"
      }
    }
  }]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;注意： 目前使用 KMS SDK 和 CLI 请求 KMS 时，还不支持添加 attestation 证明文件，所以在 Enclave 中向 KMS 发起以上三个 API 请求时，只能用过 HTTP POST 的方式构建 API 请求，将 attestation 加入到 request parameter 中。同时，KMS将自动使用证明文件中的 Public Key 对 API Response 中的明文进行加密，Enclave 收到 Response 后，需要使用 Private Key 进行解密&lt;/p&gt; 
&lt;p&gt;例如: 在 KMS Decrypt API Request 中，新增的Recipient字段将包括AttestationDocument证明文件，同时在 API Response 中，原本的Plaintext字段将替换为加密的CiphertextForRecipient字段，明文字段默认被 KMS 使用证明文件中的 Public Key 进行加密。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;# KMS Decrypt Request (New Recipient parameter)
{
   "CiphertextBlob": blob,
   "EncryptionAlgorithm": "string",
   "EncryptionContext": { 
      "string" : "string" 
   },
   "GrantTokens": [ "string" ],
   "Recipient": { 
      "AttestationDocument": blob,
      "KeyEncryptionAlgorithm": "string"
   }
}

# KMS Decrypt Response (CiphertextForRecipient returned instead of Plaintext)
{
   "CiphertextForRecipient": blob,
   "EncryptionAlgorithm": "string",
   "KeyId": "string",
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过 Nitro Enclave 与 KMS Attestation 的集成，可以确保敏感数据只能在 Enclave 中进行处理，不会被泄漏，嗅探和篡改。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;明文数据只在 Enclave 中可见，隔离的运行环境可确保数据不会嗅探&lt;/li&gt; 
 &lt;li&gt;在 Enclave 外部只能以加密后的形态对数据进行传输和存储，确保原始数据不会被泄漏&lt;/li&gt; 
 &lt;li&gt;同时借助 Enclave 的 Attestation，确保 Enclave 中的代码不会被篡改&lt;/li&gt; 
 &lt;li&gt;通过 KMS 密钥策略，确保数据只能在特定的 Enclave 内部才能被解密&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1.4 管理和开发 Nitro Enclave 应用&lt;/h3&gt; 
&lt;p&gt;如果需要开发一个运行于 Enclave 中的应用，需要先将 Enclave 运行所需的代码，依赖包等打包成 Docker 镜像格式， 然后将 Docker 镜像转换成 Enclave 镜像 (.eif)，以启动 Enclave。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Nitro Enclave 提供一个命令行工具 Nitro-CLI，用来创建，部署和管理Enclave:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-build-enclave.html"&gt;nitro-cli build-enclave&lt;/a&gt;: 将 Docker 镜像转换成 Enclave 镜像 (.eif文件)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli build-enclave --docker-uri repository:tag --docker-dir /path_to/dockerfile_directory --output-file enclave_image_filename --private-key key.pem --signing-certificate certificate.pem&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-run-enclave.html"&gt;nitro-cli run-enclave&lt;/a&gt;: 从 Enclave 镜像文件在 EC2 上启动一个 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;每台&lt;/strong&gt;&lt;strong&gt; EC2 &lt;/strong&gt;&lt;strong&gt;上只支持运行一个&lt;/strong&gt;&lt;strong&gt; enclave &lt;/strong&gt;&lt;strong&gt;环境，且&lt;/strong&gt;&lt;strong&gt; EC2 &lt;/strong&gt;&lt;strong&gt;实例至少具备&lt;/strong&gt;&lt;strong&gt; 4 &lt;/strong&gt;&lt;strong&gt;个&lt;/strong&gt;&lt;strong&gt; CPU&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli run-enclave --cpu-count number_of_vcpus --cpu-ids list_of_vcpu_ids --memory amount_of_memory_in_MiB --eif-path path_to_enclave_image_file [--enclave-cid cid_number] [--debug-mode]&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-describe-enclaves.html"&gt;nitro-cli describe-enclaves&lt;/a&gt;: 查看当前运行的 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli describe-enclaves&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-console.html"&gt;nitro-cli console&lt;/a&gt;: 以只读模式连接到一个运行的 Enclave，获取 Console 输出.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;只有以&lt;/strong&gt;&lt;strong&gt;–debug-mode&lt;/strong&gt;&lt;strong&gt;模式运行的&lt;/strong&gt;&lt;strong&gt; enclave&lt;/strong&gt;&lt;strong&gt;，才允许&lt;/strong&gt;&lt;strong&gt; console &lt;/strong&gt;&lt;strong&gt;连接&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli console --enclave-id enclave_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-terminate-enclave.html"&gt;nitro-cli terminate-enclave&lt;/a&gt;: 关闭指定的 enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli terminate-enclave --enclave-id enclave_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;另外，亚马逊云科技提供一系列工具，方便用户开发 Enclave 应用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://aws.amazon.com/marketplace/pp/B08R69DKQ1"&gt;Nitro Enclaves Developer AMI&lt;/a&gt;: 包含开发 Enclave 应用程序和构建 Enclave 镜像文件所需的工具和组件，以及示例应用&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws/aws-nitro-enclaves-sdk-c"&gt;Nitro Enclaves SDK&lt;/a&gt;: 一组可用于开发 enclave 应用程序的 c 语言开源库，与KMS 集成，并为 attestation 证明和加密操作提供内置支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;2. 搭建一个 Nitro Enclave 示例环境，结合 KMS 实现私钥安全&lt;/h2&gt; 
&lt;p&gt;下面将以一个私钥管理应用场景的示例，使用 Python 代码演示如何在 Nitro Enclave 中处理私钥数据，并结合 KMS 和 Attestation，保证私钥在加密，解密，存储和签名过程中的安全。该示例将包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;创建和部署两个 Enclave，一个实现私钥的生成和加密，另一个实现私钥的解密和签名&lt;/li&gt; 
 &lt;li&gt;Enclave 通过 vsock 与父实例通信&lt;/li&gt; 
 &lt;li&gt;Enclave 通过父实例上运行 KMS Proxy，访问 KMS 服务&lt;/li&gt; 
 &lt;li&gt;Enclave 向 Nitro Hypervisor 请求 Attestation 证明文件&lt;/li&gt; 
 &lt;li&gt;在 Enclave 中向 KMS 发送 API 请求时，带上证明文件&lt;/li&gt; 
 &lt;li&gt;KMS 服务配置密钥策略，将密钥的访问权限仅授予特定的 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;私钥管理应用场景示例架构图和工作流如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;首先创建一个 KMS Key，启动支持 Enclave 的两台 EC2 实例，分别创建和运行 Enclave，vsock 和 KMS Proxy。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;在 Enclave-1 中通过 kms:GenerateRandom API 生成一个 256 位的私钥，利用私钥生成对应的公钥(ecdsa-p256k1)&lt;/li&gt; 
 &lt;li&gt;在 Enclave-1 中通过 kms:GenerateDataKey API 获取加密密钥（包括一个明文 DataKey 和一个KMS加密的 DataKey），使用明文 DataKey 对私钥进行 Client-Side 加密&lt;/li&gt; 
 &lt;li&gt;在 Enclave-1 中，将加密的私钥，加密的 DataKey 和公钥，通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;在 EC2-1 父实例中，将从 vsock 中收到的数据（加密的私钥，加密的 DataKey 和公钥）写入到 DynamoDB 数据库&lt;/li&gt; 
 &lt;li&gt;在 EC2-2 父实例中，从 DynamoDB 中读取一条数据（私钥ID，加密的私钥，加密的 DataKey 和公钥），通过 vsock 将加密的私钥，加密的 DataKey 和需要被签名的消息，发送给 Enclave-2&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，从vsock接收数据（加密的私钥，加密的 DataKey 和需要被签名的消息），通过 kms:Decrypt API 对加密的 DataKey 进行解密，获取明文 DataKey&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，使用明文 DataKey 对加密的私钥进行解密，并使用私钥，对消息进行签名&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，将签名后的消息通过通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;在 EC2-2 父实例中，对送 vsock 接收到的签名消息，使用公钥进行验证&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2.1 基础环境部署&lt;/h3&gt; 
&lt;h4&gt;2.1.1 启动两台 EC2 实例，安装依赖包&lt;/h4&gt; 
&lt;p&gt;首先创建 EC2 及 Enclave 程序所需的 IAM Role，至少需要具备 DynamoDB 的访问权限。为了简化配置，在 demo 中直接使用了 KMS 和 DynamoDB 托管的 FullAccess 策略。但在生产环境中，不能直接使用托管策略，需要自定义用户策略，进行访问行为和资源级别的精细化授权。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 启动两台 Amazon Linux2 的 m5.xlarge EC2 实例(至少 4 vCPU 的 Nitro 实例类型), 需要手动启用 Enclave (创建 EC2 时默认不启用 enclave )&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建 EC2 实例时，在User Data 中，粘贴以下信息，完成安装 Nitro-CLI ，Docker，以及其他 Enclave 程序所需的依赖包，修改 Enclave 可占用的最大内存，下载 Enclave 示例代码等。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;#!/bin/bash
amazon-linux-extras install aws-nitro-enclaves-cli -y
yum install aws-nitro-enclaves-cli-devel -y
usermod -aG ne ec2-user
systemctl start nitro-enclaves-allocator.service &amp;amp;&amp;amp; systemctl enable nitro-enclaves-allocator.service
amazon-linux-extras install docker -y
usermod -aG docker ec2-user
systemctl start docker &amp;amp;&amp;amp; systemctl enable docker
yum install git -y
pip3 install ecdsa
pip3 install requests
pip3 install boto3
sed -i "s/memory_mib: 512/memory_mib: 3072/g" /etc/nitro_enclaves/allocator.yaml
su ec2-user -c 'cd /home/ec2-user &amp;amp;&amp;amp; git clone https://github.com/hxhwing/Nitro-Enclave-Demo.git'
shutdown -r now
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;EC2 启动完成后，修改实例名称用于标记：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一台 EC2: NitroEnclaveDemo-1，用于生成，加密私钥，存储到 DynamoDB&lt;/li&gt; 
 &lt;li&gt;第二台 EC2: NitroEnclaveDemo-2，用于解密私钥，签名和验证消息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.1.2 创建 KMS Key&lt;/h4&gt; 
&lt;p&gt;在 Amazon KMS 服务中创建一个对称密钥，用于在 Enclave 中调用 KMS API，进行私钥的生成和加解密。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步： 选择对称密钥&lt;/li&gt; 
 &lt;li&gt;第二步： 为 Key 添加别名NitroEnclaveDemo&lt;/li&gt; 
 &lt;li&gt;第三步： 选择 Key 的管理员用户（只有 Key 管理员可以删除或修改 Key 的权限）&lt;/li&gt; 
 &lt;li&gt;第四步： 密钥使用权限，不选择任何用户或角色&lt;/li&gt; 
 &lt;li&gt;第五步： 修改自动生成的 Key Policy，在 Statements 中添加以下策略，为前面步骤创建的 EC2 Role 分配 “kms:Decrypt”,”kms:GenerateDataKey”,”kms:GenerateRandom” 权限，暂不配置策略条件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;       {
           "Sid": "Allow NitroEnclave-Demo Role",
           "Effect": "Allow",
           "Principal": {
               "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"  # Replace account ID
           },
           "Action": [
               "kms:GenerateRandom",
               "kms:GenerateDataKey",
               "kms:Decrypt"
               ],
           "Resource": "*"
       },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.1.3 创建 DynamoDB Table&lt;/h4&gt; 
&lt;p&gt;创建一个 DynamoDB Table，用于存放加密后的私钥，加密的 DataKey 和公钥。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Table Name:&amp;nbsp;UserToken&lt;/li&gt; 
 &lt;li&gt;Partition key:&amp;nbsp;userid (String)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;DynamoDB Table Name &lt;/strong&gt;&lt;strong&gt;和&lt;/strong&gt;&lt;strong&gt; Partition key &lt;/strong&gt;&lt;strong&gt;请与上面完全一致，如果需要修改，请同时相应修改示例程序中&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;client.py&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;的&lt;/strong&gt;&lt;strong&gt; DynamoDB &lt;/strong&gt;&lt;strong&gt;相关代码。&lt;/strong&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2.2 创建Enclave，运行示例代码&lt;/h3&gt; 
&lt;p&gt;示例代码&amp;nbsp;Nitro-Enclave-Demo&amp;nbsp;已经被自动下载到 ec2-user 用户目录下，示例代码包含两个目录&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GenerateToken: 运行在第一台 EC2 ，用于生成和加密私钥的 Enclave&lt;/li&gt; 
 &lt;li&gt;SignVerify: 运行在第二台 EC2，用于解密私钥，签名和验证消息的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 ~]$ cd Nitro-Enclave-Demo/
[ec2-user@ip-172-31-33-19 Nitro-Enclave-Demo]$ ls -l
total 4
drwxr-xr-x 2 ec2-user ec2-user  206 Aug 28 16:12 GenerateToken
drwxr-xr-x 2 ec2-user ec2-user   87 Aug 28 16:12 pics
-rw-r--r-- 1 ec2-user ec2-user 3094 Aug 28 16:12 README.md
drwxr-xr-x 2 ec2-user ec2-user  189 Aug 28 16:12 SignVerify
drwxr-xr-x 4 ec2-user ec2-user   51 Aug 28 16:12 src
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h4&gt;2.2.1 创建和运行第一个 Enclave，生成和加密私钥&lt;/h4&gt; 
&lt;p&gt;首先登录到第一台 EC2，进入 /home/ec2-user/Nitro-Enclave-Demo/GenerateToken/ 目录，主要包括以下几个文件&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;main.py: 运行在 Enclave 中的主程序文件，包括：从 KMS 生成私钥，从 KMS 获取 DataKey，加密私钥，将加密后的数据通过vsock发给父实例&lt;/li&gt; 
 &lt;li&gt;traffic-fowarder.py: 运行在 Enclave 中，用于将 Enclave 访问 KMS 的请求通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;kms.py: 用于获取 Attestation 签名，访问 KMS API，以及解密 KMS API Response&lt;/li&gt; 
 &lt;li&gt;client.py: 运行在父实例中的程序文件，包括：从 Enclave 接收加密后的数据，将数据写入到 DynamoDB&lt;/li&gt; 
 &lt;li&gt;Dockerfile: Docker 镜像文件，&lt;a href="http://main.py/"&gt;main.py&lt;/a&gt;和&amp;nbsp;&lt;a href="http://traffic-fowarer.py/"&gt;traffic-fowarer.py&lt;/a&gt;&amp;nbsp;都将被打包进容器镜像&lt;/li&gt; 
 &lt;li&gt;build.sh: 创建 Docker 镜像，将 Docker 镜像转换为 Enclave 镜像，并运行 Enclave 的自动化脚本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;运行build.sh，创建 Enclave 镜像，并以debug-mode 运行 Enclave。其中创建 Enclave 镜像完成后，将自动生成该 Enclave 的 PCR 0/1/2，保存到 EnclaveImage.log 的文件中.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 GenerateToken]$ chmod +x build.sh
[ec2-user@ip-172-31-33-19 GenerateToken]$ ./build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;build 脚本运行完成后， Enclave 将以 debug 模式运行，用户可通过 nitro-cli 连接到运行的 Enclave 控制台，查看 Enclave 运行过程输出到Console的日志，主要用于排错&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli console --enclave-id $(nitro-cli describe-enclaves | jq -r ".[0].EnclaveID")&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p style="padding-left: 40px"&gt;2. 运行 client.py 代码，运行方式如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-python"&gt;python3 client.py &amp;lt;KMS Key-id&amp;gt; &amp;lt;UserID&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;其中 “KMS Key-id” 为前面步骤中创建的别名为 NitroEnclaveDemo 的 KMS Key， “UserID” 用于标示即将生成的私钥属于哪个用户。&lt;/p&gt; 
&lt;p&gt;运行&amp;nbsp;client.py&amp;nbsp;代码后，将自动返回从 Enclave 中接收到的数据，并将数据写入到 DynamoDB Table，数据字段包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;userid: 用于标示私钥属于哪个用户&lt;/li&gt; 
 &lt;li&gt;encrypted_privatekey: 在 Enclave 中，被 KMS DataKey 加密后的私钥&lt;/li&gt; 
 &lt;li&gt;publickey: 在 Enclave 中，由私钥生成的公钥&lt;/li&gt; 
 &lt;li&gt;encrypted_datakey: KMS 加密后的 DataKey，将用于解密私钥&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 GenerateToken]$ python3 client.py alias/NitroEnclaveDemo u001
 {"userid": "u001", "encrypted_privatekey": "4xiMsmD1VMw1I48HMApw4LzDSWT9lz/x74dMNCz1427hz98t0JzyrFzDd68vrKl0wKB1a/LoLyhi\nvJSgQwSfCA==\n", "publickey": "0a0756e60e112d11f0d5e4a88858251f1234e27ea37261da4698d497baa6a52bbe9a3d227534866351086d7220548a4ff00fb081c9b318361cac5dae9c661f8c", "encrypted_datakey": "AQIBAHhVM1N8G00xz9DVe3FbnRAxaxNCkCaRYV6/wLYxbwj04QFUWvIkLZ6TYPE2GTUdKvMbAAAAdjB0BgkqhkiG9w0BBwagZzBlAgEAMGAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMMhfwZjlaOr8pCQneAgEQgDNMimKpywvNdcpJIgPZUYrhE5uQvzonU5o/uYhPMmZmb/kWotQNH6KSFxuTBdx6FeM0vQs="} Write User Token to DynamoDB Successfully [ec2-user@ip-172-31-33-19 GenerateToken]$&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h4&gt;2.2.2 创建和运行第二个 Enclave，解密私钥，签名和验证消息&lt;/h4&gt; 
&lt;p&gt;登录到第二台 EC2，进入 /home/ec2-user/Nitro-Enclave-Demo/SignVerify 目录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;main.py: 运行在 Enclave 中的主程序文件，包括：从 KMS 解密 DataKey，用 DataKey 解密私钥，用私钥签名消息，将签名后的消息通过vsock发给父实例&lt;/li&gt; 
 &lt;li&gt;client.py: 运行在父实例中的程序文件，包括：从 DynamoDB 中读取数据，发送到 Enclave，然后从 Enclave 接收被私钥签名后的消息，并使用公钥验证签名消息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;运行build.sh，创建 Enclave 镜像，并以debug-mode 运行 Enclave。其中创建 Enclave 镜像完成后，将自动生成该 Enclave 的 PCR 0/1/2，保存到 EnclaveImage.log 的文件中.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-36-174 SignVerify]$ chmod +x build.sh
[ec2-user@ip-172-31-36-174 SignVerify]$ ./build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;运行client.py代码，运行格式如下：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;python3 client.py &amp;lt;UserID&amp;gt; &amp;lt;Message to be Signed&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其中 “UserID” 代表从 DynamoDB 中读取哪个用户的密钥数据，“Message to be Signed” 代表将被发送到 Enclave 中被私钥签名的消息。&lt;/p&gt; 
&lt;p&gt;运行&amp;nbsp;client.py&amp;nbsp;代码后，将自动返回从 Enclave 中接收到的数据，数据字段包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Signed Message: Enclave 中被私钥签名后的消息&lt;/li&gt; 
 &lt;li&gt;Signed message verified by public key: True/False，表示签名的消息是否可以被公钥验证，确保私钥和公钥没有被修改&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-36-174 SignVerify]$ python3 client.py u001 'Hellow World'
Signed Message: 6053cfc42883d03888ba175950e463c1d8164cab8b4873b85af8531a0c6f86b8ad07012107e3322d30118ea24976f8c8f70014119159101ecc1797e7a9f72915
Signed message verified by public key: True
[ec2-user@ip-172-31-36-174 SignVerify]$
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;2.3 配置 KMS 密钥策略，根据 Attestation PCR 授权&lt;/h3&gt; 
&lt;p&gt;当以&amp;nbsp;debug-mode&amp;nbsp;运行 Enclave 时，Attestation 证明文件中的 PCR 为全 0，无法用来在外部服务上作为策略条件，进行权限控制。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli run-enclave ...... --debug-mode&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;运行 nitro-cli run-enclave 时，不加–debug-mode, 是以正常模式运行 Enclave，Attestation 证明文件中才会包含 Enclave 正常的 PCR。&lt;/p&gt; 
&lt;p&gt;首先在 KMS 密钥策略，添加相应的 Condition Key 限制 Attestation PCR ，其中&amp;nbsp;kms:RecipientAttestation:ImageSha384&amp;nbsp;与 PCR 0 为相同的值，每个 Enclave 的 PCR 0/1/2，可以在 Build Enclave 镜像的时候获取，本示例是写到所在代码目录下 EnclaveImage.log 文件中。&lt;/p&gt; 
&lt;p&gt;在 KMS NitroEnclaveDemo 这个 Key 的密钥策略中，添加以下两条 Deny 权限策略语句，到 KMS Key Policy 的 Statement 字段中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一段策略，授权只有来自 Enclave-1，且携带 Attestation 证明文件才能访问 kms:GenerateDataKey API，注意请替换为您自己的 PCR 0/1/2 Value&lt;/li&gt; 
 &lt;li&gt;第二段策略，授权只有来自 Enclave-2 ，且携带 Attestation 证明文件才能访问 kms:Decrypt API，注意请替换为您自己的 PCR 0/1/2 Value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;        {
            "Sid": "Only Allow NitroEnclaveDemo-1",
            "Effect": "Deny",
            "Principal": {
                "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"
            },
            "Action": [
                "kms:GenerateRandom",
                "kms:GenerateDataKey"
            ],
            "Resource": "*",
            "Condition": {
              "StringNotEqualsIgnoreCase": {
                "kms:RecipientAttestation:ImageSha384":"17b041934b2255ae55b07433012e4d41999feda85eb839970645458a35f8571360f32ca68b5178dca8bdecf9fd37c010",
                "kms:RecipientAttestation:PCR0":"17b041934b2255ae55b07433012e4d41999feda85eb839970645458a35f8571360f32ca68b5178dca8bdecf9fd37c010",
                "kms:RecipientAttestation:PCR1":"c35e620586e91ed40ca5ce360eedf77ba673719135951e293121cb3931220b00f87b5a15e94e25c01fecd08fc9139342", 
                "kms:RecipientAttestation:PCR2":"1fc61c8c21fb3ec93ae854341f5b9adc1e7bbc2eb437cc308e5fb2f4787393fe500fa4c894422a92d79eb3ce172c1a8e"
              }
            }
        },
        {
            "Sid": "Only Allow NitroEnclaveDemo-2",
            "Effect": "Deny",
            "Principal": {
                "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"
            },
            "Action": [
                "kms:Decrypt"
            ],
            "Resource": "*",
            "Condition": {
              "StringNotEqualsIgnoreCase": {
                "kms:RecipientAttestation:ImageSha384":"810257e9bd2ecad2181fcff508c7547ef0f3c1d446628f5465c955c4f2a2d3cfac9198919999614ffbed8e0b18c6c084",
                "kms:RecipientAttestation:PCR0":"810257e9bd2ecad2181fcff508c7547ef0f3c1d446628f5465c955c4f2a2d3cfac9198919999614ffbed8e0b18c6c084",
                "kms:RecipientAttestation:PCR1":"c35e620586e91ed40ca5ce360eedf77ba673719135951e293121cb3931220b00f87b5a15e94e25c01fecd08fc9139342", 
                "kms:RecipientAttestation:PCR2":"72457ef34f66f041996e7077f55604f0f73b1d2e3fad54881308d38da6d22bc8cd2084ab3b8810b22da629a24eef94e6"
              }
            }
        },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 在 EC2 上测试直接用 CLI 访问 KMS，提示请求被拒绝，确认密钥策略权限已生效&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;
[ec2-user@ip-172-31-33-19 ~]$ aws kms generate-data-key --key-id alias/NitroEnclaveDemo --number-of-bytes 32 --region ap-northeast-1

An error occurred (AccessDeniedException) when calling the GenerateDataKey operation: User: arn:aws:sts::xxxxxxxxxx:assumed-role/NitroEnclave-Demo/i-0e4fc2c648b901c7e is not authorized to perform: kms:GenerateDataKey on resource: arn:aws:kms:ap-northeast-1:xxxxxxxxxx:key/6390f2e0-86d6-46cb-8478-37dcfa6aa2dc with an explicit deny
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;分别在两台 EC2 上执行以下命令，终止前面步骤启动的 Enclave&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli terminate-enclave --enclave-id $(nitro-cli describe-enclaves | jq -r ".[0].EnclaveID")&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;然后在两台 EC2 上重新启动 Enclave，不添加 –debug-mode 参数&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;## NitroEnclaveDemo-1
[ec2-user@ip-172-31-33-19 GenerateToken]$ nitro-cli run-enclave --cpu-count 2 --memory 2900 --enclave-cid 10 --eif-path GenerateToken-demo.eif
Start allocating memory...
Started enclave with enclave-cid: 10, memory: 3072 MiB, cpu-ids: [1, 3]
{
  "EnclaveID": "i-0e4fc2c648b901c7e-enc17b908ba803d724",
  "ProcessID": 7565,
  "EnclaveCID": 10,
  "NumberOfCPUs": 2,
  "CPUIDs": [
    1,
    3
  ],
  "MemoryMiB": 3072
}


## NitroEnclaveDemo-2
[ec2-user@ip-172-31-36-174 SignVerify]$ nitro-cli run-enclave --cpu-count 2 --memory 2900 --enclave-cid 10 --eif-path SignVerify-demo.eif
Start allocating memory...
Started enclave with enclave-cid: 10, memory: 3072 MiB, cpu-ids: [1, 3]
{
  "EnclaveID": "i-0558cbee6ea7a393c-enc17b908f0730bcb2",
  "ProcessID": 7533,
  "EnclaveCID": 10,
  "NumberOfCPUs": 2,
  "CPUIDs": [
    1,
    3
  ],
  "MemoryMiB": 3072
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;然后分别在两台 EC2 的父实例上，运行client.py，确认代码能正常运行。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;## NitroEnclaveDemo-1
[ec2-user@ip-172-31-33-19 GenerateToken]$ python3 client.py alias/NitroEnclaveDemo u010
{"userid": "u010", "encrypted_privatekey": "h08szIyVaTrjH1TF95+aXooPKC/QZwGRDaZv7Cp/LmFG2FQumbZR49NrnsOYBsS+VxsvPtSlBE2s\nnEYQLMI9lQ==\n", "publickey": "9552c9f2c51be3b7143e3cfe9c71f7dcac028d368530ffbbdb34512092611e4996e9e1bcab27e4a879ff630629d7f930d2db84c295e97334d1f3335d31e7ac87", "encrypted_datakey": "AQIBAHhVM1N8G00xz9DVe3FbnRAxaxNCkCaRYV6/wLYxbwj04QFKhpZ//ap2EgINgILddtu0AAAAdjB0BgkqhkiG9w0BBwagZzBlAgEAMGAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMScLI1DYM6y6hd0d4AgEQgDO2pbbcrEEd+trVcqiqkFdlhXY/ZVEMoRqRsQAUMdJq24zwGgl6UYOjLCviBHs2wI8jC5A="}
Write User Token to DynamoDB Successfully
[ec2-user@ip-172-31-33-19 GenerateToken]$

## NitroEnclaveDemo-2
[ec2-user@ip-172-31-36-174 SignVerify]$ python3 client.py u010 'Hello World'
Signed Message: b27a5c527e218774b316f674eae537ce88b3f986b7f5df583906b1c9a9ba9bb00d2975fe4a065d5a1e74bb6947fe11c8fc90d3ac389be638b2745431de04ebd9
Signed message verified by public key: True
[ec2-user@ip-172-31-36-174 SignVerify]$
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在 CloudTrail 中，查看 KMS API 的请求记录，在来自 Enclave 的请求记录中，将会存在额外的 Attestation 数据。&lt;/p&gt; 
&lt;p&gt;来自第一台 Enclave 请求 kms:GenerateDataKey 的 CloudTrail：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 来自第二台 Enclave 请求 kms:Decrypt 的 CloudTrail：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;Nitro Enclave 使用户可以在 亚马逊云科技上，简便，安全地运行隔离的可信计算环境，用于处理私钥，PII等敏感数据。另外 Nitro Enclave 不需要强制绑定 CPU 芯片，支持 Intel，AMD 芯片的计算实例，没有任何额外费用，具备更好的灵活性和成本效益，且与云原生的安全服务 KMS，ACM 直接集成，为用户提供更好的使用体验和安全性保障。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/hxh.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;胡新华&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责金融行业基于AWS的云计算架构咨询和设计。加入AWS之前就职于IBM，在数据中心IT基础架构相关的解决方案设计和交付方面，具有十多年经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>增强Amazon Athena对历史查询记录的统计分析功能</title>
		<link>https://aws.amazon.com/cn/blogs/china/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records/</link>
				<pubDate>Thu, 02 Sep 2021 03:11:56 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Athena]]></category>

		<guid isPermaLink="false">5d41f51e363379c2c35c97dc1c407cec8f874090</guid>
				<description>Amazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 分析 Amazon S3 中的数据。Athena 采用无服务器架构，因此您无需管理任何基础设施，且只需为您运行的查询付费。Athena 简单易用，只需指向您存储在 Amazon S3 中的数据，定义架构并使用标准 SQL 开始查询。</description>
								<content:encoded>&lt;h2&gt;背景介绍&lt;/h2&gt; 
&lt;p&gt;Amazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 分析 Amazon S3 中的数据。Athena 采用无服务器架构，因此您无需管理任何基础设施，且只需为您运行的查询付费。Athena 简单易用，只需指向您存储在 Amazon S3 中的数据，定义架构并使用标准 SQL 开始查询。就可在数秒内获取最多的结果。您可以使用Athena 控制台查看成功和失败的查询、下载成功查询结果文件以及查看失败查询的错误详细信息。Athena 将查询历史记录保留 45 天。如果要将查询历史记录保留超过 45 天，您可以检索查询历史记录并将其保存到等 Amazon S3 等数据存储中。本方案自动执行此过程，使用 Athena 和 Amazon S3 API将数据导入到Amazon S3，并使用Athena分析历史数据，结合Amazon CloudTrail的Athena API调用日志可以对Athena的历史SQL执行记录进行多个维度的分析，以便用于评估Athena的使用和优化线上SQL等。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;部署架构&lt;/h2&gt; 
&lt;p&gt;利用CloudWatch Event定时触发Lambda代码同步Athena历史查询日志到Amazon S3，利用DynamoDB记录每次增量同步的记录位置，Amazon CloudTrail记录Athena API call日志，创建CloudTrail的跟踪，将日志持续导入到S3中，最终通过Athena多维分析历史查询日志和CloudTrail日志并利用Amazon QuickSight进行图表展现。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;方案部署步骤&lt;/h2&gt; 
&lt;h3&gt;导出Athena查询历史记录日志到Amazon S3&lt;/h3&gt; 
&lt;p&gt;因为Athena历史查询记录日志只保留45天，我们通过一段Python代码将Athena历史查询记录日志持续的，增量的导入到Amazon S3中，利用DynamoDB记录每次导出的最近位置，下次导出的时候，从上次导出的最新位置开始增量导出，避免产生重复数据，我们也可以将这段代码部署在在Lambda上，通过CloudWatch Event定时触发同步日志到Amazon S3。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;创建&lt;/strong&gt;&lt;strong&gt;DynamoDB表，保存每次增量导入的最新位置&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;表名称：athena_his_sql&lt;/p&gt; 
&lt;p&gt;主分区键：workgroup&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;创建&lt;/strong&gt;&lt;strong&gt;Lambda函数athena_his_fun&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;将下面的脚本复制到Lambda的入口脚本lambda_function.py（Lambda函数执行的角色需要具备操作Amazon S3读写，DynamoDB读写的权限）并修改Lambda的内存（500M）和超时时间（10min）。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import boto3
import time
import io
import json
import uuid
from datetime import datetime, date
def lambda_handler(event, context):
    # TODO implement
    to_scrape=5000
    page_size=50
    bucket = "quandata1"
    prefix = "athena_his/"
    s3_client = boto3.client('s3')
    ath = boto3.client('athena')
    paginator = ath.get_paginator("list_query_executions")
    dynamodb = boto3.resource('dynamodb')
    def json_serial(obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        raise TypeError("Type %s not serializable" % type(obj))
    df = []
    break_flag = False
    for workgroup in [w['Name'] for w in ath.list_work_groups()['WorkGroups']]:
        print(f'running {workgroup}')
        i=0
        table = dynamodb.Table('athena_his_sql')
        response = table.get_item(Key={'workgroup': workgroup,})
        curr_query_id = ''
        if  ("Item" in response): curr_query_id = response['Item']['curr_query_id']
        print("get ddb curr_id: " + workgroup + curr_query_id)
        args = {"WorkGroup": workgroup, "PaginationConfig": {"MaxItems": to_scrape, "PageSize": page_size}}
        for page in paginator.paginate(**args):
            query_ids = page['QueryExecutionIds']
            for query_id in query_ids:
                print("query_id:" + query_id)
                if i == 0:
                    table.update_item(
                        Key={'workgroup': workgroup,},
                        UpdateExpression='SET curr_query_id = :val1',
                        ExpressionAttributeValues={':val1': query_id})
                    print("update ddb curr_id: " + query_id)
                if query_id == curr_query_id:
                    break_flag=True
                    break
                query_metadata = ath.get_query_execution(QueryExecutionId=query_id)['QueryExecution']
                df.append(query_metadata)
                i += 1
            if break_flag==True:
                break
            time.sleep(1)
    json_writer = io.BytesIO()
    for record in df:
        line = json.dumps(record, default=json_serial) + "\n"
        json_writer.write(line.encode())
    s3_client.put_object(
        Bucket=bucket,
        Key=prefix + "%s.json" % uuid.uuid4(),
        ContentType='text/json',
        Body=json_writer.getvalue()
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;部署完毕后设置利用CloudWatch Event定时触发执行（例如按小时触发）&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 脚本执行后，会在DynamoDB的表athena_his_sql中更新当前最新的查询ID，方便后续增量导出。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 利用Amazon CLI或者控制台检查Amazon S3路径下是否正确上传了日志文件，（注：本方案没有对上传到S3的数据进行分区存放，可以参考下文CloudTrail日志的方式利用Athena的分区投影功能实现自动分区管理）。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;创建Athena历史记录日志表&lt;/h3&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE EXTERNAL TABLE athena_queries (
    QueryExecutionId string,
    Query string,
    StatementType string,
    Status struct&amp;lt;State:string,SubmissionDateTime:string,CompletionDateTime:string&amp;gt;,
    Statistics struct&amp;lt;EngineExecutionTimeInMillis:int,DataScannedInBytes:int, TotalExecutionTimeInMillis:int, QueryQueueTimeInMillis:int, QueryPlanningTimeInMillis:int, ServiceProcessingTimeInMillis:int&amp;gt;,
    WorkGroup string
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
LOCATION 's3://quandata1/athena_his';
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;创建CloudTrail日志表&lt;/h3&gt; 
&lt;p&gt;开启CloudTrail跟踪，将CloudTrail日志通过跟踪功能持续保存到S3中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建CloudTrail日志表cloudtrail_logs，建表语句中LOCATION根据实际跟踪配置的S3路径填写。使用Athena分区投影功能自动进行分区管理，降低查询时间和数据扫描量。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE EXTERNAL TABLE cloudtrail_logs(
    eventVersion STRING,
    userIdentity STRUCT&amp;lt;
        type: STRING,
        principalId: STRING,
        arn: STRING,
        accountId: STRING,
        invokedBy: STRING,
        accessKeyId: STRING,
        userName: STRING,
        sessionContext: STRUCT&amp;lt;
            attributes: STRUCT&amp;lt;
                mfaAuthenticated: STRING,
                creationDate: STRING&amp;gt;,
            sessionIssuer: STRUCT&amp;lt;
                type: STRING,
                principalId: STRING,
                arn: STRING,
                accountId: STRING,
                userName: STRING&amp;gt;&amp;gt;&amp;gt;,
    eventTime STRING,
    eventSource STRING,
    eventName STRING,
    awsRegion STRING,
    sourceIpAddress STRING,
    userAgent STRING,
    errorCode STRING,
    errorMessage STRING,
    requestParameters STRING,
    responseElements STRING,
    additionalEventData STRING,
    requestId STRING,
    eventId STRING,
    readOnly STRING,
    resources ARRAY&amp;lt;STRUCT&amp;lt;
        arn: STRING,
        accountId: STRING,
        type: STRING&amp;gt;&amp;gt;,
    eventType STRING,
    apiVersion STRING,
    recipientAccountId STRING,
    serviceEventDetails STRING,
    sharedEventID STRING,
    vpcEndpointId STRING
  )
PARTITIONED BY (
   `timestamp` string)
ROW FORMAT SERDE 'com.amazon.emr.hive.serde.CloudTrailSerde'
STORED AS INPUTFORMAT 'com.amazon.emr.cloudtrail.CloudTrailInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  's3://bucket/AWSLogs/account-id/CloudTrail/aws-region'
TBLPROPERTIES (
  'projection.enabled'='true', 
  'projection.timestamp.format'='yyyy/MM/dd', 
  'projection.timestamp.interval'='1', 
  'projection.timestamp.interval.unit'='DAYS', 
  'projection.timestamp.range'='2021/01/01,NOW', 
  'projection.timestamp.type'='date', 
  'storage.location.template'='s3://bucket/AWSLogs/account-id/CloudTrail/aws-region/${timestamp}')
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;使用Athena对数据进行分析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;查看不同&lt;/strong&gt;&lt;strong&gt;SQL语句的执行总次数排名&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select count(*),query from athena_queries group by query order by 1 desc limit 10&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看执行状态失败的&lt;/strong&gt;&lt;strong&gt;SQL总数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select count(*) from athena_queries where status.state='FAILED'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看执行超过特定执行时长的历史&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select query from athena_queries where statistics.totalexecutiontimeinmillis &amp;gt;=5000&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看超过特定数据扫描量的历史&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select query from athena_queries where statistics.datascannedinbytes &amp;gt;=10741612544&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;根据&lt;/strong&gt;&lt;strong&gt;IAM用户统计数据扫描量&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;select sum(b.statistics.datascannedinbytes),
a.userIdentity.username 
from 
cloudtrail_logs a,
athena_queries b 
where 
a.eventsource='athena.amazonaws.com' and a.eventName='StartQueryExecution' and 
a.responseElements != 'null' and substr(a.responseElements,22,36) = b.queryexecutionid 
group by 
a.userIdentity.username
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;使用Amazon Quicksight可视化分析结果&lt;/h2&gt; 
&lt;p&gt;利用SQL的方式（将cloudtrail_logs和athena_queries两张表联表查询）创建QuickSight中Athena数据集，然后根据实际需要在Amazon QuickSight创建可视化图表。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.queryexecutionid,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.query,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statementtype,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.State,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.SubmissionDateTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.CompletionDateTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.EngineExecutionTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.DataScannedInBytes,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.TotalExecutionTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.QueryQueueTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.QueryPlanningTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.ServiceProcessingTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.workgroup,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.userIdentity.username&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;from&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;cloudtrail_logs a,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;athena_queries b&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;where&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.eventsource='athena.amazonaws.com' and a.eventName='StartQueryExecution' and&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.responseElements != 'null' and substr(a.responseElements,22,36) = b.queryexecutionid&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;创建可视化图表如下&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;通过本文介绍的方案可以更长时间的保留Athena查询历史日志，通过对Athena历史查询日志的分析，让我们可以直观的了解和掌握Athena的使用细节，查看Top SQL，检测应用性能问题，在时间、用户、SQL语句等多个维度增强对Athena使用的洞察。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/querying.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/querying.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/monitor-with-cloudtrail.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/monitor-with-cloudtrail.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html"&gt;https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xiangqua.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;柳向全&lt;/h3&gt; 
  &lt;p&gt;AWS 解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，目前主要专注于容器和大数据技术领域研究和AWS云服务在国内和全球的应用和推广。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>云原生编排数据分析管道初探</title>
		<link>https://aws.amazon.com/cn/blogs/china/preliminary-study-on-cloud-native-data-analysis-pipeline-orchestration/</link>
				<pubDate>Tue, 31 Aug 2021 09:38:55 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[AWS Glue]]></category>
		<category><![CDATA[AWS Step Functions]]></category>

		<guid isPermaLink="false">0b70c5edda6b82f38e382a0cee30e9d3989f70d1</guid>
				<description>公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL) 过程进行任务编排。要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施。二是编排好数据管道的 ETL 任务顺序。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。</description>
								<content:encoded>&lt;h2&gt;摘要&lt;/h2&gt; 
&lt;p&gt;公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL) 过程进行任务编排。亚马逊云科技（亚马逊）的 Step Functions 状态机和开源社区的 Airflow 是其中的典型代表。要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施，例如部署好 Airflow 的调度器和执行器等。二是编排好数据管道的 ETL 任务顺序，例如状态机的 JSON 定义文件或者 Airflow 的有向无环图定义。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。&lt;/p&gt; 
&lt;h2&gt;Abstract&lt;/h2&gt; 
&lt;p&gt;Public cloud is one of the most suitable platforms for data analysis and big data processing. In recent years, many excellent workflow orchestration tools have proliferated in cloud services and open source communities to facilitate orchestration of complex ETL jobs in data analysis. AWS Step Functions and Airflow from open source community are two typical examples. To run the data analysis pipelines successfully, at least two steps are necessary. Firstly, to build the infrastructure to support running the data pipelines, such as the deployment of Airflow’s schedulers and executors. Secondly, to orchestrate the ETL tasks in the data pipelines, such as the JSON definition of the state machine or Airflow’s directed acyclic graph definition. The former involves dev-ops, while the latter is related to application. From the perspective of data analysis, it is ideal that the difficulty of dev-ops is minimized, and the user-friendliness of application is maximized. This article analyzes how well Airflow and Step Functions support data analysis pipelines from the above two points of view, and preliminarily discusses the methodology and significance of cloud-native services for orchestrating data pipelines.&lt;/p&gt; 
&lt;h3&gt;目标读者&lt;/h3&gt; 
&lt;p&gt;本文预期读者需要掌握以下技术的基础知识：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache Airflow 及其相关概念&lt;/li&gt; 
 &lt;li&gt;亚马逊开发包：CDK, SDK&lt;/li&gt; 
 &lt;li&gt;亚马逊服务：CloudTrail, EventBridge, Glue, Lambda, MWAA, Redshift, S3, Step Functions, VPC, 密码管理器&lt;/li&gt; 
 &lt;li&gt;语言：Javascript, JSON, Python&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;开放源代码&lt;/h3&gt; 
&lt;p&gt;本文所述解决方案源代码开放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline"&gt;https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;绪论&lt;/h2&gt; 
&lt;p&gt;2020年11月，亚马逊发布了托管的 Airflow 服务，全称为 Managed Workflows for Apache Airflow (MWAA)，支持 1.10.12 版。2021年5月开始支持 2.0.2 版。但截至目前（2021年8月），中国北京区、宁夏区和香港区皆未提供托管服务。如果要使用 Airflow，则需要自行搭建部署，例如利用 Elastic Container Service。或者换成其他云原生的编排服务，例如 Step Functions 状态机或 Simple Workflow Service。本文以某 MWAA 的数据分析指导教程为引子，介绍 MWAA 资源代码化的方法，并对如何在中国区使用云原生服务达到类似编排数据分析管道的目的，进行初探。&lt;/p&gt; 
&lt;h2&gt;教程简介&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;是指导利用 MWAA 搭建数据分析管道的教程。该分析管道较简单，线性分为五步，分别是监控文件，爬元数据，转换数据，整合数据，保存结果。简单起见，本文将第四步改造为 Glue 任务，不使用 Elastic MapReduce 集群。部署好的数据管道有向无环图如下：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.png" width="624"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以 MWAA 为基础的架构图如下所示。虚线和编号表示该数据管道运行时的数据流向和任务执行顺序。此处不同服务的调用是通过 Airflow 的操作符间接完成的，以 Python 定义在数据管道的有向无环图中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.png" width="500"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;根据该教程介绍，完成时间为一小时左右。抛开初学者的因素，所用时间较长主要是因为所涉及的资源及其配置都是在亚马逊控制台上手工完成，非常耗时，效率低下。如果利用资源代码化技术，则部署时间可以在数分钟内完成（排除 MWAA 自身启动需要的约半小时），提高工作效率，尤其在需要多环境部署测试的情况下。&lt;/p&gt; 
&lt;h3&gt;资源代码化&lt;/h3&gt; 
&lt;p&gt;利用亚马逊云开发包 (Cloud Development Kit)，可快速构建云资源部署程序。结合相关代码仓库管理工具如 github，可代码化管理资源的创建和修改过程，方便协同工作和排错溯源。限于篇幅以下仅展示关键代码。完整代码请参阅开放源代码。首先建立 Redshift 集群。云开发包建立好集群后，会自动在密码管理器中新建一密码项，即为该集群的连接密码，全程密码无暴露。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCluster(landingZone, subnetGroup) {
    return new redshift.Cluster(this, "MainCluster", {
        masterUser: { masterUsername: "admin" },
        vpc: landingZone.vpc,
        numberOfNodes: 2,
        publiclyAccessible: false,
        defaultDatabaseName: RedshiftStack.DB_NAME,
        securityGroups: [landingZone.securityGroup],
        nodeType: redshift.NodeType.DC2_LARGE,
        roles: [this.role],
        subnetGroup: subnetGroup
    })
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其次是建立 MWAA 环境。简化起见配置为可以公网访问。实际生产中建议配置为私网访问。MWAA 对网络配置有特别要求，若不达标环境可能无法启动。子网建议配置为私有子网，即有路由到 NAT 网关。具体请参阅使用手册。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createEnvironment(envName, role, landingZone, bucket) {
    return new airflow.CfnEnvironment(this, "Lab", {
        name: envName,
        airflowVersion: "2.0.2",
        environmentClass: "mw1.small",
        executionRoleArn: role.roleArn,
        sourceBucketArn: bucket.bucketArn,
        webserverAccessMode: "PUBLIC_ONLY",
        dagS3Path:           "airflow/lab/dags",
        pluginsS3Path:       "airflow/lab/plugins/awsairflowlib_202.zip",
        requirementsS3Path:  "airflow/lab/requirements/requirements.txt",
        networkConfiguration: {
            securityGroupIds: [landingZone.securityGroup.securityGroupId],
            subnetIds: landingZone.vpc.privateSubnets.map(subnet =&amp;gt; subnet.subnetId)
        }
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;MWAA 配置好以后，还需要把有向无环图定义文件上传到存储桶指定位置。利用云开发包的 S3 部署模块完成：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;uploadDagFile(bucket) {
    new deploy.BucketDeployment(this, "DagScript",
        sources: [deploy.Source.asset(path.join(__dirname, '../../scripts/airflow/lab/dags/'))],
        destinationBucket: bucket,
        destinationKeyPrefix: 'airflow/lab/dags/'
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;至此就完成了 MWAA 相关资源的部署程序。部署上述 MWAA 大约耗时半小时，因为涉及服务器的启动连接等。部署耗时长也凸显出非无服务器服务的弊端。当环境状态变为“可用”后，点击“打开 Airflow UI”即可打开 Airflow 的控制台。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.png" width="800"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;部署完成后，根据教程即可完成数据分析管道相关操作。Airflow 控制台可以显示数据管道完成时间甘特图，形象展示各任务耗时多寡。这是其亮点之一。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.png" width="800"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;安全隐患&lt;/h3&gt; 
&lt;p&gt;最后一步把存储桶文件复制到 Redshift，需要在 Airflow 控制台配置到 Redshift 的连接。连接属性包含用户名和密码明文。此处有暴露密码明文的安全隐患。下面介绍的云原生技术通过密码管理器实现无缝连接，可有效规避密码暴露风险，切实提高系统安全水平。&lt;/p&gt; 
&lt;h2&gt;云原生编排&lt;/h2&gt; 
&lt;p&gt;目前 MWAA 尚不支持中国区，故需要自行搭建并维护 Airflow 环境，例如在 ECS Fargate 上。但是运维难度不容小觑。亚马逊提供了其他编排服务，例如状态机，完全可以代替 Airflow 对数据管道进行编排。此外状态机是无服务器的，毋需关心并事先设定服务器数量性能等运维难题。使用云原生服务，和其他服务紧密集成，可最大化服务效益，增强安全性。和教程数据分析管道等价的状态机工作流如下所示。状态机跨服务集成支持直接启动 Glue 任务，较为简单。其他步骤需做些许变通。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.png" width="400"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以云原生服务为基础的架构图如下所示。状态机在各服务之间调度，其中 Glue 任务可以直接执行。爬虫任务需要通过 Lambda 函数辅助。把存储桶的数据载入到 Redshift 可以有多种方法完成，例如 Glue 任务可以直接连接 Redshift 并保存数据。为了和教程中的步骤一一对应，此处利用 Lambda 函数来辅助完成。存储桶文件监控则通过跟踪与规则联合完成。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.png" width="500"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;爬元数据&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成目前暂不支持调用 Glue 爬虫，需替代方案。此处利用两个 Lambda 函数和轮询机制实现相同功能。启动爬虫很简单：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;await glue.startCrawler({Name: crawlerName}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫状态查询，如果不是“就绪”状态，则等待十秒后再次查询，直至成功或者超时。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;exports.handler = async event =&amp;gt; {
    response = await glue.getCrawler({Name: event.crawlerName}).promise();
    const state = response.Crawler.State;
    return state == "READY";
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫调用代替方案的其他两步可以利用状态机的“选择”和“等待”原生操作符完成。这里传入变量 next 作为爬虫轮询结束后的下一步操作。以下代码可作为爬虫调用的模版使用。若想提高响应速度可缩短等待时长。一个典型的爬虫任务需时数分钟。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCrawlerStep(next) {
    const crawlTask = new task.LambdaInvoke(this, "Crawl", {
        lambdaFunction: this.lambda("CrawlLambda", role, "../lambda/crawler/crawl"),
        payload: sf.TaskInput.fromObject({CrawlerTagName: "NF1-Airflow-Lab-RawGreenCrawler"}),
        payloadResponseOnly: true,
        resultPath: "$.crawlerName",
    });
    const checkCrawled = new task.LambdaInvoke(this, "Check if crawled", {
        lambdaFunction: this.lambda("CheckCrawledLambda", role, "../../lambda/crawler/check"),
        payloadResponseOnly: true,
        resultPath: "$.crawled",
    });
    const wait = 10;
    crawlTask.next(checkCrawled)
    .next(new sf.Choice(this, "Is crawled?")
        .when(sf.Condition.booleanEquals("$.crawled", true), next)
        .otherwise(new sf.Wait(this, `Wait for ${wait} Seconds`, {
            time: sf.WaitTime.duration(core.Duration.seconds(wait)),
        }).next(checkCrawled)));
    return crawlTask;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;保存结果&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成尚未对 Redshift 提供支持，对保存结果需要替代方案。Airflow 提供 S3ToRedshiftOperator 操作符将数据从存储桶复制到 Redshift 表中。本质上是通过 Redshift 的 COPY 命令实现的。替代方案亦遵循此思路。利用亚马逊软件开发包的 RedshiftData 模块，可以执行 SQL 语言和数据操作命令。此处通过密码 ARN 获取密码，完全规避密码明文暴露的问题。此外 Glue 也提供应用接口支持直接把数据保存到 Redshift。在保存数据到数据仓库之前可多做一步，将目标表做清空操作（truncate 或 delete），避免因原表中有数据导致冗余。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;await data.executeStatement({
    ClusterIdentifier: event.ClusterIdentifier,
    Database: event.Database,
    SecretArn: event.SecretArn,
    Sql: event.Sql
}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;状态机保存结果的替代方案可以一个 Lambda 函数实现。在生产环境，此处建议以更细粒度和最小化原则配置该函数所赋予的权限，夯实系统安全性。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCopyS3ToRedshift(bucket, redshift) {
    const dir = bucket.s3UrlForObject("airflow/lab/data/aggregated");
    const sql = `copy nyc.green from '${dir}' iam_role '${redshift.role.roleArn}' format as parquet;`;

    return new task.LambdaInvoke(this, "Copy S3 to Redshift", {
        lambdaFunction: this.lambda("CopyToRedshiftLambda", role, "../lambda/redshift/execute"),
        payloadResponseOnly: true,
        payload: sf.TaskInput.fromObject({
            ClusterIdentifier: redshift.cluster.clusterName,
            Database: RedshiftStack.DB_NAME,
            SecretArn: redshift.cluster.secret.secretArn,
            Sql: sql,
        })
    });
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;监控文件&lt;/h3&gt; 
&lt;p&gt;最后还需要处理对存储桶文件的监控任务。Airflow 提供 S3PrefixSensor 来监控文件上传到某个桶，进而触发数据管道进行数据处理。此处有多种方式监控存储桶里面的文件。例如 S3 自带的事件通知功能。不过事件通知的目标不支持启动状态机，还需要 Lambda 辅助。或者可以通过 CloudTrail 跟踪桶写入操作，然后通过 EventBridge 的个规则来捕获事件进而触发状态机执行。跟踪只需要关注特定桶特定目录的写入即可。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createTrail(logBucket, monitorBucket) {
    const trail = new cloudtrail.Trail(this, 'CloudTrail', {
        bucket: logBucket,
        s3KeyPrefix: "data-trail",
    });
    trail.addS3EventSelector(
        [{bucket: monitorBucket, objectPrefix: "airflow/lab/data/raw"}],
        {readWriteType: cloudtrail.ReadWriteType.WRITE_ONLY});
    return trail;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;捕获规则和跟踪一样，只需要捕获特定桶特定目录的写入即可，此处利用 prefix 前缀操作符来限定。规则目标可以直接启动状态机，开启数据分析管道进程。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createS3Event(machine, bucket) {
    new events.Rule(this, "S3StepFunctions", {
        description: "S3 invoke StepFunctions",
        eventPattern: {
            source: [ "aws.s3" ],
            detailType: [ "AWS API Call via CloudTrail" ],
            detail: {
                "eventSource": [ "s3.amazonaws.com" ],
                "eventName": [ "PutObject" ],
                "requestParameters": {
                    "bucketName": [ bucket.bucketName ],
                    "key": [{ "prefix": "airflow/lab/data/raw" }]
                }}},
        targets: [ new targets.SfnStateMachine(machine) ]
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;方案对比&lt;/h2&gt; 
&lt;p&gt;至此云原生编排数据分析管道的改造宣告完成。回顾本文，重新审视和对比各项方案的利弊得失，可以更好的帮助读者选择更适合业务场景的方案。例如，如果在中国区新建数据分析管道项目，则建议使用状态机。如果从 Airflow 的老环境迁移上云，则建议使用 MWAA 或者自建 Airflow，这样可以复用积累的代码。亦可两者并行，对新的数据管道用云原生方案。&lt;/p&gt; 
&lt;table style="border-collapse: collapse;border: 3px solid grey" border="1"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;状态机&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MWAA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;自建 Airflow&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;编写语言&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;JSON 及云开发包支持的所有语言&lt;br&gt; (TypeScript, JavaScript, Python, Java, and C#)&lt;/td&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;支持中国区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;无服务器&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;托管服务&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;连接密码暴露&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;开源社区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;部署时间（近似值）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;开箱即用&lt;/td&gt; 
   &lt;td&gt;一小时&lt;/td&gt; 
   &lt;td&gt;数小时到数天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Airflow &lt;/strong&gt;&lt;strong&gt;最新版本&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;（2021&lt;/strong&gt;&lt;strong&gt;年8&lt;/strong&gt;&lt;strong&gt;月）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;不适用&lt;/td&gt; 
   &lt;td&gt;2.0.2&lt;/td&gt; 
   &lt;td&gt;2.1.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;服务调度集成&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;云原生&lt;/td&gt; 
   &lt;td&gt;通过操作符&lt;/td&gt; 
   &lt;td&gt;通过操作符&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;本文从 MWAA 的数据分析管道指导教程为引子，介绍利用云开发包快速搭建部署程序的方法，并以状态机为编排平台，尝试改造其为云原生编排的数据管道，辅以几个关键操作的替代方案介绍。本文初步探讨云原生编排数据分析管道的方法，借此抛砖引玉，供读者讨论。从“方案对比”一节可以看出，云原生的编排方案有诸多优势，尤其表现在零部署时间，无服务器化管理，多语言支持和增强安全性上。相信随着跨服务集成的深度和广度越来越高，云原生的编排优势会如虎添翼，成为数据分析管道编排平台的不二选择。&lt;/p&gt; 
&lt;h3&gt;工作展望&lt;/h3&gt; 
&lt;p&gt;有几个有趣的展开方向。首先就 Airflow 的诸多操作符，研究云原生改造方法，以期对所有 Airflow 有向无环图皆可支持改造，利于迁移。能自动化改造更佳。其次研究将 Airflow 的数据分析管道以 Glue 的蓝图和工作流为基础进行改造。Glue 蓝图的编排平台和状态机的编排平台是一对有趣的对比。再者就自建 Airflow 的方案如何高效搭建基础设施并降低运维难度亦值得关注。&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/clementy.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;袁文俊&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务部顾问。曾在亚马逊美国西雅图总部工作多年，就职于 Amazon Relational Database Service (RDS) 关系型数据库服务开发团队。拥有丰富的后端开发及运维经验。现负责业务持续性及可扩展性运行、企业应用及数据库上云迁移、云上灾难恢复管理系统等架构咨询、方案设计及项目实施工作。他拥有复旦大学理学学士学位和香港大学哲学硕士学位。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xzhom.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;赵鑫&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务团队数据架构师，专注于生命科学、自动驾驶领域的数据架构与数据分析&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用托管节点组结合启动模板简化EKS升级与运维</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance/</link>
				<pubDate>Tue, 31 Aug 2021 04:09:59 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Containers]]></category>
		<category><![CDATA[Amazon EKS]]></category>
		<category><![CDATA[Amazon EKS Managed Node Group]]></category>
		<category><![CDATA[EC2 Launch Template]]></category>

		<guid isPermaLink="false">c7a2915de4f1e2f686bc64ad252f93fc8fe230e0</guid>
				<description>随着应用容器化不断流行与深入，采用Kubernetes（K8S）作为容器编排方式的应用也随之增加。作为亚马逊云科技的用户，在云上使用Amazon Web Service托管的K8S服务Elastic Kubernetes Service（EKS）服务的客户也在不断增加。同时根据K8S社区的发布规则K8S每年会有三个小版本的发布， 相应的EKS也会跟随上游K8S的版本发布3个版本，目前支持的版本以及相应终止支持的时间信息可以参考亚马逊EKS发布日历。</description>
								<content:encoded>&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;随着应用容器化不断流行与深入，采用Kubernetes（K8S）作为容器编排方式的应用也随之增加。作为亚马逊云科技的用户，在云上使用Amazon Web Service托管的K8S服务Elastic Kubernetes Service（EKS）服务的客户也在不断增加。同时根据K8S社区的发布规则K8S每年会有三个小版本的发布， 相应的EKS也会跟随上游K8S的版本发布3个版本，目前支持的版本以及相应终止支持的时间信息可以参考&lt;a href="https://docs.aws.amazon.com/zh_cn/eks/latest/userguide/kubernetes-versions.html"&gt;亚马逊EKS发布日历&lt;/a&gt;。每个上游的K8S版本都会有1年支持窗口加上2个月升级过渡窗口，为了保持与K8S社区版本的同步来获得社区的支持，客户每隔一段时间都要对现有的K8S或者EKS集群做升级，也就是说K8S与EKS的升级已经成为常态。&lt;/p&gt; 
&lt;p&gt;在EKS上这个升级主要涉及到控制平面升级、数据平面升级与插件组件升级。其中以数据平面的升级最为繁琐与复杂，所以本着减少无差别的繁重的运维工作为出发点，本文通过一个端到端的实验详细介绍通过使用托管节点组与启动模板简化客户的升级操作的过程与方法，从而为运维人员减负。并实现应用的平滑升级与灵活回退，进而保证应用与业务的稳定和可用性。&lt;/p&gt; 
&lt;p&gt;了解EKS的用户或者读者知道EKS的数据平面可以分为有服务器与无服务器两大类：有服务器即采用EC2的方式来运行K8S的应用；无服务器的方式即EKS Fargete，客户将工作负载部署在Fargate的环境而不是自己的VPC内，EKS节点对客户透明。有服务器EC2的节点管理方式又分为两种模式：&lt;a href="https://eksctl.io/usage/eks-managed-nodes/"&gt;托管节点组&lt;/a&gt;（Managed Node Group）与&lt;a href="https://eksctl.io/usage/nodegroup-upgrade/"&gt;非托管节点组&lt;/a&gt;（Unmanaged Node Group）。非托管节点组的命名来自于官方的EKS创建与维护工具eksctl.io文档中Unmanaged Node Group的中文直译，根据EKS官方文档， 非托管节点组模式被称为自行管理的节点（Self-managed nodes），为了简化与对比起见本文统一称为非托管节点组。托管节点组即将集群EC2节点的创建与生命周期管理由EKS服务来自动化管理，不需要客户干预。根据&lt;a href="https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability"&gt;eksctl对非托管节点组的设计原则&lt;/a&gt;，非托管节点组中的节点除了可以做扩缩容其他配置均不可变。下表列出了两种模式的主要区别：&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;项目&lt;/td&gt; 
   &lt;td width="198"&gt;托管节点组&lt;/td&gt; 
   &lt;td width="331"&gt;非托管节点组&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;升级方法&lt;/td&gt; 
   &lt;td width="198"&gt;原地升级&lt;/td&gt; 
   &lt;td width="331"&gt; &lt;p&gt;需要创建新的非托管节点组&lt;/p&gt; &lt;p&gt;（注：适用于通过eksctl创建的非托管节点组，其他方式可以通过更新CloudFormation&lt;/p&gt; &lt;p&gt;栈的方法更新AMI来升级，细节可以参考：&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/update-workers.html"&gt;官方文档&lt;/a&gt;）&lt;/p&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;EKS管理控制台可见&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;配置变更支持&lt;/td&gt; 
   &lt;td width="198"&gt; &lt;p&gt;是（可以变更的选项有：Min Size，Max Size，Desired Size, Kubernetes labels, taints, tags,&lt;/p&gt; &lt;p&gt;Maximum unavailable等配置，其他配置项变更需要通过切换启动模板版本实现。）&lt;/p&gt;&lt;/td&gt; 
   &lt;td width="331"&gt;否（除节点数量扩缩）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;支持关联启动模板&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;自定义AMI支持&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;考虑到EKS 1.17将于2021年11月终止支持，同时目前绝大部分客户使用的还是EC2的方式，并且因为非托管节点组相对于托管节点组的功能是更早发布，加上早期的托管节点组功能较少的原因，一部分客户还停留在非托管节点组的模式，所以本文的实验通过将非托管节点组转换为托管节点组结合启动模板的方式简化EKS 集群从1.17升级到1.18的升级过程（虽然本实验进行的的是1.17到1.18的升级，但过程和其中的方法对其他EKS版本的升级同样适用，比如从1.15升级到1.16或者1.18升级到1.19）。其中主要内容涵盖：控制平面升级、数据平面非托管节点组迁移到托管节点组、托管节点组升级与变更等。&lt;/p&gt; 
&lt;p&gt;在升级路径的选择上，也可以先将控制平面由1.17升级到1.18，然后创建托管节点组，再将工作负载由非托管节点组迁移到托管节点组，这样可以减少一次数据平面托管节点组的升级，加快集群整体升级的过程。因为本文的重点是介绍推广托管节点组结合启动模板的实践方法，先升级控制平面再创建托管节点组的做法，笔者测试下来对于文中简单的样例应用Nginx是可以的，遵从K8S官方的&lt;a href="https://kubernetes.io/releases/version-skew-policy/"&gt;Version Skew Policy&lt;/a&gt;：kubelet must not be newer than kube-apiserver, and may be up to two minor versions older。笔者尝试过将控制平面从1.17升级到1.18再连续升级到1.19，然后再创建托管节点组与迁移工作负载也是可以成功通过的，但如果集群中有对1.17到1.18/1.19版本变化敏感或者需要改造的应用，稳妥起见还是建议按照本实验的顺序来操作，并引入必要的测试。有兴趣的读者可以自行测试验证。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;本文目标读者：EKS运维与管理人员&lt;/p&gt; 
&lt;p&gt;实验所需时长：3小时&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;操作步骤&lt;/h2&gt; 
&lt;p&gt;前提：当前使用的用户具有Administrator Access权限&lt;/p&gt; 
&lt;h3&gt;准备Cloud9实验环境&lt;/h3&gt; 
&lt;p&gt;在AWS管理控制台中选择Cloud9服务，然后创建一个名称为：eksworkshop的环境，将Cost-saving setting选项设置为：After four hours，其他配置保持默认。创建完毕后关闭Welcome和底部的工作区页面，然后在主工作区中打开一个新的Terminal。&lt;/p&gt; 
&lt;p&gt;在IAM服务中，使用&lt;a href="https://console.aws.amazon.com/iam/home#/roles$new?step=type&amp;amp;commonUseCase=EC2%2BEC2&amp;amp;selectedUseCase=EC2&amp;amp;policies=arn:aws:iam::aws:policy%2FAdministratorAccess"&gt;链接&lt;/a&gt;创建一个名称为：eksworkshop-admin的角色，确认：AWS service和EC2被选中，点击下一步，确认AdministratorAccess策略被选中，点击下一步，跳过Tag选项，点击下一步在Review页面中输入eksworkshop-admin作为新角色的名称，点击创建角色完成创建。&lt;/p&gt; 
&lt;p&gt;点击&lt;a href="https://console.aws.amazon.com/ec2/v2/home?#Instances:tag:Name=aws-cloud9-eksworkshop;sort=desc:launchTime"&gt;链接&lt;/a&gt;在EC2服务中查看刚刚创建的Cloud9环境对应的EC2实例，选中该实例，然后在菜单选择：Actions / Security / Modify IAM Role，在IAM Role的下拉列表中选择eksworkshop-admin的角色，点击保存。&lt;/p&gt; 
&lt;p&gt;返回刚刚创建好的Cloud9环境，点击页面右上角的齿轮，打开首选项设置页面，然后选择AWS SETTINGS，关闭AWS managed temporary credentials单选框，最后关闭首选项设置页面。&lt;/p&gt; 
&lt;p&gt;在打开的终端中运行以下命令确认临时的秘钥凭证已经被删除干净，并验证在返回结果的ARN 中包含eksworkshop-admin。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;rm -vf ${HOME}/.aws/credentials&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws sts get-caller-identity&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列脚本安装实验所需的Kubernetes 工具：eksctl，kubectl，helm，jq，aws cli&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;# create a folder for the scripts
mkdir ~/environment/scripts
# tools script
cat &amp;gt; ~/environment/scripts/install-tools &amp;lt;&amp;lt;-"EOF"
#!/bin/bash -ex
sudo yum install -y jq gettext bash-completion

# install kubectl
sudo curl --silent --location -o /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.18.10/bin/linux/amd64/kubectl
sudo chmod +x /usr/local/bin/kubectl
echo 'source &amp;lt;(kubectl completion bash)' &amp;gt;&amp;gt;~/.bashrc
source ~/.bashrc
# install eksctl
curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv -v /tmp/eksctl /usr/local/bin
if ! [ -x "$(command -v jq)" ] || ! [ -x "$(command -v envsubst)" ] || ! [ -x "$(command -v kubectl)" ] || ! [ -x "$(command -v eksctl)" ] || ! [ -x "$(command -v ssm-cli)" ]; then
  echo 'ERROR: tools not installed.' &amp;gt;&amp;amp;2
  exit 1
fi
#pip install awscli --upgrade --user
# install aws cli v2
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
. ~/.bash_profile
# install helm 3
curl -sSL https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
helm version --short
helm repo add stable https://charts.helm.sh/stable
helm completion bash &amp;gt;&amp;gt; ~/.bash_completion
. /etc/profile.d/bash_completion.sh
. ~/.bash_completion
source &amp;lt;(helm completion bash)
helm repo update
EOF
chmod +x ~/environment/scripts/install-tools
~/environment/scripts/install-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;创建EKS集群（版本：1.17）&lt;/h3&gt; 
&lt;p&gt;配置创建集群需要的环境变量&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account)
export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r '.region')
export EKS_CLUSTER_NAME=eksworkshop
export EKS_UNMANAGED_NODEGROUP_NAME=ung-1
export EKS_MANAGED_NODEGROUP_NAME=mng-1
export AWS_DEFAULT_REGION=$AWS_REGION
echo "export ACCOUNT_ID=${ACCOUNT_ID}" &amp;gt;&amp;gt; ~/.bash_profile
echo "export AWS_REGION=${AWS_REGION}" &amp;gt;&amp;gt; ~/.bash_profile
echo "export AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}" &amp;gt;&amp;gt; ~/.bashrc
echo "export EKS_CLUSTER_NAME=${EKS_CLUSTER_NAME}" &amp;gt;&amp;gt; ~/.bashrc
echo "export EKS_MANAGED_NODEGROUP_NAME=${EKS_MANAGED_NODEGROUP_NAME}" &amp;gt;&amp;gt; ~/.bashrc
echo "export EKS_UNMANAGED_NODEGROUP_NAME=${EKS_UNMANAGED_NODEGROUP_NAME}" &amp;gt;&amp;gt; ~/.bashrc
aws configure set default.region ${AWS_REGION}
aws configure get default.region
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;运行下列命令创建EKS集群配置模板文件 eks-cluster.yml.template&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;cat &amp;gt; ~/environment/scripts/eks-cluster.yml.template &amp;lt;&amp;lt;-"EOF"
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: $EKS_CLUSTER_NAME
  region: $AWS_REGION
  version: "1.17"
nodeGroups:
  - name: $EKS_UNMANAGED_NODEGROUP_NAME
    minSize: 1
    maxSize: 3
    desiredCapacity: 2
    labels: {role: unmanaged-ng-worker}
    tags:
      Name: unmanaged-ng-worker
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;利用 &lt;a href="https://eksctl.io/"&gt;eksctl &lt;/a&gt;工具来创建 EKS 集群，运行下列命令创建一个 EKS 1.17 的集群，同时会创建一个新的 VPC，并且在该VPC中创建 一个含有2个节点的非托管节点组，整个过程大概需要 20 分钟左右（集群和节点组各10分钟左右）。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;envsubst &amp;lt; ~/environment/scripts/eks-cluster.yml.template &amp;gt; ~/environment/scripts/eks-cluster.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create cluster -f ~/environment/scripts/eks-cluster.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在EKS服务界面上验证集群eksworkshop已经成功创建。运行下列命令验证 EKS 集群节点组ung-1已经成功创建&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl get nodegroup --cluster $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令测试 EKS 集群节点是否正常工作&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get nodes --show-labels&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令将当前登录管理控制台的用户加入到EKS集群管理员组中，这样使得当前登录用户可以在EKS服务界面上查看集群信息。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;c9builder=$(aws cloud9 describe-environment-memberships --environment-id=$C9_PID | jq -r '.memberships[].userArn')
if echo ${c9builder} | grep -q user; then
	rolearn=${c9builder}
        echo Role ARN: ${rolearn}
elif echo ${c9builder} | grep -q assumed-role; then
        assumedrolename=$(echo ${c9builder} | awk -F/ '{print $(NF-1)}')
        rolearn=$(aws iam get-role --role-name ${assumedrolename} --query Role.Arn --output text) 
        echo Role ARN: ${rolearn}
fi
eksctl create iamidentitymapping --cluster $EKS_CLUSTER_NAME --arn ${rolearn} --group system:masters --username admin
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们可以在EC2控制台看到新创建了2个名称为eksworkshop-ung-1-Node类型为m5.large 的EC2实例，也可以在管理控制台的EKS服务的集群列表中查看刚刚创建好的集群节点、网络和其他集群配置信息。因为我们刚刚创建的是一个非托管节点组，所以如下图所示在EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute界面查看托管节点组为空&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 同时，因为eksctl工具的底层实现是依赖CloudFormation服务的，所以可以再CloudFormation服务的管理界面查看为了创建集群而新建的2个CloudFormaiton模板：集群控制平面CloudFormaiton Stack、非托管节点组CloudFormaiton Stack。+&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;部署样例工作负载&lt;/h3&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;cat &amp;gt; ~/environment/scripts/nginx.yaml &amp;lt;&amp;lt;-"EOF"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 10
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: "nginx"
spec:
  selector:
    app: nginx
  type: ClusterIP
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
EOF
kubectl apply -f ~/environment/scripts/nginx.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过下列命令参考样例Nginx程序已经成功部署&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get deploy&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;创建启动模板&lt;/h3&gt; 
&lt;p&gt;进入EC2服务，选择Launch Templates &amp;gt; Create launch template，分别填入&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Launch template name：demo&lt;/li&gt; 
 &lt;li&gt;Instance type：large&lt;/li&gt; 
 &lt;li&gt;Security groups：在EKS集群管理控制台 EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Networking中显示Cluster security groupInfo的安全组ID&lt;/li&gt; 
 &lt;li&gt;Resource Tags Key: Name, Value: eksworkshop-mng-1, Resource types: Instances&lt;/li&gt; 
 &lt;li&gt;User Data: 如果某些客户在使用非托管节点组的配置YAML文件中有使用：preBootstrapCommands或者overrideBootstrapCommand之类的一些自定义命令，那么在转换到托管节点组加启动模板这种方式后将不再支持，如果继续使用会出现错误：cannot set instanceType, ami, …, preBootstrapCommands, overrideBootstrapCommand, placement in managedNodeGroup when a launch template is supplied。用户可以将这些选项中配置的SHELL命令迁移到User Data中。如果有使用自定义AMI，则必须在User Data中填入下列命令将节点加入到集群，否则会出现错误：node bootstrapping script (UserData) must be set when using a custom AMI。具体User Data输入的MIME格式要求请参考这里的&lt;a href="https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html"&gt;官方文档&lt;/a&gt;。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;#!/bin/bash&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/eks/bootstrap.sh cluster_name&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;点击Create launch template创建启动模板。在启动模板的版本列表中查看刚刚创建好的版本号为1的启动模板，因为启动模板的版本是不可变的，只能通过选择版本1后点击Actions &amp;gt; Modify template (Create new version)来创建新的版本。&lt;/p&gt; 
&lt;p&gt;如果在EKS集群中有使用自定义AMI，那么可以在创建模板过程中指定已经定义好的AMI。需要注意的是，根据&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html"&gt;EKS升级官方文档&lt;/a&gt;在升级控制平面之前要求自定义AMI的节点版本需要与控制平面的版本相同。在本实验中来说就是要求自定义AMI及kubelet版本必须是1.17。这样当控制平面升级到1.18以后就会导致托管节点组还停留在1.17版本，存在一个小版本的差异。这样在托管节点组升级到1.18之前是不能将控制平面升级到版本1.19，否则得到错误提示：Nodegroups xxx must be updated to match cluster version 1.1x before updating cluster version。如果自定义AMI的节点组比控制平面低一个版本，则不能直接在界面上通过点击“Update now”操作来升级节点组。如果后续有继续将版本从1.18升级到更高版本的需求则需要根据目标EKS版本的EKS优化AMI重新定义自己的AMI，通过创建新的启动模板版本来指定这个新的AMI，然后再托管节点组中切换启动模板版本即可完成升级。具体切换启动模板版本的流程可以参考下面的章节“切换启动模板版本”。&lt;/p&gt; 
&lt;h3&gt;创建托管节点组&lt;/h3&gt; 
&lt;p&gt;运行下列命令设置环境变量并创建托管节点组&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;export LT_ID=$(aws ec2 describe-launch-templates --launch-template-name demo --output json | jq -r '.LaunchTemplates[0].LaunchTemplateId')
cat &amp;gt; ~/environment/scripts/mng-1.yml.template &amp;lt;&amp;lt;-"EOF"
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: $EKS_CLUSTER_NAME
  region: $AWS_REGION
  version: "1.17"
managedNodeGroups:
  - name: $EKS_MANAGED_NODEGROUP_NAME
    minSize: 1
    maxSize: 3
    desiredCapacity: 2
    labels: {role: managed-ng-worker}
    launchTemplate:
      id: $LT_ID
      version: "1"
EOF
envsubst &amp;lt; ~/environment/scripts/mng-1.yml.template &amp;gt; ~/environment/scripts/mng-1.yml
eksctl create nodegroup -f ~/environment/scripts/mng-1.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;整个过程大概需要 3分钟左右。之后我们可以在EC2控制台看到新创建了2个名称为eksworkshop-mng-1类型为m5.large 的EC2实例。同时因为我们刚刚创建的是一个托管节点组，所以如下图所示在EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute界面可以查看到刚刚创建的托管节点组。&lt;/p&gt; 
&lt;p&gt;注意上述托管节点组的配置文件中设置的版本1.17是与控制平面一致的版本，如果托管节点组配置的版本与EKS集群控制平面不一致时，eksctl会自动使用控制平面版本。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 从选中的部分可以看出托管节点组mng-1对应的启动模本名称为demo版本为1。也可以运行下列命令验证 EKS 集群节点组mng-1已经成功创建&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl get nodegroup --cluster $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令测试 EKS 集群新加入的两个节点是否正常工作&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get nodes --show-labels&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;需要特别指出的是启动模板对于创建托管节点组是一个推荐的可选项。不预先配置启动模板，而是直接利用下列的配置文件也可以创建托管节点组。因为在配置中没有显示的配置启动模板，eksctl会根据配置自动生成一个名称为“eksctl-集群名称-nodegroup-托管节点组名称 (N)”的一个启动模板，这个启动模板是由eksctl创建、管理和维护，因此不建议手动创建新版本修改或者复用。这种方式下创建的每个托管节点组的启动模板都是独立的，不能复用，如果有统一配置的需求和后续针对单个节点组的修改需求就更加麻烦。同时因为没有在配置文件中显示的指定启动模板，需要根据命名规则或者在EKS的托管节点组控制界面上查询这个启动模板，所以这种方式不利于配置变更的跟踪。而显示的声明在多个托管节点组中可以共用一个启动模板，当出现不同的配置需求时又可以通过新建启动模板版本来解决，相对于隐式的方式更加灵活高效，所以在本实验中托管节点组采用的是显示的启动模板。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: eksworkshop
  region: us-east-1
  version: "1.17"
  availabilityZones: ["us-east-1a", "us-east-1b", "us-east-1c"]
managedNodeGroups:
- name: nodegroup
  minSize: 1
  maxSize: 3
  desiredCapacity: 3
  instanceType: m5.large
  ssh:
    enableSsm: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;迁移工作负载并删除非托管节点组&lt;/h3&gt; 
&lt;p&gt;因为非托管节点组的&lt;a href="https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability"&gt;不可变性&lt;/a&gt;，除了改变节点数量无法更改其配置，所以当遇到升级集群版本的情况是需要创建新的非托管节点组然后迁移负载再删除旧的节点组的方法来实现升级节点组。而托管节点组可以做到原地（In place）升级，所以本实验先将样例工作负载迁移到托管节点组再做集群的升级。&lt;/p&gt; 
&lt;p&gt;运行下列命令查验当前的nginx pod运行在非托管节点组的节点上&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令将在非托管节点组的节点上的工作负载驱逐到刚刚创建的托管节点组&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl drain nodegroup --cluster=$EKS_CLUSTER_NAME --name=$EKS_UNMANAGED_NODEGROUP_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行命令：&lt;code&gt;kubectl get no&lt;/code&gt;可以发现旧节点组的状态已经变为：Ready,SchedulingDisabled，重新运行下列命令查验当前的nginx pod运行在托管节点组的节点上&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令删除非托管节点组&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete nodegroup --cluster $EKS_CLUSTER_NAME --name $EKS_UNMANAGED_NODEGROUP_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令监视节点删除情况直至非托管节点组被完全删除。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get no -w&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;升级集群控制平面&lt;/h3&gt; 
&lt;p&gt;如下图所示在EKS集群控制台上点击Update Now升级集群控制平面，因为K8S需要逐个版本升级，所以只有1.18目标版本是可选状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 升级后如下图所示集群处于Updating状态，整个升级过程大约需要30~40分钟。这步升级操作也可以通过eksctl命令或者aws cli来完成，具体做法请参考&lt;a href="https://docs.amazonaws.cn/eks/latest/userguide/update-cluster.html"&gt;官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 升级成功后可以看到集群版本变为1.18。&lt;/p&gt; 
&lt;p&gt;需要注意的是如果有多个托管节点组，在升级控制平面之前，需要确认所有的托管节点组都已经升级到控制平面的版本，否则升级时会得到错误提示：Nodegroups xxx must be updated to match cluster version 1.1x before updating cluster version。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;升级托管节点组&lt;/h3&gt; 
&lt;p&gt;如下图所示进入EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute可以看到New AMI Release versios are avaiable for 1 Node Group的提示，并且在Node Groups中mng-1的AMI release version列的旁边出现了Update now的链接&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;点击Update now升级托管节点组到1.18&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在上面的弹出的对话框中可以看到Update Strategy设置为Rolling update，也即滚动更新，点击Update开始节点组升级更新，整个过程需要约20分钟。&lt;/p&gt; 
&lt;p&gt;其间可以在EC2控制台中查看新旧节点的变化情况，在新启动的实例细节信息里查验AMI name已经改为amazon-eks-node-1.18-v2021xxxx。通过运行命令：kubectl get no可以看到旧的节点被设置为SchedulingDisabled状态，Nginx Pod在被逐步迁移到新的节点上。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以通过如下图所示的编辑托管节点组 EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Node Group: mng-1 &amp;gt; Edit Node Group的Node Group update configuration来设置最大不可用节点数目或者比例数，从而控制滚动更新的颗粒度。当然也可以变更最小、最大、期望节点数，k8s labels，taints和tags等其他配置。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相比之下，如果我们这里使用的依旧是非托管节点组，那么在这个步骤中我们就要重新创建一个与控制平面版本一致的1.18的新的非托管节点组，然后将工作负载从旧的1.17的节点组迁移到新的1.18的节点组再删除1.17的非托管节点组，这个过程相对于上述托管节点组的一键升级的流程复杂许多，而且存在一个新旧非托管节点组同时存在的时间窗口给集群的管理与维护增加了难度与不确定性。更令运维人员头疼的是，这个升级过程在后续的版本升级中（比如1.18到1.19）仍然需要重复一遍。对比可见数据平面的升级在托管节点组的支持下变得非常简单方便。&lt;/p&gt; 
&lt;h3&gt;切换启动模板版本&lt;/h3&gt; 
&lt;p&gt;在日常集群的维护中，我们经常会有一些变更需求，比如切换实例类型，修改各种资源比如EC2的名称等，这些在非托管节点组是无法实现的，而在配置了启动模板的托管节点组中可以轻松实现，下面将演示将节点组实例类型切换为m5.2xlarge的方法。&lt;/p&gt; 
&lt;p&gt;基于启动模板demo的版本1新创建一个新版本：version 2，将实例类型设置为m5.2xlarge同时保持其他选项不变。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;等待托管节点组mng-1升级到1.18完成后，可以看到节点组的AMI release version改为1.18.20-xxxx，同时因为我们增加了一个新的启动模板的版本，点击Change version将mng-1节点组切换到新创建的版本2从而修改节点组的实例类型到m5.2xlarge。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 点击Update开始节点组滚动更新，类似的整个过程需要约20分钟。等待更新完毕后，按照相同的方法可以重新切换回版本1。启动模版的版本信息可以通过下列命令导出到yaml作为配置变更管理的一部分通过git等源代码版本管理工具来管理。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws ec2 describe-launch-template-versions --launch-template-name demo --output yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;需要注意的是在启动模板的不同版本间做切换目前不支持在有使用EKS优化AMI与自定义AMI的不同版本间切换。否则会得到错误：You cannot specify an image id within the launch template, since your nodegroup is configured to use an EKS optimized AMI（默认EKS优化版本改为自定义AMI版本）或者The request must contain the parameter ImageId（自定义AMI版本改为默认EKS优化版本）。如果有将默认AMI替换为自定义AMI的需求，可以通过创建一个新的托管节点组来引用配置有自定义AMI的启动模板的版本来解决。&lt;/p&gt; 
&lt;h3&gt;删除EKS集群和Cloud9环境&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete cluster --name $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;最后，在AWS控制台的Cloud9服务的环境列表中删除eksworkshop。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;本文通过一个端到端的例子说明了将非托管节点组转换到托管节点组来实现工作负载的迁移。同时完成集群和托管节点组从 1.17到1.18的版本升级。最后通过在不同启动模板版本间切换的方法实现了节点组配置的灵活原地更新。需要特别指出虽然上述实验进行的的是1.17到1.18的升级，但过程对于其他EKS版本的升级同样适用，比如从1.18升级到1.19。&lt;/p&gt; 
&lt;p&gt;相比EKS集群的托管节点组，非托管节点组具有不可变性，所以必须通过新建节点组然后迁移工作负载的方式来更新。而托管节点组则可以通过改变启动模板的版本然后进行滚动更新来实现常用配置的变更，同时在出现失败的情况下支持回退，所以在日常变更管理与集群版本升级上更加简便。并且一个集群或者多个集群中的多个节点组可以共用一个启动模板，极大的简化了维护与管理的成本。另外将多项节点组配置选项转移到启动模板中，实现了节点组配置一定程度的解耦。最后因为启动模板支持多个版本，同一托管节点组可以在同一个启动模板的不同版本间灵活切换，也极大的方便了日常节点组的变更与维护。关于更多托管节点组的新功能请参考&lt;a href="https://aws.amazon.com/blogs/containers/catching-up-with-managed-node-groups-in-amazon-eks/"&gt;托管节点组最新动态博客&lt;/a&gt;与&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html"&gt;EKS官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;最后需要指出的是EKS升级的范畴远大于文中介绍的内容，鉴于篇幅所限，其他方面的升级方法请读者自行参考官方K8S升级手册与官方EKS升级文档。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html&lt;/li&gt; 
 &lt;li&gt;https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability&lt;/li&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html&lt;/li&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html&lt;/li&gt; 
 &lt;li&gt;https://aws.amazon.com/blogs/containers/catching-up-with-managed-node-groups-in-amazon-eks/&lt;/li&gt; 
 &lt;li&gt;https://aws.amazon.com/blogs/containers/introducing-launch-template-and-custom-ami-support-in-amazon-eks-managed-node-groups/&lt;/li&gt; 
 &lt;li&gt;https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html&lt;/li&gt; 
 &lt;li&gt;https://www.eksworkshop.com/&lt;/li&gt; 
 &lt;li&gt;https://eksctl.io/usage/schema/&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/dapengt.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;田大鹏&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责帮助客户进行上云架构的设计和咨询。在电商及互联网行业有丰富的咨询和架构设计经验。加入 AWS 前曾于全球领先的存储和虚拟化企业，担任研发主管工程师及研发经理多种职位，负责在线存储及备份系统的多个子系统的高并发、高可用系统架构设计，应用微服务化等敏捷项目。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/guili.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;何归丽&lt;/h3&gt; 
  &lt;p&gt;AWS高级解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，同时致力于AWS云服务在国内的应用和推广。加入AWS之前在外企软件部门担任系统架构师，有十多年的软件研发和架构设计经验，在微服务架构和容器、企业应用信息安全、DevOps等领域有丰富的经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/panwenmi.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;潘文明&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责基于 AWS 的云计算方案的咨询与架构设计。专注于游戏行业，帮助客户利用AWS全球基础设施与强大的技术能力打造爆款游戏，降低游戏运行成本。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>如何将您的自定义容器镜像导入Amazon SageMaker Studio notebooks</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks/</link>
				<pubDate>Tue, 31 Aug 2021 03:41:59 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon SageMaker Studio]]></category>

		<guid isPermaLink="false">75a8705bab975b942b359066fef42d5d15ceef5c</guid>
				<description>Amazon SageMaker Studio是第一套用于机器学习（ML）的全集成开发环境（IDE）。Amazon SageMaker Studio可帮助数据科学家们快速启动Studio notebooks以探索数据、构建模型、启动Amazon SageMaker训练作业并部署托管端点。Studio notebooks中随附一组预构建镜像，这些镜像由Amazon SageMaker Python SDK&amp;nbsp;与IPython运行时或内核的最新版本构成。凭借此项新功能，您可以轻松将自定义镜像导入Amazon SageMaker notebooks当中。在本文中，我们将具体探讨如何将自定义容器镜像导入Amazon SageMaker notebooks。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://aws.amazon.com/sagemaker/"&gt;Amazon SageMaker Studio&lt;/a&gt;是第一套用于机器学习（ML）的全集成开发环境（IDE）。Amazon SageMaker Studio可帮助数据科学家们快速启动Studio notebooks以探索数据、构建模型、启动Amazon SageMaker训练作业并部署托管端点。Studio notebooks中随附一组预构建镜像，这些镜像由&lt;a href="https://sagemaker.readthedocs.io/en/stable/"&gt;Amazon SageMaker Python SDK&lt;/a&gt;&amp;nbsp;与IPython运行时或内核的最新版本构成。凭借此项新功能，您可以轻松将自定义镜像导入Amazon SageMaker notebooks当中。在本文中，我们将具体探讨如何将自定义容器镜像导入Amazon SageMaker notebooks。&lt;/p&gt; 
&lt;p&gt;开发人员与数据科学家一般需要在以下几种不同用例内使用自定义镜像：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;访问流行机器学习框架（包括TensorFlow、MXNet以及PyTorch等）的特定或最新版本。&lt;/li&gt; 
 &lt;li&gt;将本地开发的自定义代码或算法引入Studio notebooks内以进行快速迭代及模型训练。&lt;/li&gt; 
 &lt;li&gt;通过API访问数据湖或本地数据存储，且管理员需要在镜像中添加相应驱动程序。&lt;/li&gt; 
 &lt;li&gt;访问后端运行时（也称内核）；除IPython之外，还有R、Julia或其它环境等。您也可以使用本文中概述的方法安装其他自定义内核。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在大型企业中，机器学习平台管理员往往需要保证安全团队预先批准第三方软件包及代码，而非直接通过互联网下载。在常见的工作流示例中，机器学习平台团队会批准一组要使用的软件包与框架，使用这些软件包构建自定义容器、测试容器中的漏洞，而后将核准后的镜像推送至私有容器注册表内，例如&lt;a href="https://aws.amazon.com/ecr/"&gt;Amazon Elastic Container Registry&lt;/a&gt;&amp;nbsp;(Amazon ECR)。现在，机器学习平台团队可以将经过核准的镜像直接附加至Studio域内（请参见以下工作流程图）。您只需在Studio中选定所需的获准自定义镜像即可。在当前版本中，单一Studio域最多可以包含30个自定义镜像，您可以根据需求添加新版本或删除镜像。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在，我们将逐步介绍如何使用此项功能将自定义容器镜像导入Amazon SageMaker Studio notebooks当中。这里主要演示在互联网上使用时的默认方法，您也可以对其稍加修改以配合&lt;a href="https://aws.amazon.com/vpc/"&gt;Amazon Virtual Private Cloud&lt;/a&gt;&amp;nbsp;(Amazon VPC)进行使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;先决条件&lt;/h2&gt; 
&lt;p&gt;在开始之前，大家需要满足以下先决条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;亚马逊云科技账户。&lt;/li&gt; 
 &lt;li&gt;确保用于访问Amazon SageMaker的角色拥有以下Amazon Web Services身份与访问管理（IAM）权限，使Amazon SageMaker Studio能够在Amazon ECR中以smstudio为前缀创建一个repo，并面向此repo进行镜像推送与提取。要使用现有repo，请将其中的Resource部分替换为您的repo ARN。要构建容器镜像，您可以使用本地Docker客户端，或者直接在Amazon SageMaker Studio中创建镜像。本文采用后一种方法。要在Amazon ECR内创建repo，Amazon SageMaker Studio需要使用&lt;a href="https://aws.amazon.com/codebuild/"&gt;Amazon CodeBuild&lt;/a&gt;；您还需要拥有使用CodeBuild的权限，具体如下所示。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
            "Effect": "Allow",
            "Action": [
                "ecr:CreateRepository",
                "ecr:BatchGetImage",
                "ecr:CompleteLayerUpload",
                "ecr:DescribeImages",
                "ecr:DescribeRepositories",
                "ecr:UploadLayerPart",
                "ecr:ListImages",
                "ecr:InitiateLayerUpload",
                "ecr:BatchCheckLayerAvailability",
                "ecr:GetDownloadUrlForLayer",
                "ecr:PutImage"
            ],
            "Resource": "arn:aws:ecr:*:*:repository/smstudio*"
        },
        {
            "Effect": "Allow",
            "Action": "ecr:GetAuthorizationToken",
            "Resource": "*"
           }
{
            "Effect": "Allow",
            "Action": [
                "codebuild:DeleteProject",
                "codebuild:CreateProject",
                "codebuild:BatchGetBuilds",
                "codebuild:StartBuild"
            ],
            "Resource": "arn:aws:codebuild:*:*:project/sagemaker-studio*"
}
{
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "arn:aws:iam::*:role/*",
            "Condition": {
                "StringLikeIfExists": {
                    "iam:PassedToService": "codebuild.amazonaws.com"
                }
            }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;您的Amazon SageMaker角色还应在Amazon CodeBuild中拥有信任策略，具体如下所示。关于更多详细信息，请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/"&gt;使用Amazon SageMaker Studio镜像构建CLI在Studio notebooks中构建容器镜像&lt;/a&gt;。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": [
          "codebuild.amazonaws.com"
        ]
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;在您的本地机器上安装Amazon Web Services命令行界面（Amazon CLI）。关于详尽操作说明，请参阅&lt;a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html"&gt;安装Amazon&lt;/a&gt; Web Services。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;准备一个SageMaker Studio域。要创建此域，请使用&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateDomain.html"&gt;CreateDomain&lt;/a&gt;&amp;nbsp;API或者&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/cli/latest/reference/sagemaker/create-domain.html"&gt;create-domain&lt;/a&gt;&amp;nbsp;CLI命令。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果您希望使用自有VPC以安全引入自定义容器，则需要完成以下操作：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;带有专有子网的VPC。&lt;/li&gt; 
 &lt;li&gt;用于以下服务的VPC端点： 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service&lt;/a&gt;&amp;nbsp;(Amazon S3)&lt;/li&gt; 
   &lt;li&gt;Amazon SageMaker&lt;/li&gt; 
   &lt;li&gt;Amazon ECR&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html"&gt;Amazon Security Token Service&lt;/a&gt;&amp;nbsp;(Amazon STS)&lt;/li&gt; 
   &lt;li&gt;用于构建Docker容器的CodeBuild&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;要设置上述资源，请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/securing-amazon-sagemaker-studio-connectivity-using-a-private-vpc/"&gt;使用专用VPC保护Amazon SageMaker Studio连接&lt;/a&gt;以及相关&lt;a href="https://github.com/aws-samples/amazon-sagemaker-studio-vpc-blog"&gt;GitHub repo&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;创建Dockerfile&lt;/h2&gt; 
&lt;p&gt;为了体现数据科学家使用最新框架进行试验的普遍性需求，我们在本次演练中使用以下Dockerfile，其选择最新的TensorFlow 2.3版本作为基础镜像。您也可以使用自己指定的Dockerfile进行替换。目前，Amazon SageMaker Studio已经能够支持多种基础镜像，例如Ubuntu、Amazon Linux 2等等。Dockerfile将安装运行Juypter notebooks所需要的IPython运行时，同时安装Amazon SageMaker Python SDK与boto3。&lt;/p&gt; 
&lt;p&gt;除了笔记本电脑之外，除了notebooks之外，数据科学家与机器学习工程师们还经常使用各种流行IDE（例如Visual Studio Code或者PyÇharm）在本地notebooks上进行迭代与试验。您可能希望将这些脚本引入云端，借此进行扩展化训练或数据处理。您可以将这些脚本打包进Docker容器之内，并在Amazon SageMaker Studio的本地存储中查看。在以下Dockerfile中，我们复制的train.py&amp;nbsp;脚本是一套用于在MNIST数据集上训练简单深度学习模型的基础脚本。您也可以使用自己的脚本或包含代码的软件包替换此脚本。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;FROM tensorflow/tensorflow:2.3.0
RUN apt-get update 
RUN apt-get install -y git
RUN pip install --upgrade pip
RUN pip install ipykernel &amp;amp;&amp;amp; \
    python -m ipykernel install --sys-prefix &amp;amp;&amp;amp; \
    pip install --quiet --no-cache-dir \
    'boto3&amp;gt;1.0&amp;lt;2.0' \
    'sagemaker&amp;gt;2.0&amp;lt;3.0'&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;COPY train.py /root/train.py #可以替换为您的自定义脚本或软件包&lt;/p&gt; 
&lt;p&gt;以下代码为train.py脚本：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import tensorflow as tf
import os 

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=1)
model.evaluate(x_test, y_test)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;除了自定义脚本之外，您也可以添加其他文件，例如可通过&lt;a href="https://aws.amazon.com/secrets-manager/"&gt;Amazon Secrets Manage&lt;/a&gt;r 或&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html"&gt;Amazon Systems Manager Parameter Store&lt;/a&gt;访问客户端secrets以及环境变量的Python文件、用于连接私有PyPi repo的config文件、或者其他软件包管理工具。您也可以使用自定义镜像复制脚本，但在这种情况下，Dockerfile中的一切ENTRYPOINT或CMD命令均无法运行。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;设置安装文件夹&lt;/h2&gt; 
&lt;p&gt;您需要在本地机器上创建一个文件夹，并向其中添加以下文件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在上一步中创建完成的Dockerfile。&lt;/li&gt; 
 &lt;li&gt;名为&amp;nbsp;app-image-config-input.json&amp;nbsp;的文件，具体内容如下：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;"AppImageConfigName": "custom-tf2",
    "KernelGatewayImageConfig": {
        "KernelSpecs": [
            {
                "Name": "python3",
                "DisplayName": "Python 3"
            }
        ],
        "FileSystemConfig": {
            "MountPath": "/root/data",
            "DefaultUid": 0,
            "DefaultGid": 0
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们将此Dockerfile的后端内核设置为IPython内核，并提供指向&lt;a href="https://aws.amazon.com/efs/"&gt;Amazon Elastic File System&lt;/a&gt;&amp;nbsp;(Amazon EFS)的挂载路径。Amazon SageMaker可以识别出Juypter定义的内核。例如，对于R内核，您可以将之前代码中的Name部分设置为ir。请注意保证其中的Uid、Gid以及内核名称与Docker镜像中的kernelspecs及用户信息相匹配。要获取这些值，请参阅本&lt;a href="https://github.com/aws-samples/sagemaker-studio-custom-image-samples/blob/main/DEVELOPMENT.md"&gt;文档&lt;/a&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用以下内容创建一个名为&amp;nbsp;default-user-settings.json&amp;nbsp;的文件。如果您需要添加多个自定义镜像，请直接将其添加至&amp;nbsp;CustomImages列表。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  "DefaultUserSettings": {
    "KernelGatewayAppSettings": {
      "CustomImages": [
          {
                   "ImageName": "tf2kernel",
                   "AppImageConfigName": "custom-tf2"
                }
            ]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;创建镜像并将其附加至您的Studio域&lt;/h2&gt; 
&lt;p&gt;如果您已经拥有现成的域，则直接使用新镜像进行更新即可。在本节中，我们将演示现有Studio用户如何进行镜像附加。关于启动新用户的说明，请参阅&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-iam.html"&gt;使用IAM登入Amazon SageMaker Studio&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;首先，我们使用Amazon SageMaker Studio Docker构建CLI构建Dockerfile，并将其推送至Amazon ECR。请注意，您也可以使用其他方法将容器推送至ECR，例如通过本地Docker客户端以及AWS CLI。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用您的用户信息登录至Studio。&lt;/li&gt; 
 &lt;li&gt;将您的Dockerfile、以及其他需要复制到容器当中的代码或依赖项上传至Studio域。&lt;/li&gt; 
 &lt;li&gt;导航至包含Dockerfile的文件夹。&lt;/li&gt; 
 &lt;li&gt;在终端窗口或notebook内 —&amp;gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;!pip install sagemaker-studio-image-build&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;导出一个名为IMAGE_NAME的变量，并将其设定为您在&amp;nbsp;default-user-settings.json当中所指定的值。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;sm-docker build . –repository smstudio-custom:IMAGE_NAME&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果要使用其他repo，请将以上代码中的smstudio-custom替换为您的repo名称。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Amazon SageMaker Studio将为您构建Docker镜像，将该镜像推送至Amazon ECR当中一个名为smstudio-custom的repo内，并为其标记适当的镜像名称。要进一步自定义此项功能（例如提供详细的文件路径或其他选项），请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/"&gt;使用Amazon SageMaker Studio镜像构建CLI在Studio notebooks中构建容器镜像&lt;/a&gt;。要让以上pip命令在专用VPC环境下起效，您需要设置互联网路由或访问专用repo内的相应软件包。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在之前的安装文件夹中，创建一个名为&amp;nbsp;create-and-update-image.sh的新文件：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;ACCOUNT_ID=AWS ACCT ID # 替换为您的AWS账户ID
REGION=us-east-2 # 替换为您的区域
DOMAINID=d-####### # 替换为您的SageMaker Studio域名称
IMAGE_NAME=tf2kernel # 替换为您的镜像名称

# 使用Amazon SageMaker Studio
## 使用ECR中的镜像创建SageMaker镜像（根据需求修改镜像名称）
ROLE_ARN='The Execution Role ARN for the execution role you want to use'

aws --region ${REGION} sagemaker create-image \
    --image-name ${IMAGE_NAME} \
    --role-arn ${ROLE_ARN}

aws --region ${REGION} sagemaker create-image-version \
    --image-name ${IMAGE_NAME} \
    --base-image "${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/smstudio-custom:${IMAGE_NAME}"
    
## 为此镜像创建AppImageConfig（根据需要修改app-image-config-input.json中的AppImageConfigName与KernelSpecs参数）
aws --region ${REGION} sagemaker create-app-image-config --cli-input-json file://app-image-config-input.json

## 提供镜像与AppImageConfig以更新此域
aws --region ${REGION} sagemaker update-domain --domain-id ${DOMAINID} --cli-input-json file://default-user-settings.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;请参阅Amazon CLI以了解可在&amp;nbsp;&lt;a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker/create-image.html"&gt;create-image&lt;/a&gt;&amp;nbsp;API中使用的各项参数的详细信息。要检查当前状态，请导航至您的Amazon SageMaker控制台，并在导航面板中选择Amazon SageMaker Studio。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;使用Studio UI附加镜像&lt;/h2&gt; 
&lt;p&gt;您也可以通过UI完成将镜像附加至Studio域的最后一步。在此用例中，UI将处理镜像与镜像版本的创建操作，并使用附加的镜像完成域更新。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在Amazon SageMaker控制台上，选择Amazon SageMaker Studio。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在Control Panel页面上，可以看到已经置备完成的Studio域以及您所创建的所有用户配置。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Attach image&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;选择要附加新镜像，还是附加原有镜像。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ol&gt; 
   &lt;li style="list-style-type: none"&gt; 
    &lt;ol&gt; 
     &lt;li&gt;如果您选择Existing image，请从Amazon SageMaker镜像库中选择一个镜像。&lt;/li&gt; 
     &lt;li&gt;如果您选择New image，请提供Docker镜像的Amazon ECR注册表路径。此路径需要与Studio域处于同一区域内。ECR repo还需要与您的Studio域处于同一账户内；如果需要跨账户操作，则Studio必须具备相应权限。&lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Next&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;在&lt;/strong&gt;&lt;strong&gt;Image name&lt;/strong&gt;部分，输入名称。&lt;/li&gt; 
 &lt;li&gt;在&lt;strong&gt;Image display name&lt;/strong&gt;部分，输入描述性名称。&lt;/li&gt; 
 &lt;li&gt;在&amp;nbsp;&lt;strong&gt;Description&lt;/strong&gt;部分，输入标签定义。&lt;/li&gt; 
 &lt;li&gt;在IAM role部分，选择Amazon SageMaker用于向Amazon SageMaker镜像附加Amazon ECR镜像的IAM角色。&lt;/li&gt; 
 &lt;li&gt;此外，您也可以对镜像做出其他标记。&lt;/li&gt; 
 &lt;li&gt;选择&amp;nbsp;&lt;strong&gt;Next&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在Kernel name部分，输入Python 3。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Submit&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;绿色复选框代表镜像已被成功附加至域内。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker镜像存储将自动对镜像进行版本控制。您可以选择一个预先附加的镜像，而后选择Detach以分离该镜像及所有相关版本，或者选择Attach image以附加新版本。各镜像的版本数量或分离镜像的功能不受限制。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;自定义镜像用户体验&lt;/h2&gt; 
&lt;p&gt;下面，我们尝试Studio的实际用户体验。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用您的用户资料登录至Studio。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;要启动新活动，请选择&lt;/strong&gt;&lt;strong&gt;Launcher&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;在&lt;strong&gt;Select a SageMaker image to launch your activity&lt;/strong&gt;&lt;strong&gt;部分，选择&lt;/strong&gt;&lt;strong&gt;tf2kernel&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Notebook&lt;/strong&gt;图标，使用自定义内核打开一个新notebook。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Notebook内核需要几分钟才能启动完成，之后即可开始使用！&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;在notebook中测试您的自定义容器&lt;/h2&gt; 
&lt;p&gt;在内核启动并开始运行之后，您即可在notebook中运行代码。首先，我们测试Dockerfile中指定的TensorFlow是否为正确版本。在以下截屏中，可以看到我们刚刚创建的notebook正在使用tf2kernel。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker notebooks还会显示本地CPU与内存使用量。&lt;/p&gt; 
&lt;p&gt;接下来，我们直接在notebook中使用自定义训练脚本。将训练脚本复制到notebook单元中并运行。此脚本会从tf.keras.datasets处下载mnist数据集，并将数据拆分为训练数据集与测试数据集，自定义一项定制化深度神经网络算法，在训练数据集上训练算法，并在测试数据集上测试算法。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要尝试使用TensorFlow 2.3框架，大家可能希望测试新发布的API，例如Keras中提供的预处理实用程序等新功能。在以下截屏中，我们导入了随TensorFlow 2.3版本发布的keras.layers.experimental&amp;nbsp;库，其中包含用于数据预处理的新API。我们加载其中一个API，而后在notebook中重新运行脚本。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker还能够在代码运行过程中动态修改CPU与内存使用率。通过引入自定义容器与训练脚本，此功能使您能够直接在Amazon SageMaker notebook中尝试自定义训练脚本与算法。如果您对Studio notebook中的试验结果感到满意，则可立即启动训练作业。&lt;/p&gt; 
&lt;p&gt;Docker file中所包含的、使用COPY命令的Python文件或其他自定义文件运行情况如何？Amazon SageMaker Studio会挂载app-image-config-input.json所提供的文件路径中的弹性文件系统，在本示例中我们将其设定为root/data。为了避免Studio覆盖掉需要包含的自定义文件，COPY命令会将train.py文件加载至路径/root当中。要访问此文件，请打开终端或notebook并运行以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;! cat /root/train.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;这时您应看到以下截屏所示的输出结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以看到train.py&amp;nbsp;文件位于指定位置。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;CloudWatch中的日志记录&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker Studio还会将内核指标发布至Amazon CloudWatch供您进行故障排查。这些指标将被捕捉至/aws/sagemaker/studio命名空间之内。&lt;/p&gt; 
&lt;p&gt;要访问日志，请在CloudWatch控制台上选择CloudWatch Logs。在Log groups页面中，输入命名空间以查看与Jupyter服务器及内核网关相关的日志记录。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;分离镜像或版本&lt;/h2&gt; 
&lt;p&gt;您可以从域中分离镜像或特定镜像版本。&lt;/p&gt; 
&lt;p&gt;要分离镜像及其全部版本，请在Custom images attached to domain表内选定该镜像，而后选择Detach。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;您还可以选择删除镜像及所有版本，这不会影响到Amazon ECR中的镜像。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要分离镜像的特定版本，请选定该镜像。在Image details页面上，从Image versions attached to domain表中选择目标镜像版本（一个或者多个版本），而后选择Detach。您会看到如上所示的警告及操作选项。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker Studio使您能够更轻松地对机器学习模型进行协作、实验、训练及部署。在这之前，数据科学家往往需要通过公共及私有代码repo以及软件包管理工具才能访问最新机器学习框架、自定义脚本以及软件包。现在，您可以将所有相关代码打包进自定义镜像之内，并使用Studio notebook启动这些镜像。这些镜像可供Studio域内的所有用户使用。您也可以使用此项功能使用Python之外的其他流行语言及运行时，包括R、Julia以及Scala等。您可以在&lt;a href="https://github.com/aws-samples/sagemaker-studio-custom-image-samples"&gt;GitHub repo&lt;/a&gt;中找到示例文件。关于此项功能的更多详细信息，请参阅&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html"&gt;自带SageMaker镜像&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/stenatu.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Stefan Natu&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技公司高级机器学习专家。他致力于帮助金融服务客户在亚马逊云科技上构建端到端机器学习解决方案。在业余时间，他喜欢阅读机器学习技术博客、演奏吉他和探索纽约当地的各种美食。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/jaipreet.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Jaipreet Singh&lt;/h3&gt; 
  &lt;p&gt;Amazon SageMaker Studio团队高级软件工程师。他自2017年立项以来就一直从事Amazon SageMaker的开发工作，并为多个Jupyter开源项目做出贡献。业余时间，他喜欢远足和滑雪。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/huonguh.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Huong Nguyen&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技公司高级产品经理。她负责Amazon SageMaker Studio的用户体验工作。她在企业级及消费级领域拥有13年客户体验与数据驱动产品开发经验。在业余时间，她喜欢读书、享受自然风光和陪伴家人。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
	</channel>
</rss>