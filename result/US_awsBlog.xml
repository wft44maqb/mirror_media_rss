<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>亚马逊AWS官方博客</title>
	<atom:link href="https://aws.amazon.com/cn/blogs/china/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/cn/blogs/china/</link>
	<description>Just another AWS Brew Blogs  site</description>
	<lastBuildDate>Fri, 17 Sep 2021 03:03:26 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>在Amazon SageMaker上快速、灵活构建TensorFlow模型的在线推理服务</title>
		<link>https://aws.amazon.com/cn/blogs/china/build-tensorflow-model-on-amazon-sagemaker/</link>
				<pubDate>Fri, 17 Sep 2021 03:03:26 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon SageMaker]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">19d9d1af6fab0c4f845f5d7b86988dc765bec5e1</guid>
				<description>本文会介绍如何将本地训练好的TensorFlow模型部署到Amazon SageMaker来快速、灵活地创建TensorFlow模型服务器</description>
								<content:encoded>&lt;h2&gt;背景介绍&lt;/h2&gt; 
&lt;p&gt;当算法工程师在本地使用TensorFlow深度学习框架训练好模型后，会创建模型服务器供应用程序调用实现在线推理。由于部署本身存在一定的复杂性，他们需要考虑如何安装TensorFlow Serving相关的依赖，如何实现模型服务的高可用、请求负载均衡、A/B测试、自动伸缩机制等。Amazon SageMaker可以帮助用户快速创建多台模型服务器进行负载均衡，利用云上多可用区的方式实现高可用，并且在请求量变化时可以根据用户配置的策略进行自动扩展或收缩。本文会介绍如何将本地训练好的TensorFlow模型部署到Amazon SageMaker来快速、灵活地创建TensorFlow模型服务器。&lt;/p&gt; 
&lt;h2&gt;1. TensorFlow Serving请求数据格式&lt;/h2&gt; 
&lt;p&gt;在将模型部署到SageMaker之前，我们首先要了解TensorFlow Serving的&lt;a href="https://www.tensorflow.org/tfx/serving/signature_defs"&gt;SignatureDefs&lt;/a&gt;，它标识了保存模型时所需的接受请求函数的输入与输出，不同SignatureDefs下的请求数据格式不同。TensorFlow Serving支持gRPC API与RESTful API两种方式进行请求，本文以RESTful API的方式为例。&lt;/p&gt; 
&lt;h3&gt;1.1 Classify与Regress API&lt;/h3&gt; 
&lt;p&gt;Classify与Regress 的SignatureDefs分别支持分类与回归的TersorFlow Serving结构化调用方式。即当Serving的输入函数封装了&lt;a href="https://www.tensorflow.org/tutorials/load_data/tfrecord"&gt;tf.Example&lt;/a&gt;（一种灵活的消息类型，表示{“string”: value}的映射，常用来进行训练过程中的数据流式传输或解析feature_column中的特征列），需要调用该API进行推理。&lt;/p&gt; 
&lt;p&gt;参考以下代码，在保存模型时指定input_receiver_fn作为接受请求函数，其中定义了将feature_column解析为tf.Example消息类型的过程，然后输入给模型进行推理。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-python"&gt;def input_receiver_fn(features):
    example_spec = tf.feature_column.make_parse_example_spec(features)
    return tf.estimator.export.build_parsing_serving_input_receiver_fn(
        example_spec, default_batch_size=5)
model.export_savedmodel(export_dir, input_receiver_fn(features))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在创建模型服务器后，若想对服务器进行请求得到推理结果，就需要将数据构造成Classify与Regress API所能接受的格式，如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-json"&gt;{
  // Optional: serving signature to use.
  // If unspecifed default serving signature is used.
  "signature_name": &amp;lt;string&amp;gt;,

  // Optional: Common context shared by all examples.
  // Features that appear here MUST NOT appear in examples (below).
  "context": {
    "&amp;lt;feature_name3&amp;gt;": &amp;lt;value&amp;gt;|&amp;lt;list&amp;gt;
    "&amp;lt;feature_name4&amp;gt;": &amp;lt;value&amp;gt;|&amp;lt;list&amp;gt;
  },

  // List of Example objects
  "examples": [
    {
      // Example 1
      "&amp;lt;feature_name1&amp;gt;": &amp;lt;value&amp;gt;|&amp;lt;list&amp;gt;,
      "&amp;lt;feature_name2&amp;gt;": &amp;lt;value&amp;gt;|&amp;lt;list&amp;gt;,
      ...
    },
    {
      // Example 2
      "&amp;lt;feature_name1&amp;gt;": &amp;lt;value&amp;gt;|&amp;lt;list&amp;gt;,
      "&amp;lt;feature_name2&amp;gt;": &amp;lt;value&amp;gt;|&amp;lt;list&amp;gt;,
      ...
    }
    ...
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;1.2 Predict API&lt;/h3&gt; 
&lt;p&gt;Predict SignatureDefs支持将tensor作为输入和输出，可通用于分类与回归的推理问题类型。参考以下代码，在input_receiver_fn函数中，读取到数据后构造成tensor，作为模型的输入。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-python"&gt;def input_receiver_fn ():
    feature_map = {}
    for i in range(len(iris_data.CSV_COLUMN_NAMES) -1):
        feature_map[iris_data.CSV_COLUMN_NAMES[i]] = tf.placeholder(
            tf.float32,shape=[3],name='{}'.format(iris_data.CSV_COLUMN_NAMES[i]))
    return tf.estimator.export.build_raw_serving_input_receiver_fn(feature_map)
model.export_savedmodel(export_dir_base=export_dir,serving_input_receiver_fn=input_receiver_fn ())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该情况下对模型服务器发起请求就需要使用Predict API，其所能接受的数据格式如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-json"&gt;{
  // (Optional) Serving signature to use.
  // If unspecifed default serving signature is used.
  "signature_name": &amp;lt;string&amp;gt;,

  // Input Tensors in row ("instances") or columnar ("inputs") format.
  // A request can have either of them but NOT both.
  "instances": &amp;lt;value&amp;gt;|&amp;lt;(nested)list&amp;gt;|&amp;lt;list-of-objects&amp;gt;
  "inputs": &amp;lt;value&amp;gt;|&amp;lt;(nested)list&amp;gt;|&amp;lt;object&amp;gt;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;1.3 在SageMaker中向Serving发送请求&lt;/h3&gt; 
&lt;p&gt;在SageMaker的SDK（&lt;a href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-predictor"&gt;https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-predictor&lt;/a&gt;）中，将上述三种不同的API封装成了三种方法，即创建好Predictor之后，根据上述不同SignatureDefs所能接受的数据格式构造请求，就可以选择调用方法进行推理，Predict API、Classify与Regress API的调用方法如下所示：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;2.将已训练好的TensorFlow模型部署到SageMaker&lt;/h2&gt; 
&lt;p&gt;将模型压缩打包上传到S3之后，有两种方式可以实现模型的部署。&lt;/p&gt; 
&lt;h3&gt;2.1方法一：不提供inference.py脚本&lt;/h3&gt; 
&lt;p&gt;若不需要对请求中的数据进行前处理和后处理，就不需要提供inference.py脚本，实例化TensorFlowModel对象时只需要指定模型在S3中的位置，以及相关的role，如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-python"&gt;from sagemaker.tensorflow import TensorFlowModel
model = TensorFlowModel(model_data='s3://mybucket/model.tar.gz', role='MySageMakerRole')
predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;部署完成之后，在推理时需要根据Serving所使用的SignatureDefs，将数据构造成SignatureDefs可以接受的格式，再调用相关的API进行推理。比如，若使用Classify API进行推理，则需要先将数据构造成1.1节中提到的请求格式，然后调用Predictor的classify方法，将推理数据作为参数传入，即可得到推理结果。&lt;/p&gt; 
&lt;h3&gt;2.2方法二：提供inference.py脚本&lt;/h3&gt; 
&lt;p&gt;若需要对输入模型的数据进行前处理或对推理产生的结果进行后处理，则需要在实例化TensorFlowModel对象时提供inference.py脚本，通过entry_point参数指定，如下所示：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-python"&gt;from sagemaker.tensorflow import TensorFlowModel
model = Model(entry_point='inference.py',
              model_data='s3://mybucket/model.tar.gz',
              role='MySageMakerRole')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在inference.py的代码中需要定义两个函数，分别是input_handler与output_handler。其中input_handler首先需要对传递进来的序列化对象进行解析。比如TensorFlow Serving Predictor默认的serializer为&lt;a href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-predictor"&gt;JSONSerializer&lt;/a&gt;，那么在input_handler中就需要对json序列化对象解析，之后就可以对数据进行前处理操作。类似地，在推理前需要把处理好的数据转化为SignatureDefs所能接受的格式。注意，构造SignatureDefs数据格式这个过程是在input_handler中定义的，这么做的好处就是用户无需在请求Serving前完成请求数据格式的定义，让前端传入的数据更加简洁灵活。&lt;/p&gt; 
&lt;p&gt;同样，在得到推理结果后，可以把数据后处理过程写在output_handler函数中，通过response_centent_type指定序列化对象，将结果返回给前端。&lt;/p&gt; 
&lt;h2&gt;3. 实验&lt;/h2&gt; 
&lt;p&gt;本实验使用已经训练好的iris模型，展示带有inference.py和不带inference.py在SageMaker上进行模型部署的过程，并调用Classify API进行推理。实验所需环境：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用cn-northwest-1区域；&lt;/li&gt; 
 &lt;li&gt;在SageMaker中创建一台Jupyter Notebook实例，创建过程可参考官方文档：&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-create-ws.html"&gt;https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-create-ws.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;下载实验所需的材料：git clone https://github.com/micxyj/awsblog-lab-guide.git，进入文件夹，将tf-byom.zip文件，上传至Notebook环境。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实验步骤如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;打开Notebook命令行，执行以下命令解压zip包；&lt;/li&gt; 
   &lt;li&gt;cd SageMaker/&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="padding-left: 80px"&gt;unzip tf-byom.zip&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;双击打开tf_byom.ipynb笔记本文件，逐步执行notebook中的步骤；&lt;/li&gt; 
   &lt;li&gt;可以看到若不提供inference.py，在进行推理前需要构造好Classify SignatureDefs所能接受的数据格式，如下图key为examples的字典：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker2.png" width="624" height="78"&gt;&lt;/a&gt;SageMaker SDK会把推理数据进行序列化传递给Serving，推理完成之后会将结果反序化回前端。&lt;/li&gt; 
   &lt;li&gt;在提供了inference.py的场景中，由于在input_handler函数中定义了加载列表生成Classify SignatureDefs数据格式，在调用classify进行推理时只需要传入列表数据即可，如下所示：&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-tensorflow-model-on-amazon-sagemaker4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;4. 总结&lt;/h2&gt; 
&lt;p&gt;本文介绍了TensorFlow Serving三种不同SignatureDefs的区别以及调用方法，展示了如何将本地训练的模型在SageMaker上进行部署与推理。通过使用SageMaker，用户可以快速地将模型进行部署上线，无需进行复杂的配置便可实现高可用的、可扩展的模型服务器架构。&lt;/p&gt; 
&lt;h2&gt;5. 参考资料&lt;/h2&gt; 
&lt;p&gt;[1] &lt;a href="https://www.tensorflow.org/tfx/serving/api_rest"&gt;https://www.tensorflow.org/tfx/serving/api_rest&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] &lt;a href="https://www.tensorflow.org/tfx/serving/signature_defs"&gt;https://www.tensorflow.org/tfx/serving/signature_defs&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] &lt;a href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html"&gt;https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xiaoyj.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;肖元君&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责基于AWS云计算方案的架构咨询和设计实现，同时致力于数据分析与AI的研究与应用。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/guoren.png" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;郭韧&lt;/h3&gt; 
  &lt;p&gt;AWS AI和机器学习方向解决方案架构师，负责基于AWS的机器学习方案架构咨询和设计，致力于游戏、电商、互联网媒体等多个行业的机器学习方案实施和推广。在加入AWS之前，从事数据智能化相关技术的开源及标准化工作，具有丰富的设计与实践经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>通过 SageMaker 与 Step Functions 实现机器学习的 CI/CD 方案</title>
		<link>https://aws.amazon.com/cn/blogs/china/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions/</link>
				<pubDate>Fri, 17 Sep 2021 02:30:24 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon SageMaker]]></category>
		<category><![CDATA[CI/CD]]></category>
		<category><![CDATA[machine learning]]></category>
		<category><![CDATA[Step Functions]]></category>

		<guid isPermaLink="false">4722c539101d393551e8507d8163daa7d38e9772</guid>
				<description>本文会介绍通过SageMaker与Step Functions进行模型自动训练与部署的方法，并会与CodeCommit、CodeBuild、Jenkins集成，实现机器学习的CI/CD方案。</description>
								<content:encoded>&lt;p&gt;在传统的机器学习工作流程当中，经常会面临两个问题：（1）数据迭代迅速，需要定期对模型进行重新训练，每次训练完成后，都需要重新部署模型，如何实现训练与部署过程的的自动化，从而提升工作效率；（2）算法团队不断地对算法进行开发与变更，并且需要尝试不同的特征工程，每次变更都需要做单元测试，如何将SageMaker与CI/CD工具整合，在提升开发效率的同时减少运维团队的工作负担。本文会介绍通过SageMaker与Step Functions进行模型自动训练与部署的方法，并会与CodeCommit、CodeBuild、Jenkins集成，实现机器学习的CI/CD方案。&lt;/p&gt; 
&lt;h2&gt;1. 相关技术介绍&lt;/h2&gt; 
&lt;p&gt;在开始之前，请先对以下技术进行简单了解。&lt;/p&gt; 
&lt;h3&gt;1.1 Amazon SageMaker&lt;/h3&gt; 
&lt;p&gt;Amazon SageMaker 是一项完全托管的机器学习PaaS平台，它提供的功能完整的覆盖了整个机器学习生命周期。并且您不需要对用于训练和推理的实例进行维护，只需要根据工作负载指定相应的机型与数量即可，通过简单的API进行模型的一键训练与部署。&lt;/p&gt; 
&lt;h3&gt;1.2 Step Functions&lt;/h3&gt; 
&lt;p&gt;Step Functions是一项云原生的workflow编排工具，在创建时不需要配置基础设施，只需要在工作流程当中指定要执行的步骤即可。Step Functions为开发者提供了&lt;a href="https://aws-step-functions-data-science-sdk.readthedocs.io/en/stable/readmelink.html"&gt;数据科学开发工具包&lt;/a&gt;，并且已经与SageMaker进行了集成，开发者可以通过面向对象编程的方式在workflow中定义SageMaker的步骤，因此可以将模型训练与部署的过程自动化。&lt;/p&gt; 
&lt;h3&gt;1.3 CodeCommit与CodeBuild&lt;/h3&gt; 
&lt;p&gt;CodeCommit与CodeBuild是AWS CI/CD系列当中的两个重要服务，CodeCommit是一项完全托管的代码仓库服务，可以提供给用户近乎无限的代码存储空间，在使用习惯上和标准的git工具没有差异。 CodeBuild 可编译源代码，运行单元测试，并构建可供部署的项目，并且也无需预置、管理和扩展自己的构建服务器，可以在构建请求高峰时实现自动扩展。&lt;/p&gt; 
&lt;h3&gt;1.4 Jenkins&lt;/h3&gt; 
&lt;p&gt;Jenkins是一个自包含的开源自动化服务器，可用于自动化与构建，测试以及交付或部署软件有关的各种任务。它的开源社区非常活跃，整合了1000多种插件，为CI/CD的过程提供了极大的灵活性，并且也可以与AWS Code系列集成，使得开发者可以轻松的集成两者的优势。&lt;/p&gt; 
&lt;h2&gt;2. 演练&lt;/h2&gt; 
&lt;h3&gt;2.1 流程架构图与过程简介&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;（1）在一台EC2上安装Jenkins，配置好与CodeCommit、CodeBuild集成的插件；&lt;br&gt; （2）开发人员push代码到CodeCommit后触发Jenkins pipeline，代码在CodeBuild中封装成docker image，并推送到ECR当中（注：在本实验中，为了方便在CI/CD过程中对代码版本进行控制，会通过BYOC的方式在SageMaker中使用自定义算法，该方式需要自己编写Dockerfile并将算法build为docker image，然后上传到ECR当中，详细介绍可参考&lt;a href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/your-algorithms.html"&gt;将您的算法或模型与Amazon SageMaker结合使用&lt;/a&gt;）；&lt;br&gt; （3）触发Step Functions执行SageMaker训练与部署的步骤；&lt;br&gt; （4）SageMaker从ECR中加载docker image与S3中的数据进行训练；&lt;br&gt; （5）训练完成后对模型进行部署，暴露供推理使用的endpoint。&lt;/p&gt; 
&lt;h3&gt;2.2 前提条件&lt;/h3&gt; 
&lt;p&gt;（1）本文示例所使用的区域为us-east-1；&lt;br&gt; （2）在该区域使用Ubuntu 18.04的AMI创建一台EC2，并确保与其绑定的IAM Role有AdministratorAccess权限，安全组放开8080端口供Jenkins web使用，后续章节有安装Jenkins的具体步骤；&lt;br&gt; （3）为了模拟用户的开发环境，请先在本地或远程服务器配置好git工具与aws的credentials，并确定其拥有AdministratorAccess权限。&lt;/p&gt; 
&lt;h3&gt;2.3 实现过程&lt;/h3&gt; 
&lt;h4&gt;2.3.1 在Step Functions中定义使用SageMaker训练与部署模型的步骤&lt;/h4&gt; 
&lt;p&gt;（1）在SageMaker中创建一台笔记本实例，输入名称并保持其他默认配置，待创建完成后打开JupterLab，在初始界面下拉找到Terminal，点击进入执行cd SageMaker命令；&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;（2）打开IAM console，找到SageMaker自动创建的新角色，添加AdministratorAccess权限；&lt;br&gt; （3）在Terminal中执行命令：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;git clone https://github.com/micxyj/awsblog-lab-guide.git&lt;/code&gt;&lt;br&gt; （4）进入下载好的文件夹，执行unzip package.zip命令进行解压，待解压完成后在Jupyter notebook左侧的工作目录中打开sfn_deploy_byoc.ipynb文件；&lt;br&gt; （5）按照该notebook中的步骤执行一遍即可；&lt;br&gt; （6）执行完成后，打开Step Functions控制台，会看到多出一个状态机，如下图所示：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;（7）选中该状态机，点击定义，可以看到如下所示的工作流，其中定义了SageMaker从训练到部署所需的步骤：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions5.png" width="312" height="39"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.3.2 在EC2上安装Jenkins&lt;/h4&gt; 
&lt;p&gt;在本实验中，Jenkins只用来提供pipeline的作用，构建编译的步骤全部会由CodeBuild来完成。&lt;br&gt; （1）登陆EC2，安装Java环境；&lt;br&gt; &lt;code&gt;sudo apt-get update&lt;/code&gt;&lt;br&gt; &lt;code&gt;sudo apt-get upgrade -y&lt;/code&gt;&lt;br&gt; &lt;code&gt;sudo apt-get install openjdk-8-jdk -y&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;（2）根据&lt;a href="https://pkg.jenkins.io/debian-stable/"&gt;Jenkins官方文档&lt;/a&gt;安装Jenkins 2.235版本；&lt;br&gt; （3）安装完成后，执行下列命令，记下初始密码；&lt;br&gt; &lt;code&gt;sudo cat /var/lib/jenkins/secrets/initialAdminPassword&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;（4）在浏览器输入Jenkins server的URL，输入上一步的初始密码并点击Continue；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （5）选择Install suggested plugins并等待插件安装完成；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （6）配置Admin User并选择Save and Continue，接下来的步骤保持默认并点击继续完成配置；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （7）在Jenkins服务器上切换到jenkins用户，并配置后续实验所需的依赖包。&lt;br&gt; &lt;code&gt;sudo su -&lt;/code&gt;&lt;br&gt; &lt;code&gt;sudo vim /etc/sudoers&lt;/code&gt;&lt;br&gt; &lt;code&gt;# 在文件中的User privilege specification下添加一行：jenkins ALL=(ALL) NOPASSWD: ALL，然后保存并关闭文件&lt;/code&gt;&lt;br&gt; &lt;code&gt;su jenkins&lt;/code&gt;&lt;br&gt; &lt;code&gt;sudo apt install python3-pip&lt;/code&gt;&lt;br&gt; &lt;code&gt;pip3 install awscli --upgrade --user&lt;/code&gt;&lt;br&gt; &lt;code&gt;vim ~/.bashrc&lt;/code&gt;&lt;br&gt; &lt;code&gt;# 在文件中添加一行python路径：export PATH=$HOME/.local/bin:$PATH，然后保存并关闭文件&lt;/code&gt;&lt;br&gt; &lt;code&gt;source ~/.bashrc&lt;/code&gt;&lt;br&gt; &lt;code&gt;# 命令行输入aws configure，不需要设置access id与access key，在Default region name配置中输入us-east-1即可&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;2.3.3 创建CodeCommit与CodeBuild&lt;/h4&gt; 
&lt;p&gt;（1）打开CodeCommit控制台，点击创建存储库；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （2）输入存储库名称并点击创建；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （3）进入到IAM控制台中，选择并配置本地环境使用的iam user的CodeCommit HTTPS Git凭证；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 点击生成凭证后将凭证下载到本地，供实验后续使用&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions15.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions15.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （4）回到CodeCommit控制台，选择第二步中创建好的存储库，克隆HTTPS URL，在本地执行git clone；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions16.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions16.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions17.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions17.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 一般第一次执行git clone会要求用户输入CodeCommit HTTPS Git的凭证，打开上一步下载好的凭证，输入用户名与密码即可，如果有报错，请查询&lt;a href="https://docs.aws.amazon.com/zh_cn/codecommit/latest/userguide/troubleshooting.html"&gt;CodeCommit问题排查&lt;/a&gt;。&lt;br&gt; （5）从github上下载实验所需代码到本地，并上传到CodeCommit的代码仓库；&lt;br&gt; &lt;code&gt;git clone https://github.com/micxyj/ml-ops.git&lt;/code&gt;&lt;br&gt; &lt;code&gt;cp -r ml-ops/* ml-ops-codecommit&lt;/code&gt;&lt;br&gt; &lt;code&gt;cd ml-ops-codecommit&lt;/code&gt;&lt;br&gt; &lt;code&gt;git add .&lt;/code&gt;&lt;br&gt; &lt;code&gt;git commit -m 'update'&lt;/code&gt;&lt;br&gt; &lt;code&gt;git push&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;push成功之后，回到CodeCommit控制台，打开存储库，发现代码已经上传完成；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions18.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions18.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 在cifar10文件夹中包含了使用tensorflow对cifar-10数据集进行训练与创建tersorflow serving的代码，会通过Dockerfile文件与build_and_push.sh打包封装成docker image并上传到ECR当中，上传完成后会执行invoke_sfn.py脚本，运行已经定义好的Step Functions状态机，从而完成SageMaker训练与部署的过程。&lt;br&gt; （6）打开CodeBuild控制台，按照下述信息创建项目；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions19.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions19.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions20.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions20.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions21.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions21.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions22.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions22.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions23.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions23.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; Buildspec中定义的代码即为在构建编译过程中所需要执行的命令，可以把该过程理解为：1）下载执行脚本所需的依赖包boto3；2）执行build_and_push.sh脚本将算法封装成docker image并上传到ECR；3）执行invoke_sfn.py脚本，触发Step Functions状态机进行模型的训练与部署。在build commands下复制粘贴以下代码：&lt;br&gt; &lt;code&gt;- pip install boto3&lt;/code&gt;&lt;br&gt; &lt;code&gt;- chmod 777 build_and_push.sh&lt;/code&gt;&lt;br&gt; &lt;code&gt;- ./build_and_push.sh sagemaker-tf-cifar10-example&lt;/code&gt;&lt;br&gt; &lt;code&gt;- python invoke_sfn.py&lt;/code&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions24.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions24.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions25.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions25.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 其他配置保持默认即可，点击创建构建项目。&lt;br&gt; （7）打开iam role的控制台，赋予codebuild-ml-ops-service-role角色AmazonEC2ContainerRegistryFullAccess与AWSStepFunctionsFullAccess的权限；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions26.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions26.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.3.4 将CodeCommit、CodeBuild与Jenkins集成&lt;/h4&gt; 
&lt;p&gt;（1）打开jenkins web页面，下载与CodeCommit、CodeBuild集成的相关插件；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions27.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions27.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （2）搜索AWS CodeCommit Trigger与AWS CodeBuild插件并安装，安装完成之后点击restart；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions28.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions28.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （3）配置AWS CodeCommit Trigger插件；&lt;br&gt; &lt;a href="https://plugins.jenkins.io/aws-codecommit-trigger/"&gt;AWS CodeCommit Trigger&lt;/a&gt;插件需要通过SQS与SNS来实现webhook的功能（即push代码到CodeCommit之后，触发Jenkins Pipeline），因此需要先对SQS与SNS进行配置。&lt;br&gt; 创建一个新的SNS主题并输入名称。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions29.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions29.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions30.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions30.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 将以下json代码复制到访问策略当中，将your_account_id与your_sns_name替换为你的账户id和SNS名称，其他配置保持不变并点击创建主题。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;{&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; "Version": "2008-10-17",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; "Id": "__default_policy_ID",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; "Statement": [&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Sid": "__default_statement_ID",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Effect": "Allow",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Principal": {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "AWS": "*"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; },&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Action": [&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:Publish",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:RemovePermission",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:SetTopicAttributes",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:DeleteTopic",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:ListSubscriptionsByTopic",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:GetTopicAttributes",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:Receive",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:AddPermission",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "SNS:Subscribe"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ],&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Resource": "arn:aws:sns:us-east-1:your_account_id:your_sns_name",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Condition": {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "StringEquals": {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "AWS:SourceOwner": "your_account_id"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; ]&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions31.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions31.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 打开CodeCommit控制台，配置触发器，按图中信息进行配置，选择刚刚创建好的SNS主题后点击创建触发器。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions32.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions32.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions33.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions33.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 打开SQS控制台，创建SQS队列并输入名称。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions34.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions34.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions35.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions35.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 复制以下json代码到访问策略当中，将your_account_id、your_sqs_name、your_sns_name替换为相应的信息，其他配置保持不变并点击创建。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;{&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; "Version": "2012-10-17",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; "Id": "arn:aws:sqs:us-east-1:your_account_id:your_sqs_name/SQSDefaultPolicy",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; "Statement": [&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Effect": "Allow",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Principal": {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Service": "sns.amazonaws.com"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; },&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Action": "sqs:SendMessage",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Resource": "arn:aws:sqs:us-east-1:your_account_id:your_sqs_name",&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "Condition": {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; "ArnEquals": {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;"aws:SourceArn": "arn:aws:sns:us-east-1:your_account_id:your_sns_name"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; ]&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions36.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions36.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 点击订阅SNS主题，选择之前创建好的SNS主题ARN后保存即可。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions37.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions37.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions38.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions38.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 打开Jenkins web页面，点击系统配置。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions39.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions39.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 下拉到AWS Code Commit Trigger SQS Plugin栏目，首先添加aws的credentials，使用具有AdministratorAccess权限的iam user即可。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions40.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions40.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions41.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions41.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 添加完成credentials之后，选择刚创建好的credentials、正确的region（us-east-1）与之前创建好的sqs队列，点击Test access，返回successful则表示配置正确，最后点击save。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions42.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions42.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （4）创建Jenkins Item；&lt;br&gt; 输入名称ml-ops-pipeline并选择Pipeline。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions43.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions43.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 在Pipeline中的Build Triggers栏目，勾选“Build when a CodeCommit repository is updated and notifies a SQS queue”，点击 “Manually enter CodeCommit URL and branches”，在“Code commit repository URL”处输入CodeCommit代码仓库的Git URL。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions44.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions44.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 下拉到Pipeline栏目，在“Definition”中选择“Pipeline script from SCM”，在“SCM”中选择“Git”。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions45.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions45.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 点击“Credentials”旁的“add”按钮，选择Jenkins，将弹出如下页面，输入为CodeCommit的Git credentials（其中Username与Password都在2.3.3章节提到的Git凭证中）：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions46.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions46.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 添加完成之后，输入CodeCommit代码仓库的Git URL与刚创建好的Credentials。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions47.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions47.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 其他配置保持默认选项，点击Save。&lt;/p&gt; 
&lt;h4&gt;3. 展示&lt;/h4&gt; 
&lt;p&gt;（1）打开下载到本地的CodeCommit远程仓库代码文件夹，打开invoke_sfn.py文件，将your_account_id与your_step_functions_name分别替换为你的账户id与之前执行notebook后生成的Step Functions状态机的名称；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions48.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions48.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （2）打开Jenkinsfile，将your_project_name替换为你的CodeBuild项目名称，从代码中可以看出，Jenkins安装完成AWS CodeBuild插件之后，就可以以常见的Groovy语法定义需要执行的step，触发CodeBuild执行相应的构建编译的过程，因此，Jenkins在这里只起到调度的作用，编译构建的负载全部交给CodeBuild来完成，用户并不需要预置底层资源；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions49.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions49.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （3）此时代码已经发生了变更，push代码到Codecommit当中，触发整个CI/CD的流程；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions50.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions50.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （4）查看CodeBuild的构建日志，任务正在执行，由于Jenkins安装了CodeBuild的插件，也可以在Jenkins的console上看到相同的日志输出，可以利用这一机制，在Jenkins上对构建过程的输出进行统一监控管理；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions51.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions51.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions52.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions52.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （5）待CodeBuild将docker image上传到ECR之后，会执行buildspec中第二个步骤，触发Step Functions，打开Step Functions与SageMaker训练任务的界面，可以看到SageMaker训练过程正在执行；&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions53.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions53.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions54.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions54.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions55.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions55.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; （6）待状态机中部署的过程执行完成，打开SageMaker的终端节点界面，可以看到终端节点正在创建过程当中，待创建完成之后，就可以用于推理。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions56.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions56.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions57.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/ci-cd-solution-for-machine-learning-through-sagemaker-and-step-functions57.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;4. 总结&lt;/h2&gt; 
&lt;p&gt;本文介绍了如何利用Step Functions定义SageMaker中训练与部署的过程，当模型需要重新训练时，可以直接触发Step Functions中定义好的状态机，从而减少运维人员重复工作；当算法或特征工程代码发生变更时，需要考虑如何实现MLOps，AWS的Code系列可以轻松和开源的工具集成，开发者可以利用到两者的优势，比如可以使用Jenkins提供的多种插件，并且在编译构建的过程中使用CodeBuild，将任务高峰期扩展资源的任务交给AWS自动完成。本文通过上述两个场景实现机器学习的CI/CD过程，从而进一步提升算法工程师的开发效率，减少运维团队的工作负担。&lt;/p&gt; 
&lt;h2&gt;5. 参考资料&lt;/h2&gt; 
&lt;p&gt;[1] &lt;a href="https://aws.amazon.com/blogs/machine-learning/automating-model-retraining-and-deployment-using-the-aws-step-functions-data-science-sdk-for-amazon-sagemaker/"&gt;Automating model retraining and deployment using the AWS Step Functions Data Science SDK for Amazon SageMaker&lt;/a&gt;&lt;br&gt; [2] &lt;a href="https://aws.amazon.com/blogs/machine-learning/automated-and-continuous-deployment-of-amazon-sagemaker-models-with-aws-step-functions/"&gt;Automated and continuous deployment of Amazon SageMaker models with AWS Step Functions&lt;/a&gt;&lt;br&gt; [3] &lt;a href="https://docs.aws.amazon.com/zh_cn/codebuild/latest/userguide/jenkins-plugin.html"&gt;将 AWS CodeBuild 与 Jenkins 结合使用&lt;/a&gt;&lt;br&gt; [4] &lt;a href="https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/tensorflow_bring_your_own/tensorflow_bring_your_own.ipynb"&gt;Building your own TensorFlow container&lt;/a&gt;&lt;br&gt; [5] &lt;a href="https://martinfowler.com/articles/cd4ml.html"&gt;Continuous Delivery for Machine Learning&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xiaoyj.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/tag/肖元君/"&gt;肖元君&lt;/a&gt;&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责基于AWS云计算方案的架构咨询和设计实现，同时致力于数据分析与AI的研究与应用。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/zhongmij.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/tag/金忠敏/"&gt;金忠敏&lt;/a&gt;&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，现在专注于云计算解决方案和架构的工作。具有超过15年的IT从业经验，曾从事软件开发，售后支持，系统交付，售前等工作。参与过很多大型项目架构设计和实施交付。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/panxiank.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/tag/Pan Xiankun/"&gt;Pan Xiankun&lt;/a&gt;&lt;/h3&gt; 
  &lt;p&gt;AWS 解决方案架构师&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>Apache Atlas数据血缘</title>
		<link>https://aws.amazon.com/cn/blogs/china/apache-atlas-data-bloodline/</link>
				<pubDate>Fri, 17 Sep 2021 01:58:55 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[AWS Big Data]]></category>
		<category><![CDATA[Atlas]]></category>
		<category><![CDATA[Data lineage]]></category>
		<category><![CDATA[EMR]]></category>
		<category><![CDATA[Glue]]></category>

		<guid isPermaLink="false">a40960c10059e527e5918807fd30af0012f6bd08</guid>
				<description>Atlas 是一套可伸缩且可扩展的数据治理服务，使企业能够有效和高效地满足其在 Hadoop 生态中的合规要求，并允许与整个企业数据生态系统集成。</description>
								<content:encoded>&lt;h2&gt;一.&amp;nbsp; 什么是数据血缘&lt;/h2&gt; 
&lt;p&gt;数据血缘跟踪、记录、展示了数据来自何处，以及在数据流转过程中应用了哪些转换操作，它有助于追溯数据来源及处理过程。&lt;/p&gt; 
&lt;p&gt;数据血缘系统的核心功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;数据资产的自动发现及创建&lt;/li&gt; 
 &lt;li&gt;血缘关系的自动发现及创建&lt;/li&gt; 
 &lt;li&gt;不同视角的血缘及资产分析展示&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;与数据血缘容易混淆的概念：数据起源。数据起源重点在于跟踪数据的原始来源，包括与数据相关的采集、规则、流程，以帮助数据工程师评估数据的质量。&lt;/p&gt; 
&lt;h2&gt;二.&amp;nbsp; Apache Atlas及其特性&lt;/h2&gt; 
&lt;p&gt;Atlas 是一套可伸缩且可扩展的数据治理服务，使企业能够有效和高效地满足其在 Hadoop 生态中的合规要求，并允许与整个企业数据生态系统集成。&lt;/p&gt; 
&lt;p&gt;Atlas 为组织提供开放的元数据管理和治理能力，以建立其数据资产目录、对这些资产进行分类和管理，并为数据科学家、分析师和数据治理团队提供围绕这些数据资产的协作能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;元数据及实体&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;预定义的Hadoop及非Hadoop系统的元数据类型。&lt;/p&gt; 
&lt;p&gt;基于Rest API的类别及实体管理&lt;/p&gt; 
&lt;p&gt;类别及实体的自动捕获&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;数据血缘&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;血缘自动捕获&lt;/p&gt; 
&lt;p&gt;可探查的数据血缘展示&lt;/p&gt; 
&lt;p&gt;基于Rest API的数据血缘管理&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;搜索&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可按数据资产类别，实体及属性的搜索&lt;/p&gt; 
&lt;p&gt;基于Rest API的复杂搜索&lt;/p&gt; 
&lt;p&gt;类SQL的搜索语言&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;安全及敏感数据遮蔽&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;元数据访问的细粒度管控。&lt;/p&gt; 
&lt;p&gt;与Apache Ranger集成，进行基于实体分类的授权及数据遮蔽。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;分类&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;类别自动发现&lt;/p&gt; 
&lt;p&gt;实体类别标签自动化&lt;/p&gt; 
&lt;p&gt;基于血缘分类传播&lt;/p&gt; 
&lt;h2&gt;三.&amp;nbsp; 数据血缘视角&lt;/h2&gt; 
&lt;h3&gt;（一）工程师视角&lt;/h3&gt; 
&lt;p&gt;数据工程师通常希望看到数据处理细节的血缘，例如数据处理过程中的mapping，de-duplicate，data masking，merge，join， update, delete, insert等诸如此类的操作，这样便于在数据出现问题的时候方便他们进行回溯分析定位。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-data-bloodline1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-data-bloodline1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;（二）业务用户视角&lt;/h3&gt; 
&lt;p&gt;业务用户通常希望看到数据从哪里来，经过了那些关键的处理环节，每个处理环节是谁来负责，他们通常不关心诸如merge，join等非常技术细节的操作。例如：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-data-bloodline2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-data-bloodline2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在这个典型的用户视角内，最左侧的数据原始发源地，以及爬虫，ftp这些关键节点事实上很难被Apache Atlas自动发现和管理，在Apache Atlas内这部元数据通常需要手工捕获。&lt;/p&gt; 
&lt;p&gt;根据Apache Atlas版本特性来看，1.0并不支持实体类型的图标定制化功能。2.1的版本支持实体类型图标定制化功能，哥尼斯堡七桥问题成功阐释了一幅图胜过千言万语，同时也诞生了一个全新的学科：图论，选择符合业务实际场景的实体图标类型，往往能减少很多不必要的解释说明。&lt;/p&gt; 
&lt;p&gt;注意：Apache Atlas不是一个可以同时兼容两种血缘视角的软件。实际场景，手工捕获缺失的关键实体类别及实体信息，形成完整的数据血缘关系。&lt;/p&gt; 
&lt;h2&gt;四.&amp;nbsp; Apache Atlas编译部署&lt;/h2&gt; 
&lt;p&gt;Apache Atlas提供了&lt;a href="https://atlas.apache.org/#/BuildInstallation"&gt;两种构建模式&lt;/a&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;标准模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;标准模式通常用于部署在生产环境中。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;mvn clean -DskipTests package -Pdist&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;嵌入式模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;嵌入式构建模式提供了开箱即用的功能，通常用于PoC或者小规模场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;预打包Hbase及Solr&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;mvn clean -DskipTests package -Pdist,embedded-hbase-solr&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;其中Hbase为Atlas图库提供存储，而Solr则负责为Atlas提供搜索。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;预打包Cassandra及Solr&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;mvn clean package -Pdist,embedded-cassandra-solr&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;其中Cassandra为Atlas图库提供存储，而Solr则负责为Atlas提供搜索。&lt;/p&gt; 
&lt;p&gt;不论选择哪种构建模式，避免配置阿里的Maven镜像仓库，因为缺少部分依赖包而无法完成构建，在构建过程中，至少保证有20GB的可用空间，构建会在少于2小时内完成。&lt;/p&gt; 
&lt;p&gt;以嵌入式embedded-hbase-solr为例部署一个快速原型的环境。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;#!/bin/bash
# This script was tested in EMR 6.3 environment.
# The "embedded Apache HBase &amp;amp; Apache Solr" was tested.

# Create apache directory
sudo mkdir /apache 
sudo chown hadoop.hadoop /apache

# Download JDK
cd /apache
wget https://corretto.aws/downloads/latest/amazon-corretto-11-x64-linux-jdk.tar.gz
tar xzf amazon-corretto-11-x64-linux-jdk.tar.gz

# Download Atlas-2.1.0
# ---------------start---------------
cd /apache
# Please upload your compiled distribution package into your bucket and grant read permission.
curl -O https://your-s3-bucketname.s3.amazonaws.com/apache-atlas-2.1.0-bin.tar.gz
tar xzf apache-atlas-2.1.0-bin.tar.gz
# Configuration
# atlas-env.sh 
# 20 export JAVA_HOME=/apache/amazon-corretto-11.0.12.7.1-linux-x64
sed -i "s%.*export JAVA_HOME.*%export JAVA_HOME=/apache/amazon-corretto-11.0.12.7.1-linux-x64%" /apache/apache-atlas-2.1.0/conf/atlas-env.sh 
sed -i "s%.*export JAVA_HOME.*%export JAVA_HOME=/apache/amazon-corretto-11.0.12.7.1-linux-x64%" /apache/apache-atlas-2.1.0/hbase/conf/hbase-env.sh 

# atlas-application.properties 
# 104 atlas.notification.embedded=false
# 106 atlas.kafka.zookeeper.connect=localhost:2181
# 107 atlas.kafka.bootstrap.servers=localhost:9092
sed -i "s/atlas.graph.index.search.solr.zookeeper-url.*/atlas.graph.index.search.solr.zookeeper-url=localhost:9983" /apache/apache-atlas-2.1.0/conf/atlas-application.properties 
sed -i "s/atlas.notification.embedded=.*/atlas.notification.embedded=false/" /apache/apache-atlas-2.1.0/conf/atlas-application.properties 
sed -i "s/atlas.kafka.zookeeper.connect=.*/atlas.kafka.zookeeper.connect=localhost:9983/" /apache/apache-atlas-2.1.0/conf/atlas-application.properties 
sed -i "s/atlas.kafka.bootstrap.servers=.*/atlas.kafka.bootstrap.servers=localhost:9092/" /apache/apache-atlas-2.1.0/conf/atlas-application.properties
sed -i "s/atlas.audit.hbase.zookeeper.quorum=.*/atlas.audit.hbase.zookeeper.quorum=localhost/" /apache/apache-atlas-2.1.0/conf/atlas-application.properties
# ---------------end---------------


# Solr start
# ---------------start---------------
# Export environment variable
export JAVA_HOME=/apache/amazon-corretto-11.0.12.7.1-linux-x64
export SOLR_BIN=/apache/apache-atlas-2.1.0/solr/bin
export SOLR_CONF=/apache/apache-atlas-2.1.0/conf/solr

# Startup solr
$SOLR_BIN/solr start -c 

# Initialize the index
$SOLR_BIN/solr create_collection -c vertex_index   -d $SOLR_CONF 
$SOLR_BIN/solr create_collection -c edge_index     -d $SOLR_CONF 
$SOLR_BIN/solr create_collection -c fulltext_index -d $SOLR_CONF 
# ---------------end---------------

# Config the hive hook
# ---------------start---------------
sudo sed -i "s#&amp;lt;/configuration&amp;gt;#   &amp;lt;property&amp;gt;\n     &amp;lt;name&amp;gt;hive.exec.post.hooks&amp;lt;/name&amp;gt;\n     &amp;lt;value&amp;gt;org.apache.atlas.hive.hook.HiveHook&amp;lt;/value&amp;gt;\n   &amp;lt;/property&amp;gt;\n\n&amp;lt;/configuration&amp;gt;#" /etc/hive/conf/hive-site.xml
sudo cp /apache/apache-atlas-2.1.0/conf/atlas-application.properties /etc/hive/conf
sudo sed -i 's%export HIVE_AUX_JARS_PATH.*hcatalog%export HIVE_AUX_JARS_PATH=${HIVE_AUX_JARS_PATH}${HIVE_AUX_JARS_PATH:+:}/usr/lib/hive-hcatalog/share/hcatalog:/apache/apache-atlas-2.1.0/hook/hive%' /etc/hive/conf/hive-env.sh
sudo cp -r /apache/apache-atlas-2.1.0/hook/hive/* /usr/lib/hive/auxlib/
sudo systemctl stop hive-server2
sudo systemctl start hive-server2
# ---------------end---------------

# Start atlas
# ---------------start---------------
# Initialize will be completed in 15 mintues
export MANAGE_LOCAL_HBASE=true
export MANAGE_LOCAL_SOLR=true
python2 /apache/apache-atlas-2.1.0/bin/atlas_start.py
python2 /apache/apache-atlas-2.1.0/bin/atlas_stop.py
python2 /apache/apache-atlas-2.1.0/bin/atlas_start.py
# ---------------end---------------


# Download and startup kafka
# ---------------start---------------
cd /apache
curl -O https://mirrors.bfsu.edu.cn/apache/kafka/2.8.0/kafka_2.13-2.8.0.tgz
tar xzf kafka_2.13-2.8.0.tgz
sed -i "s/zookeeper.connect=.*/zookeeper.connect=localhost:9983/" /apache/kafka_2.13-2.8.0/config/server.properties
/apache/kafka_2.13-2.8.0/bin/kafka-server-start.sh -daemon /apache/kafka_2.13-2.8.0/config/server.properties
# ---------------end---------------&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;Apache Atlas虽然内嵌了Hive/Hbase/Sqoop/Storm/Falcon/Kafka的hook，但是除此之外的其他处理引擎的plugin极少，例如目前广泛使用的Spark/Flink，如果使用这两个计算引擎处理数据，则需要进行定制开发才能捕获相关的数据血缘。&lt;/p&gt; 
&lt;h2&gt;五.&amp;nbsp; 手工捕获数据&lt;/h2&gt; 
&lt;p&gt;Apache Atlas是一个典型的类型继承系统，在追加无法通过Atlas hook或者plugin自动捕获的数据时，必须先了解其类型系统，及血缘的形成原理。然后根据业务需要创建必要的子类型及其实体。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-data-bloodline3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-data-bloodline3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;其中绿色标记的为DataSet静态子类型，红色标记的为Process子类型，Process实体通过连接作为输入输出的DataSet子类型实体从而形成血缘关系。&lt;/p&gt; 
&lt;p&gt;本文业务用户视角血缘的demo由于涉及较多的代码，详细步骤及代码，请参见：&lt;a href="https://github.com/picomy/manually-catch-data-for-atlas"&gt;https://github.com/picomy/manually-catch-data-for-atlas&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;六.&amp;nbsp; Spark与Apache Atlas&lt;/h2&gt; 
&lt;p&gt;捕获Spark数据血缘可以采用以下两大类的方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Connector， 优点自动化数据捕获&lt;/li&gt; 
 &lt;li&gt;REST API，优点定制化程度高&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;（一） &lt;a href="/github.com/hortonworks-spark/spark-atlas-connector"&gt;spark-atlas-connector&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;是Hortonworks开源的Connector，最后一次代码更新是在2019年7月12日，从实际的代码编译结果来看，与Spark 3.1.1存在兼容性问题。该项目默认的配置(pom.xml)：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Spark 2.4.0&lt;/li&gt; 
 &lt;li&gt;Scala 2.11.12&lt;/li&gt; 
 &lt;li&gt;Atlas 2.0.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果是2.4.0本的Spark可以考虑采用该connector。&lt;/p&gt; 
&lt;p&gt;对于该项目使用文档的一些补充，如果使用rest api方式进行数据的自动填充，请配置以下参数：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;rest.address&lt;/li&gt; 
 &lt;li&gt;client.username&lt;/li&gt; 
 &lt;li&gt;client.password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些配置选项来源于AtlasClientConf.scala文件。&lt;/p&gt; 
&lt;h3&gt;（二）&lt;a href="https://absaoss.github.io/spline/"&gt;spline&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;是目前活跃度较高的捕获Spark数据血缘的开源项目，但是它与Atlas兼容性不好，而是自成一体，但是该项目对于Spark的兼容性非常好。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/picomy.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/tag/杨帅军/"&gt;杨帅军&lt;/a&gt;&lt;/h3&gt; 
  &lt;p&gt;资深数据架构师，专注于数据处理。目前主要为车企提供数据治理服务。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>Step-by-Step 快速上手 AWS IoT OTA 固件升级</title>
		<link>https://aws.amazon.com/cn/blogs/china/step-by-step-hands-on-aws-iot-ota-hardware-update/</link>
				<pubDate>Thu, 16 Sep 2021 08:46:54 +0000</pubDate>
		<dc:creator><![CDATA[郭松]]></dc:creator>
				<category><![CDATA[Internet of Things]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<category><![CDATA[Amazon S3]]></category>
		<category><![CDATA[AWS EC2]]></category>
		<category><![CDATA[AWS IoT Core]]></category>
		<category><![CDATA[AWS IoT Device Management]]></category>
		<category><![CDATA[郭松]]></category>

		<guid isPermaLink="false">386ab79b3a344d8b589ef7e767d672c213cdf8f4</guid>
				<description>本文旨在帮助读者一步步的快速上手并理解 OTA 升级流程，其中会使用到 AWS IoT Core, IoT Device Management, EC2 以及 S3 的相关功能。关于在开发过程中的具体流程可以配合参考&amp;nbsp;AWS IoT Device SDK&amp;nbsp;文档和另外一篇官方博客。</description>
								<content:encoded>&lt;p&gt;为了保证物联网设备能够保持在功能上随时更新，并且在出现问题的时候及时得到修复。小到智能手环，空气净化器，大到家用汽车，设备厂商无不是通过提供OTA（Over-The-Air）功能来提高用户满意度。而利用 AWS IoT Device Management 中的 Jobs 组件，可以帮助客户非常快速的开发出物联网设备的 OTA 功能。本文旨在帮助读者一步步的快速上手并理解 OTA 升级流程，其中会使用到 AWS IoT Core, IoT Device Management, EC2 以及 S3 的相关功能。关于在开发过程中的具体流程可以配合参考&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/iot/latest/developerguide/iot-sdks.html" rel="nofollow"&gt;AWS IoT Device SDK&lt;/a&gt;&amp;nbsp;文档和另外一篇&lt;a href="https://aws.amazon.com/cn/blogs/china/aws-iot-series-4/" rel="nofollow"&gt;官方博客&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;&lt;a id="user-content-准备工作" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"&gt;准备工作&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用具有 admin 权限的用户登陆 AWS Console。&lt;/li&gt; 
 &lt;li&gt;本文中的AWS IoT 设备会使用一台&lt;a href="https://aws.amazon.com/cn/ec2/" rel="nofollow"&gt;Amazon Linux EC2&lt;/a&gt;实例模拟，Amazon Linux EC2 实例上默认安装了AWS 命令行工具AWSCLI，接下来的所有操作都是以 AWS 北京区为示例。启动一台 Amazon Linux EC2 实例作为模拟的IoT设备，由于后面安装要安装的rpm包有依赖关系，这里要确保使用的是 Amazon Linux AMI 2018.03.0 (HVM)。另外为了保证网络畅通，在实验环节Security Group建议开放全部的IP和端口。&lt;/li&gt; 
 &lt;li&gt;在 AWS Console 上赋予这台 EC2 实例一个具有足够权限的 Role，测试中可以直接用admin权限。&lt;/li&gt; 
 &lt;li&gt;登陆到 EC2 实例上使用 aws configure 命令配置好默认 Region 为 cn-north-1。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;a id="user-content-操作流程" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B"&gt;操作流程&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;环境准备&lt;/li&gt; 
 &lt;li&gt;在 AWS 上创建 IoT Thing&lt;/li&gt; 
 &lt;li&gt;编写 AWS IoT Jobs 文档&lt;/li&gt; 
 &lt;li&gt;运行 IoT 设备端程序&lt;/li&gt; 
 &lt;li&gt;创建 AWS IoT Jobs 进行固件升级&lt;/li&gt; 
 &lt;li&gt;验证固件升级是否成功&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;a id="user-content-第一步---环境准备" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E7%AC%AC%E4%B8%80%E6%AD%A5---%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"&gt;第一步 – 环境准备&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;登陆 EC2 实例，安装 git&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ sudo yum install git&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;安装 node.js&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash
$ . ~/.nvm/nvm.sh
$ nvm install node&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;安装 AWS IoT Device SDK – Javascript&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ git clone https://github.com/aws/aws-iot-device-sdk-js.git
$ cd aws-iot-device-sdk-js
$ npm install&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;下载两个不同版本的 telnet 程序包，后续模拟固件升级时使用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ cd ~/aws-iot-device-sdk-js/examples/
$ wget https://www.rpmfind.net/linux/centos/6.10/os/x86_64/Packages/telnet-0.17-48.el6.x86_64.rpm
$ wget https://www.rpmfind.net/linux/centos/7.6.1810/os/x86_64/Packages/telnet-0.17-64.el7.x86_64.rpm&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;安装旧版本 telnet 程序，后续我们会通过 OTA 完成这个程序从 telnet-0.17-48.el6.x86_64 版本到 telnet-0.17-64.el7.x86_64 版本的升级&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ sudo rpm -ivh telnet-0.17-48.el6.x86_64.rpm&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;创建一个 S3 bucket 作为新固件的存储位置，并上传新版本的 telnet 程序&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ aws s3 mb s3://example-bucket-123 # 桶名请替换成自己定义的名称
$ aws s3 cp telnet-0.17-64.el7.x86_64.rpm s3://example-bucket-123&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;a id="user-content-第二步---在-aws-上创建-iot-thing" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E7%AC%AC%E4%BA%8C%E6%AD%A5---%E5%9C%A8-aws-%E4%B8%8A%E5%88%9B%E5%BB%BA-iot-thing"&gt;第二步 – 在 AWS 上创建 IOT thing&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建 IoT thing，记录下输出中的 thingArn:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ aws iot create-thing --thing-name aws-iot-device-sdk-js
{
    "thingArn": "arn:aws-cn:iot:cn-north-1:408221054609:thing/aws-iot-device-sdk-js", 
    "thingName": "aws-iot-device-sdk-js", 
    "thingId": "35e3e6ab-da11-489f-8375-196427cb61f4"
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;下载 AWS IoT 根证书，创建 IoT 设备证书和密钥，记录下生成的 certificateArn:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;div class="hide-language"&gt; 
   &lt;pre&gt;&lt;code class="lang-json"&gt;$ pwd
/home/ec2-user/aws-iot-device-sdk-js/examples
$ mkdir certs
$ cd certs
$ wget https://www.amazontrust.com/repository/AmazonRootCA1.pem
$ mv AmazonRootCA1.pem root-CA.crt
$ aws iot create-keys-and-certificate \
    --certificate-pem-outfile "certificate.pem.crt" \
    --public-key-outfile "public.pem.key" \
    --private-key-outfile "private.pem.key"
#从上一步的命令输出中记录下自己的 certificateArn, 后面的命令中会用到
#example: 

"certificateArn": "arn:aws-cn:iot:cn-north-1:408221054609:cert/661bdfb4f083bf58607ac1a54904162e0f91f542e9969b58ee10136ded565925"&lt;/code&gt;&lt;/pre&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;创建一个 IoT Policy，挂载给证书并激活证书:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ cd .. 
$ pwd
/home/ec2-user/aws-iot-device-sdk-js/examples

# 编写一个 policy 文档，复制以下JSON格式的策略并保存为 iot-policy.json 文件
$ vi iot-policy.json  
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "iot:Publish",
        "iot:Subscribe",
        "iot:Connect",
        "iot:Receive"
      ],
      "Resource": [
        "*"
      ]
    }
  ]
}

# 创建 iot policy
$ aws iot create-policy --policy-name ota-policy --policy-document file://iot-policy.json 

# 挂载 policy 到之前创建的 IoT 设备证书上，注意这里的 --target 替换成自己的证书Arn
$ aws iot attach-policy \
    --policy-name ota-policy \
    --target "arn:aws-cn:iot:cn-north-1:408221054609:cert/661bdfb4f083bf58607ac1a54904162e0f91f542e9969b58ee10136ded565925"
    
# 激活证书，注意 --certificate-id 替换成自己证书的id
$ aws iot update-certificate --certificate-id 661bdfb4f083bf58607ac1a54904162e0f91f542e9969b58ee10136ded565925 --new-status ACTIVE

# Attach thing 到证书，其中 --principal 是自己证书的 Arn
$ aws iot attach-thing-principal --thing-name aws-iot-device-sdk-js --principal arn:aws-cn:iot:cn-north-1:408221054609:cert/661bdfb4f083bf58607ac1a54904162e0f91f542e9969b58ee10136ded565925&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;a id="user-content-第三步---编写-aws-iot-jobs-文档" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E7%AC%AC%E4%B8%89%E6%AD%A5---%E7%BC%96%E5%86%99-aws-iot-jobs-%E6%96%87%E6%A1%A3"&gt;第三步 – 编写 AWS IoT Jobs 文档&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;编写一个 IoT Jobs 文档。关于文档编写的格式，请参考&amp;nbsp;&lt;a href="https://github.com/aws/aws-iot-device-sdk-js#jobsAgent%E3%80%82%E5%BD%93"&gt;https://github.com/aws/aws-iot-device-sdk-js#jobsAgent。当&lt;/a&gt;IoT 设备请求 IoT Jobs 文档时，AWS IoT 会生成预签名 URL 并使用预签名 URL 替换占位符 URL。然后将 IoT Jobs 文档发送到设备，设备会通过这个预签名 URL 取得访问 S3 bucket 中固件的权限。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ pwd
/home/ec2-user/aws-iot-device-sdk-js/examples

# 编写一个jobs文档，复制以下JSON格式文档并保存为 jobs-document.json 文件。其中 “example-bucket-123” 请替换成您自己 S3 桶的名字。
$ vi jobs-document.json
{
  "operation": "install",
  "packageName": "new-firmware",
  "workingDirectory": "../examples",
  "launchCommand": "sudo rpm -Uvh new-firmware.rpm",
  "autoStart": "true",
  "files": [
    {
      "fileName": "new-firmware.rpm",
      "fileVersion": "1.0",
      "fileSource": {
        "url": "${aws:iot:s3-presigned-url:https://example-bucket-123.s3.cn-north-1.amazonaws.com.cn/telnet-0.17-64.el7.x86_64.rpm}"
      }
    }
  ]
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;上传 IoT Jobs 文档到 S3 bucket&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ aws s3 cp jobs-document.json s3://example-bucket-123&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;在创建使用预签名 Amazon S3 URL 的 Job 时，您必须提供一个 IAM 角色，该角色可授予 AWS IoT 服务从 Amazon S3 存储桶中下载文件的权限。该角色还必须向 AWS IoT 授予 assumeRole 的权限，也就是让 AWS IoT 具有代表设备去 S3 上面下载固件的权限。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;# 编写一个 assumeRole 的 policy 文档，复制以下JSON格式的策略并保存为 trust-policy.json 文件
$ vi trust-policy.json 
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": [
          "iot.amazonaws.com"
        ]
      },
      "Action": "sts:AssumeRole"
    }
  ]
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;# 创建 IAM Role, 记录下 Arn
$ aws iam create-role --role-name iot-access-s3 --assume-role-policy-document file://trust-policy.json 
{
    "Role": {
        "AssumeRolePolicyDocument": {
            "Version": "2012-10-17", 
            "Statement": [
                {
                    "Action": "sts:AssumeRole", 
                    "Principal": {
                        "Service": [
                            "iot.amazonaws.com"
                        ]
                    }, 
                    "Effect": "Allow", 
                    "Sid": ""
                }
            ]
        }, 
        "RoleId": "AROAV6C6662IW2BAC4NEW", 
        "CreateDate": "2019-08-27T04:58:31Z", 
        "RoleName": "iot-access-s3", 
        "Path": "/", 
        "Arn": "arn:aws-cn:iam::408221054609:role/iot-access-s3"
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;# 编写一个从 S3 存储桶下载文件的 policy 文档，制以下JSON格式的策略并保存为 s3-policy.json 文件
$ vi s3-policy.json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "s3:GetObject",
            "Resource": "arn:aws-cn:s3:::example-bucket-123/*" #这里替换成自己的 bucket name
        }
    ]
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;# 创建 policy, 记录下 Arn
$ aws iam create-policy --policy-name iot-access-s3 --policy-document file://s3-policy.json
{
    "Policy": {
        "PolicyName": "iot-access-s3", 
        "PermissionsBoundaryUsageCount": 0, 
        "CreateDate": "2019-08-27T05:18:58Z", 
        "AttachmentCount": 0, 
        "IsAttachable": true, 
        "PolicyId": "ANPAV6C6662I6TMQS6KAL", 
        "DefaultVersionId": "v1", 
        "Path": "/", 
        "Arn": "arn:aws-cn:iam::408221054609:policy/iot-access-s3", 
        "UpdateDate": "2019-08-27T05:18:58Z"
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;# 挂载 policy iot-access-s3 到 role iot-access-s3
$ aws iam attach-role-policy --role-name iot-access-s3 --policy-arn arn:aws-cn:iam::408221054609:policy/iot-access-s3&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;a id="user-content-第四步---运行-iot-设备端程序" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E7%AC%AC%E5%9B%9B%E6%AD%A5---%E8%BF%90%E8%A1%8C-iot-%E8%AE%BE%E5%A4%87%E7%AB%AF%E7%A8%8B%E5%BA%8F"&gt;第四步 – 运行 IoT 设备端程序&lt;/a&gt;&lt;/h2&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ pwd
/home/ec2-user/aws-iot-device-sdk-js/examples

# 查看自己的 AWS IoT Endpoint
$ aws iot describe-endpoint --endpoint-type iot:Data-ATS
{
    "endpointAddress": "a1hk0pcc0rk07l.ats.iot.cn-north-1.amazonaws.com.cn"
}

# 运行客户端程序 jobs-agent.js，并等待jobs的提交
$ node jobs-agent.js -f ~/aws-iot-device-sdk-js/examples/certs -H a1hk0pcc0rk07l.ats.iot.cn-north-1.amazonaws.com.cn -T aws-iot-device-sdk-js -D

{
  keyPath: '/home/ec2-user/aws-iot-device-sdk-js/examples/certs/private.pem.key',
  certPath: '/home/ec2-user/aws-iot-device-sdk-js/examples/certs/certificate.pem.crt',
  caPath: '/home/ec2-user/aws-iot-device-sdk-js/examples/certs/root-CA.crt',
  clientId: 'ec2-user52261',
  region: undefined,
  baseReconnectTimeMs: 4000,
  keepalive: 300,
  protocol: 'mqtts',
  port: 8883,
  host: 'a1hk0pcc0rk07l.ats.iot.cn-north-1.amazonaws.com.cn',
  thingName: 'aws-iot-device-sdk-js',
  debug: true,
  username: '?SDK=JavaScript&amp;amp;Version=2.2.1',
  reconnectPeriod: 4000,
  fastDisconnectDetection: true,
  resubscribe: false,
  key: &amp;lt;Buffer 2d 2d 2d 2d 2d 42 45 47 49 4e 20 52 53 41 20 50 52 49 56 41 54 45 20 4b 45 59 2d 2d 2d 2d 2d 0a 4d 49 49 45 6f 77 49 42 41 41 4b 43 41 51 45 41 77 76 ... 1625 more bytes&amp;gt;,
  cert: &amp;lt;Buffer 2d 2d 2d 2d 2d 42 45 47 49 4e 20 43 45 52 54 49 46 49 43 41 54 45 2d 2d 2d 2d 2d 0a 4d 49 49 44 57 54 43 43 41 6b 47 67 41 77 49 42 41 67 49 55 49 68 ... 1170 more bytes&amp;gt;,
  ca: &amp;lt;Buffer 2d 2d 2d 2d 2d 42 45 47 49 4e 20 43 45 52 54 49 46 49 43 41 54 45 2d 2d 2d 2d 2d 0a 4d 49 49 44 51 54 43 43 41 69 6d 67 41 77 49 42 41 67 49 54 42 6d ... 1138 more bytes&amp;gt;,
  requestCert: true,
  rejectUnauthorized: true
}
attempting new mqtt connection...
subscribeToJobs: { thingName: 'aws-iot-device-sdk-js', operationName: 'shutdown' }
subscribeToJobs: { thingName: 'aws-iot-device-sdk-js', operationName: 'reboot' }
subscribeToJobs: { thingName: 'aws-iot-device-sdk-js', operationName: 'install' }
subscribeToJobs: { thingName: 'aws-iot-device-sdk-js', operationName: 'systemStatus' }
subscribeToJobs: { thingName: 'aws-iot-device-sdk-js', operationName: 'stop' }
subscribeToJobs: { thingName: 'aws-iot-device-sdk-js', operationName: 'start' }
subscribeToJobs: { thingName: 'aws-iot-device-sdk-js', operationName: 'restart' }
agent connected
startJobNotifications completed for thing: aws-iot-device-sdk-js&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;a id="user-content-第五步---创建-aws-iot-jobs-进行固件升级" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E7%AC%AC%E4%BA%94%E6%AD%A5---%E5%88%9B%E5%BB%BA-aws-iot-jobs-%E8%BF%9B%E8%A1%8C%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7"&gt;第五步 – 创建 AWS IoT Jobs 进行固件升级&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;新开一个命令行窗口到 EC2 实例，查看当前固件版本&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ rpm -qa |grep telnet
telnet-0.17-48.el6.x86_64&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;创建 AWS IoT Jobs&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ cd /home/ec2-user/aws-iot-device-sdk-js/examples

#注意这里的 --targets, example-bucket-123 和 roleArn 要替换成自己的
$ aws iot create-job --job-id 1 --targets arn:aws-cn:iot:cn-north-1:408221054609:thing/aws-iot-device-sdk-js --document-source https://example-bucket-123.s3.cn-north-1.amazonaws.com.cn/jobs-document.json --presigned-url-config "{\"roleArn\":\"arn:aws-cn:iam::408221054609:role/iot-access-s3\", \"expiresInSec\":3600}" --target-selection SNAPSHOT
{
    "jobArn": "arn:aws-cn:iot:cn-north-1:408221054609:job/1", 
    "jobId": "1"
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;a id="user-content-第六步---验证固件升级是否成功" class="anchor" href="https://github.com/hhzzjj/Prepare/blob/master/Step-by-step%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BAWS%20IoT%20OTA%20%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7.md#%E7%AC%AC%E5%85%AD%E6%AD%A5---%E9%AA%8C%E8%AF%81%E5%9B%BA%E4%BB%B6%E5%8D%87%E7%BA%A7%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F"&gt;第六步 – 验证固件升级是否成功&lt;/a&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;查看之前 IoT设备端程序输出&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;agent connected
startJobNotifications completed for thing: aws-iot-device-sdk-js
job execution handler invoked: { thingName: 'aws-iot-device-sdk-js', operationName: 'install' }
updateJobStatus: {
  thingName: 'aws-iot-device-sdk-js',
  jobId: '1',
  status: 'IN_PROGRESS',
  statusDetails: { step: 'downloading', fileName: 'new-firmware.rpm' }
}
updateJobStatus: {
  thingName: 'aws-iot-device-sdk-js',
  jobId: '1',
  status: 'IN_PROGRESS',
  statusDetails: { operation: 'install', step: 'restarting package' }
}
updateJobStatus: {
  thingName: 'aws-iot-device-sdk-js',
  jobId: '1',
  status: 'SUCCEEDED',
  statusDetails: { operation: 'install', state: 'package installed and started' }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;查看 IoT Job 状态&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;$ aws iot describe-job --job-id 1
{
    "documentSource": "https://example-bucket-123.s3.cn-north-1.amazonaws.com.cn/jobs-document.json", 
    "job": {
        "status": "COMPLETED", 
        "jobArn": "arn:aws-cn:iot:cn-north-1:408221054609:job/1", 
        "completedAt": 1566886074.239, 
        "jobProcessDetails": {
            "numberOfQueuedThings": 0, 
            "numberOfInProgressThings": 0, 
            "numberOfSucceededThings": 1, 
            "numberOfCanceledThings": 0, 
            "numberOfFailedThings": 0, 
            "numberOfRemovedThings": 0, 
            "numberOfRejectedThings": 0
        }, 
        "presignedUrlConfig": {
            "expiresInSec": 300, 
            "roleArn": "arn:aws-cn:iam::408221054609:role/iot-access-s3"
        }, 
        "jobId": "1", 
        "lastUpdatedAt": 1566886074.239, 
        "targetSelection": "SNAPSHOT", 
        "jobExecutionsRolloutConfig": {}, 
        "targets": [
            "arn:aws-cn:iot:cn-north-1:408221054609:thing/aws-iot-device-sdk-js"
        ], 
        "createdAt": 1566886070.087
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;查看固件版本号&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="highlight highlight-source-shell"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-json"&gt;# 程序版本已由 telnet-0.17-48.el6.x86_64 升级到 telnet-0.17-64.el7.x86_64
$ rpm -qa |grep telnet
telnet-0.17-64.el7.x86_64&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;到此为止，通过以上几步简单的动手环节，您已成功的完成了 OTA 升级。&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>使用Amazon SageMaker部署CVAT AI自动图像标注系统</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search-2/</link>
				<pubDate>Wed, 15 Sep 2021 06:50:27 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon Fargate]]></category>
		<category><![CDATA[Amazon SageMaker]]></category>

		<guid isPermaLink="false">dababdda0e3a49faf6841c7a91366bbb024024f6</guid>
				<description>本文将CVAT开源标注平台部署到亚马逊云科技中国区域，并对官方的部署模式升级为无服务器化的方式提升架构的高可用性和并发能力，同时使用强大的SageMaker推理功能增强自动标注功能。</description>
								<content:encoded>&lt;h2&gt;背景介绍&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker可以帮助开发人员和数据科学家快速准备构建、训练和部署机器学习（ML）模型的完全托管的云服务。特别的SageMaker提供了一种可扩展且经济高效的方法来部署大量的预先训练好的机器学习模型，借助SageMaker多容器多模型的部署可以使用单个端点访问的模式提供多种类型的推理服务。&lt;/p&gt; 
&lt;p&gt;而我们都知道在机器学习领域，训练数据集的重要性不言而喻，特别是目前应用最为广泛的监督式计算机视觉领域中的深度学习，往往一个这种项目最开始的工作就是标注各种媒资数据。而&lt;a href="https://openvinotoolkit.github.io/cvat/about/"&gt;CVAT&lt;/a&gt;就是为用户提供一套完整的工具平台，方便用户标注数字图像和视频。CVAT 支持与对象检测、图像分类、图像分割和3D数据标注有关的监督机器学习任务，CVAT自2018年在GitHub上开源以来已经发展成为业界中最为流行的视觉领域标注工具,特别是AI自动标注功能非常受用户欢迎。&lt;/p&gt; 
&lt;p&gt;官方文档中&lt;a href="https://openvinotoolkit.github.io/cvat/docs/administration/basics/installation/"&gt;安装CVAT&lt;/a&gt;的推荐方式为单机部署模式，无论应用层、数据库层还是缓存层以及AI推理层都是通过Docker的方式部署在一台物理机或者虚拟机中，这种方式无论从资源利用、安全性、部署架构的高可用性上都难以满足企业级应用部署的规范。本文作者拥有多次大型企业在亚马逊云科技上通过无服务器化（Serverless）部署CVAT的经验，特别是对最为受欢迎的AI自动标注功能使用SageMaker模型部署推理层改造的经验，通过AWS CloudFormation一键部署模式，将整个CVAT平台系统部署在亚马逊云的Serverless的架构之上。&lt;/p&gt; 
&lt;h2&gt;部署架构介绍&lt;/h2&gt; 
&lt;p&gt;CVAT主体开发使用了Python Django Web应用框架，并大量使用了缓存技术提升系统的稳定性和降低应用的延迟，数据库使用了开源的PostgreSQL，最为重要的AI推理引擎也使用了数据科学界开源的&lt;a href="https://nuclio.io/"&gt;nuclio&lt;/a&gt;作为基础无服务器（Serverless）的架构层。由于上文提及CVAT官方提供的部署方案需要把所有的技术组建容器化后部署在一台物理机或者虚拟机中，通过Docker Compose的集群方式部署。官方的推荐架构明显较于目前云原生或Serverless的架构趋势有很大的区别，因此我们在将CVAT部署到AWS云上的时候将架构进行改造。具体的架构图如下：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;其中改造的点如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先我们可以将整套架构运行在安全的AWS VPC中，通常情况下我们把需要通过公网访问的CVAT用户界面的ALB放在公有子网，同时我们的&lt;a href="https://aws.amazon.com/cn/fargate/?nc1=h_ls&amp;amp;whats-new-cards.sort-by=item.additionalFields.postDateTime&amp;amp;whats-new-cards.sort-order=desc&amp;amp;fargate-blogs.sort-by=item.additionalFields.createdDate&amp;amp;fargate-blogs.sort-order=desc"&gt;Fargate&lt;/a&gt;（一种适用于容器的无服务器计算引擎）到公网拉取Docker镜像需要的NAT Gateway也放在公有子网，其余所有Fargate容器、RDS/ElastiCache、EFS甚至SageMaker的Endpoint都通过私有网络进行访问，如有必要甚至可以将整个VPC与互联网进行隔离，满足客户企业级安全的要求；&lt;/li&gt; 
 &lt;li&gt;将CVAT的Server和UI两个服务的容器运行到ECS的Fargate Serverless上，并通过ALB替换掉traefik容器将用户的流量分别发送到这两个ECS的服务上，实现Fargate容器多节点和冗余；&lt;/li&gt; 
 &lt;li&gt;将CVAT的缓存层从原来的Docker容器中剥离出来运行在ElastiCache的Redis上，实现缓存层的全托管；&lt;/li&gt; 
 &lt;li&gt;将CVAT的数据库层从原来的Docker容器中剥离出来运行在RDS的PostgreSQL上，实现数据库层的全托管；&lt;/li&gt; 
 &lt;li&gt;将CVAT存放媒资的本地Docker卷剥离出来存放在EFS的共享存储上，方便CVAT Server的容器在Fargate上的漂移和多节点扩展；&lt;/li&gt; 
 &lt;li&gt;最为重要的是对AI推理层的改造，新增CVAT Serverless服务替换原有nuclio无服务器服务，主要原因是nuclio对底层物理机或虚拟机的侵入性太强，需要开放大量的底层权限才能使用（比如运行Docker的UNIX Socket接口），无法在AWS上真正实现Serverless，同时Amazon SageMaker为我们提供了强大的推理端点（Endpoint）部署的功能，因此我们通过新增的CVAT Serverless服务与SageMaker进行对接，将推理服务运行在SageMaker Host Endpoint上，并将CVAT Serverless服务运行在Fargate上；&lt;/li&gt; 
 &lt;li&gt;另外为了初始化CVAT数据库，及一些S3上的Demo媒资复制到创建好的EFS上，我们使用了一个Fargate ECS的Task来完成一次性初始化的动作；&lt;/li&gt; 
 &lt;li&gt;最后我们还会使用一些其他亚马逊云科技的服务来帮助我们实现整个CVAT架构的无服务器化，包括使用S3存储AI推理模型、媒资，使用Cloud Map作为微服务的发现机制，使用ECR来托管所有Docker镜像（包括ECS和SageMaker都会使用）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;相比较于CVAT社区官方版本的部署方案，运行在亚马逊云上CVAT具有非常明显的优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;所有技术模块实现了高可用；&lt;/li&gt; 
 &lt;li&gt;真正全解偶并实现无服务器化，用户无需再关心底层资源调度；&lt;/li&gt; 
 &lt;li&gt;可以支持大量用户同时使用CVAT系统进行协作标注，实现了CVAT内部协作功能架构基础；&lt;/li&gt; 
 &lt;li&gt;AI推理模块可扩展性更强，更为灵活。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;方案部署步骤&lt;/h2&gt; 
&lt;p&gt;本方案所有的技术模块可以通过预先定义好的CloudFormation服务创建，点击下面的按键就可以跳转到Amazon CloudFormation控制台界面（宁夏区）进行整个方案架构的部署，对于部署的源代码大家可以参考这个&lt;a href="https://github.com/aws-samples/cvat-on-aws-china"&gt;链接&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;快速启动&lt;/h3&gt; 
&lt;p&gt;方案架构快速部署有很多配置选项可以修改，但是如果是基于测试或者全新快速部署使用的目的可以全部使用默认的值，只有两个是必须输入的：一个是给整个架构堆栈起一个名称，另外一个就是对创建IAM资源影响的确认项。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;额外灵活的配置&lt;/h3&gt; 
&lt;p&gt;如果你想对整个CVAT有更为深入灵活的配置，可以通过修改CloudFormation参数来实现，这些参数主要分为以下几种类型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CVAT用户相关的参数&lt;/li&gt; 
 &lt;li&gt;与数据库相关的参数&lt;/li&gt; 
 &lt;li&gt;VPC网络相关的参数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;模版的输出&lt;/h3&gt; 
&lt;p&gt;经过15到20分钟的等待，我们CVAT的模版将创建完成。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;点击“输出”的页面，模版输出了在AWS创建的各种资源的ID，其中最为重要的URL，这个输出是部署好的CVAT链接地址，可以直接点击这个链接登录新创建好的CVAT系统。&lt;/p&gt; 
&lt;h2&gt;使用CVAT AI图像自动标签系统&lt;/h2&gt; 
&lt;p&gt;登录CVAT的链接会需要使用CVAT的用户名密码登录，就是我们在创建CloudFormation时使用到&lt;em&gt;CVATUser&lt;/em&gt;和&lt;em&gt;CVATPassword&lt;/em&gt;参数，默认为&lt;em&gt;admin/cvat123456&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;登录后点击Models链接，可以查看我们已经在SageMaker五个模型推理的端点（Endpoint）&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;点击Tasks链接，并点击Create new task按钮&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在Create a new task页面需要填入如下信息：Name可以填入&lt;em&gt;handball&lt;/em&gt;，增加一个标签&lt;em&gt;person&lt;/em&gt;，并点击Connected file share链接&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在Connected file share这个页面中所有的媒资文件都是存放在我们CloudFormation创建的EFS共享存储中，实现我们通过Fargate Task已经将S3上的demo数据复制到共享存储上了，点击展开&lt;em&gt;root&lt;/em&gt;节点，选择&lt;em&gt;handball&lt;/em&gt;文件夹，这里包含了400张图片，是一段视频经过抽帧的结果，点击Submit按钮。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;很快页面就会反馈后台已经把CVAT Task已经创建好，会有一个浮动窗口提示我们，这里可以点击Open task按钮或者点击页面上方的Tasks链接进入Tasks页面。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在我们已经创建好了一个CVAT Task，可以选择用手工的方式给每一帧分别打标签，这里我们使用AI标注的功能来提升打标签的效率。在Tasks页面点击Actions链接中的菜单，并点击Automatic annotation链接&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;这时会弹出一个浮动窗口让我们选择一个模型，这里我们选择使用&lt;em&gt;pth-faster-rcnn&lt;/em&gt;模型。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;这时CVAT会帮助我们自动将模型里能够识别的标签与我们在任务中定义个标签进行匹配，点击Annotate，CVAT就会通过SageMaker的Endpoint进行推理，对任务里所有的图片帧中的人物进行标注。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;这个过程会持续一段时间，在Task页面我们可以监控到后台推理的进度。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search15.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search15.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;经过10分钟左右我们就可以用过SageMaker将400张图片全部标注完成，现在可以通过点击下面Job的链接查看结果。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search16.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search16.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;打开Job页面以后我们就能看到AI标注的结果，所有在每帧图片中的人物都用标注框标注出来了，我们可以点击播放按钮看到以下效果。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search17.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-aws-vpc-kms-lambda-and-elasticsearch-to-implement-secure-and-encrypted-data-search17.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如果大家感兴趣还可以继续尝试其他AI标注方式，比如interactor方式可以自动识别物体边界多边形式标注，tracker方式可以通过自动语义分割的方式在视频中追踪标记目标标注物，reid方式可以使用业界流行的行人重识别（reidentification）算法对所有标注的行人人物进行标签合并。&lt;/p&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;使用将CVAT通过无服务器化改造的方式，特别是将AI标注推理功能运行在Amazon SageMaker上，可以大大提升开源CVAT单机部署的性能以及稳定性，可以非常好的支撑企业内部图像AI项目的标注任务。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/huadebin.png" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;黄德滨&lt;/h3&gt; 
  &lt;p&gt;AWS资深解决方案架构师，服务于全球客户销售团队，负责技术架构设计和咨询，致力于企业级应用在AWS云服务的运用和部署，对于大型企业级应用开发和实施拥有近二十年的丰富经验，在云计算领域工作多年，拥有大量帮助各种类型企业上云的经验，在加入AWS之前先后服务于百度、甲骨文等国内外知名IT企业。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>Amazon Redshift数据实时摄入最佳实践</title>
		<link>https://aws.amazon.com/cn/blogs/china/best-practices-for-real-time-data-ingestion-in-amazon-redshift/</link>
				<pubDate>Wed, 15 Sep 2021 06:35:13 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Aurora]]></category>
		<category><![CDATA[Amazon Redshift]]></category>
		<category><![CDATA[Lambda]]></category>

		<guid isPermaLink="false">d858b86933215b57eb3d3da49113847d44e13d41</guid>
				<description>本文将针对在Amazon Redshift的使用场景下，探讨如何准实时或实时的摄入数据到Redshift，以使得数据立即可用，并可以依此来构建实时数仓架构。</description>
								<content:encoded>&lt;h2&gt;背景介绍&lt;/h2&gt; 
&lt;p&gt;Amazon Redshift 是使用最广泛的云数据仓库。通过它您可以快速、简单而经济高效地使用标准 SQL 和现有商业智能 (BI) 工具分析您的所有数据。它还允许您使用高性能存储中的列式存储通过复杂的查询优化对 TB 级到 PB 级结构化和半结构化数据运行复杂的分析查询，并能大规模执行并行查询。随着新业务的发展人们对数据的实效性要求越来越高，离线数据都是每日或每小时才能就绪，分析人员无法及时的洞察数据，能够在数据产生后的分钟级甚至是秒级可用是数据分析平台建设的难题。&lt;br&gt; 本文将针对在Amazon Redshift的使用场景下，探讨如何准实时或实时的摄入数据到Redshift，以使得数据立即可用，并可以依此来构建实时数仓架构。&lt;/p&gt; 
&lt;h2&gt;Redshift摄入外部数据的常见方式&lt;/h2&gt; 
&lt;h3&gt;INSERT&lt;/h3&gt; 
&lt;p&gt;Amazon Redshift 支持标准的数据操作语言 (DML) 命令（INSERT、UPDATE 和 DELETE），您可使用这些命令插入表中的行。使用单个 INSERT 语句填充表可能过于缓慢，所以只在数据量较少的情况下适用，并尽量避免单行插入，可以将多个行合并到一个语句中插入降低开销。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;insert into customer values 
(14, default, default, default), 
(15, default, default, default);&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;COPY&lt;/h3&gt; 
&lt;p&gt;推荐使用COPY进行数据加载，COPY命令可以从Amazon S3/Amazon EMR/Amazon DynamoDB/Remote Hosts等多个数据源将数据加载到Redshift中。COPY 命令能够同时从多个数据文件或多个数据流读取。Amazon Redshift 将工作负载分配到集群节点并且并行执行加载操作，包括对行进行排序和跨节点切片分配数据。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;copy customer 
from 's3://mybucket/mydata' 
access_key_id '&amp;lt;access-key-id&amp;gt;' 
secret_access_key '&amp;lt;secret-access-key'
delimiter '|';&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;Amazon Kinesis Data Firehose&lt;/h3&gt; 
&lt;p&gt;Amazon Kinesis Data Firehose 是一项完全托管的服务，用于实时提供流式处理数据到目标如Amazon Redshift。使用 Kinesis Data Firehose，您无需编写应用程序或管理资源。对于Redshift目标，Kinesis Data Firehose 先将数据传输到您的 S3 存储桶，然后发出 Amazon Redshift COPY命令将数据加载到您的 Amazon Redshift 集群中。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我们可以在Kinesis Data Firehose中设置到Redshift的传输流，配置包括缓冲区大小和缓冲时间等参数，在Firehose传输流配置中，我们可以看到Firehose为我们自动生成了COPY命令，如下图所示：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; Kinesis Data Firehose会定时按设置的触发条件，使用下面命令将数据摄入到Redshift中。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;COPY test FROM 's3://bucket/&amp;lt;manifest&amp;gt;' 
CREDENTIALS 'aws_iam_role=arn:aws:iam::&amp;lt;aws-account-id&amp;gt;:role/&amp;lt;role-name&amp;gt;' 
MANIFEST;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;AWS DMS&lt;/h3&gt; 
&lt;p&gt;AWS Database Migration Service (AWS DMS) 是一项云服务，可轻松迁移关系数据库、数据仓库、NoSQL 数据库及其他类型的数据存储。你可以利用AWS DMS将多种数据源的数据加载到Redshift中，DMS支持增量和全量数据加载，也支持CDC数据同步至Redshift。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;AWS DMS 从源数据库读取数据并创建一系列逗号分隔值 (.csv) 文件。对于完全加载操作，AWS DMS为每个表创建文件。当文件上传到 Amazon S3，AWS DMS发送 COPY 命令，将文件中的数据复制到 Amazon Redshift。对于变更处理操作，AWS DMS将更改复制到 .csv 文件。AWS DMS接下来将更改文件上传到 Amazon S3 并将数据复制到 Amazon Redshift。&lt;br&gt; 具体操作如下：首先配置目标终端节点，选择目标引擎为Amazon Redshift。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 然后创建新的数据库迁移任务&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 我们可以在DMS中选择是进行持续复制还是全量复制。在DMS中将Redshift作为目标的详细配置步骤可以参考：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Target.Redshift.html"&gt;https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Target.Redshift.html&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;AWS Glue&lt;/h3&gt; 
&lt;p&gt;AWS Glue 是一项完全托管的 ETL（提取、转换和加载）服务，使您能够轻松而经济高效地对数据进行分类、清理和扩充，并在各种数据存储和数据流之间可靠地移动数据。在将数据移至 Amazon Redshift 集群时，AWS Glue 作业将文件上传到 Amazon S3 并向 Amazon Redshift 发出 COPY命令以实现最大吞吐量。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; Glue中可以构建ETL脚本将数据写入到Redshift中。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;my_conn_options = {
    "dbtable": "redshift table name",
    "database": "redshift database name",
    "aws_iam_role": "arn:aws:iam::account id:role/role name"
}
glueContext.write_dynamic_frame.from_jdbc_conf(
    frame = input dynamic frame, 
    catalog_connection = "connection name", 
    connection_options = my_conn_options, 
    redshift_tmp_dir = args["TempDir"])&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;利用Redshift Federated Query实现数据实时摄入&lt;/h2&gt; 
&lt;p&gt;除了通过手工构建数据加载管道之外，通过AWS的托管服务可以更容易的将数据加载到Redshift中，但上述数据加载的方式，除了INSERT外（无法应对大批量数据），底层都是采用COPY的方式进行数据加载。COPY命令本身需要消耗Redshift集群的资源进行数据的加载工作，更频繁的COPY命令会影响到其他查询或ETL作业的正常运行。另外也无法做到数据的实时摄入（最少分钟级）。&lt;br&gt; Amazon Redshift支持Federated Query，利用Federated Query功能可以直接查询存储在Amazon Aurora PostgreSQL/MySQL与Amazon RDS for PostgreSQL/MySQL数据库内的数据。Federated Query可实现实时数据集成并简化ETL处理流程和直接在Amazon Redshift中连接实时数据源并借此提供实时报告与分析结果。&lt;br&gt; 借助Federated Query和简化的ETL流程，我们可以实现redshift的实时数据摄入能力，详细方案如下：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/best-practices-for-real-time-data-ingestion-in-amazon-redshift7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;方案中，我们在Aurora for PostgreSQL中创建Redshift的实时摄入缓存表，并设置定时任务将PostgreSQL中最近插入的数据异步加载到Redshift中，源表的数据插入时间字段，我们根据时间字段加载最新数据。&lt;/p&gt; 
&lt;h3&gt;在Redshift中进行Federated Query配置&lt;/h3&gt; 
&lt;p&gt;在Redshift中进行Federated Query的配置，创建External Schema。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE EXTERNAL SCHEMA pg
FROM POSTGRES
DATABASE 'postgres' SCHEMA 'public'
URI 'xxx.rds.amazonaws.com' PORT 5432
IAM_ROLE 'arn:aws:iam::xxx:role/xxx'
SECRET_ARN 'arn:aws:secretsmanager:xxx:secret:xxx';&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;配置Federated Query的其他前提步骤请参考下面链接：&lt;a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/getting-started-federated.html"&gt;https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/getting-started-federated.html&lt;/a&gt;&lt;br&gt; Federated Query最佳实践请参考：&lt;a href="https://aws.amazon.com/cn/blogs/big-data/amazon-redshift-federated-query-best-practices-and-performance-considerations/"&gt;https://aws.amazon.com/cn/blogs/big-data/amazon-redshift-federated-query-best-practices-and-performance-considerations/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;数据摄入方案初始配置&lt;/h3&gt; 
&lt;p&gt;1、初始化需要实时摄入的源表和目标表&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;-- 如果在PostgreSQL中的源表没有时间字段，则在创建表的时候，默认填充时间字段为unix时间戳格式，建表的范例如下
CREATE TABLE realtime_offline (
  id int,
  update_time int NOT NULL
  );
-- 如果源表有时间字段，则直接在Redshift中利用源表结构创建Redshift中的表
CREATE TABLE realtime_offline AS (SELECT * FROM pg.realtime_online LIMIT 0)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;2、在PostgreSQL中创建分区触发器，根据时间字段自动将数据插入到分区表中（利用分区表可以加快Federated Query对PostgreSQL的查询性能，如果数据量不大，也可以通过定期删除PostgreSQL中旧数据的方式提高查询性能）&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;-- 创建分区函数，按update_time字段换算成每分钟1个分区，根据数据量调整分区规则
CREATE OR REPLACE FUNCTION realtime_online_partition_trigger()
    RETURNS TRIGGER AS
$$
DECLARE
    date_text                TEXT;
    DECLARE insert_statement TEXT;
BEGIN
    SELECT NEW.update_time/60*60 INTO date_text;
    insert_statement := 'INSERT INTO realtime_online_'
                            || date_text
        || ' VALUES ($1.*)';
    EXECUTE insert_statement USING NEW;
    RETURN NULL;
EXCEPTION
    WHEN UNDEFINED_TABLE
        THEN
            EXECUTE
                                'CREATE TABLE IF NOT EXISTS realtime_online_'
                                || date_text
                            || '( like realtime_online)'
                        || ' INHERITS (realtime_online)';
            RAISE NOTICE 'CREATE NON-EXISTANT TABLE realtime_online_%', date_text;
            EXECUTE
                                'CREATE INDEX realtime_online_timestamp_'
                                || date_text
                            || ' ON realtime_online_'
                        || date_text
                    || '(update_time)';
            EXECUTE insert_statement USING NEW;
            RETURN NULL;
END;
$$
    LANGUAGE plpgsql;

-- 创建主表触发器 挂载分区Trigger
CREATE TRIGGER insert_realtime_online_partition_trigger
    BEFORE INSERT
    ON realtime_online
    FOR EACH ROW
EXECUTE PROCEDURE realtime_online_partition_trigger();
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;3、在Redshift中创建统一视图，方便上层应用通过视图查询Redshift和PostgreSQL中的数据&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE OR REPLACE VIEW public.realtime_view AS
SELECT * FROM public.realtime_offline
where update_time &amp;lt; (select max(update_time)
                   from public.realtime_offline
)
UNION ALL
SELECT * FROM pg.realtime_online
where update_time &amp;gt;= (select max(update_time)
                    from public.realtime_offline
)
with no schema binding;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;配置定时更新和同步脚本&lt;/h3&gt; 
&lt;p&gt;定时脚本可以按固定频率执行，每次执行任务有两个操作：定时加载新的数据、在PostgreSQL中删除过期数据&lt;br&gt; 1、先获取当前系统unix时间（根据字段时间格式修改，本方案使用unix时间戳格式填充记录插入时间字段）&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;date +%s
#替换后面SQL中的1630854036&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;2、摄入外部数据，为避免当前时间戳的数据正在写入，我们提取对比当前时间提前（120s）的数据，此时间可根据实际情况调整。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;INSERT INTO realtime_offline SELECT * FROM pg.realtime_online 
WHERE update_time &amp;gt; (SELECT MAX(update_time) FROM realtime_offline) AND update_time &amp;lt;= 1630854036-120;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;3、根据实际业务需求，在PG数据库中删除较早的历史数据&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;-- 如果PG的源表是分区表，则按时间戳删除历史分区表
DROP TABLE realtime_online_1630854000；
-- 如果PG的源表不是分区表，则按时间戳删除历史数据
DELETE FROM realtime_online WHERE update_time &amp;lt; 1630854036-120;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们可以将上述的步骤通过python脚本来实现并通过Lambda部署的方式，利用CloudWatch Event按规定频率调度运行&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import string
import time
import psycopg2

def sync_data(rs_host,rs_database,rs_user,rs_password,rs_port,curr_time,rs_table_name,pg_table_name):
    conn = psycopg2.connect(host=rs_host,port=rs_port,database=rs_database,user=rs_user,password=rs_password)
    cursor=conn.cursor()
    #sql='select 1'
    sql="insert into " + rs_table_name + " select * from pg." + pg_table_name + " where update_time &amp;gt; (SELECT MAX(update_time) FROM " + rs_table_name + ") and update_time &amp;lt;= " + str(curr_time) + "-120;"
    print(time.ctime() + ": " + sql)
    cursor.execute(sql)
    conn.commit()
    print(time.ctime() + ": " + "sync data sql exec completed")
    cursor.close()
    conn.close()

def delete_data(pg_host,pg_database,pg_user,pg_password,pg_port,curr_time,pg_table_name):
    conn = psycopg2.connect(host=pg_host,port=pg_port,database=pg_database,user=pg_user,password=pg_password)
    cursor=conn.cursor()
    sql="delete from " + pg_table_name + "where update_time &amp;lt; " + str(curr_time) + "-120;"
    print(time.ctime() + ": " + sql)
    cursor.execute(sql)
    conn.commit()
    print(time.ctime() + ": " + "delete data sql exec completed")
    cursor.close()
    conn.close()
    
def delete_table(pg_host,pg_database,pg_user,pg_password,pg_port,curr_time,pg_table_name):
    conn = psycopg2.connect(host=pg_host,port=pg_port,database=pg_database,user=pg_user,password=pg_password)
    cursor=conn.cursor()
    sql1 = "SELECT inhrelid::regclass FROM pg_catalog.pg_inherits WHERE inhparent = \'" + pg_table_name + "\'::regclass;"
    cursor.execute(sql1)
    tables = cursor.fetchall()
    for table in tables:
        if (int(str(table[0])[-10:]) &amp;lt; curr_time-3600):
            sql2 = "drop table "+ table[0]
            print(time.ctime() + ": " + sql2)
            cursor.execute(sql2)
    conn.commit()
    print(time.ctime() + ": " + "drop table sql exec completed")
    cursor.close()
    conn.close()

if __name__=='__main__':    
    pg_host = 'xx'
    pg_user = 'xx'
    pg_database = 'xx'
    pg_password = 'xx'
    pg_port = '5432'
    rs_host = 'xx.ap-southeast-1.redshift.amazonaws.com'
    rs_user = 'xx'
    rs_database = 'xx'
    rs_password = 'xx'
    rs_port = '5439'
    pg_table_name = "realtime_online"
    rs_table_name = "realtime_offline"
    t = time.time() 
    curr_time = int(t)
    try:
        sync_data(rs_host,rs_database,rs_user,rs_password,rs_port,curr_time,rs_table_name,pg_table_name)
        delete_table(pg_host,pg_database,pg_user,pg_password,pg_port,curr_time,pg_table_name)
        #delete_data(pg_host,pg_database,pg_user,pg_password,pg_port,curr_time,pg_table_name)

    except Exception as e:
        print(e)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;变更数据的摄入&lt;/h2&gt; 
&lt;p&gt;Redshift COPY命令无法直接针对更新数据进行同步加载，我们可以通过简单的ETL语句实现更新语义。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;create temp table stage (like target);
insert into stage select * from source where source.filter = 'filter_expression';

begin transaction;
delete from target using stage where target.primarykey = stage.primarykey;
insert into target select * from stage;
end transaction;
drop table stage;        
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;基于Glue构建的数据加载pipeline中，我们同样可以利用SQL执行ETL将变更数据更新至Redshift中。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;post_query="begin;delete from target_table using stage_table where stage_table.id = target_table.id ; insert into target_table select * from stage_table; drop table stage_table; end;"
        
datasink4 = glueContext.write_dynamic_frame.from_jdbc_conf(
frame = datasource0, 
catalog_connection = "test_red", 
connection_options = {"preactions":"drop table if exists stage_table;create table stage_table as select * from target_table where 1=2;","dbtable": "stage_table", "database": "redshiftdb","postactions":post_query},
redshift_tmp_dir = 's3://s3path', 
transformation_ctx = "datasink4"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;针对Federated Query场景下数据加载过程，如果数据源有数据库INSERT和UPDATE，可以使用如下范例语句。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;BEGIN;
CREATE TEMP TABLE staging (LIKE ods.store_sales);
INSERT INTO staging SELECT * FROM pg.store_sales p
    WHERE p.last_updated_date &amp;gt; (SELECT MAX(last_updated_date) FROM ods.store_sales)
DELETE FROM ods.store_sales USING staging s WHERE ods.store_sales.id = s.id;
INSERT INTO ods.store_sales SELECT * FROM staging;
DROP TABLE staging;
COMMIT;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;如果需要对CDC数据摄入方式的完全同步，我们可以借助DMS，DMS可以解析CDC数据中INSERT、UPDATE、DELETE语句同步到Redshift中，除了DMS之外，我们也可以借助第三方的ETL工具来实现。&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;对比总结几种数据摄入方式如下：&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;&lt;/td&gt; 
   &lt;td width="104"&gt;&lt;strong&gt;吞吐量&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="80"&gt;&lt;strong&gt;CDC支持 &lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;&lt;strong&gt;是否需要编写脚本&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="85"&gt;&lt;strong&gt;调度方式&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="88"&gt;&lt;strong&gt;摄入时延&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;INSERT(DML)&lt;/td&gt; 
   &lt;td width="104"&gt;低&lt;/td&gt; 
   &lt;td width="80"&gt;是&lt;/td&gt; 
   &lt;td width="71"&gt;是&lt;/td&gt; 
   &lt;td width="85"&gt;借助第三方&lt;/td&gt; 
   &lt;td width="88"&gt;秒级别&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;COPY&lt;/td&gt; 
   &lt;td width="104"&gt;高&lt;/td&gt; 
   &lt;td width="80"&gt;否&lt;/td&gt; 
   &lt;td width="71"&gt;是&lt;/td&gt; 
   &lt;td width="85"&gt;借助第三方&lt;/td&gt; 
   &lt;td width="88"&gt;分钟级别&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;Kinesis Data Firehose&lt;/td&gt; 
   &lt;td width="104"&gt;高，COPY实现&lt;/td&gt; 
   &lt;td width="80"&gt;否&lt;/td&gt; 
   &lt;td width="71"&gt;否&lt;/td&gt; 
   &lt;td width="85"&gt;自动&lt;/td&gt; 
   &lt;td width="88"&gt;分钟级别&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;DMS&lt;/td&gt; 
   &lt;td width="104"&gt;高，COPY实现&lt;/td&gt; 
   &lt;td width="80"&gt;是&lt;/td&gt; 
   &lt;td width="71"&gt;否&lt;/td&gt; 
   &lt;td width="85"&gt;自动&lt;/td&gt; 
   &lt;td width="88"&gt;分钟级别&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;Glue&lt;/td&gt; 
   &lt;td width="104"&gt;高，COPY实现&lt;/td&gt; 
   &lt;td width="80"&gt;否&lt;/td&gt; 
   &lt;td width="71"&gt;可自动生成&lt;/td&gt; 
   &lt;td width="85"&gt;内置调度&lt;/td&gt; 
   &lt;td width="88"&gt;分钟级别&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;Federated Query&lt;/td&gt; 
   &lt;td width="104"&gt;中&lt;/td&gt; 
   &lt;td width="80"&gt;否&lt;/td&gt; 
   &lt;td width="71"&gt;是&lt;/td&gt; 
   &lt;td width="85"&gt;借助第三方&lt;/td&gt; 
   &lt;td width="88"&gt;毫秒级别&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;综合对比几种数据摄入方式，在数据量较大的离线数据加载场景下，推荐使用COPY，COPY可以使用整个集群的资源实现数据的并行加载，并根据集群资源和数据量控制加载频率。对于数据源为流式数据的场景下，可以使用Kinesis Data Firehose内置机制自动的实现数据加载至Redshift。对于CDC场景可以通过DMS读取RDS等数据库的binlog变更日志，通过DMS解析后转换成加载语句加载至Redshift中。对于想实现数据实时摄入、秒级延迟的场景，可以借助Amazon Redshift Federated Query，通过Aurora for Postgresql/MySQL作为实时数据摄入缓存表接收数据，然后异步合并到Redshift中，从而实现数据的实时可用。&lt;/p&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/merge-replacing-existing-rows.html"&gt;https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/merge-replacing-existing-rows.html&lt;/a&gt;&lt;br&gt; &lt;a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/getting-started-federated.html"&gt;https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/getting-started-federated.html&lt;/a&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/premiumsupport/knowledge-center/sql-commands-redshift-glue-job/"&gt;https://aws.amazon.com/premiumsupport/knowledge-center/sql-commands-redshift-glue-job/&lt;/a&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/cn/blogs/big-data/amazon-redshift-federated-query-best-practices-and-performance-considerations/"&gt;https://aws.amazon.com/cn/blogs/big-data/amazon-redshift-federated-query-best-practices-and-performance-considerations/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xiangqua.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;柳向全&lt;/h3&gt; 
  &lt;p&gt;AWS 解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，目前主要专注于容器和大数据技术领域研究和AWS云服务在国内和全球的应用和推广。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/jiasunm.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;孙健&lt;/h3&gt; 
  &lt;p&gt;孙健，AWS大数据解决方案架构师，负责基于AWS的大数据解决方案的咨询与架构设计，同时致力于大数据方面的研究和推广。在大数据运维调优、容器解决方案，湖仓一体以及大数据企业应用等方面有着丰富的经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用 AWS Lambda Powertools进行定制化数据验证</title>
		<link>https://aws.amazon.com/cn/blogs/china/customized-data-verification-using-aws-lambda-powertools/</link>
				<pubDate>Tue, 14 Sep 2021 15:46:40 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Serverless]]></category>
		<category><![CDATA[Amazon Lambda]]></category>

		<guid isPermaLink="false">cbdef7ac0d127ea119b87fe19cd71bb6b7eda281</guid>
				<description>在这篇文章中，我们将介绍如何使用 Powertools 在无服务器架构的 Amazon Lambda 中对JSON进行数据验证。</description>
								<content:encoded>&lt;h2&gt;背景故事&lt;/h2&gt; 
&lt;p&gt;任何应用最本质的东西其实都是数据，用户使用产品的过程，就是在和产品进行数据交换的过程。比如在电商平台中，产品的介绍信息，描述信息，参数信息，时时刻刻都在与终端客户进行交互，因此作为应用程序，数据的验证就变得至关重要。&lt;/p&gt; 
&lt;p&gt;当您的程序需要从上游程序数据源读取数据时，很有可能存在数据格式及内容的不合规范，这一数据问题严重威胁着后续程序的鲁棒性。另一方面，如果我们自己完全去手写验证数据的代码，本身开发成本比较高，又由于这部分代码的业务逻辑性强，也不易于后期的迭代和维护。&lt;/p&gt; 
&lt;p&gt;为了解决以上这些问题，我们引入了带有基于JSON Schema的验证模块的开源库，AWS Lambda Powertools。JSON Schema 是对 JSON 数据进行数据结构描述的一个协议，按照协议的规定，我们既可以对 JSON 数据的结构进行描述，也可以通过上述描述内容验证特定的 JSON 数据。而 Lambda Powertools 在 Python 版本就集成了 JSON Schema 验证的功能。在这篇文章中，我们将介绍如何使用 Powertools 在无服务器架构的 Amazon Lambda 中对JSON进行数据验证。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/customized-data-verification-using-aws-lambda-powertools1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/customized-data-verification-using-aws-lambda-powertools1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;关于AWS Lambda Powertools validation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://awslabs.github.io/aws-lambda-powertools-python/"&gt;Lambda Powertools&lt;/a&gt;是一个AWS推出的开源框架库，它可以帮助开发人员大幅提升工作效率，减少重复劳动，从而提高生产力。 它目前支持使用&amp;nbsp;Python 3.6&amp;nbsp;及以上版本编写的&amp;nbsp;AWS Lambda&amp;nbsp;函数。 它内嵌的&amp;nbsp;validation&amp;nbsp;功能可以让您通过编写&amp;nbsp;JSON Schema&amp;nbsp;对数据进行定制化校验，基于定制化的&amp;nbsp;JSON Schema&amp;nbsp;，它主要具有以下几项功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;调用函数对某一字典直接进行验证&lt;/li&gt; 
 &lt;li&gt;对传入事件(incoming event)和响应进行验证&lt;/li&gt; 
 &lt;li&gt;支持使用JMESPath在数据验证之前对事件内容进行提取&lt;/li&gt; 
 &lt;li&gt;支持使用预置包封(Built-in envelopes)对热门事件(popular event)的负载进行提取&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;在本篇文章中我们将着重介绍JSON Schema文件的编写规则和调用函数对数据进行校验的方法。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;配置与安装&lt;/h2&gt; 
&lt;p&gt;AWS Powertools包托管于PyPi，因此我们可以使用&amp;nbsp;pip&amp;nbsp;直接进行安装(当你使用一些功能时，requests&amp;nbsp;,&amp;nbsp; boto3 也有可能需要被安装)。除此之外，我们还建议你将&amp;nbsp;AWS Lambda Powertools&amp;nbsp;添加到你的项目依赖文件中，我们这里以 pip freeze 到 requirements.txt&amp;nbsp;为例：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;$ pip install aws_lambda_powertools
$ pip freeze | grep aws_lambda_powertools &amp;gt;&amp;gt; requirements.txt&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;JSON Schema验证示例&lt;/h3&gt; 
&lt;p&gt;假如有如下场景，我们的数据源是下方的JSON文件（文件名country.json），我们希望该文件为一个包含的所有对象至少拥有“country”属性的列表。&lt;/p&gt; 
&lt;p&gt;内容如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[{
    "country": "JP",
    "ship_from": true,
    "ship_to": false
}, 
{
  "country": "CN",
  "ship_from": true,
  "display_name": "China",
  "ship_to": false
},
{
  "country": "",
  "ship_from": true,
  "display_name": "United States",
  "ship_to": false
}]&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;为了完成上述的需求，我们可以编写对应的JSON Schema，并将其储存为Python字典的格式，我们可以单独建立一个新文件储存该字典常量，如country_template.py，内容如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;# We organize Json Schema in python's dictionary form.
# Json Schema use "false", but python use False.
# Json Schema don't support any comment.
COUNTRY_TEMPLATE = {
    "required": [
        "country",  # Partition Key must exist
    ],
    "type": "object",  # Correspond to dict in python
    "properties": {
        "country": {
            "minLength": 1,  # Because it's the Partition Key
            "examples": [
                "US"
            ],
            "type": "string"
        },
        "ship_from": {
            "type": "boolean"
        },
        "display_name": {
            "examples": [
                "United States"  # You can write a example for people to understand
            ],
            "type": "string"
        },
        "ship_to": {
            "type": "boolean"
        }
    },
    # We don't tolerate any property excpet those above.
    "additionalProperties": False
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;对于上方的来自数据源的文件和JSON Schema验证模版，我们可以编写如下的Python代码，我们不妨将其储存为validate.py：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;from aws_lambda_powertools.utilities.validation import validate, SchemaValidationError
from country_template import COUNTRY_TEMPLATE
import json

json_countries = json.load(open('country.json')) 

for country in json_countries:
    try:
        validate(event = country, schema = COUNTRY_TEMPLATE)
        print("No errors in data: " + country["country"])
    except SchemaValidationError as validation_error:
        print(validation_error)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;上述的代码运行结果如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;No errors in data: JP
No errors in data: CN
Failed schema validation. Error: data.country must be longer than or equal to 1 characters, Path: ['data', 'country'], Data:&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;当Python抛出 SchemaValidationError&amp;nbsp;时，我们可以使用 try-except&amp;nbsp;语句获取错误信息并进行解析，所有的错误类型可以在 PowerTools&amp;nbsp;集成的开源工具&lt;a href="https://github.com/horejsek/python-fastjsonschema"&gt;Fast JSON schema validator for Python&lt;/a&gt;的&lt;a href="https://github.com/horejsek/python-fastjsonschema/tree/91148b9345910bde3dde46c76d285bd6b77c6f4a/fastjsonschema"&gt;fastjsonschema&lt;/a&gt;文件夹下的 draftXX.py&amp;nbsp;中找到。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Json&amp;nbsp;Schema 验证进阶&lt;/h2&gt; 
&lt;p&gt;由于AWS Powertools并没有在官方文档给出Json Schema的具体写法，我们在这里简单介绍一些Json Schema语法，读者也可以根据提示的关键字对语法进行进一步搜索。&lt;/p&gt; 
&lt;h3&gt;1. String&lt;/h3&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;功能&lt;/td&gt; 
   &lt;td width="216"&gt;关键词&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;限定字符串长度&lt;/td&gt; 
   &lt;td width="216"&gt;“minLength”,&amp;nbsp;“maxLength”&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;正则匹配&lt;/td&gt; 
   &lt;td width="216"&gt;“pattern”&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;枚举&lt;/td&gt; 
   &lt;td width="216"&gt;“enum”&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;在下面的示例中我们验证了一个由大写字母构成，长度在1～99个字符之间，且必须在“CN”, “US”, “JP”的中的字符串：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
    "type": "string",
    "minLength": 1,
    "maxLength": 9999,
    "pattern": "[A-Z]+",
    "enum": ["CN", "US", "JP"],
    "examples": [
        "US"
    ]
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Integer&lt;/h3&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;功能&lt;/td&gt; 
   &lt;td width="216"&gt;关键词&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;限定数字大小&lt;/td&gt; 
   &lt;td width="216"&gt;“minimum”,&amp;nbsp;“maximum”, “exclusiveMinimum”, “exclusiveMaximum”&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;倍数&lt;/td&gt; 
   &lt;td width="216"&gt;“multipleOf”&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;在下面的示例中我们验证了一个必须大于1，小于等于100而且为3的倍数的整数：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
   "type": "integer",
   "exclusiveMinimum": 1,
   "maximum": 100,
   "multipleOf": 3
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. Object&lt;/h3&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;功能&lt;/td&gt; 
   &lt;td width="247"&gt;关键词&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;键名&lt;/td&gt; 
   &lt;td width="247"&gt;“properties”,&amp;nbsp;“patternProperties”&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;额外的键&lt;/td&gt; 
   &lt;td width="247"&gt;“additionalProperties”&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;必须有的键&lt;/td&gt; 
   &lt;td width="247"&gt;“required”&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="122"&gt;键的数量&lt;/td&gt; 
   &lt;td width="247"&gt;“minProperties”,&amp;nbsp;“maxProperties”&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Object的例子可以参考JSON Schema验证示例部分。&lt;/p&gt; 
&lt;p&gt;此外，JSON Schema也支持数组类型的验证以及其他的一些引用功能，读者如果有需要可以参考JSON Schema手册。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;辅助工具&lt;/h2&gt; 
&lt;p&gt;JSON Schema也可以使用开源工具直接从Json文件中自动推导生成(&lt;a href="https://www.jsonschema.net/home"&gt;JSON Schema Tool&lt;/a&gt;)，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/customized-data-verification-using-aws-lambda-powertools2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/customized-data-verification-using-aws-lambda-powertools2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在此之后，我们还需要对生成的框架进行精简和调整以适应其他JSON数据（可以参考验证进阶部分的内容进行调整）。与此同时，我们也可以找到很多JSON Schema验证的开源工具，它们可以方便我们对JSON Schema进行测试和验证(&lt;a href="https://jsonschemalint.com/"&gt;JSON Schema Validator&lt;/a&gt;)。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/customized-data-verification-using-aws-lambda-powertools3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/customized-data-verification-using-aws-lambda-powertools3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;今天是移动互联网的时代，也是数据信息的时代。无论是在电商运营中，还是在社交媒体中，数据都扮演着举足轻重的角色。在系统之间进行数据交互的场景下，应用程序的鲁棒性(Robust)十分依赖于数据本身的健壮性(Fitness)和一致的(Consistency)。因此，对于数据的接收方来说，对数据的格式，内容的验证过程显得至关重要。&lt;/p&gt; 
&lt;p&gt;通常我们可以自己编写代码在进程使用前对数据进行进行验证，但是这样做往往会存在代码复杂不易修改和验证覆盖度较低的问题。相比于传统的验证方式，AWS Lambda Powertools提供了一种更清晰简洁的校验方式。依托于JSON Schema强大的拓展性，它理论上几乎可以实现对任何内容的json文件的验证。而丰富的JSON Schema工具无疑进一步提高了生产效率，希望本文能够给您提供一些帮助，更好的时间数据的验证。通过对数据进行细致地校验，可以显著降低不符合系统规范的数据进入系统，大幅度降低系统不稳定甚至崩溃的风险。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/zxiaogon.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;张晓功&lt;/h3&gt; 
  &lt;p&gt;AWS云原生应用架构师，负责基于AWS的云计算方案架构的咨询和设计，同时致力于AWS云服务在国内的应用和推广。精通微服务架构设计、治理、容器编排、监控熔断等性能和可靠性等具体功能落地。具有丰富的互联网产品开发、大规模并行计算、性能优化等经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/junruiw.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;王钧睿&lt;/h3&gt; 
  &lt;p&gt;云原生应用实习生，负责基于AWS的云计算方案架构的设计和实施开发。对高级算法和计算机系统底层架构以及编译过程具有研究和热情，致力于用高效稳定的程序为客户解决实际问题。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>降低AWS Lambda 冷启动时间的4种方案</title>
		<link>https://aws.amazon.com/cn/blogs/china/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda/</link>
				<pubDate>Tue, 14 Sep 2021 15:23:04 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Serverless]]></category>
		<category><![CDATA[Amazon EventBridge]]></category>
		<category><![CDATA[Amazon Lambda]]></category>

		<guid isPermaLink="false">bbe8bb866335baf4d23453ffea4a1a9dfb2f36da</guid>
				<description>自从 AWS 推出无服务架构 AWS Lambda 以来，成千上万的用户都受益于此，您无需预置或管理任何服务器，就可以快速部署和运行代码。但是在无服务器架构带来极大便利的同时，我们需要承认，如果您使用无服务器架构模型，在实时性要求较高的应用场景下，Lambda 冷启动将会是您的应用程序需要面临的一个切实的挑战。本文总结了四种有关 Lambda 冷启动优化的解决方案。编程语言选择， 应用程序瘦身，代码预热（温程序）和jvm优化。每个解决方案，都有自己的优势和局限。</description>
								<content:encoded>&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;自从 AWS 推出无服务架构 AWS Lambda 以来，成千上万的用户都受益于此，您无需预置或管理任何服务器，就可以快速部署和运行代码。但是在无服务器架构带来极大便利的同时，我们需要承认，如果您使用无服务器架构模型，在实时性要求较高的应用场景下，Lambda 冷启动将会是您的应用程序需要面临的一个切实的挑战。&lt;/p&gt; 
&lt;h3&gt;Lambda 生命周期&lt;/h3&gt; 
&lt;p&gt;我们先来看一下 Lambda 执行环境的生命周期，Lambda 生命周期可以分为三个阶段：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Init&lt;/strong&gt;：在此阶段，Lambda 会尝试解冻之前的执行环境，若没有可解冻的环境，Lambda 会进行资源创建，下载函数代码，初始化扩展和 Runtime，然后开始运行初始化代码（主程序外的代码）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Invoke&lt;/strong&gt;：在此阶段，Lambda 接收事件后开始执行函数。函数运行到完成后，Lambda 会等待下个事件的调用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shutdown&lt;/strong&gt;：如果 Lambda 函数在一段时间内没有接收任何调用，则会触发此阶段。在&lt;code&gt;Shutdown&amp;nbsp;&lt;/code&gt;阶段，Runtime 关闭，然后向每个扩展发送一个&amp;nbsp;&lt;code&gt;Shutdown&amp;nbsp;&lt;/code&gt;事件，最后删除环境。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 当您在触发 Lambda 时，若当前没有处于激活阶段的 Lambda 可供调用，则 Lambda 会下载函数的代码并创建一个 Lambda 的执行环境。从事件触发到新的 Lambda 环境创建完成这个周期通常称为 “冷启动时间”。&lt;/p&gt; 
&lt;h3&gt;冷启动的影响&lt;/h3&gt; 
&lt;p&gt;由于 Lambda 特性，冷启动问题是无法避免的。&lt;/p&gt; 
&lt;p&gt;假设我们采用 Lambda 来构建 Web 服务，冷启动和 Web 服务初始化时间一共超过了5秒钟，那么无疑将会使您网站的用户体验大打折扣，因此设法减少冷启动时间，提高终端用户的使用体验，是您在构建无服务器架构时亟待解决的问题。&lt;/p&gt; 
&lt;h2&gt;减少 Lambda 冷启动影响的方案&lt;/h2&gt; 
&lt;p&gt;本文中，对目前业界的一些解决冷启动的方案进行梳理和对比，可以供您参考和选择。&lt;/p&gt; 
&lt;h3&gt;1 选择合适的编程语言&lt;/h3&gt; 
&lt;p&gt;目前 Lambda 支持的编程语言（Runtime）有 .NET Core、Go、Java、Node.js、Python、Ruby。在默认 512MB 内存的情况下，我们创建不同语言的lambda函数，做一个冷启动时间横向的测试和比较。各个语言的冷启动时间如下表所示。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 从表中可以看出，选择不同的语言，带来的冷启动时间也各不相同。如果业务和技术架构允许的前提下，我们可以尽量选择如python这样的编程语言，从根本上降低冷启动带来的影响。&lt;/p&gt; 
&lt;h3&gt;2 减小应用程序大小&lt;/h3&gt; 
&lt;p&gt;由于 Lambda 在冷启动的时候会下载函数代码，下载代码这个过程也影响着启动时间，若是代码包太大，则下载时间将会变长，直接增加 Lambda 的启动时间。&lt;/p&gt; 
&lt;p&gt;所以，想要降低冷启动时间，可以对应用程序进行瘦身，比如在程序中移除不必要的代码、减少不必要的第三方库依赖等。&lt;/p&gt; 
&lt;h3&gt;3 预热&lt;/h3&gt; 
&lt;p&gt;在事件触发 Lambda 函数时，若此时有处于激活状态的 Lambda 可被调用，那么就可以避免冷启动，降低响应时间。在 AWS 环境中，有多种方式可以预热 Lambda，这里我们向大家介绍使用Amazon EventBridge 和预制并发两种方式，供大家参考。&lt;/p&gt; 
&lt;h4&gt;3.1 Amazon EventBridge&lt;/h4&gt; 
&lt;p&gt;Amazon EventBridge 是AWS 的一个 Serverless 服务，它可以创建事件去驱动其它程序或服务。EventBridge 可以配置时间计划，按照时间间隔去生成事件。&lt;br&gt; 因此，想要让 Lambda 达到一个预热的效果，我们可以通过EventBridge按照一定的时间间隔去对lambda进行调用。比如通过创建一个每五分钟（时间间隔根据应用场景决定）触发一次的 EventBridge 来执行调用 Lambda。这样在真正想要处理的事件抵达之前，就会有已经被预热 Lambda 保持激活状态以等待响应。以上方式在有些文章中也被称为“温程序”。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 不过这种方式比较适用于事件较少且同一时间段事件请求不会太多的应用场景，当同一时间段调用 Lambda 的事件过多，预热的函数不足以响应时，AWS 就会增加新的 Lambda实例，同样造成冷启动，增加响应时间。对于这种场景，我们可以通过配置预置并发的方式同时预热更多 Lambda 实例来进行响应。&lt;/p&gt; 
&lt;h4&gt;3.2 预置并发&lt;/h4&gt; 
&lt;p&gt;预置并发是 AWS Lambda 在 2019 年推出的一个功能，该功能能够指定处于激活状态的 Lambda 实例数量，使函数保持初始化状态，在两位数毫秒的超短时间内做出响应。这是实现交互式服务（例如 Web 和移动后端、对延迟敏感的微服务或同步 API）的理想选择。&lt;br&gt; 我们可在 Lambda 控制台中进行配置预置并发。配置过程如下图所示。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;4 JVM 分层编译&lt;/h3&gt; 
&lt;p&gt;如果您的 Lambda 采用的是 Java 语言的话，那么还可以采用分层编译的方式来减少冷启动时间。&lt;/p&gt; 
&lt;h4&gt;4.1 原理&lt;/h4&gt; 
&lt;p&gt;从 Java 开发工具包 (JDK) 的第 8 版开始，两个即时编译器 C1 和 C2 已结合使用。 C1 设计用于客户端并为开发人员启用短反馈循环。 C2 设计用于服务器端并在分析后实现更高的性能。分层用于确定使用哪个编译器来实现更好的性能。这些表示为五个级别：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 在应用程序启动时，JVM 最初会解释所有字节码并收集有关它的分析信息。然后，JIT 编译器使用收集到的分析信息来查找热点。首先，JIT 编译器使用 C1 编译频繁执行的代码段，以快速达到本机代码性能。稍后，当有更多分析信息可用时，C2 就会启动。C2 使用更激进和更耗时的优化重新编译代码以提高性能：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; C2 编译器通常需要更多时间和更多内存来编译相同的方法。但是，它生成的本机代码比 C1 生成的代码优化得更好。综上所述，如果您希望实现更快启动时间的 Lambda 客户可以使用c1编译进行配置，而降低启动时间，但是带来的风险是运行效率有所降低。&lt;/p&gt; 
&lt;h4&gt;4.2 禁用分层编译&lt;/h4&gt; 
&lt;p&gt;我们可以通过设置 –XX:-TieredCompilation 标志来禁用分层编译。当我们设置这个标志时，JVM 不会在编译级别之间转换。因此，我们需要选择要使用的 JIT 编译器：C1 或 C2。除非明确指定，否则 JVM 会根据我们的 CPU 决定使用哪个 JIT 编译器。&lt;/p&gt; 
&lt;p&gt;为了禁用 C2 并仅使用 C1 而没有分析开销，我们可以应用 -XX:TieredStopAtLevel=1 参数。要完全禁用两个 JIT 编译器并使用解释器运行所有内容，我们可以应用 -Xint 标志。但是，我们应该注意禁用 JIT 编译器会对性能产生负面影响。&lt;/p&gt; 
&lt;h4&gt;4.3 操作步骤&lt;/h4&gt; 
&lt;h5&gt;4.3.1 创建 Layer&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;新建文件 java-exec-wrapper，内容为&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;#!/bin/sh
shift
export _JAVA_OPTIONS="-XX:+TieredCompilation -XX:TieredStopAtLevel=1"
java "$@"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&amp;nbsp;修改文件权限并压缩&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt; 	chmod 755 java-exec-wrapper &amp;amp;&amp;amp; zip layer.zip java-exec-wrapper&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;登录到 AWS Lambda Console&lt;/li&gt; 
 &lt;li&gt;进入 Layers 创建新的 Layer&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;5. 将刚刚压缩后的文件上传，创建新的 Layer&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;4.3.2 对 Lambda 添加分层编译&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;进入 Lambda Functions，进入优化目标的 Java Lambda 函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;默认在 Code 标签页下，将页面下滑至 Layers 面板&lt;/li&gt; 
 &lt;li&gt;点击 Add a layer 对 Lambda 进行添加 Layer&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;选择 Custom Layer，并使用刚刚创建的 Layer，选择 Version 后添加&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;给 Lambda 添加环境变量&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;环境变量 Key 为 AWS_LAMBDA_EXEC_WRAPPER，Value 为 /opt/java-exec-wrapper，点击保存&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;按照如上步骤操作后，我们可以通过 CloudWatch 来查看是否生效，我们调用 Lambda，若在 CloudWatch 的 Log 中存在 Picked up _JAVA_OPTIONS: -XX:+TieredCompilation -XX:TieredStopAtLevel=1 日志，则 Java Lambda 分层编译生效。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda15.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/4-solutions-to-reduce-the-cold-start-time-of-aws-lambda15.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;本文总结了四种有关 Lambda 冷启动优化的解决方案。编程语言选择， 应用程序瘦身，代码预热（温程序）和jvm优化。每个解决方案，都有自己的优势和局限。比如编程语言选择，这个和具体的业务场景和技术方案相关，需要架构师和开发人员有的放矢，具体的问题进行具体分析。再比如，预热对于可预期的流量效果显著，但是在处理有明显流量尖峰或不可预期流量时，也会同样面临冷启动的影响。&lt;/p&gt; 
&lt;p&gt;希望本文可以帮助您在了解和掌握解决冷启动方式和方法的同时，结合您的业务和使用场景，选择不同的应对方案，有效的提升和解决无服务器架构中的性能问题和隐患。&lt;/p&gt; 
&lt;h2&gt;参考文献&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/introduction-to-lambda-pre-configured-concurrency/"&gt;https://aws.amazon.com/cn/blogs/china/introduction-to-lambda-pre-configured-concurrency/&lt;/a&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/"&gt;https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/&lt;/a&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-2/"&gt;https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-2/&lt;/a&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/cn/blogs/china/new-provisioned-concurrency-for-lambda-functions/"&gt;https://aws.amazon.com/cn/blogs/china/new-provisioned-concurrency-for-lambda-functions/&lt;/a&gt;&lt;br&gt; &lt;a href="https://aws.amazon.com/cn/blogs/compute/increasing-performance-of-java-aws-lambda-functions-using-tiered-compilation/"&gt;https://aws.amazon.com/cn/blogs/compute/increasing-performance-of-java-aws-lambda-functions-using-tiered-compilation/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/zxiaogon.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;张晓功&lt;/h3&gt; 
  &lt;p&gt;AWS云原生应用架构师，负责基于AWS的云计算方案架构的咨询和设计，同时致力于AWS云服务在国内的应用和推广。精通微服务架构设计、治理、容器编排、监控熔断等性能和可靠性等具体功能落地。具有丰富的互联网产品开发、大规模并行计算、性能优化等经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/hefengx.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;许和风&lt;/h3&gt; 
  &lt;p&gt;AWS 云原生应用工程师，负责基于 AWS 的云计算方案架构的设计和实施。对公有云、DevOps、微服务、容器化、Serverless、全栈开发等有深入的研究，同时致力于推广云原生应用，帮助客户利用云原生来实现业务需求。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>构建在Amazon EMR之上的Apache Atlas展现数据目录和数据血缘</title>
		<link>https://aws.amazon.com/cn/blogs/china/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship/</link>
				<pubDate>Tue, 14 Sep 2021 14:54:21 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Data Catalog]]></category>

		<guid isPermaLink="false">ec80b8909fd90595bad45cb40063527cb1b4d7a5</guid>
				<description>在数据驱动业务的时代，各行各业中不同体量的客户都意识到数据的重要性，但是面对日 益增加的各式各样的数据，如何知晓这些数据是什么，什么时间，什么地方发生了变化， 这个数据的拥有者又是谁,等等。只有清楚的知晓这些内容，才能做到数据驱动业务。这 个时候，数据的元数据管理与数据治理成为企业级数据湖的重要部分。本文聚焦于构建在 Amazon EMR 之上的 Apache Atlas 展现数据目录和数据血缘。</description>
								<content:encoded>&lt;h2&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在数据驱动业务的时代，各行各业中不同体量的客户都意识到数据的重要性，但是面对日益增加的各式各样的数据，如何知晓这些数据是什么，什么时间，什么地方发生了变化，这个数据的拥有者又是谁,等等。只有清楚的知晓这些内容，才能让不同的业务部门利用到数据，也才能做到数据驱动业务。这个时候，数据的元数据管理与数据治理成为企业级数据湖的重要部分。本文聚焦于构建在Amazon EMR之上的Apache Atlas展现数据目录和数据血缘。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;二、简要说明&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Amazon EMR是是一个托管的Hadoop平台，可简化运行大数据框架（如Apache Hadoop和Apache Spark)的方式, 在亚马逊云科技的公有云平台上处理和分析海量数据。借助这些框架和相关的开源项目 (如 Apache Hive 和 Apache Pig)。您可以处理用于分析目的的数据和商业智能工作负载。此外，您可以使用 Amazon EMR 提取/处理/载入数据到其他亚马逊云科技的数据存储和数据库中，例如 Amazon Simple Storage Service (Amazon S3) 。&lt;/p&gt; 
&lt;p&gt;Apache Atlas最早由HortonWorks实现，用来管理Hadoop项目里面的元数据，进而设计为数据治理的框架。后来开源出来给Apache社区。以下是其架构图：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;图片来源:&lt;a href="https://atlas.apache.org/#/Architecture"&gt;https://atlas.apache.org/#/Architecture&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;该框架天然就支持横向扩展，能很好的和Hadoop平台中其他组件进行集成，非常适合在共有云上使用。&lt;/p&gt; 
&lt;p&gt;Apache Atlas的最核心部分就是类型管理系统(Type System)，用户可以把数据资产进行类型定义，然后使用Ingest/Export模块进行元数据的导入、修改、删除等管理。和外界的接口可以通过Http/Rest API或使用Kafaka进行消息交换。数据对象存放在按照图的模式进行管理的JanusGraph图数据库中，具体JanusGraph又把元数据存放在HBase中，索引存放在Solr中。这样用户可以非常便捷和直观的通过层次图进行浏览，可以按照字符串进行精确的检索。&lt;/p&gt; 
&lt;p&gt;另外，Atlas为组织提供开放的元数据管理和治理能力，以建立其数据资产的目录。Atlas支持数据的分类，数据发现，数据血缘。它还提供了搜索关键元素及其业务定义的功能。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;三、环境部署&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此处我们会使用两种方式来创建Amazon EMR集群和安装Atlas，分别是手动创建Amazon EMR集群和安装Atlas，以及通过CDK来自动创建Amazon EMR集群和安装Atlas&lt;/p&gt; 
&lt;h3&gt;(一)手动创建Amazon EMR集群和安装Atlas&lt;/h3&gt; 
&lt;p&gt;1) 创建Amazon EMR集群&lt;/p&gt; 
&lt;p&gt;首先创建一个带有Apache Hadoop、Hive、HBase、Hue和ZooKeeper等应用的Amazon EMR集群。Apache Atlas使用Apache Solr进行搜索功能，使用Apache HBase进行存储。Solr和HBase都安装在持久的Amazon EMR集群上，作为Atlas安装的一部分。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws emr create-cluster --auto-scaling-role EMR_AutoScaling_DefaultRole --termination-protected --applications Name=Hadoop Name=Hive Name=HBase Name=Hue Name=ZooKeeper --ebs-root-volume-size 50 --ec2-attributes '{"KeyName":"&amp;lt;your_key_name&amp;gt;","InstanceProfile":"EMR_EC2_DefaultRole","SubnetId":"subnet-0c3b898eea96b4f3e","EmrManagedSlaveSecurityGroup":"sg-0d5296d5ecc314461","EmrManagedMasterSecurityGroup":"sg-0f5a587aa2c9d43dc"}' --service-role EMR_DefaultRole --enable-debugging --release-label emr-5.33.0 --log-uri 's3n://aws-logs-6***********-cn-northwest-1/elasticmapreduce/' --name 'emratlas' --instance-groups '[{"InstanceCount":2,"EbsConfiguration":{"EbsBlockDeviceConfigs":[{"VolumeSpecification":{"SizeInGB":32,"VolumeType":"gp2"},"VolumesPerInstance":2}]},"InstanceGroupType":"CORE","InstanceType":"m5.xlarge","Name":"Core - 2"},{"InstanceCount":1,"EbsConfiguration":{"EbsBlockDeviceConfigs":[{"VolumeSpecification":{"SizeInGB":32,"VolumeType":"gp2"},"VolumesPerInstance":2}]},"InstanceGroupType":"MASTER","InstanceType":"m5.xlarge","Name":"Master - 1"}]' --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region cn-northwest-1&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 下面的命令显示Amazon EMR集群的状况&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws emr list-clusters --active | jq .Clusters[0]&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 如下图说明集群已经正常可用。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2) 创建额外的步骤&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws emr add-steps --cluster-id j-18RWZV76AQF4M  --steps Name='Run Script',Jar=command-runner.jar,Args=[bash,-c,'curl https://aws-bigdata-jerry-blog.s3.cn-northwest-1.amazonaws.com.cn/apache-atlas.sh -o /tmp/script.sh; chmod +x /tmp/script.sh; /tmp/script.sh']&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;此步骤主要是安装Atlas的和kafka这样的依赖的组件。具体内容请查看Github 链接( &lt;a href="https://github.com/jerryjin2018/Bigdata-Atlas/blob/main/apache-atlas.sh"&gt;https://github.com/jerryjin2018/Bigdata-Atlas/blob/main/apache-atlas.sh&lt;/a&gt; )&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;正常执行完成。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws emr list-steps --cluster-id j-18RWZV76AQF4M | jq .Steps[0]&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;登陆到Amazon EMR集群master节点上，可以看到Atlas服务已经启动，并且监听在21000端口。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;(二)通过CDK自动创建Amazon EMR集群和安装Atlas&lt;/h3&gt; 
&lt;p&gt;可以参考链接 https://github.com/aws-samples/aws-cdk-emr-atlas&lt;/p&gt; 
&lt;p&gt;1) 准备前置条件&lt;/p&gt; 
&lt;p&gt;(1)你需要准备一个密钥对，将被赋给Amazon EMR集群中的EC2实例，在接下来步骤中的aws-cdk-emr-atlas/aws-emr-cdk目录中的app-config.yaml文件中进行配置&lt;/p&gt; 
&lt;p&gt;(2)你需要创建两个S3桶，并在app-config.yaml中配置为s3_log_bucket和s3_script_bucket&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws s3 mb s3://jerry-cdk-emr-log-bucket
aws s3 mb s3://jerry-cdk-emr-script-bucket
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; (3)将aws-cdk-emr-atlas/aws-emr-cdk放置到刚才为s3_script_bucket创建的S3桶，上面的例子中的jerry-cdk-emr-script-bucket&lt;/p&gt; 
&lt;p&gt;(4)EMR服务的IAM角色和工作流IAM角色将被自动创建&lt;/p&gt; 
&lt;p&gt;(5)一个带有公共子网的VPC将被自动创建&lt;/p&gt; 
&lt;p&gt;2) 创建Amazon EMR集群&lt;/p&gt; 
&lt;p&gt;亚马逊云科技Cloud Development Kit(CDK) 是一种开源软件开发框架，可让您使用熟悉的编程语言来定义云应用程序资源。&lt;/p&gt; 
&lt;p&gt;亚马逊云科技CDK利用编程语言的常见性和表达能力为应用程序建模。它为您提供名为结构的高级组件，使用经过验证的默认值预配置云资源，因此您无需成为专家也可构建云应用程序。亚马逊云科技CDK通过亚马逊云科技 CloudFormation以安全、可重复的方式预置您的资源。它还支持您编写和分享体现组织要求的自定义结构，帮助您更快启动新项目。&lt;/p&gt; 
&lt;p&gt;按照此链接（ &lt;a href="https://docs.aws.amazon.com/zh_cn/cdk/latest/guide/getting_started.html"&gt;https://docs.aws.amazon.com/zh_cn/cdk/latest/guide/getting_started.html&lt;/a&gt; ）&lt;/p&gt; 
&lt;p&gt;中的步骤，安装CDK和下载相关安装代码（此处以Amazon Linux 2环境为例）&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;sudo npm install -g aws-cdk
cdk –version
git clone https://github.com/aws-samples/aws-cdk-emr-atlas
cd aws-cdk-emr-atlas/aws-emr-cdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 注意修改一下aws-cdk-emr-atlas/aws-emr-cdk目录中app-config.yml文件的内容，主要就是替换你的亚马逊云科技的Account ID和对应EMR集群所在的区域。还有就是EMR的版本和S3桶的桶名和秘钥对，具体是如下5项你已经准备了的.&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;另外就是用如下命令将apache-atlas-emr.sh上传到为s3_script_bucket创建的S3桶，上面的例子中的jerry-cdk-emr-script-bucket&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws s3 cp apache-atlas-emr.sh s3://jerry-cdk-emr-script-bucket/&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 安装相应的依赖包和创建Amazon EMR集群和安装Atlas&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pip3 install PyYAML
pip3 install aws_cdk.core
pip3 install aws_cdk.aws_emr
pip3 install aws_cdk.aws_ec2
cdk deploy
#You may need to upgrade CDK CLI through following command 
npm install -g aws-cdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;创建Amazon EMR集群的过程&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef7.png" width="624" height="78"&gt;&lt;/a&gt;下面的命令显示Amazon EMR集群的状况&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws emr list-clusters --active | jq .Clusters[0]&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;登陆到Amazon EMR集群master节点上，可以看到Atlas服务已经启动，并且监听在21000端口。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/abcdef9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;(三)后续步骤&lt;/h3&gt; 
&lt;p&gt;1) 创建浏览器代理&lt;/p&gt; 
&lt;p&gt;因为创建的Amazon EMR集群中服务（除了SSH服务）是不会直接对公网开放的，那如何从你的workstation访问这些服务了。可以通过“使用SSH动态端口转发与主节点之间的 SSH 隧道” &lt;a href="https://docs.amazonaws.cn/emr/latest/ManagementGuide/emr-ssh-tunnel.html"&gt;https://docs.amazonaws.cn/emr/latest/ManagementGuide/emr-ssh-tunnel.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;和“配置浏览器代理以查看EMR主节点上托管的服务“ &lt;a href="https://docs.amazonaws.cn/emr/latest/ManagementGuide/emr-connect-master-node-proxy.html"&gt;https://docs.amazonaws.cn/emr/latest/ManagementGuide/emr-connect-master-node-proxy.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;来访问。&lt;/p&gt; 
&lt;p&gt;2) 访问Atlas&lt;/p&gt; 
&lt;p&gt;通过亚马逊云科技Amazon EMR的页面，我们可以看到我们刚刚创建的EMR集群的信息。当我们选择”应用程序历史记录”选项时，我们可以看到On-cluster application user interfaces的信息，这里包含了EMR集群中的一些服务的访问地址。我们按照“HDFS 名称节点”的URL的格式，将端口换为21000，我们就可以访问Atlas的服务页面&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在开启SSH动态端口转发情况下，访问Atlas的web界面（默认的用户名和密码都是admin），如下图：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为 “类型” (type)的定义组成。这些元数据对象也被被称为“实体”(entities)。由 Atlas 管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为各种类型的“实体”(entities)。&lt;/p&gt; 
&lt;p&gt;Type：Atlas中的 “类型” 定义了如何存储和访问特定类型的元数据对象。类型表示了所定义元数据对象的一个或多个属性集合。如果您有开发背景，很容易将 “类型” 理解成面向对象的编程语言的 “类” 定义的或关系数据库的 “表模式”。&lt;/p&gt; 
&lt;p&gt;当我们在Atlas的SEARCH选项中的“Search By Type”中选择Asset再Search,可以看到我们目前什么内容也没有，因为数据目录中还没有数据：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;四、数据目录和数据血缘&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;1) 创建实验数据一&lt;/h3&gt; 
&lt;p&gt;Atlas安装包提供了两个例子数据。登陆到Amazon EMR的master节点上，我们先来看看这两个例子数据：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;cd /apache/atlas/bin/
ls -l
sudo python ./quick_start.py
sudo python ./quick_start_v1.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; …&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 我们在Atlas中再Search Asset，看到了各种类型(Type)的“实体”(entities)。&lt;/p&gt; 
&lt;p&gt;Atlas 提供了一些预定义的系统类型，特别是如下的集中类型:&lt;/p&gt; 
&lt;p&gt;Asset：此类型包含名称，说明和所有者等属性&lt;/p&gt; 
&lt;p&gt;DataSet：此类型扩展了Referenceable和Asset 。在概念上，它可以用于表示存储数据的类型。在 Atlas 中，hive表，Sqoop RDBMS表等都是从 DataSet 扩展的类型。扩展 DataSet 的类型可以期望具有模式，它们将具有定义该数据集的属性的属性。例如， hive_table 中的 columns 属性。另外，扩展 DataSet 的实体类型的实体参与数据转换，这种转换可以由 Atlas 通过 lineage（血缘）生成图形。&lt;/p&gt; 
&lt;p&gt;Process：此类型扩展了Referenceable和Asset 。在概念上，它可以用于表示任何数据变换操作。例如，将原始数据的 hive 表转换为存储某个聚合的另一个 hive 表的 ETL 过程可以是扩展过程类型的特定类型。流程类型有两个特定的属性，输入和输出。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Apache atlas的其中一个核心特性就是可以追溯数据湖中数据的血缘关系（lineage）并以可视化的方式呈现，使用户能够快速了解数据的生命周期，并能够知晓数据是从那里来以及和数据湖中数据之间的关联关系。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2) 创建实验数据二&lt;/h3&gt; 
&lt;p&gt;我们来创建一些Hive的外表，从如下链接下载一些公开的数据集,并做简单处理(删除几个不需要的字段，和更改字段名称)，再将数据文件上传到笔者的名称为aws-bigdata-jerry-blog的S3存储桶中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"&gt;https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;登陆到Amazon EMR集群的master节点上，在命令提示符处，输入命令:&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;hive
show databases;
show tables;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship15.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship15.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建trip_details表&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE external TABLE trip_details
(
  dispatching_num    int ,
  pickup_datetime    string ,
  dropoff_datetime   string ,
  location_id        int 
)
row format delimited
fields terminated by ',' stored as textfile
LOCATION 's3://aws-bigdata-jerry-blog/trip_details/';&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship16.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship16.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建trip_zone_lookup表&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE external TABLE trip_zone_lookup 
(
LocationID     int ,
Borough        string ,
Zone           string ,
service_zone   string
)
row format delimited
fields terminated by ',' stored as textfile
LOCATION 's3://aws-bigdata-jerry-blog/trip_zone_lookup/';&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship17.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship17.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 查看trip_details和trip_zone_lookup表的数据的条数：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship18.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship18.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建一个由trip_details和trip_zone_lookup join的表trip_details_by_zone&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;create table trip_details_by_zone as select *  from trip_details p join trip_zone_lookup z on z.LocationID = p.location_id;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship19.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship19.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 这次我们在Atlas中再Search Asset，看到了更多类型(Type)的“实体”(entities)，特别是hive_table,hive_column和hive_process.&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship20.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship20.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;这次我在Atlas左侧选择的SEARCH选项中的“Search By Type”中选择hive_table, “Search By Text”中选择trip_details_by_zone,再Search：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship21.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship21.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;从Properties，我们能看到关于这张表的信息，特别是这张表中的数据字段是什么，什么时间，什么地方发生了变化（创建时间），这个数据的拥有者又是谁,等等。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship22.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship22.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我们再来看一下表trip_details_by_zone的血缘关系（lineage）和关系（Relationships）&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship23.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship23.png" width="624" height="78"&gt;&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship24.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/apache-atlas-built-on-amazon-emr-shows-data-catalog-and-data-blood-relationship24.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;五、总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在这篇博客中，我们概述了通过使用AWS CLI和通过CDK来安装和配置Amazon EMR集群，以及在Amazon EMR集群之上部署和配置Apache Atlas。我们还探讨了如何将数据导入Atlas，并使用Atlas界面来查询和查看相关数据的数据目录和数据血缘。&lt;/p&gt; 
&lt;h2&gt;参考材料:&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.jianshu.com/p/c65f54dd5e7d"&gt;https://www.jianshu.com/p/c65f54dd5e7d&lt;/a&gt;&lt;br&gt; &lt;a href="https://my.oschina.net/sunmin/blog/3064462"&gt;https://my.oschina.net/sunmin/blog/3064462&lt;/a&gt;&lt;br&gt; &lt;a href="https://atlas.apache.org/2.0.0/InstallationSteps.html"&gt;https://atlas.apache.org/2.0.0/InstallationSteps.html&lt;/a&gt;&lt;br&gt; &lt;a href="https://developpaper.com/getting-started-with-apache-atlas/"&gt;https://developpaper.com/getting-started-with-apache-atlas/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/zhongmij.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;金忠敏&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，现在专注于云计算解决方案和架构的工作。具有超过15年的IT从业经验，曾从事软件开发，售后支持，系统交付，售前等工作。参与过很多大型项目架构设计和实施交付。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/jiatin.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;贾婷&lt;/h3&gt; 
  &lt;p&gt;AWS快速原型解决方案架构师，致力于帮助客户设计和开发大数据方向的快速原型方案，有游戏、汽车行业的大数据开发经验。在业余时间，她喜欢跑步、瑜伽以及和家人旅行。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>欢迎参加 2021 年 AWS 存储日</title>
		<link>https://aws.amazon.com/cn/blogs/china/welcome-to-aws-storage-day-2021/</link>
				<pubDate>Thu, 09 Sep 2021 14:45:25 +0000</pubDate>
		<dc:creator><![CDATA[Marcia Villalba]]></dc:creator>
				<category><![CDATA[Storage]]></category>

		<guid isPermaLink="false">9a1fcc2a3243e1db02dfcc207442a0c14ea8a339</guid>
				<description>欢迎参加第三届 2021 年 AWS 存储日！ 在 2020 年存储日和 2019 年首个存储日期间，我们向客户发布了许多具有影响力的公告，今年也会同样精彩。为期一天的免费 2021 AWS 存储日 虚拟活动将在 Twitch 的 AWS 频道上进行。您可以聆听专家介绍与 AWS 存储服务相关的公告、领导层洞察和教育内容。</description>
								<content:encoded>&lt;p&gt;欢迎参加第三届 2021 年 AWS 存储日！ 在&lt;a href="https://aws.amazon.com/blogs/aws/welcome-to-aws-storage-day-2020/"&gt; 2020 年存储日&lt;/a&gt;和&lt;a href="https://aws.amazon.com/blogs/aws/welcome-to-aws-storage-day/"&gt; 2019 年首个存储日期间，&lt;/a&gt;我们向客户发布了许多具有影响力的公告，今年也会同样精彩。为期一天的免费&lt;a href="https://pages.awscloud.com/AWS-Storage-Day-2021.html"&gt; 2021 AWS 存储日 &lt;/a&gt; 虚拟活动将在&lt;a href="https://www.twitch.tv/aws"&gt; Twitch 的 AWS 频道上&lt;/a&gt;进行。您可以聆听专家介绍与&lt;a href="https://aws.amazon.com/products/storage/"&gt; AWS 存储服务&lt;/a&gt;相关的公告、领导层洞察和教育内容。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/17/AWS_Storage-Day_wType_green-on-squid-800x400-2.jpg"&gt;&lt;img class="wp-image-54000 size-full alignright" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/17/AWS_Storage-Day_wType_green-on-squid-800x400-2.jpg" alt="AWS 存储日当天" width="409" height="391"&gt;&lt;/a&gt;的第一部分是领导对话。存储、边缘和数据治理副总裁 Wayne Duso 将进行现场主题演讲。他将介绍 AWS 云存储的新功能以及这些服务如何帮助企业提高敏捷性和加速创新。主旨演讲之后，将现场采访 AWS 存储领导团队，包括 AWS 数据块和对象存储副总裁 Mai-Lan Tomsen Bukovec。&lt;/p&gt; 
&lt;p&gt;存储日的第二部分是技术内容，您将了解到更多关于 &lt;a title="" href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/ebs/"&gt;Amazon Elastic Block Store (EBS)&lt;/a&gt;、 &lt;a title="" href="https://aws.amazon.com/efs"&gt;Amazon Elastic File System (Amazon EFS)&lt;/a&gt;、 &lt;a title="" href="https://aws.amazon.com/backup/"&gt;AWS Backup&lt;/a&gt;、 &lt;a href="https://aws.amazon.com/cloud-data-migration/"&gt;Cloud Data Migration&lt;/a&gt;、 &lt;a title="" href="https://aws.amazon.com/aws-transfer-family"&gt;AWS Transfer Family&lt;/a&gt; 和 &lt;a title="Amazon FSx" href="https://aws.amazon.com/fsx/"&gt;Amazon FSx&lt;/a&gt; 的信息。&lt;/p&gt; 
&lt;p&gt;请访问&lt;a href="https://pages.awscloud.com/AWS-Storage-Day-2021.html"&gt; 2021 年 AWS 存储日活动页面&lt;/a&gt; 注册参加活动。&lt;/p&gt; 
&lt;p&gt;现在，正如 Jeff Barr 喜欢说的那样，让我们来看看这些公告。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Amazon FSx for NetApp ONTAP&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;今天，我们很高兴为您介绍 &lt;a title="" href="https://aws.amazon.com/fsx/netapp-ontap/"&gt;Amazon FSx for NetApp ONTAP&lt;/a&gt;, 这是一项新的存储服务，允许您云启动和运行完全托管式的 NetApp ONTAP 文件系统。&lt;span title=""&gt;Amazon FSx for NetApp ONTAP&lt;/span&gt; 加入 &lt;span title=""&gt;Amazon FSx for Lustre&lt;/span&gt; 和 &lt;span title=""&gt;Amazon FSx for Windows File Server&lt;/span&gt;，成为 &lt;span title=""&gt;Amazon FSx&lt;/span&gt; 提供的最新文件系统。&lt;/p&gt; 
&lt;p&gt;&lt;span title=""&gt;Amazon FSx for NetApp ONTAP&lt;/span&gt; 提供了完整的 ONTAP 用户体验，这些功能和 API 使得您可以轻松地在 AWS 上运行那些依赖 NetApp 或网络连接存储 (NAS) 设备的应用程序，而无需更改应用程序代码或数据管理方式。要了解详情，请参阅 &lt;a href="https://aws.amazon.com/blogs/aws/new-amazon-fsx-for-netapp-ontap"&gt;New — Amazon FSx for NetApp ONTAP&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Amazon S3&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;a href="https://aws.amazon.com/s3/features/multi-region-access-points/"&gt;Amazon S3 多区域访问点&lt;/a&gt;是一项新的&lt;span title=""&gt; S3&lt;/span&gt; 功能，允许您定义跨越多个 AWS 区域中存储桶的全球端点。使用此功能，您现在可以使用相同的系统架构构建多区域应用程序，就像您使用的是单个 AWS 区域一样，而不会增加应用程序的复杂性。&lt;/p&gt; 
&lt;p&gt;S3 多区域访问点构建于 &lt;a title="AWS Global Accelerator" href="https://aws.amazon.com/de/global-accelerator/?blogs-global-accelerator.sort-by=item.additionalFields.createdDate&amp;amp;blogs-global-accelerator.sort-order=desc&amp;amp;aws-global-accelerator-wn.sort-by=item.additionalFields.postDateTime&amp;amp;aws-global-accelerator-wn.sort-order=desc"&gt; 之上。AWS Global Accelerator 和&lt;/a&gt;路由 &lt;span title=""&gt;S3&lt;/span&gt; 通过全局 AWS 网络进行请求。S3 多区域访问点将您的请求动态路由到最低延迟的数据副本，因此上载和下载性能可以提高 60％。对于依赖从 &lt;span title=""&gt;S3&lt;/span&gt; 读取文件的应用程序以及需要向 &lt;span title=""&gt;S3&lt;/span&gt;写入大量数据的自驾车等应用程序，这是一个很好的解决方案。要了解此次新启动的更多详情，请参阅&lt;a href="https://aws.amazon.com/blogs/aws/s3-multi-region-access-points-accelerate-performance-availability"&gt;如何使用 Amazon S3 多区域访问点提高多区域应用程序的性能和实用性 &lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/06/07/s3-multi-region-access-point-create-name.png"&gt;&lt;img class="alignnone wp-image-52656 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/06/07/s3-multi-region-access-point-create-name-1024x458.png" alt="创建多区域访问点" width="1024" height="458"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;还有关于 &lt;a href="https://aws.amazon.com/blogs/aws/s3-intelligent-tiering-adds-archive-access-tiers/"&gt; Amazon S3 Intelligent-Tiering 存储的好消息！&lt;/a&gt; 使用条件已更新。存储在 S3 Intelligent-Tiering 中的所有对象存储不再有最短存储持续时间，已删除小于 128 KB 的对象的监控和自动化费用。存储在 S3 Intelligent-Tiering 中较小的对象（128 KB 或更少）不符合自动分层条件。既然小型对象没有监控和自动化费用，也没有最短存储持续时间，因此，原定设置下，您可以对访问模式未知或更改访问模式的所有工作负载使用 S3 Intelligent-Tiering 存储类。要了解此次发布会的详情，请参阅 &lt;a href="http://aws.amazon.com/blogs/aws/amazon-s3-intelligent-tiering-further-automating-cost-savings-for-short-lived-and-small-objects"&gt; Amazon S3 Intelligent-Tiering — 提高短期和小型对象的成本优化&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;&lt;span title=""&gt;Amazon EFS&lt;/span&gt;&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;span title=""&gt;Amazon EFS&lt;/span&gt; 智能分层是一项新功能，可在访问模式发生变化时更轻松地优化共享文件存储成本。启用&lt;span title=""&gt; Amazon EFS&lt;/span&gt; 智能分层后，它将在适当的时间将文件存储在适当的存储类中。例如，如果对于一段时间内未使用的文件，EFS 智能分层会将该文件移动到&lt;a href="https://aws.amazon.com/efs/features/infrequent-access/"&gt;不频繁访问 (IA) 存储类别&lt;/a&gt;。如果再次访问该文件，智能分层会自动将其移回标准存储类。&lt;/p&gt; 
&lt;p&gt;请在新的或现有的文件系统中启用生命周期管理，然后选择生命周期策略以便在不同存储类别之间自动转移文件，即可开启智能分层。&lt;span title=""&gt;Amazon EFS&lt;/span&gt; 智能分层非常适合访问模式不断变化或未知访问模式的工作负载，例如机器学习推理和培训、分析、内容管理和媒体资产。要了解此次发布会的更多详情，请参阅 &lt;a href="https://aws.amazon.com/blogs/aws/new-amazon-efs-intelligent-tiering-optimizes-costs-for-workloads-with-changing-access-patterns"&gt;Amazon EFS 智能分层通过不断变化的访问模式优化工作负载的成本&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt;&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 允许您简化备份的数据管理和合规性管理，而无需 AWS 服务的支持。它提供了可自定义的控制和参数，例如备份频率或保留期。您还可以审计备份，以查看它们是否满足您的企业和监管要求。如果一个受监控备份偏离了预定义的参数，AWS Backup Audit Manager 将通知您，以便您可以采取纠正措施。此项新功能还能够生成报告，以便与审计员和监管机构共享。要了解详情，请参阅&lt;a href="https://aws.amazon.com/blogs/aws/monitor-evaluate-and-demonstrate-backup-compliance-with-aws-backup-audit-manager"&gt; 如何使用 AWS Backup Audit Manager 监控、评估和展示备份合规性。&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;Amazon EBS&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Amazon EBS direct API 现在支持直接从任何数据块存储数据（包括本地部署）创建 64 TB EBS 快照。从 16 TB 增加到 64 TB 后，允许客户创建最大的快照并将其恢复到&lt;a href="https://aws.amazon.com/blogs/aws/amazon-ebs-io2-block-express-volumes-with-amazon-ec2-r5b-instances-are-now-generally-available/"&gt; Amazon EBS io2 Block Express 卷&lt;/a&gt;。要了解详情，请参阅&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-accessing-snapshot.html"&gt; Amazon EBS 直接 API 文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;AWS Transfer Family&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;a title="" href="https://aws.amazon.com/aws-transfer-family"&gt;AWS Transfer Family&lt;/a&gt; 托管式工作流是一项新功能，它允许您减少预处理数据的手动任务。托管式工作流为您省去了许多繁重的迁移，例如在文件到达时搭建基础设施以便运行代码、持续监控错误以及验证是否记录了对数据的所有更改。托管式工作流可帮助您处理错误脚本，以便在需要时触发故障安全模式。&lt;/p&gt; 
&lt;p&gt;&lt;span title=""&gt;AWS Transfer Family&lt;/span&gt; 托管式工作流允许您一次配置所有必要的任务，以便任务可以在后台自动运行。现在可以在 AWS Transfer Family 管理控制台中找到托管式工作流。要了解详情，请参阅 &lt;a href="https://aws.amazon.com/aws-transfer-family/faqs/"&gt;Transfer Family 常见问题&lt;/a&gt; 。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/17/Site-Merch_Storage-Day_ConsoleSign-In.png"&gt;&lt;img class="alignright wp-image-53989 size-medium" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/17/Site-Merch_Storage-Day_ConsoleSign-In-300x237.png" alt="2021 年存储日" width="300" height="237"&gt;&lt;/a&gt; 线上加入我们了解更多信息！&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;别忘记&lt;a href="https://pages.awscloud.com/AWS-Storage-Day-2021.html"&gt;注册并加入我们，参加 2021 年 AWS 存储日&lt;/a&gt;虚拟活动。该活动将于 9 月 2 日太平洋时间上午 8:30（东部时间上午 11:30）直播。新加坡时间 9 月 3 日星期五上午 8:30 将为亚太地区观众重播该活动，并可以向主持人线上提问。所有会话将安排在下周。&lt;/p&gt; 
&lt;p&gt;我们期待您的参与！&lt;/p&gt; 
&lt;p&gt;– &lt;a href="https://twitter.com/mavi888uy"&gt;Marcia&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
	</channel>
</rss>