<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>亚马逊AWS官方博客</title>
	<atom:link href="https://aws.amazon.com/cn/blogs/china/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/cn/blogs/china/</link>
	<description>Just another AWS Brew Blogs  site</description>
	<lastBuildDate>Fri, 03 Sep 2021 13:36:50 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>Amazon Managed Grafana 现已全面推出，并具有许多新功能</title>
		<link>https://aws.amazon.com/cn/blogs/china/amazon-managed-grafana-is-now-generally-available-with-many-new-features/</link>
				<pubDate>Fri, 03 Sep 2021 13:36:50 +0000</pubDate>
		<dc:creator><![CDATA[Danilo Poccia]]></dc:creator>
				<category><![CDATA[News]]></category>

		<guid isPermaLink="false">d35bdf870737959a67f2dba3bb762a65b082508d</guid>
				<description>12 月，我们推出了 Amazon Managed Grafana 的预览版，这是一项与 Grafana Labs 合作开发的完全托管服务，可让您轻松使用开源版本和企业版 Grafana 来可视化和分析多个来源的数据。借助 Amazon Managed Grafana，您可以分析指标、日志和跟踪，而无需预置服务器或配置和更新软件。</description>
								<content:encoded>&lt;p&gt;12 月，我们推出了 &lt;a href="https://aws.amazon.com/grafana/"&gt;Amazon Managed Grafana&lt;/a&gt; 的&lt;a href="https://aws.amazon.com/blogs/aws/announcing-amazon-managed-grafana-service-in-preview/"&gt;预览版&lt;/a&gt;，这是一项&lt;a href="https://grafana.com/blog/2020/12/15/announcing-amazon-managed-service-for-grafana/"&gt;与 Grafana Labs 合作开发&lt;/a&gt;的完全托管服务，可让您轻松使用开源版本和企业版 &lt;a href="https://grafana.com/"&gt;Grafana&lt;/a&gt; 来可视化和分析多个来源的数据。借助 Amazon Managed Grafana，您可以分析指标、日志和跟踪，而无需预置服务器或配置和更新软件。&lt;/p&gt; 
&lt;p&gt;在预览期间，Amazon Managed Grafana 增加了很多&lt;a href="https://aws.amazon.com/blogs/mt/amazon-managed-service-for-grafana-amg-preview-updated-with-new-capabilities/"&gt;新的功能&lt;/a&gt;。今天，我很高兴地宣布，Amazon Managed Grafana 现已&lt;strong&gt;全面推出&lt;/strong&gt;，并附加全新功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;Grafana 现已&lt;a href="https://grafana.com/docs/grafana/latest/whatsnew/whats-new-in-v8-0/"&gt;升级至版本 8&lt;/a&gt;，并提供了新的数据源、可视化和功能，包括您只需构建一次即可在多个控制面板上重复使用的库面板、一个用于快速查找和查询指标的 Prometheus 指标浏览器，以及全新的状态时间表和状态历史可视化。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;要在 Amazon Managed Grafana 工作区中集中查询其他数据源，您现在可以使用 &lt;a href="https://grafana.com/grafana/plugins/simpod-json-datasource/"&gt;JSON 数据源插件&lt;/a&gt;来查询数据。您现在还可以查询 &lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;、&lt;a href="https://www.sap.com/products/hana.html"&gt;SAP HANA&lt;/a&gt;、&lt;a href="https://www.salesforce.com/"&gt;Salesforce&lt;/a&gt;、&lt;a href="https://www.servicenow.com/"&gt;ServiceNow&lt;/a&gt;、&lt;a href="https://www.atlassian.com/software/jira"&gt;Atlassian Jira&lt;/a&gt; 以及更多数据源。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;您可以使用 &lt;a href="https://docs.aws.amazon.com/grafana/latest/userguide/Using-Grafana-APIs.html"&gt;Grafana API 密钥&lt;/a&gt;来发布您自己的控制面板或以编程方式访问您的 Grafana 工作区。例如，这是一个可用于添加数据源和控制面板的 &lt;a href="https://aws-observability.github.io/aws-o11y-recipes/recipes/amg-automation-tf/"&gt;Terraform 配方&lt;/a&gt;。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;您可以使用&lt;a href="https://en.wikipedia.org/wiki/SAML_2.0"&gt;安全断言标记语言 2.0 (SAML 2.0)&lt;/a&gt; 来启用对 Amazon Managed Grafana 工作区的单点登录。我们与以下身份提供商 (IdP) 合作，以便在启动时将其集成：&lt;a href="https://www.cyberark.com/"&gt;Cyber​​Ark&lt;/a&gt;、&lt;a href="https://www.okta.com/"&gt;Okta&lt;/a&gt;、&lt;a href="https://www.onelogin.com/"&gt;OneLogin&lt;/a&gt;、&lt;a href="https://www.pingidentity.com/"&gt;Ping Identity&lt;/a&gt; 和 &lt;a href="https://azure.microsoft.com/en-us/services/active-directory/"&gt;Azure Active Directory&lt;/a&gt;。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;&lt;a title="" href="https://aws.amazon.com/cloudtrail/"&gt;AWS CloudTrail&lt;/a&gt; 会捕获来自 Amazon Managed Grafana 控制台的所有调用以及对 Amazon Managed Grafana API 操作的代码调用。通过这种方式，您可以记录用户、角色或 AWS 服务在 Amazon Managed Grafana 中执行的操作。此外，您现在可以审核 Amazon Managed Grafana 工作区中发生的突变，诸如控制面板被删除或者数据源权限被更改。&lt;/li&gt; 
 &lt;li&gt;该服务在 10 个 &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/#Regions"&gt;AWS 区域&lt;/a&gt;（完整列表位于文章末尾）推出。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;让我们快速演练一下，看看这在实践中是如何运作的。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;使用 Amazon Managed Grafana&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;在 &lt;a href="https://console.aws.amazon.com/grafana/home"&gt;Amazon Managed Grafana 控制台&lt;/a&gt;中，我选择&lt;strong&gt;创建工作区&lt;/strong&gt;。“工作区”是逻辑上隔离的、高度可用的 Grafana 服务器。我输入工作区的名称和描述，然后选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-create-workspace.png"&gt;&lt;img class="aligncenter size-large wp-image-53771" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-create-workspace-1024x567.png" alt="控制台屏幕截图。" width="1024" height="567"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我可以通过 SAML 使用 &lt;a href="https://aws.amazon.com/single-sign-on/"&gt;AWS Single Sign-On (AWS SSO)&lt;/a&gt; 或外部身份提供商对我工作区的用户进行身份验证。为简单起见，我选择 AWS SSO。在后文中，我将展示 SAML 身份验证的工作原理。如果这是您第一次使用 AWS SSO，则您可以查看&lt;a href="https://docs.aws.amazon.com/singlesignon/latest/userguide/prereqs.html"&gt;文档中的先决条件（例如，设置 AWS Organizations）&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/05/amg-auth.png"&gt;&lt;img class="aligncenter wp-image-53844 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/05/amg-auth-1024x670.png" alt="控制台屏幕截图。" width="1024" height="670"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;然后，我选择&lt;strong&gt;服务托管&lt;/strong&gt;权限类型。这样，Amazon Managed Grafana 会自动预置必要的 IAM 权限，以便访问我在下一步中要选择的 AWS 服务。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-type.png"&gt;&lt;img class="aligncenter size-large wp-image-53773" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-type-1024x346.png" alt="控制台屏幕截图。" width="1024" height="346"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;服务托管权限设置&lt;/strong&gt;中，我选择监控我当前 AWS 账户中的资源。如果您使用 &lt;a href="https://aws.amazon.com/organizations/"&gt;AWS Organizations&lt;/a&gt; 来集中管理您的 AWS 环境，您可以使用 Grafana 来监控您&lt;a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_ous.html"&gt;组织单位 (OU)&lt;/a&gt; 中的资源。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-access.png"&gt;&lt;img class="aligncenter size-large wp-image-53786" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-access-1024x339.png" alt="控制台屏幕截图。" width="1024" height="339"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我可以选择我计划使用的 AWS 数据源。此配置将创建一个 &lt;a title="" href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; 角色，使 Amazon Managed Grafana 能够访问我账户中的这些资源。稍后，在 Grafana 控制台中，我可以将选定的服务设置为数据源。现在，我选择 &lt;a title="" href="https://aws.amazon.com/cloudwatch/"&gt;Amazon CloudWatch&lt;/a&gt;，以便我可以在 Grafana 控制面板中快速可视化 &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html"&gt;CloudWatch 指标&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在此，我还配置了将 &lt;a href="https://aws.amazon.com/prometheus/"&gt;Amazon Managed Service for Prometheus (AMP)&lt;/a&gt; 作为数据源的权限，并为我的应用程序提供完全托管的监控解决方案。例如，我可以使用 &lt;a href="https://aws.amazon.com/otel/"&gt;AWS Distro for OpenTelemetry&lt;/a&gt; 或 &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; 服务器作为收集代理，从 &lt;a title="" href="https://aws.amazon.com/eks/"&gt;Amazon Elastic Kubernetes Service (EKS)&lt;/a&gt; 和 &lt;a title="" href="https://aws.amazon.com/ecs/"&gt;Amazon Elastic Container Service (Amazon ECS)&lt;/a&gt; 环境中收集 Prometheus 指标。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/amg-permission-aws-data-sources.png"&gt;&lt;img class="aligncenter size-large wp-image-54028" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/amg-permission-aws-data-sources-1024x829.png" alt="控制台屏幕截图。" width="1024" height="829"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在此步骤中，我还选择 &lt;a title="" href="https://aws.amazon.com/sns/"&gt;Amazon Simple Notification Service (SNS)&lt;/a&gt; 作为通知渠道。与之前的数据源类似，此选项允许 Amazon Managed Grafana 访问 SNS，但不会设置通知渠道。我可以稍后在 Grafana 控制台中执行此操作。具体而言，此设置会将 SNS 发布权限以 &lt;code&gt;grafana&lt;/code&gt; 开头的主题添加到 Amazon Managed Grafana 控制台所创建的 IAM 角色中。如果您希望对 SNS 或任何数据源的权限进行更严格的控制，您可以在 IAM 控制台中编辑角色或对您的工作区使用客户托管权限。&lt;/p&gt; 
&lt;p&gt;最后，我查看一下所有选项并创建工作区。&lt;/p&gt; 
&lt;p&gt;几分钟后，工作区准备就绪，我找到了可用于访问 Grafana 控制台的&lt;strong&gt;工作区 URL&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-workspace-summary.png"&gt;&lt;img class="aligncenter size-large wp-image-53776" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-workspace-summary-1024x301.png" alt="控制台屏幕截图。" width="1024" height="301"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我需要至少为 Grafana 工作区分配一个用户或组才能访问工作区 URL。我选择&lt;strong&gt;分配新用户或组&lt;/strong&gt;，然后选择我的一个 AWS SSO 用户。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-auth.png"&gt;&lt;img class="aligncenter size-large wp-image-53778" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-auth-1024x289.png" alt="控制台屏幕截图。" width="1024" height="289"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;默认情况下，该用户被分配了&lt;strong&gt;查看者&lt;/strong&gt;用户类型，对工作区具有“仅查看”权限。要授予此用户创建和管理仪表板和警报的权限，我选择该用户，然后选择&lt;strong&gt;设为管理员&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-admin.png"&gt;&lt;img class="aligncenter size-large wp-image-53779" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-admin-1024x400.png" alt="控制台屏幕截图。" width="1024" height="400"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;回到工作区摘要，我按照工作区 URL 并使用我的 AWS SSO 用户凭证进行登录。我现在使用的是开源版的 Grafana。如果您是一名 Grafana 用户，那么您肯定对一切都很熟悉了。就我的第一个配置，我将专注于 AWS 数据源，因此我选择左侧竖条上的 AWS 徽标。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-data-sources.png"&gt;&lt;img class="aligncenter size-large wp-image-53780" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-data-sources-1024x512.png" alt="控制台屏幕截图。" width="1024" height="512"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在此，我选择 CloudWatch。权限已经设置，因为我之前在服务托管权限设置中选择了 CloudWatch。我选择默认的 AWS 区域并添加数据源。我选择 CloudWatch 数据源，然后在&lt;strong&gt;控制面板&lt;/strong&gt;选项卡上，我找到了一些 AWS 服务的控制面板，例如 &lt;a title="" href="https://aws.amazon.com/ec2/"&gt;Amazon Elastic Compute Cloud (Amazon EC2)&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/ebs/"&gt;Amazon Elastic Block Store (EBS)&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/lambda/"&gt;AWS Lambda&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/rds/"&gt;Amazon Relational Database Service (RDS)&lt;/a&gt; 和 &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html"&gt;CloudWatch LogsLogs&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-cloudwatch-dashboards.png"&gt;&lt;img class="aligncenter size-large wp-image-53781" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-cloudwatch-dashboards-1024x379.png" alt="控制台屏幕截图。" width="1024" height="379"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我导入 AWS Lambda 控制面板。我现在可以使用 Grafana 来监控我账户中 Lambda 函数的调用、错误和限制。这边就没有屏幕截图了，因为我在这个区域没有什么有趣的数据。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;使用 SAML 身份验证&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;如果我没有启用 AWS SSO，我可以在创建工作区时选择 SAML 身份验证选项，并使用外部身份提供商 (IdP) 对 Amazon Managed Grafana 工作区的用户进行身份验证。对于现有工作区，我可以在工作区摘要中选择&lt;strong&gt;设置 SAML 配置&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;首先，我必须向我的 IdP 提供工作区 ID 和 URL 信息，以便生成用于配置此工作区的 IdP 元数据。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-idp.png"&gt;&lt;img class="aligncenter size-large wp-image-53782" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-idp-1024x254.png" alt="控制台屏幕截图。" width="1024" height="254"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;配置 IdP 后，我通过指定 URL 或复制并粘贴到编辑器来导入 IdP 元数据。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-import-metadata.png"&gt;&lt;img class="aligncenter size-large wp-image-53783" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-import-metadata-1024x252.png" alt="控制台屏幕截图。" width="1024" height="252"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;最后，我可以将 IdP 中的用户权限映射到 Grafana 用户权限，诸如指定哪些用户将在我的 Amazon Managed Grafana 工作区中拥有“管理员”、“编辑者”和“查看者”权限。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-assertion-mapping.png"&gt;&lt;img class="aligncenter size-large wp-image-53784" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-assertion-mapping-1024x383.png" alt="控制台屏幕截图。" width="1024" height="383"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;可用性和定价&lt;/span&gt;&lt;br&gt; &lt;/strong&gt;&lt;a href="https://aws.amazon.com/grafana/"&gt;Amazon Managed Grafana&lt;/a&gt; 现已在 10 个 AWS 区域推出：美国东部（弗吉尼亚北部）、美国东部（俄亥俄）、美国西部（俄勒冈）、欧洲（爱尔兰）、欧洲（法兰克福）、欧洲（伦敦）、亚太地区（新加坡）、亚太地区（东京）、亚太地区（悉尼）和亚太地区（首尔）。有关更多信息，请参阅 &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/"&gt;AWS 区域服务列表&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;使用 Amazon Managed Grafana，您每月只需为每个工作区中的活跃用户付费。用于发布控制面板的 Grafana API 密钥，每月按每个工作区的 API 用户许可证计费。您可以升级到企业版 Grafana，以便直接从 Grafana Labs 获取企业版插件、支持和按需培训。有关更多信息，&lt;a href="https://aws.amazon.com/grafana/pricing/"&gt;请参阅 Amazon Managed Grafana 定价页面&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://amazon.webex.com/webappng/sites/amazon/meeting/info/d66eaebcfa2c4f448e72c583ca8dcef2?isPopupRegisterView=true"&gt;欲了解更多信息，您可以参加将于 9 月 9 日星期四上午 9:00 PDT / 12:00 pm EDT / 6:00 pm CEST 举行的网络研讨会。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/grafana/"&gt;立即开始使用 Amazon Managed Grafana，以便可视化和分析任何规模的运营数据。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;— &lt;a title="Danilo 的 Twitter" href="https://twitter.com/danilop"&gt;Danilo&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>AWS CloudFormation 的新功能 – 从故障点快速重试堆栈操作</title>
		<link>https://aws.amazon.com/cn/blogs/china/new-for-aws-cloudformation-quickly-retry-stack-operations-from-the-point-of-failure/</link>
				<pubDate>Fri, 03 Sep 2021 13:35:24 +0000</pubDate>
		<dc:creator><![CDATA[Danilo Poccia]]></dc:creator>
				<category><![CDATA[News]]></category>

		<guid isPermaLink="false">165ee27e85f79d9952436041e30c678bf6993358</guid>
				<description>AWS CloudFormation 为您提供了一种简单的方法，可以对相关 AWS 和第三方资源集合进行建模，快速、一致地预置它们，并在其整个生命周期中对它们进行管理。CloudFormation 模板描述了所需的资源及其依赖关系，以便您将它们作为堆栈共同启动和配置。您可以使用模板将整个堆栈作为单个单元创建、更新和删除，而不是单独管理资源。</description>
								<content:encoded>&lt;p&gt;云计算的巨大优势之一是您有权访问可编程基础设施。这可让您管理&lt;a href="https://docs.aws.amazon.com/whitepapers/latest/introduction-devops-aws/infrastructure-as-code.html"&gt;基础设施即代码&lt;/a&gt;，并将相同的应用程序代码开发实践应用于基础设施预置。&lt;/p&gt; 
&lt;p&gt;&lt;a title="" href="https://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt; 为您提供了一种简单的方法，可以对相关 AWS 和第三方资源集合进行建模，快速、一致地预置它们，并在其整个生命周期中对它们进行管理。CloudFormation &lt;strong&gt;模板&lt;/strong&gt;描述了所需的资源及其依赖关系，以便您将它们作为&lt;strong&gt;堆栈&lt;/strong&gt;共同启动和配置。您可以使用模板将整个堆栈作为单个单元创建、更新和删除，而不是单独管理资源。&lt;/p&gt; 
&lt;p&gt;创建或更新堆栈时，您的操作可能会由于不同的原因而失败。例如，模板、模板的参数中可能存在错误，也可能存在模板之外的问题，例如 &lt;a title="" href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; 权限错误。发生此类错误时，CloudFormation 会将堆栈回滚到之前的稳定状态。对于堆栈创建，这意味着删除直到出错点之前创建的所有资源。对于堆栈更新，这意味着恢复以前的配置。&lt;/p&gt; 
&lt;p&gt;回滚到以前状态的操作对于生产环境来说非常合适，但您可能很难理解出现错误的原因。根据模板的复杂性和所涉及资源的数量，您可能会花很多时间等待所有资源回滚，然后再使用正确的配置更新模板并重试该操作。&lt;/p&gt; 
&lt;p&gt;今天，我很高兴与大家分享的功能是，CloudFormation 目前可让您&lt;strong&gt;禁用&lt;/strong&gt;自动回滚，在错误发生之前&lt;strong&gt;保持&lt;/strong&gt;资源成功创建或更新，以及从故障点&lt;strong&gt;重试&lt;/strong&gt;堆栈操作。通过这种方式，您可以快速迭代以解决和修复错误，并大大减少在开发环境中测试 CloudFormation 模板所需的时间。您可以在创建堆栈、更新堆栈时以及执行&lt;a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html"&gt;更改集&lt;/a&gt;时应用此新功能。我们来看看这些步骤的实际操作。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;快速迭代以解决和修复 CloudFormation 堆栈问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;对于我的一个应用程序，我需要设置 &lt;a title="" href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt; 存储桶、&lt;a title="" href="https://aws.amazon.com/sqs/"&gt;Amazon Simple Queue Service (SQS)&lt;/a&gt; 队列和 &lt;a title="" href="https://aws.amazon.com/dynamodb/"&gt;Amazon DynamoDB&lt;/a&gt; 表，该表将项目级更改串流至 &lt;a title="" href="https://aws.amazon.com/kinesis/"&gt;Amazon Kinesis&lt;/a&gt; 数据流。对于此设置，我编写了 CloudFormation 模板的第一个版本。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-yaml"&gt;AWSTemplateFormatVersion: "2010-09-09"
说明：一个用于解决和修复问题的示例模板
Parameters:
  ShardCountParameter:
    Type: Number
    说明：Kinesis 流的分区数
Resources:
  MyBucket:
    Type: AWS::S3::Bucket
  MyQueue:
    Type: AWS::SQS::Queue
  MyStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount: !Ref ShardCountParameter
  MyTable：
    Type: AWS::DynamoDB::Table
    Properties:
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: "ArtistId"
          AttributeType: "S"
        - AttributeName: "Concert"
          AttributeType: "S"
        - AttributeName: "TicketSales"
          AttributeType: "S"
      KeySchema:
        - AttributeName: "ArtistId"
          "KeyType": "HASH"
        - AttributeName: "Concert"
          KeyType: "RANGE"
      KinesisStreamSpecification:
        StreamArn: !GetAtt MyStream.Arn
Outputs:
  BucketName:
    Value: !Ref MyBucket
    说明：我的 S3 存储桶的名称
  QueueName:
    Value: !GetAtt MyQueue.QueueName
    说明：我的 SQS 队列的名称
  StreamName:
    Value: !Ref MyStream
    说明：我的 Kinesis 流的名称
  TableName:
    Value: !Ref MyTable
    说明：我的 DynamoDB 表的名称&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;现在，我想用这个模板创建一个堆栈。在 &lt;a href="https://console.aws.amazon.com/cloudformation/home"&gt;CloudFormation 控制台&lt;/a&gt;上，我选择&lt;strong&gt;创建堆栈&lt;/strong&gt;。然后，我上传模板文件并选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-create-stack.png"&gt;&lt;img class="aligncenter size-large wp-image-54040" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-create-stack-1024x659.png" alt="控制台屏幕截图。" width="1024" height="659"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我输入堆栈的名称。然后，我填写堆栈参数。我的模板文件有一个参数 (&lt;code&gt;ShardCountParameter&lt;/code&gt;)，用于配置 Kinesis 数据流的&lt;a href="https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html"&gt;分区数量&lt;/a&gt;。我知道分区数量应该大于或等于 1，但错误地输入 0 并选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-name-parameters.png"&gt;&lt;img class="aligncenter size-large wp-image-54043" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-name-parameters-1024x499.png" alt="控制台屏幕截图。" width="1024" height="499"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;为了创建、修改或删除堆栈中的资源，我使用 &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html"&gt;IAM 角色&lt;/a&gt;。这样，我就明确界定了 CloudFormation 可用于堆栈操作的权限。此外，我可以使用相同的角色来在标准化和可重复的环境中自动部署堆栈。&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;权限&lt;/strong&gt;中，我选择要用于堆栈操作的 IAM 角色。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-permissions.png"&gt;&lt;img class="aligncenter size-large wp-image-54042" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-permissions-1024x325.png" alt="控制台屏幕截图。" width="1024" height="325"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在是使用新功能的时候了！ 在&lt;strong&gt;堆栈故障选项&lt;/strong&gt;中，我选择&lt;strong&gt;保留成功预置的资源&lt;/strong&gt;，以便在出错时保留已创建的资源。失败的资源始终回滚到最近一个已知的稳定状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-failure-options.png"&gt;&lt;img class="aligncenter size-large wp-image-54044" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-failure-options-1024x273.png" alt="控制台屏幕截图。" width="1024" height="273"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我将所有其他选项保留为默认值，然后选择&lt;strong&gt;下一步&lt;/strong&gt;。然后，我查看自己的配置并选择&lt;strong&gt;创建堆栈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;堆栈的创建操作会执行几秒钟，然后由于错误而失败。在&lt;strong&gt;事件&lt;/strong&gt;选项卡中，我查看事件的时间表。开始创建堆栈的事件位于底部。最近的事件位于顶部。由于分区的数量 (&lt;code&gt;ShardCount&lt;/code&gt;) 低于最小值，因此流资源的属性验证失败。因此，堆栈现在处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-parameter.png"&gt;&lt;img class="aligncenter size-large wp-image-54045" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-parameter-1024x605.png" alt="控制台屏幕截图。" width="1024" height="605"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我选择保留预置的资源，因此在错误发生之前创建的所有资源仍然存在。在&lt;strong&gt;资源&lt;/strong&gt;选项卡中，S3 存储桶和 SQS 队列处于 &lt;code&gt;CREATE_COMPLETE&lt;/code&gt; 状态，而 Kinesis 数据流处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 状态。DynamoDB 表的创建取决于 Kinesis 数据流是否可用，因为该表将数据流用于其属性之一 (&lt;code&gt;KinesisStreamSpecification&lt;/code&gt;)。因此，表的创建尚未开始，并且该表不在列表中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-preserved-resources.png"&gt;&lt;img class="aligncenter size-large wp-image-54046" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-preserved-resources-1024x408.png" alt="控制台屏幕截图。" width="1024" height="408"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;回滚现在已暂停，并且我有一些新的选项：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;重试&lt;/strong&gt; – 在不作任何更改的情况下重试堆栈操作。如果资源由于模板之外的问题而无法预置，此选项就非常有用。我可以修复这个问题，然后从故障点重试。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt; – 在重试堆栈创建之前更新模板或参数。堆栈更新从最近一个操作因错误而中断的位置开始。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;回滚&lt;/strong&gt; – 回滚到最近一个已知的稳定状态。这类似于默认的 CloudFormation 行为。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-paused-options.png"&gt;&lt;img class="aligncenter size-large wp-image-54048" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-paused-options-1024x204.png" alt="控制台屏幕截图。" width="1024" height="204"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;修复参数中的问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;我很快意识到输入了错误的分区数量参数，因此选择&lt;strong&gt;更新&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;我不需要更改模板来修复此错误。&amp;nbsp;在&lt;strong&gt;参数&lt;/strong&gt;中，我修复了之前的错误并输入正确的分区数量：一个分区。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-update-stack-parameters.png"&gt;&lt;img class="aligncenter size-large wp-image-54051" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-update-stack-parameters-1024x308.png" alt="控制台屏幕截图。" width="1024" height="308"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我将所有其他选项保留为当前值，然后选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;更改集预览&lt;/strong&gt;中，我看到更新将尝试修改 Kinesis 流 (当前处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 状态) 并添加 DynamoDB 表。我查看其他配置并选择&lt;strong&gt;更新堆栈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-change-set-preview-1.png"&gt;&lt;img class="aligncenter size-large wp-image-54056" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-change-set-preview-1-1024x389.png" alt="控制台屏幕截图。" width="1024" height="389"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在更新进行中。我解决了所有问题吗？ 还没有。一段时间后，更新失败。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;修复模板之外的问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Kinesis 流已创建，但 CloudFormation 担任的 IAM 角色没有创建 DynamoDB 表的权限。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-permissions.png"&gt;&lt;img class="aligncenter wp-image-54057 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-permissions-1024x488.png" alt="控制台屏幕截图。" width="1024" height="488"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在 &lt;a href="https://console.aws.amazon.com/iam/home"&gt;IAM 控制台&lt;/a&gt;中，我向堆栈操作使用的角色添加额外权限，以便该角色能够创建 DynamoDB 表。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-iam-permissions.png"&gt;&lt;img class="aligncenter size-large wp-image-54063" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-iam-permissions-1024x315.png" alt="控制台屏幕截图。" width="1024" height="315"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;返回 &lt;a href="https://console.aws.amazon.com/cloudformation/home"&gt;CloudFormation 控制台&lt;/a&gt;，我选择&lt;strong&gt;重试&lt;/strong&gt;选项。具备新权限后，DynamoDB 表的创建将开始，但一段时间后，出现另一个错误。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;修复模板中的问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;这一次，在定义 DynamoDB 表的模板中存在错误。在 &lt;code&gt;AttributeDefinitions&lt;/code&gt; 部分中，有一个未在架构中使用的属性 (&lt;code&gt;TicketSales&lt;/code&gt;)。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-template.png"&gt;&lt;img class="aligncenter size-large wp-image-54058" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-template-1024x185.png" alt="控制台屏幕截图。" width="1024" height="185"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;对于 DynamoDB，模板中定义的属性应用于主键或索引。我更新了模板并删除 &lt;code&gt;TicketSales&lt;/code&gt; 属性定义。&lt;/p&gt; 
&lt;p&gt;由于正在编辑模板，因此我借此机会将 &lt;code&gt;MinValue&lt;/code&gt; 和 &lt;code&gt;MaxValue&lt;/code&gt; 属性添加到分区数量参数 (&lt;code&gt;ShardCountParameter&lt;/code&gt;) 中。这样，CloudFormation 可以在开始部署之前检查值是否在正确的范围内，而我可以避免进一步的错误。&lt;/p&gt; 
&lt;p&gt;我选择&lt;strong&gt;更新&lt;/strong&gt;选项。我选择更新当前模板，然后上传新的模板文件。我确认了参数的当前值。然后，我将所有其他选项保留为当前值，接下来选择&lt;strong&gt;更新堆栈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这次，堆栈成功创建，其状态为 &lt;code&gt;UPDATE_COMPLETE&lt;/code&gt;。我可以在&lt;strong&gt;资源&lt;/strong&gt;选项卡中查看所有资源，并在&lt;code&gt;输出&lt;/code&gt;选项卡中查看它们的说明 (基于模板的&lt;strong&gt;输出&lt;/strong&gt;部分)。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-outputs.png"&gt;&lt;img class="aligncenter size-large wp-image-54060" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-outputs-1024x354.png" alt="控制台屏幕截图。" width="1024" height="354"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以下是模板的最终版本：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-yaml"&gt;AWSTemplateFormatVersion: "2010-09-09"
说明：一个用于解决和修复问题的示例模板
Parameters:
  ShardCountParameter:
    Type: Number
    MinValue: 1
    MaxValue: 10
    说明：Kinesis 流的分区数
Resources:
  MyBucket:
    Type: AWS::S3::Bucket
  MyQueue:
    Type: AWS::SQS::Queue
  MyStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount: !Ref ShardCountParameter
  MyTable：
    Type: AWS::DynamoDB::Table
    Properties:
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: "ArtistId"
          AttributeType: "S"
        - AttributeName: "Concert"
          AttributeType: "S"
      KeySchema:
        - AttributeName: "ArtistId"
          "KeyType": "HASH"
        - AttributeName: "Concert"
          KeyType: "RANGE"
      KinesisStreamSpecification:
        StreamArn: !GetAtt MyStream.Arn
Outputs:
  BucketName:
    Value: !Ref MyBucket
    说明：我的 S3 存储桶的名称
  QueueName:
    Value: !GetAtt MyQueue.QueueName
    说明：我的 SQS 队列的名称
  StreamName:
    Value: !Ref MyStream
    说明：我的 Kinesis 流的名称
  TableName:
    Value: !Ref MyTable
    说明：我的 DynamoDB 表的名称&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这是一个简单的示例，但从故障点重试堆栈操作的新功能为我节省了大量时间。它可让我快速解决和修复问题，从而减少了反馈循环并增加了在同一时间内完成的迭代次数。除了使用其进行调试之外，该功能对于模板的增量交互式开发也非常有用。对于更复杂的应用程序，我们将可节省大量的时间！&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;使用 AWS CLI 解决和修复 CloudFormation 堆栈问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;我可以使用 &lt;a title="" href="https://aws.amazon.com/cli/"&gt;AWS 命令行界面 (CLI)&lt;/a&gt; 保留成功预置的资源，方法是在创建堆栈、更新堆栈或执行更改集时指定 &lt;code&gt;--disable-rollback&lt;/code&gt; 选项。例如：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;aws cloudformation create-stack --stack-name my-stack \
    --template-body file://my-template.yaml -–disable-rollback
aws cloudformation update-stack --stack-name my-stack \
    --template-body file://my-template.yaml --disable-rollback
aws cloudformation execute-change-set --stack-name my-stack --change-set-name my-change-set \
    --template-body file://my-template.yaml --disable-rollback&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;对于现有堆栈，我可以查看是否使用 describe stack 命令启用了 &lt;code&gt;DisableRollback&lt;/code&gt; 属性：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;aws cloudformation describe-stacks --stack-name my-stack&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我现在可以更新处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 或 &lt;code&gt;UPDATE_FAILED&lt;/code&gt; 状态的堆栈。要手动回滚处于&lt;code&gt;CREATE_FAILED&lt;/code&gt; 或 &lt;code&gt;UPDATE_FAILED&lt;/code&gt; 状态的堆栈，我可以使用新的 rollback stack 命令：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;aws cloudformation rollback-stack --stack-name my-stack&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;可用性和定价&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;a title="" href="https://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt; 从故障点重试堆栈操作的功能在以下 &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/#Regions"&gt;AWS 区域&lt;/a&gt;免费提供：美国东部 (弗吉尼亚北部、俄亥俄)、美国西部 (俄勒冈、加利福尼亚北部)、AWS GovCloud (美国东部、美国西部)、加拿大 (中部)、欧洲 (法兰克福、爱尔兰、伦敦、米兰、巴黎、斯德哥尔摩)、亚太地区 (香港、孟买、大阪、首尔、新加坡、悉尼、东京)、中东 (巴林)、非洲 (开普敦) 和南美洲 (圣保罗)。&lt;/p&gt; 
&lt;p&gt;您更喜欢使用熟悉的编程语言 (例如 JavaScript、TypeScript、Python、Java、C# 和 Go) 来定义云应用程序资源吗？ 好消息！ &lt;a title="" href="https://aws.amazon.com/cdk/"&gt;AWS Cloud Development Kit (AWS CDK)&lt;/a&gt; 团队计划在接下来的几周内增加对本文中所介绍新功能的支持。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stack-failure-options.html"&gt;借助从故障点开始重试堆栈操作的新功能，可以用更少的时间来解决和修复 CloudFormation 堆栈问题。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;— &lt;a title="Danilo 的 Twitter" href="https://twitter.com/danilop"&gt;Danilo&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>使用更具体的 Amazon VPC 路由检查子网到子网的流量</title>
		<link>https://aws.amazon.com/cn/blogs/china/inspect-subnet-to-subnet-traffic-with-amazon-vpc-more-specific-routing/</link>
				<pubDate>Fri, 03 Sep 2021 04:30:44 +0000</pubDate>
		<dc:creator><![CDATA[Sébastien Stormacq]]></dc:creator>
				<category><![CDATA[Announcements]]></category>

		<guid isPermaLink="false">308ee0fb555368909267bfb075f24cf12dbcb77e</guid>
				<description>自 2019 年 12 月以来，Amazon Virtual Private Cloud（VPC）允许您将所有进站流量（也称为南北流量）路由到特定网络接口。您可能出于多种原因使用此功能。例如，使用入侵检测系统（IDS）设备检测进站流量或将进站流量路由到防火墙。</description>
								<content:encoded>&lt;p&gt;自 2019 年 12 月以来，&lt;a title="" href="https://aws.amazon.com/vpc/"&gt;Amazon Virtual Private Cloud（VPC）&lt;/a&gt;允许您将所有进站流量（也称为&lt;a href="https://en.wikipedia.org/wiki/North-south_traffic"&gt;南北流量&lt;/a&gt;）路由到特定网络接口。您可能出于多种原因使用此功能。例如，使用入侵检测系统（IDS）设备检测进站流量或将进站流量路由到防火墙。&lt;/p&gt; 
&lt;p&gt;自我们推出此功能以来，许多用户要求我们提供类似的功能来分析从一个子网流向 VPC 内的另一个子网的流量，也称为&lt;a href="https://en.wikipedia.org/wiki/East-west_traffic"&gt;东西流量&lt;/a&gt;。到今天为止，这仍然是不可能的，因为路由表中的路由不能比默认本地路由更具体（有关更多详细信息，请查看&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html"&gt;VPC 文档&lt;/a&gt;）。简单地说，这意味着任何一个路由的目标使用的 &lt;a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing"&gt;CIDR&lt;/a&gt; 范围都不能小于默认本地路由（即整个 VPC 的 CIDR 范围）。例如，当 VPC 范围为 &lt;code&gt;10.0.0/16&lt;/code&gt; 且子网有 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 时，通向 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 的路由比通向 &lt;code&gt;10.0.0/16&lt;/code&gt; 的路由更具体。&lt;/p&gt; 
&lt;p&gt;路由表不再有此限制。路由表中的路由可以有比默认本地路由更具体的路由。您可以使用此类更具体的路由将所有流量发送到专用设备或服务，以检测、分析或过滤两个子网之间的所有流量（东西流量）。路由目标可以是连接到您构建或购买的设备的网络接口（ENI）、出于性能或高可用性原因将流量分配到多个设备的 &lt;a href="https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/"&gt;AWS 网关负载均衡器&lt;/a&gt;（GWLB）终端节点、&lt;a title="" href="https://aws.amazon.com/firewall-manager/"&gt;AWS Firewall Manager&lt;/a&gt; 终端节点或 &lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html"&gt;NAT 网关&lt;/a&gt;。它还允许在子网和 &lt;a href="https://aws.amazon.com/transit-gateway/"&gt;AWS Transit Gateway&lt;/a&gt; 之间插入设备。&lt;/p&gt; 
&lt;p&gt;可以将设备链接起来，以便在源子网和目标子网之间进行多种类型的分析。例如，您可能希望首先使用防火墙（AWS 托管防火墙或&lt;a href="https://aws.amazon.com/marketplace/solutions/security"&gt;第三方防火墙设备&lt;/a&gt;）筛选流量，然后将流量发送到&lt;a href="https://aws.amazon.com/marketplace/solutions/infrastructure-software/ids-ips"&gt;入侵检测和防御系统&lt;/a&gt;，最后，执行深度数据包检测。您可以从我们的 &lt;a href="https://aws.amazon.com/partners/"&gt;AWS 合作伙伴网络&lt;/a&gt;和 &lt;a href="https://aws.amazon.com/marketplace"&gt;AWS Marketplace&lt;/a&gt; 访问虚拟设备。&lt;/p&gt; 
&lt;p&gt;链接设备时，每个设备和每个终端节点都必须位于单独的子网中。&lt;/p&gt; 
&lt;p&gt;让我们动手试试这个新功能。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;工作原理&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 在本博客文章中，我们假设我有一个具有三个子网的 &lt;span title=""&gt;VPC&lt;/span&gt;。第一个子网是公有子网，有一个堡垒主机。它需要访问资源，例如 API 或第二个子网中的数据库。第二个子网是私有子网。它托管堡垒所需的资源。我写了&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;一个简单的 CDK 脚本&lt;/a&gt;来帮助您部署此设置。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/Slide1.png"&gt;&lt;img class="aligncenter wp-image-52363 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/Slide1-e1621855971954-1024x584.png" alt="更具体的 VPC 路由" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;出于合规性原因，我们公司要求此私有应用程序的流量流经入侵检测系统。&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;CDK 脚本&lt;/a&gt;还创建了第三个子网（私有子网）来托管网络设备。它提供了三个 &lt;a title="" href="https://aws.amazon.com/ec2/"&gt;Amazon Elastic Compute Cloud（Amazon EC2）&lt;/a&gt;实例：堡垒主机、应用程序实例和网络分析设备。该脚本还创建了 NAT 网关，允许引导应用程序实例并使用 &lt;a title="" href="https://aws.amazon.com/systems-manager/"&gt;AWS Systems Manager&lt;/a&gt; Session Manager （SSM）连接到三个实例。&lt;/p&gt; 
&lt;p&gt;因为这是一个演示，所以网络设备是配置为 IP 路由器的常规 Amazon Linux &lt;span title=""&gt;EC2&lt;/span&gt; 实例。在现实生活中，您可能要使用我们的合作伙伴在 &lt;a title="" href="https://aws.amazon.com/marketplace/"&gt;AWS Marketplace&lt;/a&gt; 上提供的众多设备之一，或者&lt;a href="https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/"&gt;网关负载均衡器&lt;/a&gt;终端节点或 Network Firewall。&lt;/p&gt; 
&lt;p&gt;让我们修改路由表以通过设备发送流量。&lt;/p&gt; 
&lt;p&gt;使用 &lt;a title="" href="https://console.aws.amazon.com"&gt;AWS 管理控制台&lt;/a&gt;或 &lt;a title="" href="https://aws.amazon.com/cli/"&gt;AWS 命令行界面（CLI）&lt;/a&gt;，我向 &lt;code&gt;10.0.0.0/24&lt;/code&gt; 和 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 子网路由表添加了更具体的路由。这些路由指向 &lt;code&gt;eni0&lt;/code&gt;，即流量检测设备的网络接口。&lt;/p&gt; 
&lt;p&gt;使用 CLI，我首先收集设备的 VPC ID、子网 ID、路由表 ID 和 ENI ID。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;VPC_ID=$(aws                                                    \
    --region $REGION cloudformation describe-stacks             \
    --stack-name SpecificRoutingDemoStack                       \
    --query "Stacks[].Outputs[?OutputKey=='VPCID'].OutputValue" \
    --output text)
echo $VPC_ID

APPLICATION_SUBNET_ID=$(aws                                                                      \
    --region $REGION ec2 describe-instances                                                      \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='application']].NetworkInterfaces[].SubnetId" \
    --output text)
echo $APPLICATION_SUBNET_ID

APPLICATION_SUBNET_ROUTE_TABLE=$(aws                                                             \
    --region $REGION  ec2 describe-route-tables                                                  \
    --query "RouteTables[?VpcId=='${VPC_ID}'] | [?Associations[?SubnetId=='${APPLICATION_SUBNET_ID}']].RouteTableId" \
    --output text)
echo $APPLICATION_SUBNET_ROUTE_TABLE

APPLIANCE_ENI_ID=$(aws                                                                           \
    --region $REGION ec2 describe-instances                                                      \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='appliance']].NetworkInterfaces[].NetworkInterfaceId" \
    --output text)
echo $APPLIANCE_ENI_ID

BASTION_SUBNET_ID=$(aws                                                                         \
    --region $REGION ec2 describe-instances                                                     \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='BastionHost']].NetworkInterfaces[].SubnetId" \
    --output text)
echo $BASTION_SUBNET_ID

BASTION_SUBNET_ROUTE_TABLE=$(aws \
 --region $REGION ec2 describe-route-tables \
 --query "RouteTables[?VpcId=='${VPC_ID}'] | [?Associations[?SubnetId=='${BASTION_SUBNET_ID}']].RouteTableId" \
 --output text)
echo $BASTION_SUBNET_ROUTE_TABLE&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接下来，我会添加两条更具体的路由。一条路由通过设备网络接口将来自堡垒公有子网的流量发送到应用程序私有子网。&amp;nbsp;第二条路由与路由回复的方向相反。它通过设备网络接口将更具体的流量从应用程序私有子网路由到堡垒公有子网。&amp;nbsp;感到困惑？ 让我们看看下图：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/illustration-1.png"&gt;&lt;img class="aligncenter wp-image-52368 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/illustration-1-1024x584.png" alt="更具体的 VPC 路由" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;首先，让我们修改堡垒路由表：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;aws ec2 create-route                                  \
     --region $REGION                                 \
     --route-table-id $BASTION_SUBNET_ROUTE_TABLE     \
     --destination-cidr-block 10.0.1.0/24             \
     --network-interface-id $APPLIANCE_ENI_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接下来，让我们修改应用程序路由表：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;aws ec2 create-route                                  \
    --region $REGION                                  \
    --route-table-id $APPLICATION_SUBNET_ROUTE_TABLE  \
    --destination-cidr-block 10.0.0.0/24              \
    --network-interface-id $APPLIANCE_ENI_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我还可以使用 Amazon VPC 控制台进行这些修改。只需从 Routes (路由) 选项卡中选择“Bastion”(堡垒) 路由表，然后单击 Edit routes (编辑路由) 即可。&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-33-52.png"&gt;&lt;img class="aligncenter size-large wp-image-52421" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-33-52-1024x584.png" alt="MSR：选择路由表" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我添加了一个路由，用于将 &lt;code&gt;10.0.1.0/24&lt;/code&gt;（应用程序子网）的流量发送到设备 ENI（&lt;code&gt;eni-055...&lt;/code&gt;）。&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-35-20.png"&gt;&lt;img class="aligncenter size-large wp-image-52422" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-35-20-1024x494.png" alt="MSR：创建路由" width="1024" height="494"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下一步是定义相反的回复路由，将 &lt;code&gt;10.0.0.0/24&lt;/code&gt; 的流量从应用程序子网发送到设备 ENI（&lt;code&gt;eni-05...&lt;/code&gt;）。&amp;nbsp;完成后，应用程序子网路由表应如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-36-34.png"&gt;&lt;img class="aligncenter size-large wp-image-52423" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-36-34-1024x559.png" alt="MSR：最终路由表" width="1024" height="559"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;配置设备实例&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 最后，我将设备实例配置为转发其接收的所有流量。您的软件设备通常会为您完成此操作。当您使用 &lt;a title="" href="https://aws.amazon.com/marketplace/"&gt;AWS Marketplace&lt;/a&gt; 设备或&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;我为此演示提供的 CDK 脚本&lt;/a&gt;创建的实例时，无需执行额外步骤。如果您使用的是普通 Linux 实例，请完成以下两个额外步骤：&lt;/p&gt; 
&lt;p&gt;1.连接到 &lt;span title=""&gt;EC2&lt;/span&gt; 设备实例并在内核中配置 IP 流量转发：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;sysctl -w net.ipv4.ip_forward=1
sysctl -w net.ipv6.conf.all.forwarding=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2.将 &lt;span title=""&gt;EC2&lt;/span&gt; 实例配置为接受除本身之外的其他目标的流量（称为&lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html#EIP_Disable_SrcDestCheck"&gt;源/目标检查&lt;/a&gt;）：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;APPLIANCE_ID=$(aws --region $REGION ec2 describe-instances                     \
     --filter "Name=tag:Name,Values=appliance"                                 \
     --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
     --output text)

aws ec2 modify-instance-attribute --region $REGION     \
                         --no-source-dest-check        \
                         --instance-id $APPLIANCE_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;测试设置&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 设备现已做好将流量转发到其他 &lt;span title=""&gt;EC2&lt;/span&gt; 实例的准备。&lt;/p&gt; 
&lt;p&gt;如果您使用的是&lt;a href="https://github.com/sebsto/cdkv2-vpc-example"&gt;演示设置&lt;/a&gt;，则堡垒主机上未安装 SSH 密钥。通过 &lt;a title="" href="https://aws.amazon.com/systems-manager/"&gt;AWS Systems Manager&lt;/a&gt; Session Manager 进行访问。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;BASTION_ID=$(aws --region $REGION ec2 describe-instances                      \
    --filter "Name=tag:Name,Values=BastionHost"                               \
    --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
    --output text)

aws --region $REGION ssm start-session --target $BASTION_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;连接到堡垒主机后，发出以下 &lt;code&gt;cURL&lt;/code&gt; 命令以连接到应用程序主机：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;sh-4.2$ curl -I 10.0.1.239 # use the private IP address of your application host
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Mon, 24 May 2021 10:00:22 GMT
Content-Type: text/html
Content-Length: 12338
Last-Modified: Mon, 24 May 2021 09:36:49 GMT
Connection: keep-alive
ETag: "60ab73b1-3032"
Accept-Ranges: bytes&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;要验证流量是否真正流经设备，您可以再次对实例启用源/目标检查。将 &lt;code&gt;--source-dest-check&lt;/code&gt; 参数与上面的 &lt;code&gt;modify-instance-attribute&lt;/code&gt; CLI 命令一起使用。当源/目标检查启用时，流量将受阻。&lt;/p&gt; 
&lt;p&gt;我还可以连接到设备主机并使用 &lt;code&gt;tcpdump&lt;/code&gt; 命令检测流量。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;(on your laptop)
APPLIANCE_ID=$(aws --region $REGION ec2 describe-instances     \
                   --filter "Name=tag:Name,Values=appliance" \
		   --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
  		   --output text)

aws --region $REGION ssm start-session --target $APPLIANCE_ID

(on the appliance host)
tcpdump -i eth0 host 10.0.0.16 # the private IP address of the bastion host

08:53:22.760055 IP ip-10-0-0-16.us-west-2.compute.internal.46934 &amp;gt; ip-10-0-1-104.us-west-2.compute.internal.http: Flags [S], seq 1077227105, win 26883, options [mss 8961,sackOK,TS val 1954932042 ecr 0,nop,wscale 6], length 0
08:53:22.760073 IP ip-10-0-0-16.us-west-2.compute.internal.46934 &amp;gt; ip-10-0-1-104.us-west-2.compute.internal.http: Flags [S], seq 1077227105, win 26883, options [mss 8961,sackOK,TS val 1954932042 ecr 0,nop,wscale 6], length 0
08:53:22.760322 IP ip-10-0-1-104.us-west-2.compute.internal.http &amp;gt; ip-10-0-0-16.us-west-2.compute.internal.46934: Flags [S.], seq 4152624111, ack 1077227106, win 26847, options [mss 8961,sackOK,TS val 4094021737 ecr 1954932042,nop,wscale 6], length 0
08:53:22.760329 IP ip-10-0-1-104.us-west-2.compute.internal.http &amp;gt; ip-10-0-0-16.us-west-2.compute.internal.46934: Flags [S.], seq 4152624111, ack 1077227106, win 26847, options [mss &lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;清理&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 如果您使用了&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;我为此博文提供的 CDK 脚本&lt;/a&gt;，请务必在完成后运行 &lt;code&gt;cdk destroy&lt;/code&gt;，这样就无需为我用于此演示的三个 EC2 实例和 NAT 网关付费。在 &lt;code&gt;us-west-2&lt;/code&gt; 中运行演示脚本的&lt;a href="https://calculator.aws/#/estimate?id=a460f21b3c6a0e271aae860ce4482c02389747bd"&gt;费用&lt;/a&gt;为每小时 0.062 美元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;注意事项。&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; 在使用更具体的 &lt;span title=""&gt;VPC&lt;/span&gt; 路由时，请记住以下几点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;您要向其发送流量的网络接口或服务终端节点必须位于专用子网中。它不能位于流量的源子网或目标子网中。&lt;/li&gt; 
 &lt;li&gt;您可以将设备链接起来。每台设备必须位于其专用子网中。&lt;/li&gt; 
 &lt;li&gt;您添加的每个子网都会占用一个 IP 地址块。&amp;nbsp;如果您使用的是 IPv4，请注意所用的 IP 地址数量（一个 /24 子网使用来自您的 VPC 的 256 个地址）。子网中允许的最小 CIDR 范围是 /28，它只使用 16 个 IP 地址。&lt;/li&gt; 
 &lt;li&gt;设备的安全组必须有规则接受所需端口上的传入流量。同样，应用程序的安全组必须授权来自设备安全组或 IP 地址的流量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此新功能在所有 AWS 区域均可使用，无需额外付费。&lt;/p&gt; 
&lt;p&gt;您可以立即开始使用。&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>Amazon Textract 更新：8 个亚马逊云科技区域的价格降幅达 32％，异步任务处理时间缩短近 50％</title>
		<link>https://aws.amazon.com/cn/blogs/china/amazon-textract-updates-up-to-32-price-reduction-in-8-aws-regions-and-up-to-50-reduction-in-asynchronous-job-processing-times/</link>
				<pubDate>Fri, 03 Sep 2021 04:28:17 +0000</pubDate>
		<dc:creator><![CDATA[Channy Yun]]></dc:creator>
				<category><![CDATA[Price Reduction]]></category>

		<guid isPermaLink="false">1d79dcc8d4d08e74c3b32607ec6ca943b1d1b3b6</guid>
				<description>在亚马逊云科技 re:Invent 2018 上推出的 Amazon Textract 是一项机器学习服务，它可以从扫描的文档中自动提取文本、手写和数据，并超越了简单的光学字符识别 (OCR) 来识别、理解和提取表单和表格中的数据。</description>
								<content:encoded>&lt;p&gt;在亚马逊云科技 re:Invent 2018 上推出的 &lt;a href="https://aws.amazon.com/textract/"&gt;Amazon Textract&lt;/a&gt; 是一项机器学习服务，它可以从扫描的文档中自动提取文本、手写和数据，并超越了简单的光学字符识别 (OCR) 来识别、理解和提取表单和表格中的数据。&lt;/p&gt; 
&lt;p&gt;在过去的几个月中，我们推出了处理&lt;a href="https://aws.amazon.com/blogs/machine-learning/announcing-expanded-support-for-extracting-data-from-invoices-and-receipts-using-amazon-textract/"&gt;发票和收据&lt;/a&gt;的专业技术支持，并提高了基础计算机视觉模型的质量，该模型支持&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/07/amazon-textract-announces-improvements-detection-handwritten-text-digits-dates-phone-numbers/"&gt;手写文本&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/06/amazon-textract-announces-quality-updates-to-its-forms-extraction-feature/"&gt;表单&lt;/a&gt;和&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-textract-announces-quality-update-table-extraction-feature/"&gt;表格&lt;/a&gt;的提取，并支持英语、西班牙语、德语、意大利语、葡萄牙语和法语的打印文本。&lt;/p&gt; 
&lt;p&gt;作为多个亚马逊云科技合规性计划的一部分，第三方审计员将评估 Amazon Textract 的安全性和合规性。我们还添加了 &lt;a href="https://aws.amazon.com/blogs/security/new-2021-h1-irap-report-is-now-available-on-aws-artifact-for-australian-customers/"&gt;IRAP&lt;/a&gt; 合规性技术支持并实现 &lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-textract-achieves-fedramp-compliance/"&gt;US FedRAMP&lt;/a&gt; 授权，以添加到现有的列表中，如 &lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/10/amazon-textract-is-now-a-hipaa-eligible-service/"&gt;HIPAA&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/12/amazon-textract-is-now-pci-dss-certified-and-extracts-even-more-data-from-tables-and-forms/"&gt;PCI DSS&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2020/06/amazon-textract-is-now-soc-and-iso-compliant/?nc1=h_ls"&gt;ISO SCO&lt;/a&gt; 和 &lt;a href="https://aws.amazon.com/blogs/security/aws-extends-its-mtcs-level-3-certification-scope-to-cover-united-states-regions/"&gt;MTCS&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-54262" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/24/2021-textract-price-reduction.png" alt="" width="2018" height="546"&gt;&lt;/p&gt; 
&lt;p&gt;客户使用 Amazon Textract 自动执行关键业务流程工作流（例如，在索赔和纳税表处理、贷款申请和应付账款方面）。这样可以缩短人工审核时间、提高准确性、降低成本并加快全球范围的创新步伐。与此同时，&lt;a href="https://aws.amazon.com/textract/customers/"&gt;Textract 客户&lt;/a&gt;告诉我们，我们可以做更多的工作来降低成本和改善延迟现象。&lt;/p&gt; 
&lt;p&gt;今天，我们很高兴地宣布对 Amazon Textract 的两项主要更新：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;8 个亚马逊云科技区域的价格降幅达 32%，帮助&lt;/strong&gt;全球客户通过 Textract 节省更多成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Textract 全球&lt;/strong&gt;异步操作的端到端任务处理时间减少近 50%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;8 个亚马逊云科技区域的价格降幅达 32％&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; 我们很高兴地宣布，8 个亚马逊云科技区域的价格降幅达 32％：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、加拿大（中部）、欧洲（法兰克福）、欧洲（伦敦）和欧洲（巴黎）。&lt;/p&gt; 
&lt;p&gt;这些亚马逊云科技区域中 &lt;code&gt;DetectDocumentText&lt;/code&gt; (OCR) 和 &lt;code&gt;AnalyzeDocument&lt;/code&gt;（表单和表格）的 API 定价现在与美国东部（弗吉尼亚北部）区域的定价相同。这些已确定区域的客户将看到 API 定价下降 9-32％。&lt;/p&gt; 
&lt;p&gt;在降价之前，客户对 &lt;code&gt;DetectDocumentText&lt;/code&gt; 和 &lt;code&gt;AnalyzeDocument&lt;/code&gt; API 的使用情况将按不同的费率、按区域及其使用套餐收费。无论从哪个亚马逊云科技商业区域 Textract 调用，现在都将按同样的费率向该客户收费。&lt;/p&gt; 
&lt;table style="width: 100%;border: 1px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto;text-align: right"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border: 1px solid black;background-color: #eee"&gt; 
   &lt;td style="text-align: center;border: 1px solid black" rowspan="2"&gt;&lt;strong&gt;亚马逊云科技区域&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="text-align: center;border: 1px solid black" colspan="3"&gt;&lt;strong&gt;DetectDocumentText API&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="text-align: center;border: 1px solid black" colspan="3"&gt;&lt;strong&gt;AnalyzeDocument API&lt;/strong&gt;&lt;strong&gt;（表单+表格）&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;原价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;新价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;减少&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;原价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;新价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;减少&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（孟买）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.830 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black" rowspan="8"&gt;1.50 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;18%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;79.30 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black" rowspan="8"&gt;65.0 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;18%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（首尔）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.845 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;19%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;79.95 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;19%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（新加坡）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;2.200 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;32%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;95.00 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;32%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（悉尼）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.950 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;23%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;84.50 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;23%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;加拿大（中部）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.655 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;9%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;72.15 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;10%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（法兰克福）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.875 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;20%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;81.25 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;20%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（伦敦）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.750 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;14%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;75.00 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;13%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（巴黎）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.755 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;15%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;76.05 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;15%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;此表显示了每 1,000 页的两个有效价格示例，用于在降价之前和之后处理前 100 万个按月填的页面。每月页面使用量超过 100 万个套餐的客户还会看到类似的价格下降信息，其详细信息位于 &lt;a href="https://aws.amazon.com/textract/pricing/"&gt;Amazon Textract 定价页面&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;新定价将于 &lt;strong&gt;2021 年 9 月 1 日&lt;/strong&gt;生效。新价格将自动应用于您的账单。此定价变更不适用于欧洲（爱尔兰）、美国商业区域和美国 GovCloud 区域。近期推出的 &lt;code&gt;AnalyzeExpense&lt;/code&gt; API 发票和收据的定价没有任何变化。&lt;/p&gt; 
&lt;p&gt;作为&lt;a href="https://aws.amazon.com/free/"&gt;亚马逊云科技免费套餐&lt;/a&gt;的一部分，您可以免费开始使用 Amazon Textract。&amp;nbsp;免费套餐持续 3 个月，新的 AWS 客户可以使用 Detect Document Text API 每月分析多达 1,000 页，使用 Analyze Document API 或 Analyze Expense API 每月可分析 100 页。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;端到端任务处理时间减少近 50％&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; 客户可以同步（在单页文档中）和异步（在多页文档中）调用 Textract 来检测打印和手写的行和单词（通过 &lt;code&gt;DetectDocumentText &lt;/code&gt;API）以及提取表单和表格（通过 &lt;code&gt;AnalyzeDocument&lt;/code&gt; API）。我们看到，如今绝大多数客户异步调用 Textract 来对他们的文档管道进行大规模处理。&lt;/p&gt; 
&lt;p&gt;根据客户反馈，我们对 Textract 的异步 API 操作进行了多项改善和提高，这些功能将端到端延迟减少了近 50％。具体而言，这些更新将 Textract 客户在全球异步操作中经历的端到端任务处理时间缩短了近 50％。处理时间越短，客户处理文档、实现规模和提高总体生产力的速度就越快。&lt;/p&gt; 
&lt;p&gt;要深入了解 Amazon Textract，请参阅本&lt;a href="https://aws.amazon.com/getting-started/hands-on/extract-text-with-amazon-textract/"&gt;教程中关于从文档&lt;/a&gt;中提取文本和结构性数据、GitHub 中的&lt;a href="https://github.com/aws-samples/amazon-textract-code-samples"&gt;此代码示例&lt;/a&gt;、&lt;a href="https://docs.aws.amazon.com/textract/"&gt;Amazon Textract 文档&lt;/a&gt;，以及 Amazon Web Services Machine Learning 博客&lt;a href="https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-textract/"&gt;中关于 Amazon Textract 的&lt;/a&gt;博客帖子。&lt;/p&gt; 
&lt;p&gt;– &lt;a href="https://twitter.com/channyun"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>Announcing the latest AWS Heroes – August 2021</title>
		<link>https://aws.amazon.com/cn/blogs/china/announcing-the-latest-aws-heroes-august-2021/</link>
				<pubDate>Fri, 03 Sep 2021 04:09:00 +0000</pubDate>
		<dc:creator><![CDATA[Ross Barich]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">07b49b3d09f57f003e99de21de38d56a06c40a92</guid>
				<description>AWS 勇士们不遗余力地与社群分享知识，并帮助其他人在 AWS 上更好、更快地进行构建。上个月，我们推出了 AWS 勇士内容库，这是一个资源汇集之地，构建者可以在这里找到灵感并从 AWS 勇士撰写的教学内容中学习，包括博客、视频、幻灯片演示、播客、开源项目等。随着技术社群的日益发展，新的勇士不断涌现，每个季度我们都会表彰来自世界各地的一群杰出人士，他们对社群知识的共享产生重大影响，并受到高度赞赏。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士们&lt;/a&gt;不遗余力地与社群分享知识，并帮助其他人在 AWS 上更好、更快地进行构建。上个月，我们推出了 &lt;a href="https://aws.amazon.com/developer/community/heroes/content-library/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士内容库&lt;/a&gt;，这是一个资源汇集之地，构建者可以在这里找到灵感并从 AWS 勇士撰写的教学内容中学习，包括博客、视频、幻灯片演示、播客、开源项目等。随着技术社群的日益发展，新的勇士不断涌现，每个季度我们都会表彰来自世界各地的一群杰出人士，他们对社群知识的共享产生重大影响，并受到高度赞赏。&lt;/p&gt; 
&lt;p&gt;今天，我们很高兴地介绍最新的 AWS 勇士们，包括位于喀麦隆和马来西亚的首批勇士：&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Denis Astahov – 加拿大温哥华&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/denis-astahov/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/denis-astahov.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士 &lt;a href="https://aws.amazon.com/developer/community/heroes/denis-astahov/" target="_blank" rel="noopener noreferrer"&gt;Denis Astahov&lt;/a&gt; 是 OpsGuru 的一名解决方案构架师，在那里，他使用 Terraform 利用基础设施即代码自动化和开发各种云解决方案。Denis 拥有 YouTube 频道 ADV-IT，他通过该频道向人们讲授各种 IT 知识，尤其是有关 DevOps 的话题，包括 AWS、Terraform、Kubernetes、Ansible、Jenkins、Git、Linux、Python 及许多其他主题。他的频道拥有 7 万多个订阅者和 700 多万观看次数，使其成为俄语社群中 AWS 和 DevOps 知识最受欢迎的免费来源之一。Denis 拥有 10 多项云认证，其中包括 7 项 AWS Certification。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Ivonne Roberts — 美国坦帕&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/ivonne-roberts/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/ivonne-roberts.jpg" width="175" height="263"&gt;&lt;/a&gt;无服务器勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/ivonne-roberts/" target="_blank" rel="noopener noreferrer"&gt; Ivonne Roberts&lt;/a&gt; 是一名首席软件工程师，拥有逾 15 年的软件开发经验，其中包括十年与 AWS 合作的经验以及五年以上构建无服务器应用程序的经验。近年来，Ivonne 已开始与范围更广的软件工程界分享这些行业知识。在其博客 ivonneroberts.com 和 YouTube 频道 DevWidgets 上，Ivonne 专注于揭开采用无服务器架构的神秘面纱并消除障碍，以及简化软件开发生命周期。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Kaushik Mohanraj — 马来西亚吉隆坡&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/kaushik-mohanraj/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/kaushik-mohanraj.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/kaushik-mohanraj/" target="_blank" rel="noopener noreferrer"&gt; Kaushik Mohanraj&lt;/a&gt; 是马来西亚一家名为 Blazeclan Technologies 的公司的董事。Kaushik 是一位狂热的云从业者，在评估架构良好的解决方案方面拥有丰富的经验，并且是云技术和数字化转型大使。Kaushik 持有 10 项有效的 AWS Certification，这有助于他提供最有针对性且且最佳的解决方案。Kaushik 热衷于打造一个他得以在其中充分发展的社群，因此在 2019 年作为联合组织者加入了马来西亚 AWS 用户组。他还是“大数据中的女性 — 马来西亚分会”的联合总监，旨在为科技领域的女性构建和提供一个平台。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Luc van Donkersgoed — 荷兰乌得勒支&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/luc-van-donkersgoed/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/luc-van-donkersgoed.jpg" width="175" height="263"&gt;&lt;/a&gt;DevTools 勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/luc-van-donkersgoed/" target="_blank" rel="noopener noreferrer"&gt; Luc van Donkersgoed&lt;/a&gt; 在内心里是一位技术狂热爱好者，他是一名解决方案构架师、软件开发人员，同时也是一位企业家。他着迷于尖端技术。不在 AWS 上设计和构建强大的应用程序时， Luc 很可能正在博客、文章、视频、会议、培训课程和 Twitter 上分享知识。他撰写了一个 共16 节课的 AWS 解决方案构架师专业课程，内容涉及各种主题，包括 AWS CDK 将如何助力新一代无服务器开发人员，他也曾出现在 AWS 开发人员播客中，同时他也在维护 AWS 博客 Twitter Bot。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Rick Hwang — 台湾台北市&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/rick-hwang/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/rick-hwang.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/rick-hwang/" target="_blank" rel="noopener noreferrer"&gt; Rick Hwang&lt;/a&gt; 是位于台湾的 91APP 的一名云与基础设施架构师。他为开发人员授课的热情已在内部通过年度 AWS 培训项目负责人的身份得以彰显，在外部又通过 SRE Taiwan 社群拥有者的身份得以证明。Rick 独立创办了 SRE Taiwan，在过去的 4 年里，通过点对点互动、不断分享内容和主办年度学习小组聚会，招募了 3,600 多名成员。Rick 乐于帮助人们加深对 AWS 和整个云的了解。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Rosius Ndimofor — 喀麦隆杜阿拉&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/rosius-ndimofor/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/23/rosius-ndimofor.jpg" width="175" height="263"&gt;&lt;/a&gt;无服务器勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/rosius-ndimofor/" target="_blank" rel="noopener noreferrer"&gt; Rosius Ndimo&lt;/a&gt; 是 Serverless Guru 的一名软件开发人员。8 年来，他始终在为各种客户构建桌面、Web 和移动应用程序。2020 年，Rosius 的朋友向他介绍了 AWS，他随即便被吸引住了，并开始尽可能地学习如何构建 AWS 无服务器应用程序。您会看到 Rosius 在当地每月一次的 AWS 聚会活动中发表演讲，或者从事他的强项：构建无服务器 Web 或移动应用程序并在其博客上记录整个过程。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Setia Budi — 印度尼西亚万隆&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/setia-budi/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/setia-budi.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/setia-budi/" target="_blank" rel="noopener noreferrer"&gt; Setia Budi&lt;/a&gt; 是一名来自印度尼西亚的学者。他经营着一个名为 Indonesia Belajar 的 YouTube 频道，该频道提供与计算机科学和云计算相关的学习资料（以印度尼西亚语提供）。他对 AWS 社区的热情还体现在他在 AWS DevAx Connect 上发表演讲，他正在积极构建一系列与 AWS 服务相关的学习材料，并每周直播 AWS 专家探论云计算的直播会议。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Vinicius Caridá — 巴西圣保罗&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/vinicius-carida/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/vinicius-carida.jpg" width="175" height="263"&gt;&lt;/a&gt;机器学习勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/vinicius-carida/" target="_blank" rel="noopener noreferrer"&gt; Vinicius Caridá（Vini）&lt;/a&gt;是一名计算机工程师，他相信技术、数据和人工智能可以影响人们，进而创造一个更公平、更进步的世界。他喜欢在社交媒体上、YouTube 频道上以及 AWS 圣保罗用户组（他是社群主管）等各种聚会上分享自己关于 AI、NLP 和 MLOps 的知识。Vini 还是开源机器学习框架 TensorFlow 圣保罗的社群主管。他定期参加会议，并为不同背景（学术界、科学界、技术界）和不同成熟程度（初级、中级和高级）的受众撰写文章。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如果您想了解有关这些新勇士的详情，或者与附近的勇士联系，请访问 &lt;a href="https://aws.amazon.com/developer/community/heroes/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士网站&lt;/a&gt;或浏览 &lt;a href="https://aws.amazon.com/developer/community/heroes/content-library/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士内容库&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://twitter.com/rossbarich" target="_blank" rel="noopener noreferrer"&gt;Ross&lt;/a&gt;；&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>通过亚马逊云科技Marketplace中合作伙伴（Zenlayer）的产品来加速Amazon S3的访问</title>
		<link>https://aws.amazon.com/cn/blogs/china/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace/</link>
				<pubDate>Fri, 03 Sep 2021 03:59:58 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Marketplace]]></category>

		<guid isPermaLink="false">19e4e87c516f11f5d35a00626639a9bb0cda9724</guid>
				<description>AWS Marketplace 是一个精挑细选的数字化产品目录，您可以使用它来查找、购买、部署和管理构建解决方案及运营业务所需的第三方软件、数据和服务。 AWS Marketplace 囊括了众多常见类别下的数千个软件名录，例如安全、联网、存储、机器学习、IoT、商业智能、数据库和开发运营。 AWS Marketplace 还提供灵活的定价选项和多种部署方法，从而简化了软件的许可和采购。此外, AWS Marketplace 包括 AWS Data Exchange 提供的数据产品。</description>
								<content:encoded>&lt;h2&gt;1.&amp;nbsp;&amp;nbsp; 相关服务及背景介绍&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Amazon S3&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Amazon Simple Storage Service (Amazon S3) 是一种面向 Internet 的存储服务。该服务旨在降低网络规模计算的难度。&lt;/p&gt; 
&lt;p&gt;Amazon S3 提供了一个简单 Web 服务接口，可用于随时在 Web 上的任何位置存储和检索任何数量的数据。此服务让所有开发人员都能访问同一个具备高扩展性、可靠性、安全性和快速价廉的数据存储基础设施，Amazon 用它来运行其全球的网站网络。此服务旨在为开发人员带来最大化的规模效益。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Amazon CloudFront&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Amazon CloudFront 是一项加快将静态和动态 Web 内容（例如 .html、.css、.js 和图像文件）分发给用户的速度的 Web 服务。CloudFront 通过全球数据中心（称作边缘站点）网络传输内容。当用户请求您用 CloudFront 提供的内容时，请求被路由到提供最低延迟（时间延迟）的边缘站点，从而以尽可能最佳的性能传送内容。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;亚马逊云科技&lt;/strong&gt;&lt;strong&gt;Marketplace&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AWS Marketplace 是一个精挑细选的数字化产品目录，您可以使用它来查找、购买、部署和管理构建解决方案及运营业务所需的第三方软件、数据和服务。 AWS Marketplace 囊括了众多常见类别下的数千个软件名录，例如安全、联网、存储、机器学习、IoT、商业智能、数据库和开发运营。 AWS Marketplace 还提供灵活的定价选项和多种部署方法，从而简化了软件的许可和采购。此外, AWS Marketplace 包括 AWS Data Exchange 提供的数据产品。&lt;/p&gt; 
&lt;p&gt;您只需几次单击即可快速启动预配置的软件，并可选择 Amazon 系统映像 (AMI) 和软件即服务 (SaaS) 格式以及其他格式的软件解决方案。此外，您还可以浏览和订阅数据产品。灵活的定价选项包括免费试用、每小时、每月、每年、多年和自带许可 (BYOL) 模式。所有这些定价选项都从一个来源计费。AWS 会处理账单和付款，费用将显示在您的 AWS 账单上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;应用系统或最终用户对于&lt;/strong&gt;&lt;strong&gt;S3对象的访问需求&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由于Amazon S3的灵活性与可靠性，亚马逊云科技的许多客户都使用S3用于对象的存储，Amazon S3可以用于多种用途，比如数据湖的底层存储、备份文件的存储、日志的收集存储等。&lt;/p&gt; 
&lt;p&gt;除此之外，许多应用系统也会使用S3作为底层的存储之一，比如一些在线商城系统或者社交系统，会将图片等静态文件存储在Amazon S3之中，而系统的架构设计可能需要最终访问用户通过联合认证后获得相应的角色权限去访问这些位于Amazon S3中的对象。&lt;/p&gt; 
&lt;p&gt;应用系统在进行全球化的布局过程中，往往需要适用于全球化的客户，这些客户的地理位置较为分散，尤其一些位于偏远或特殊区域的客户，他们可能离应用系统或者Amazon S3所处的区域较远或无法通过亚马逊云科技底层网络到达，这时广域化的互联网会造成较大的延迟和不稳定，这会导致部分用户的体验下降或应用程序无法正常运作。&lt;/p&gt; 
&lt;h2&gt;2.&amp;nbsp;&amp;nbsp; ZGA（Global Accelerator）功能介绍&lt;/h2&gt; 
&lt;p&gt;Zenlayer Global Accelerator为全球用户提高了应用程序的可用性和性能。即时加速用户对应用程序、网站和/或在线平台的访问，包括高动态内容（如实时流媒体和播放器操作）或安全操作（如用户身份验证和支付）。&lt;/p&gt; 
&lt;p&gt;我们的合作伙伴的平台利用180多个边缘位置、专用全球主干网和先进的智能路由技术实现与客户的高速连接，消除延迟和数据包丢失，即使在“最后一英里”也不例。ZGA拥有稳定的高速连接，安全的防护，并采用拥有骨干网络和智能路由技术的全球节点，使用户能够通过接入最近的节点来实现高速连接访问源站，消除跨境跨域访问过程里用户经常遇到的网页加载慢、通讯的延迟以及卡顿。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;联合解决方案优势 ：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;直接通过VBR对接亚马逊云科技源站，中间节点与节点之间全程骨干网络 ，回源更迅速稳定，隐私性+性能双保障。&lt;/li&gt; 
 &lt;li&gt;通过智能解析和全球调度系统为用户选取最优最近的接入方式 。&lt;/li&gt; 
 &lt;li&gt;支持IP/域名加速。支持http，https，WebSocket，WSS，FTP，SSH，TCP/UDP等多种协议。支持自定义端口及支持私有协议。&lt;/li&gt; 
 &lt;li&gt;支持源站负载均衡及实时监控，SSL加密传输，黑白名单及IP ALC等功能保护源站安全。&lt;/li&gt; 
 &lt;li&gt;操作简便，交付敏捷。通过亚马逊云科技Marketplace可以直接试用和购买合作伙伴的产品，加速平台配备了配置界面，只需几分钟就可以将客户接入加速。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3.&amp;nbsp;&amp;nbsp; ZGA优化Amazon S3常用架构&lt;/h2&gt; 
&lt;p&gt;客户在亚马逊云科技的某个Region上使用了S3服务，期望可以覆盖全球各地用户的访问&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; ZGA加速S3常用架构&lt;/p&gt; 
&lt;p&gt;对于可控的用户，固定办公场所可以安装网关就近连接到Zenlayer的边缘POP，获取S3的流量送到全球骨干进行加速。移动用户安装客户端，随时体验S3加速效果。&lt;/p&gt; 
&lt;p&gt;而对于无法安装硬件网关或客户端的用户，可以直接访问由Zenlayer提供的域名(如：www.xxx.com)替代S3原本的域名，通过Zenlayer全球智能DNS解析服务，自动将访问S3的流量牵引至就近POP，再通过全球骨干转发到距离S3源站最近的POP进行转发，实现对S3的加速.&lt;/p&gt; 
&lt;h2&gt;4.&amp;nbsp;&amp;nbsp; ZGA集成Amazon Cloudfront加速全球S3&lt;/h2&gt; 
&lt;p&gt;客户在亚马逊云科技上使用了Amazon S3服务，并在部分节点使用了Amazon CloudFront覆盖当地客户，但当最终用户的某些区域不在CloudFront覆盖范围内，无法让这些用户都快速的访问S3上的内容。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 例如：&lt;/p&gt; 
&lt;p&gt;用户在美国东部署了S3源站，通过CloudFront服务加速东南亚用户，CloudFront东南亚节点选择在新加坡，本地使用者访问质量得到了优化，但东南亚其它地区的使用者通过互联网访问到CloudFront新加坡节点时体验不佳，导致整体访问效果不好。&lt;/p&gt; 
&lt;p&gt;ZGA的方案会提供给用户一个额外的URL地址，客户在域名控制平台使用该地址替换CloudFront的CNAME地址，使用者在访问S3域名时，通过智能DNS的解析，会判断出CloudFront无法覆盖的地址，并将这些流量会返回Zenlayer边缘POP的IP地址，如泰国、菲律宾、印尼等，流量就近接入后再通过全球骨干送到新加坡的CloudFront节点，最终由CloudFront节点经亚马逊云科技转发到美国源站，动态快速的扩充了CloudFront的全球覆盖能力。&lt;/p&gt; 
&lt;h2&gt;5.&amp;nbsp;&amp;nbsp; ZGA加速S3在不同Region的传输&lt;/h2&gt; 
&lt;p&gt;用户在亚马逊云科技的多个Region都是用了Amazon S3的服务，不同Region间的S3需要做数据同步。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; Zenlayer向客户在亚马逊云科技中不同的Region发起DX连接，按照就近选择原则，通过最近的POP打通到客户不同Region的连接；&lt;/p&gt; 
&lt;p&gt;由于S3不属于Private服务，客户需要建立Public VIF并绑定到VGW，建立到Zenlayer骨干网的连接通道；&lt;/p&gt; 
&lt;p&gt;不同的Region通过BGP communities控制BGP宣告的路由信息，只发布本Region的所有public IP，Zenlayer通过DX连接将两个区域的路由同步；&lt;/p&gt; 
&lt;p&gt;使用亚马逊云科技的S3数据同步功能进行数据的复制时，会依据路由规则通过Zenlayer骨干完成传输；&lt;/p&gt; 
&lt;h2&gt;6.&amp;nbsp;&amp;nbsp; 如何通过亚马逊云科技Marketplace来交付ZGA&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;合约产品下单&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;步骤一: 打开 &lt;a href="https://aws.amazon.com/marketplace/pp/B08RNQC2WJ"&gt;https://aws.amazon.com/marketplace/pp/B08RNQC2WJ&lt;/a&gt; 后，点击 “Continue to Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤二: 选择合约期限和续约设置&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤三: 选择您所需要的带宽步骤二: 选择合约期限和续约设置&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤四: 点击“Create Contract” 按钮来创建合约&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤五: 支付此合约&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤六: 点击 “Setup your account“ 按钮设置您的账户，之后将会进入到Zenlayer的Portal网址&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤七: 开始注册Zenlayer账户，可继续遵循用户指导步骤&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;订阅产品下单&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;步骤一: 打开 &lt;a href="https://aws.amazon.com/marketplace/pp/B08S3F2PCF"&gt;https://aws.amazon.com/marketplace/pp/B08S3F2PCF&lt;/a&gt; 后，点击 “Continue to Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤二: 确认按流量收费价格后点击“Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤三: 点击“Setup your account“ 按钮进入到Zenlayer Portal网站设置您的账户步骤二: 确认按流量收费价格后点击“Subscribe” 按钮&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 步骤四: 开始注册Zenlayer账户，可继续遵循用户指导步骤&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/accelerate-the-access-of-amazon-s3-through-the-products-of-the-partner-zenlayer-in-the-amazon-cloud-technology-marketplace14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7.&amp;nbsp;&amp;nbsp; 小结步骤四: 开始注册Zenlayer账户，可继续遵循用户指导步骤&lt;/h2&gt; 
&lt;p&gt;通过本文的介绍，您应该初步了解了如何通过亚马逊云科技以及合作伙伴Zenlayer的联合解决方案来加速您的应用以及终端用户对于Amazon S3中对象的访问，以及如果通过亚马逊云科技Marketplace来对合作伙伴的产品进行试用和购买，如果您需要更多的信息，可以参考亚马逊云科技Marketplace官方文档以及合作伙伴官方网站。&lt;/p&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/mingyue.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;张明月&lt;/h3&gt; 
  &lt;p&gt;合作伙伴解决方案架构师&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/liubing.png" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;刘冰&lt;/h3&gt; 
  &lt;p&gt;Zenlayer，产品经理&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用Python语言实现Transcribe Streaming的websocket协议</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-python-language-to-implement-the-websocket-protocol-of-transcribe-streaming/</link>
				<pubDate>Fri, 03 Sep 2021 03:45:21 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon Transcribe]]></category>

		<guid isPermaLink="false">e21e52547928d10b376260b6094480799af5ab25</guid>
				<description>Amazon Transcribe是自动语音识别（ASR）服务，可让开发人员轻松地为其应用程序添加语音转文本功能，Transcribe支持文件和流式Streaming的两种音频输入方式，Transcribe Streaming可以应用在会议记录，语音控制交互，语言实时翻译等场景，Streaming方式支持HTTP/2和WebSocket两种协议。本文介绍使用Python语言实现Transcribe Streaming的WebSocket协议。</description>
								<content:encoded>&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;Amazon Transcribe是自动语音识别（ASR）服务，可让开发人员轻松地为其应用程序添加语音转文本功能，Transcribe支持文件和流式Streaming的两种音频输入方式，Transcribe Streaming可以应用在会议记录，语音控制交互，语言实时翻译等场景，Streaming方式支持HTTP/2和WebSocket两种协议。本文介绍使用Python语言实现Transcribe Streaming的WebSocket协议。&lt;/p&gt; 
&lt;h2&gt;Streaming transcription 接口介绍&lt;/h2&gt; 
&lt;p&gt;Streaming transcription 接口可以接收音频流并且实时转换为文字，然后将结果返回客户端，同时返回数据中包含partial值，用来标示句子是否结束。&lt;/p&gt; 
&lt;p&gt;Streaming的数据是被编码的，由prelude和data组成。编码格式详见：https://docs.aws.amazon.com/transcribe/latest/dg/event-stream.html&lt;/p&gt; 
&lt;h2&gt;Python语言的实现过程和示例&lt;/h2&gt; 
&lt;p&gt;Python示例程序的运行环境是Python 3.7.9版本。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加IAM Policy到你使用到的IAM user&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "transcribestreaming",
            "Effect": "Allow",
            "Action": "transcribe:StartStreamTranscriptionWebSocket",
            "Resource": "*"
        }
    ]
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;安装Python的程序包&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Python示例程序需要安装三个程序包websocket-client，boto3和amazon_transcribe；其中boto3是AWS SDK for Python，amazon_transcribe是Amazon Transcribe Streaming SDK，这两个SDK简化了和Amazon Transcribe Service的集成过程。amazon_transcribe的详细说明见：https://github.com/awslabs/amazon-transcribe-streaming-sdk&lt;/p&gt; 
&lt;p&gt;安装程序包的命令：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;pip3 install boto3
pip3 install amazon_transcribe
pip3 install websocket-client&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;Python程序的import部分：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import hashlib
import hmac
import urllib.parse
from datetime import datetime
import time
import ssl
import json
import websocket
import _thread
from amazon_transcribe.eventstream import EventStreamMessageSerializer
from amazon_transcribe.eventstream import EventStreamBuffer
from boto3.session import Session&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;创建签名URL的函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;URL签名说明详见：&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Python的实现示例：&lt;/p&gt; 
&lt;p&gt;下列代码中主体函数是create_pre_signed_url，它将生成访问Streaming transcription 接口的URL，其中包括必要的参数和签名，它需要传入4个参数:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;参数region代表将要调用的Amazon Web Service Region。可查看Streaming支持的region，详见Docs链接的Amazon Transcribe Streaming部分（&lt;a href="https://docs.aws.amazon.com/general/latest/gr/transcribe.html"&gt;https://docs.aws.amazon.com/general/latest/gr/transcribe.html&lt;/a&gt;）&lt;/li&gt; 
 &lt;li&gt;参数language_code, media_encoding, sample_rate是stream-transcription-websocket接口的参数，定义见https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def sign(key, msg):
    return hmac.new(key, msg.encode("utf-8"), hashlib.sha256).digest()

def getSignatureKey(key, dateStamp, region, serviceName):
    kDate = sign(("AWS4" + key).encode("utf-8"), dateStamp)
    kRegion = sign(kDate, region)
    kService = sign(kRegion, serviceName)
    kSigning = sign(kService, "aws4_request")
    return kSigning

def create_pre_signed_url(region, language_code, media_encoding, sample_rate):
    # 获得access key和secret key
    credentials = Session().get_credentials()
    access_key_id = credentials.access_key
    secret_access_key = credentials.secret_key

    method = "GET"
    service = "transcribe"
    endpoint = "wss://transcribestreaming." + region + ".amazonaws.com:8443"
    host = "transcribestreaming." + region + ".amazonaws.com:8443"
    algorithm = "AWS4-HMAC-SHA256"

    t = datetime.utcnow()
    amz_date =t.strftime('%Y%m%dT%H%M%SZ')
    datestamp =t.strftime('%Y%m%d')

    canonical_uri = "/stream-transcription-websocket"

    canonical_headers = "host:" + host + "\n"
    signed_headers = "host"

    credential_scope = datestamp + "/" + region + "/" + service + "/" + "aws4_request"

    canonical_querystring = "X-Amz-Algorithm=" + algorithm
    canonical_querystring += "&amp;amp;X-Amz-Credential=" + urllib.parse.quote_plus(access_key_id + "/" + credential_scope)
    canonical_querystring += "&amp;amp;X-Amz-Date=" + amz_date
    canonical_querystring += "&amp;amp;X-Amz-Expires=300"
    canonical_querystring += "&amp;amp;X-Amz-SignedHeaders=" + signed_headers
    canonical_querystring += "&amp;amp;language-code="+ language_code +"&amp;amp;media-encoding=" + media_encoding +"&amp;amp;sample-rate=" + sample_rate

    # Zero length string for connecting
    payload_hash = hashlib.sha256(("").encode('utf-8')).hexdigest()

    canonical_request = method + '\n' \
                        + canonical_uri + '\n' \
                        + canonical_querystring + '\n' \
                        + canonical_headers + '\n' \
                        + signed_headers + '\n' \
                        + payload_hash

    string_to_sign = algorithm + "\n" \
                     + amz_date + "\n" \
                     + credential_scope + "\n" \
                     + hashlib.sha256(canonical_request.encode("utf-8")).hexdigest()

    signing_key = getSignatureKey(secret_access_key, datestamp, region, service)

    signature = hmac.new(signing_key, string_to_sign.encode("utf-8"),
                         hashlib.sha256).hexdigest()

    canonical_querystring += "&amp;amp;X-Amz-Signature=" + signature

    request_url = endpoint + canonical_uri + "?" + canonical_querystring

    return request_url
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写main函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面代码中的loop_receiving和send_data函数，作用分别是从Amazon Transcribe Service接收消息，和向Amazon Transcribe Service发送消息。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def main():
    url = create_pre_signed_url("us-east-1", "en-US", "pcm", "16000")
    ws = websocket.create_connection(url, sslopt={"cert_reqs": ssl.CERT_NONE})

    _thread.start_new_thread(loop_receiving, (ws,))
    print("Receiving...")
    send_data(ws)

    while True:
        time.sleep(1)
main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写loop_receiving函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该函数位于main函数上方。它将接收Amazon Transcribe Streaming Service的返回数据，并且打印出来。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def loop_receiving(ws):
    try:
        while True:
            result = ws.recv()

            if result == '':
                continue

            eventStreamBuffer = EventStreamBuffer()

            eventStreamBuffer.add_data(result)
            eventStreamMessage = eventStreamBuffer.next()

            stream_payload = eventStreamMessage.payload

            transcript = json.loads(bytes.decode(stream_payload, "UTF-8"))

            print("response:",transcript)

            results = transcript['Transcript']['Results']
            if len(results)&amp;gt;0:
                for length in range(len(results)):
                    if 'IsPartial' in results[length]:
                        print('IsPartial:', results[length]['IsPartial'])

                    if 'Alternatives' in results[length]:
                        alternatives = results[length]['Alternatives']
                        if len(alternatives)&amp;gt;0:
                            for sublength in range(len(alternatives)):
                                if 'Transcript' in alternatives[sublength]:
                                    print('Transcript:', alternatives[sublength]['Transcript'])


    except Exception as e:
        if 'WebSocketConnectionClosedException' == e.__class__.__name__:
            print("Error: websocket connection is closed")
        else:
            print(f"Exception Name: {e.__class__.__name__}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写send_data函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该函数位于main函数上方。它将发送音频数据到Amazon Transcribe Streaming Service。其中testFile变量是测试音频文件地址，测试音频为pem格式，英语，采样率为16000。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def send_data(ws):

    testFile = "xxx.pem"

    bufferSize = 1024*16

    stream_headers = {
        ":message-type": "event",
        ":event-type": "AudioEvent",
        ":content-type": "application/octet-stream",
    }

    eventstream_serializer = EventStreamMessageSerializer()

    with open(testFile, "rb") as source:
        while True:
            audio_chunk = source.read(bufferSize)
            # 将音频数据进行编码
            event_bytes = eventstream_serializer.serialize(stream_headers, audio_chunk)

            ws.send(event_bytes, opcode = 0x2) # 0 x 2 send binary

            # end with b'' data bytes
            if len(audio_chunk) == 0:
                break&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;在这篇文章中，介绍了如何使用Python语言实现Transcribe Streaming的WebSocket协议，提供了Python的例子供参考，包括签名URL、数据编码、数据流的发送和接收等部分。完整代码见：https://github.com/xuemark/transcribe/blob/master/transcribe_streaming_websocket.py&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/transcribe"&gt;https://aws.amazon.com/transcribe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awslabs/amazon-transcribe-streaming-sdk"&gt;https://github.com/awslabs/amazon-transcribe-streaming-sdk&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/markxue.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;薛召兵&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责帮助客户进行上云架构的设计和咨询。同时致力于AWS容器服务、媒体服务和机器学习服务在国内和全球商业客户的应用和推广，推进企业服务迁移上云进程。有10年以上的软件开发、售前技术支持、系统架构设计等经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>基于 Nitro Enclave 构建安全的可信执行环境</title>
		<link>https://aws.amazon.com/cn/blogs/china/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave/</link>
				<pubDate>Thu, 02 Sep 2021 03:44:40 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Security, Identity, & Compliance]]></category>
		<category><![CDATA[Amazon EC2]]></category>
		<category><![CDATA[AWS Certificate Manager]]></category>
		<category><![CDATA[AWS KMS]]></category>

		<guid isPermaLink="false">fd8724fce745fd981e91ec04870e32556afb194e</guid>
				<description>Nitro Enclave 使用户可以在亚马逊云科技上，简便，安全地运行隔离的可信计算环境，用于处理私钥，PII等敏感数据，支持 Intel，AMD 芯片的计算实例，没有任何额外费用，具备更好的灵活性和成本效益，且与云原生的安全服务 KMS，ACM 直接集成，为用户提供更好的使用体验和安全性保障。</description>
								<content:encoded>&lt;h2&gt;前言&lt;/h2&gt; 
&lt;p&gt;随着移动通信和互联网技术的发展与应用，数据泄漏可能会造成直接的收入损失，并对业务、用户信任和企业声誉产生重大影响，如何在业务更加深入地数字化的同时，在计算环境中确保数据的机密性和完整性，将是企业面临的重大挑战，尤其是在公有云的环境中。&lt;/p&gt; 
&lt;p&gt;可信执行环境（TEE: Trusted Execution Environment）的提出，正是应对这样的需求。 可信执行环境在芯片层面单独划分出来的一个隔离空间，建立与本地操作系统（例如 Android 和 Microsoft Windows）并行运行的隔离执行环境，保证加载到内部的代码和数据在机密性和完整性方面受到保护，保护敏感代码和数据免受来自本地操作系统潜在漏洞的特权攻击。&lt;/p&gt; 
&lt;p&gt;可信执行环境典型的业务场景包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;私钥安全&lt;/strong&gt;： 用户可以在隔离的安全环境中使用和处理私钥，例如加密和签名，同时阻止父实例上的用户、应用程序查看和获取这些密钥。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;敏感数据处理&lt;/strong&gt;： 可以在隔离的安全区域内运行应用程序，将个人身份，信用卡号等 PII 敏感数据进行令牌化。同时加密的数据可以发送到安全区域进行解密并处理。在整个过程中，父 EC2 实例将无法查看或访问敏感数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;业界常见的可信执行环境的技术包括，Intel SGX 和 ARM TrustZone 等，这个隔离的空间，在 Intel SGX 中被称作 Enclave，而在 ARM TrustZone 中则被称为 Secure World。&lt;/p&gt; 
&lt;p&gt;亚马逊云科技作为公有云的技术领导者，也推出了 TEE 解决方案，&lt;a href="https://aws.amazon.com/cn/ec2/nitro/nitro-enclaves/"&gt;Nitro Enclave&lt;/a&gt;，使用 Nitro Hypervisor 技术，在 EC2 实例内部，提供 CPU 和内存隔离的一个计算环境。&lt;/p&gt; 
&lt;p&gt;Nitro Enclave 主要优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;隔离和安全的运行环境: 基于 Nitro Hypervisor 实现的完全隔离的 CPU，内存计算环境，无持久化存储，交互式访问和外部网络&lt;/li&gt; 
 &lt;li&gt;加密证明: Attestation 证明文件允许用户在外部服务中，授权 Enclave 访问权限，和验证 Enclave 中的代码完整性&lt;/li&gt; 
 &lt;li&gt;灵活: 不需要绑定 CPU 厂商，支持 Intel，AMD 芯片，和任何编程语言&lt;/li&gt; 
 &lt;li&gt;成本: Nitro Enclave 运行于 EC2 中，无任何额外费用&lt;/li&gt; 
 &lt;li&gt;云原生安全集成: 与云原生的 KMS，ACM 安全服务直接集成，提供更好的用户体验和安全保障&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;1. Nitro Enclave 介绍&lt;/h2&gt; 
&lt;h3&gt;1.1 Nitro Enclave 基础介绍&lt;/h3&gt; 
&lt;p&gt;Nitro Enclaves 是一项 Amazon EC2 功能，允许您从 Amazon EC2 实例创建隔离的执行环境，称为 enclave。 Enclave 是独立的、强化的且高度受限的虚拟机，基于 Nitro Hypervisor 虚拟化技术，确保父实例无法访问隔离的 vCPU 和 enclave 的内存。Enclave 没有持久存储、交互式访问或外部网络，仅支持与其父实例的安全 Socket 连接。 用户无法通过 SSH 进入 enclave，并且父实例的进程、应用程序或用户（root 或 admin）无法访问 enclave 内的数据和应用程序。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1.2 Attestation 证明文件&lt;/h3&gt; 
&lt;p&gt;在 Nitro Enclave 中运行程序，除了隔离环境带来的私密性之外，还提供额外的安全特性，加密证明(Cryptographic Attestation)。Attestation 是 Enclave 用来证明其身份并与外部服务建立信任的过程，以及保证数据通信的安全。&lt;/p&gt; 
&lt;p&gt;Attestation 的目的是根据在特定 enclave 中运行的代码和配置，证明 enclave 是值得信赖的实体。 Nitro Hypervisor 能够生成包含 enclave 详细信息的证明文档，包括 enclave 签名密钥、enclave 映像的哈希值、父实例 ID 的哈希值以及附加 IAM 角色的 ARN 的哈希值。&lt;/p&gt; 
&lt;p&gt;Enclave Attestation 功能是由 Nitro Hypervisor 中的 Nitro Secure Module (NSM) 组件实现。亚马逊云科技提供了&lt;a href="https://github.com/aws/aws-nitro-enclaves-nsm-api"&gt;一套 helper library&lt;/a&gt;，方便用户在开发 Enclave 程序时，与 NSM 交互， 查询 PCR 和请求 Attestation 证明文件。&lt;/p&gt; 
&lt;p&gt;关于 Nitro Enclave Attestation 生成的详细过程，可参考&lt;a href="https://github.com/aws/aws-nitro-enclaves-nsm-api/blob/main/docs/attestation_process.md"&gt;此文档&lt;/a&gt;。下面是一个 Attestation 证明文件的结构：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;AttestationDocument = {
    module_id: text,               ; issuing Nitro hypervisor module ID
    timestamp: uint .size 8,       ; UTC time when document was created, in
                                   ; milliseconds since UNIX epoch
    digest: digest,                ; the digest function used for calculating the
                                   ; register values
    pcrs: { + index =&amp;gt; pcr },      ; map of all locked PCRs at the moment the
                                   ; attestation document was generated
    certificate: cert,             ; the infrastucture certificate used to sign this
                                   ; document, DER encoded
    cabundle: [* cert],            ; issuing CA bundle for infrastructure certificate
    ? public_key: user_data,       ; an optional DER-encoded key the attestation
                                   ; consumer can use to encrypt data with
    ? user_data: user_data,        ; additional signed user data, defined by protocol
    ? nonce: user_data,            ; an optional cryptographic nonce provided by the
                                   ; aattestation consumer as a proof of authenticity
}

cert = bytes .size (1..1024)       ; DER encoded certificate
user_data = bytes .size (0..1024)
pcr = bytes .size (32/48/64)       ; PCR content
index = 0..31
digest = "SHA384"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在 Attestation 证明文件中，包含了一个 Public Key，当 Enclave 程序向外部服务发起请求时，带上证明文件，外部应用可以利用该 Public Key，对需要返回 Enclave 的 Response 进行加密， Enclave 收到该 Response 后使用 Private Key 进行解密，确保数据在传输过程中不会被嗅探，且只有发起服务请求的 Enclave 才能解密该 Response。&lt;/p&gt; 
&lt;p&gt;另外，Attestation 文件中还包括每个 Enclave 一系列属性的哈希值，被称为 PCR (Platform Configuration Registers) 。用户可以使用 PCR 的哈希值在外部服务中创建访问策略，以授予对服务请求的访问权限。 Enclave 有 6 个 PCR，分别对应 Enclave 不同的元数据，其中 PCR 0，1，2 与 Enclave 镜像文件相关，在 Enclave 创建时生成。&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PCR&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hash of&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR0&lt;/td&gt; 
   &lt;td&gt;Enclave image file&lt;/td&gt; 
   &lt;td&gt;A contiguous measure of the contents of the image file, without the section data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR1&lt;/td&gt; 
   &lt;td&gt;Linux kernel and bootstrap&lt;/td&gt; 
   &lt;td&gt;A contiguous measurement of the kernel and boot ramfs data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR2&lt;/td&gt; 
   &lt;td&gt;Application&lt;/td&gt; 
   &lt;td&gt;A contiguous, in-order measurement of the user applications, without the boot ramfs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR3&lt;/td&gt; 
   &lt;td&gt;IAM role assigned to the parent instance&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the parent instance has the correct IAM role.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR4&lt;/td&gt; 
   &lt;td&gt;Instance ID of the parent instance&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the parent instance has a specific instance ID.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR8&lt;/td&gt; 
   &lt;td&gt;Enclave image file signing certificate&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the enclave was booted from an enclave image file signed by a specific certificate.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Attestation 证明文件生成后，还将会由受信任Nitro Hypervisor Attestation Public Key Infrastructure (PKI) ，基于一个 ACM PCA 的根证书进行签署，有效期为 30 年。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CN=aws.nitro-enclaves, C=US, O=Amazon, OU=AWS&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;用户可以下载该&lt;a href="https://aws-nitro-enclaves.amazonaws.com/AWS_NitroEnclaves_Root-G1.zip"&gt;根证书&lt;/a&gt;，导入到您的任何外部服务中，当 Enclave 中运行的程序需要请求外部服务时，可向 Nitro Hypervisor 申请并签署证明文件，外部服务通过导入的根证书，来验证 Enclave 证明文件的有效性，确保服务请求是来自于特定的 Enclave，从而建立信任。&lt;/p&gt; 
&lt;p&gt;目前 Amazon Key Management Service (KMS) 和 Amazon Certificate Manager (ACM) 支持与 Nitro Enclave 以及 Attestation 原生集成，Enclave 可借助 vsock 以及父实例上的代理，向 KMS 或 ACM 发起 API 请求，进行加密，解密，和证书申请，更新等操作，同时 KMS 和 ACM 支持对 Enclave 签名的证明文件进行验证，并可将 API Response 用证明文件中的 Public Key 进行加密，确保数据隐私安全。&lt;/p&gt; 
&lt;p&gt;适用于 Nitro Enclaves 的 ACM 允许您将公有和私有 SSL/TLS 证书与在带有 Nitro Enclaves 的 EC2 实例上运行的 Web 应用一起使用。 亚马逊云科技提供了一个打包好的 ACM for Nitro Enclaves 程序，作为服务(aws-nitro-enclaves-acm) 运行在父实例 Linux 操作系统中，该服务将自动创建和运行 Enclave，与 ACM 交互创建安全私钥，将证书及其私钥分发到 enclave，并管理证书续订，证书的私钥在 enclave 中保持隔离，防止父实例及其用户访问它。 具体部署过程可参照&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html"&gt;官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;目前，ACM for Nitro Enclaves 支持与运行在 Amazon EC2 实例上的 NGINX 配合使用，以安装证书并无缝替换过期证书，以提供 HTTPS 服务，未来将添加对其他 Web 服务（Apache HTTP）的支持。&lt;/p&gt; 
&lt;h3&gt;1.3 Nitro Enclave Attestation 与 KMS 集成&lt;/h3&gt; 
&lt;p&gt;Amazon KMS 是一项云原生的密钥管理服务，用来创建和管理密钥，支持使用密钥进行 Server-side 的加密，解密，签名，验证等操作，还支持生成用于 client-side 加密的密钥。 KMS 内置原生支持 Nitro Enclaves，能够验证来自 Enclave 请求中携带的 Attestation 证明文件，并可以根据证明文件中的 PCR 值，定义密钥策略，来授予对特定 Enclave 的访问权限。&lt;/p&gt; 
&lt;p&gt;可以在 KMS Policy 中定义的 Condition Key ，对来自 Enclave 发起的以下三个 API 请求，进行 Attestation 验证和 API 请求授权，例如只允许来自指定 Enclave 的 KMS Decrypt API 请求。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;kms:GenerateRandom： 生成随机字符串&lt;/li&gt; 
 &lt;li&gt;kms:GenerateDataKey： 生成 Data Key，用于 Client-Side 加密&lt;/li&gt; 
 &lt;li&gt;kms:Decrypt： 对文本或 Data Key 进行解密&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  "Version": "2012-10-17",
  "Statement": [{
    "Sid" : "Enable enclave data processing",
    "Effect" : "Allow",
    "Principal" : {
      "AWS" : "arn:aws:iam::123456789012:role/data-processing"
    },
    "Action": [
      "kms:Decrypt",
      "kms:GenerateDataKey",
      "kms:GenerateRandom"
    ],
    "Resource": "*",
    "Condition": {
      "StringEqualsIgnoreCase": {
        "kms:RecipientAttestation:ImageSha384":"EXAMPLE8abcdef7abcdef6abcdef5abcdef4abcdef3abcdef2abcdef1abcdef1abcdef0abcdef1abcdEXAMPLE",
        "kms:RecipientAttestation:PCR0":"EXAMPLEbc2ecbb68ed99a13d7122abfc0666b926a79d5379bc58b9445c84217f59cfdd36c08b2c79552928702EXAMPLE",
        "kms:RecipientAttestation:PCR1":"EXAMPLE050abf6b993c915505f3220e2d82b51aff830ad14cbecc2eec1bf0b4ae749d311c663f464cde9f718aEXAMPLE", 
        "kms:RecipientAttestation:PCR2":"EXAMPLEc300289e872e6ac4d19b0b5ac4a9b020c98295643ff3978610750ce6a86f7edff24e3c0a4a445f2ff8EXAMPLE"
      }
    }
  }]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;注意： 目前使用 KMS SDK 和 CLI 请求 KMS 时，还不支持添加 attestation 证明文件，所以在 Enclave 中向 KMS 发起以上三个 API 请求时，只能用过 HTTP POST 的方式构建 API 请求，将 attestation 加入到 request parameter 中。同时，KMS将自动使用证明文件中的 Public Key 对 API Response 中的明文进行加密，Enclave 收到 Response 后，需要使用 Private Key 进行解密&lt;/p&gt; 
&lt;p&gt;例如: 在 KMS Decrypt API Request 中，新增的Recipient字段将包括AttestationDocument证明文件，同时在 API Response 中，原本的Plaintext字段将替换为加密的CiphertextForRecipient字段，明文字段默认被 KMS 使用证明文件中的 Public Key 进行加密。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;# KMS Decrypt Request (New Recipient parameter)
{
   "CiphertextBlob": blob,
   "EncryptionAlgorithm": "string",
   "EncryptionContext": { 
      "string" : "string" 
   },
   "GrantTokens": [ "string" ],
   "Recipient": { 
      "AttestationDocument": blob,
      "KeyEncryptionAlgorithm": "string"
   }
}

# KMS Decrypt Response (CiphertextForRecipient returned instead of Plaintext)
{
   "CiphertextForRecipient": blob,
   "EncryptionAlgorithm": "string",
   "KeyId": "string",
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过 Nitro Enclave 与 KMS Attestation 的集成，可以确保敏感数据只能在 Enclave 中进行处理，不会被泄漏，嗅探和篡改。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;明文数据只在 Enclave 中可见，隔离的运行环境可确保数据不会嗅探&lt;/li&gt; 
 &lt;li&gt;在 Enclave 外部只能以加密后的形态对数据进行传输和存储，确保原始数据不会被泄漏&lt;/li&gt; 
 &lt;li&gt;同时借助 Enclave 的 Attestation，确保 Enclave 中的代码不会被篡改&lt;/li&gt; 
 &lt;li&gt;通过 KMS 密钥策略，确保数据只能在特定的 Enclave 内部才能被解密&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1.4 管理和开发 Nitro Enclave 应用&lt;/h3&gt; 
&lt;p&gt;如果需要开发一个运行于 Enclave 中的应用，需要先将 Enclave 运行所需的代码，依赖包等打包成 Docker 镜像格式， 然后将 Docker 镜像转换成 Enclave 镜像 (.eif)，以启动 Enclave。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Nitro Enclave 提供一个命令行工具 Nitro-CLI，用来创建，部署和管理Enclave:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-build-enclave.html"&gt;nitro-cli build-enclave&lt;/a&gt;: 将 Docker 镜像转换成 Enclave 镜像 (.eif文件)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli build-enclave --docker-uri repository:tag --docker-dir /path_to/dockerfile_directory --output-file enclave_image_filename --private-key key.pem --signing-certificate certificate.pem&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-run-enclave.html"&gt;nitro-cli run-enclave&lt;/a&gt;: 从 Enclave 镜像文件在 EC2 上启动一个 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;每台&lt;/strong&gt;&lt;strong&gt; EC2 &lt;/strong&gt;&lt;strong&gt;上只支持运行一个&lt;/strong&gt;&lt;strong&gt; enclave &lt;/strong&gt;&lt;strong&gt;环境，且&lt;/strong&gt;&lt;strong&gt; EC2 &lt;/strong&gt;&lt;strong&gt;实例至少具备&lt;/strong&gt;&lt;strong&gt; 4 &lt;/strong&gt;&lt;strong&gt;个&lt;/strong&gt;&lt;strong&gt; CPU&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli run-enclave --cpu-count number_of_vcpus --cpu-ids list_of_vcpu_ids --memory amount_of_memory_in_MiB --eif-path path_to_enclave_image_file [--enclave-cid cid_number] [--debug-mode]&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-describe-enclaves.html"&gt;nitro-cli describe-enclaves&lt;/a&gt;: 查看当前运行的 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli describe-enclaves&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-console.html"&gt;nitro-cli console&lt;/a&gt;: 以只读模式连接到一个运行的 Enclave，获取 Console 输出.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;只有以&lt;/strong&gt;&lt;strong&gt;–debug-mode&lt;/strong&gt;&lt;strong&gt;模式运行的&lt;/strong&gt;&lt;strong&gt; enclave&lt;/strong&gt;&lt;strong&gt;，才允许&lt;/strong&gt;&lt;strong&gt; console &lt;/strong&gt;&lt;strong&gt;连接&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli console --enclave-id enclave_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-terminate-enclave.html"&gt;nitro-cli terminate-enclave&lt;/a&gt;: 关闭指定的 enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli terminate-enclave --enclave-id enclave_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;另外，亚马逊云科技提供一系列工具，方便用户开发 Enclave 应用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://aws.amazon.com/marketplace/pp/B08R69DKQ1"&gt;Nitro Enclaves Developer AMI&lt;/a&gt;: 包含开发 Enclave 应用程序和构建 Enclave 镜像文件所需的工具和组件，以及示例应用&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws/aws-nitro-enclaves-sdk-c"&gt;Nitro Enclaves SDK&lt;/a&gt;: 一组可用于开发 enclave 应用程序的 c 语言开源库，与KMS 集成，并为 attestation 证明和加密操作提供内置支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;2. 搭建一个 Nitro Enclave 示例环境，结合 KMS 实现私钥安全&lt;/h2&gt; 
&lt;p&gt;下面将以一个私钥管理应用场景的示例，使用 Python 代码演示如何在 Nitro Enclave 中处理私钥数据，并结合 KMS 和 Attestation，保证私钥在加密，解密，存储和签名过程中的安全。该示例将包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;创建和部署两个 Enclave，一个实现私钥的生成和加密，另一个实现私钥的解密和签名&lt;/li&gt; 
 &lt;li&gt;Enclave 通过 vsock 与父实例通信&lt;/li&gt; 
 &lt;li&gt;Enclave 通过父实例上运行 KMS Proxy，访问 KMS 服务&lt;/li&gt; 
 &lt;li&gt;Enclave 向 Nitro Hypervisor 请求 Attestation 证明文件&lt;/li&gt; 
 &lt;li&gt;在 Enclave 中向 KMS 发送 API 请求时，带上证明文件&lt;/li&gt; 
 &lt;li&gt;KMS 服务配置密钥策略，将密钥的访问权限仅授予特定的 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;私钥管理应用场景示例架构图和工作流如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;首先创建一个 KMS Key，启动支持 Enclave 的两台 EC2 实例，分别创建和运行 Enclave，vsock 和 KMS Proxy。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;在 Enclave-1 中通过 kms:GenerateRandom API 生成一个 256 位的私钥，利用私钥生成对应的公钥(ecdsa-p256k1)&lt;/li&gt; 
 &lt;li&gt;在 Enclave-1 中通过 kms:GenerateDataKey API 获取加密密钥（包括一个明文 DataKey 和一个KMS加密的 DataKey），使用明文 DataKey 对私钥进行 Client-Side 加密&lt;/li&gt; 
 &lt;li&gt;在 Enclave-1 中，将加密的私钥，加密的 DataKey 和公钥，通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;在 EC2-1 父实例中，将从 vsock 中收到的数据（加密的私钥，加密的 DataKey 和公钥）写入到 DynamoDB 数据库&lt;/li&gt; 
 &lt;li&gt;在 EC2-2 父实例中，从 DynamoDB 中读取一条数据（私钥ID，加密的私钥，加密的 DataKey 和公钥），通过 vsock 将加密的私钥，加密的 DataKey 和需要被签名的消息，发送给 Enclave-2&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，从vsock接收数据（加密的私钥，加密的 DataKey 和需要被签名的消息），通过 kms:Decrypt API 对加密的 DataKey 进行解密，获取明文 DataKey&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，使用明文 DataKey 对加密的私钥进行解密，并使用私钥，对消息进行签名&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，将签名后的消息通过通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;在 EC2-2 父实例中，对送 vsock 接收到的签名消息，使用公钥进行验证&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2.1 基础环境部署&lt;/h3&gt; 
&lt;h4&gt;2.1.1 启动两台 EC2 实例，安装依赖包&lt;/h4&gt; 
&lt;p&gt;首先创建 EC2 及 Enclave 程序所需的 IAM Role，至少需要具备 DynamoDB 的访问权限。为了简化配置，在 demo 中直接使用了 KMS 和 DynamoDB 托管的 FullAccess 策略。但在生产环境中，不能直接使用托管策略，需要自定义用户策略，进行访问行为和资源级别的精细化授权。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 启动两台 Amazon Linux2 的 m5.xlarge EC2 实例(至少 4 vCPU 的 Nitro 实例类型), 需要手动启用 Enclave (创建 EC2 时默认不启用 enclave )&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建 EC2 实例时，在User Data 中，粘贴以下信息，完成安装 Nitro-CLI ，Docker，以及其他 Enclave 程序所需的依赖包，修改 Enclave 可占用的最大内存，下载 Enclave 示例代码等。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;#!/bin/bash
amazon-linux-extras install aws-nitro-enclaves-cli -y
yum install aws-nitro-enclaves-cli-devel -y
usermod -aG ne ec2-user
systemctl start nitro-enclaves-allocator.service &amp;amp;&amp;amp; systemctl enable nitro-enclaves-allocator.service
amazon-linux-extras install docker -y
usermod -aG docker ec2-user
systemctl start docker &amp;amp;&amp;amp; systemctl enable docker
yum install git -y
pip3 install ecdsa
pip3 install requests
pip3 install boto3
sed -i "s/memory_mib: 512/memory_mib: 3072/g" /etc/nitro_enclaves/allocator.yaml
su ec2-user -c 'cd /home/ec2-user &amp;amp;&amp;amp; git clone https://github.com/hxhwing/Nitro-Enclave-Demo.git'
shutdown -r now
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;EC2 启动完成后，修改实例名称用于标记：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一台 EC2: NitroEnclaveDemo-1，用于生成，加密私钥，存储到 DynamoDB&lt;/li&gt; 
 &lt;li&gt;第二台 EC2: NitroEnclaveDemo-2，用于解密私钥，签名和验证消息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.1.2 创建 KMS Key&lt;/h4&gt; 
&lt;p&gt;在 Amazon KMS 服务中创建一个对称密钥，用于在 Enclave 中调用 KMS API，进行私钥的生成和加解密。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步： 选择对称密钥&lt;/li&gt; 
 &lt;li&gt;第二步： 为 Key 添加别名NitroEnclaveDemo&lt;/li&gt; 
 &lt;li&gt;第三步： 选择 Key 的管理员用户（只有 Key 管理员可以删除或修改 Key 的权限）&lt;/li&gt; 
 &lt;li&gt;第四步： 密钥使用权限，不选择任何用户或角色&lt;/li&gt; 
 &lt;li&gt;第五步： 修改自动生成的 Key Policy，在 Statements 中添加以下策略，为前面步骤创建的 EC2 Role 分配 “kms:Decrypt”,”kms:GenerateDataKey”,”kms:GenerateRandom” 权限，暂不配置策略条件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;       {
           "Sid": "Allow NitroEnclave-Demo Role",
           "Effect": "Allow",
           "Principal": {
               "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"  # Replace account ID
           },
           "Action": [
               "kms:GenerateRandom",
               "kms:GenerateDataKey",
               "kms:Decrypt"
               ],
           "Resource": "*"
       },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.1.3 创建 DynamoDB Table&lt;/h4&gt; 
&lt;p&gt;创建一个 DynamoDB Table，用于存放加密后的私钥，加密的 DataKey 和公钥。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Table Name:&amp;nbsp;UserToken&lt;/li&gt; 
 &lt;li&gt;Partition key:&amp;nbsp;userid (String)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;DynamoDB Table Name &lt;/strong&gt;&lt;strong&gt;和&lt;/strong&gt;&lt;strong&gt; Partition key &lt;/strong&gt;&lt;strong&gt;请与上面完全一致，如果需要修改，请同时相应修改示例程序中&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;client.py&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;的&lt;/strong&gt;&lt;strong&gt; DynamoDB &lt;/strong&gt;&lt;strong&gt;相关代码。&lt;/strong&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2.2 创建Enclave，运行示例代码&lt;/h3&gt; 
&lt;p&gt;示例代码&amp;nbsp;Nitro-Enclave-Demo&amp;nbsp;已经被自动下载到 ec2-user 用户目录下，示例代码包含两个目录&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GenerateToken: 运行在第一台 EC2 ，用于生成和加密私钥的 Enclave&lt;/li&gt; 
 &lt;li&gt;SignVerify: 运行在第二台 EC2，用于解密私钥，签名和验证消息的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 ~]$ cd Nitro-Enclave-Demo/
[ec2-user@ip-172-31-33-19 Nitro-Enclave-Demo]$ ls -l
total 4
drwxr-xr-x 2 ec2-user ec2-user  206 Aug 28 16:12 GenerateToken
drwxr-xr-x 2 ec2-user ec2-user   87 Aug 28 16:12 pics
-rw-r--r-- 1 ec2-user ec2-user 3094 Aug 28 16:12 README.md
drwxr-xr-x 2 ec2-user ec2-user  189 Aug 28 16:12 SignVerify
drwxr-xr-x 4 ec2-user ec2-user   51 Aug 28 16:12 src
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h4&gt;2.2.1 创建和运行第一个 Enclave，生成和加密私钥&lt;/h4&gt; 
&lt;p&gt;首先登录到第一台 EC2，进入 /home/ec2-user/Nitro-Enclave-Demo/GenerateToken/ 目录，主要包括以下几个文件&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;main.py: 运行在 Enclave 中的主程序文件，包括：从 KMS 生成私钥，从 KMS 获取 DataKey，加密私钥，将加密后的数据通过vsock发给父实例&lt;/li&gt; 
 &lt;li&gt;traffic-fowarder.py: 运行在 Enclave 中，用于将 Enclave 访问 KMS 的请求通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;kms.py: 用于获取 Attestation 签名，访问 KMS API，以及解密 KMS API Response&lt;/li&gt; 
 &lt;li&gt;client.py: 运行在父实例中的程序文件，包括：从 Enclave 接收加密后的数据，将数据写入到 DynamoDB&lt;/li&gt; 
 &lt;li&gt;Dockerfile: Docker 镜像文件，&lt;a href="http://main.py/"&gt;main.py&lt;/a&gt;和&amp;nbsp;&lt;a href="http://traffic-fowarer.py/"&gt;traffic-fowarer.py&lt;/a&gt;&amp;nbsp;都将被打包进容器镜像&lt;/li&gt; 
 &lt;li&gt;build.sh: 创建 Docker 镜像，将 Docker 镜像转换为 Enclave 镜像，并运行 Enclave 的自动化脚本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;运行build.sh，创建 Enclave 镜像，并以debug-mode 运行 Enclave。其中创建 Enclave 镜像完成后，将自动生成该 Enclave 的 PCR 0/1/2，保存到 EnclaveImage.log 的文件中.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 GenerateToken]$ chmod +x build.sh
[ec2-user@ip-172-31-33-19 GenerateToken]$ ./build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;build 脚本运行完成后， Enclave 将以 debug 模式运行，用户可通过 nitro-cli 连接到运行的 Enclave 控制台，查看 Enclave 运行过程输出到Console的日志，主要用于排错&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli console --enclave-id $(nitro-cli describe-enclaves | jq -r ".[0].EnclaveID")&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p style="padding-left: 40px"&gt;2. 运行 client.py 代码，运行方式如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-python"&gt;python3 client.py &amp;lt;KMS Key-id&amp;gt; &amp;lt;UserID&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;其中 “KMS Key-id” 为前面步骤中创建的别名为 NitroEnclaveDemo 的 KMS Key， “UserID” 用于标示即将生成的私钥属于哪个用户。&lt;/p&gt; 
&lt;p&gt;运行&amp;nbsp;client.py&amp;nbsp;代码后，将自动返回从 Enclave 中接收到的数据，并将数据写入到 DynamoDB Table，数据字段包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;userid: 用于标示私钥属于哪个用户&lt;/li&gt; 
 &lt;li&gt;encrypted_privatekey: 在 Enclave 中，被 KMS DataKey 加密后的私钥&lt;/li&gt; 
 &lt;li&gt;publickey: 在 Enclave 中，由私钥生成的公钥&lt;/li&gt; 
 &lt;li&gt;encrypted_datakey: KMS 加密后的 DataKey，将用于解密私钥&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 GenerateToken]$ python3 client.py alias/NitroEnclaveDemo u001
 {"userid": "u001", "encrypted_privatekey": "4xiMsmD1VMw1I48HMApw4LzDSWT9lz/x74dMNCz1427hz98t0JzyrFzDd68vrKl0wKB1a/LoLyhi\nvJSgQwSfCA==\n", "publickey": "0a0756e60e112d11f0d5e4a88858251f1234e27ea37261da4698d497baa6a52bbe9a3d227534866351086d7220548a4ff00fb081c9b318361cac5dae9c661f8c", "encrypted_datakey": "AQIBAHhVM1N8G00xz9DVe3FbnRAxaxNCkCaRYV6/wLYxbwj04QFUWvIkLZ6TYPE2GTUdKvMbAAAAdjB0BgkqhkiG9w0BBwagZzBlAgEAMGAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMMhfwZjlaOr8pCQneAgEQgDNMimKpywvNdcpJIgPZUYrhE5uQvzonU5o/uYhPMmZmb/kWotQNH6KSFxuTBdx6FeM0vQs="} Write User Token to DynamoDB Successfully [ec2-user@ip-172-31-33-19 GenerateToken]$&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h4&gt;2.2.2 创建和运行第二个 Enclave，解密私钥，签名和验证消息&lt;/h4&gt; 
&lt;p&gt;登录到第二台 EC2，进入 /home/ec2-user/Nitro-Enclave-Demo/SignVerify 目录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;main.py: 运行在 Enclave 中的主程序文件，包括：从 KMS 解密 DataKey，用 DataKey 解密私钥，用私钥签名消息，将签名后的消息通过vsock发给父实例&lt;/li&gt; 
 &lt;li&gt;client.py: 运行在父实例中的程序文件，包括：从 DynamoDB 中读取数据，发送到 Enclave，然后从 Enclave 接收被私钥签名后的消息，并使用公钥验证签名消息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;运行build.sh，创建 Enclave 镜像，并以debug-mode 运行 Enclave。其中创建 Enclave 镜像完成后，将自动生成该 Enclave 的 PCR 0/1/2，保存到 EnclaveImage.log 的文件中.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-36-174 SignVerify]$ chmod +x build.sh
[ec2-user@ip-172-31-36-174 SignVerify]$ ./build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;运行client.py代码，运行格式如下：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;python3 client.py &amp;lt;UserID&amp;gt; &amp;lt;Message to be Signed&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其中 “UserID” 代表从 DynamoDB 中读取哪个用户的密钥数据，“Message to be Signed” 代表将被发送到 Enclave 中被私钥签名的消息。&lt;/p&gt; 
&lt;p&gt;运行&amp;nbsp;client.py&amp;nbsp;代码后，将自动返回从 Enclave 中接收到的数据，数据字段包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Signed Message: Enclave 中被私钥签名后的消息&lt;/li&gt; 
 &lt;li&gt;Signed message verified by public key: True/False，表示签名的消息是否可以被公钥验证，确保私钥和公钥没有被修改&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-36-174 SignVerify]$ python3 client.py u001 'Hellow World'
Signed Message: 6053cfc42883d03888ba175950e463c1d8164cab8b4873b85af8531a0c6f86b8ad07012107e3322d30118ea24976f8c8f70014119159101ecc1797e7a9f72915
Signed message verified by public key: True
[ec2-user@ip-172-31-36-174 SignVerify]$
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;2.3 配置 KMS 密钥策略，根据 Attestation PCR 授权&lt;/h3&gt; 
&lt;p&gt;当以&amp;nbsp;debug-mode&amp;nbsp;运行 Enclave 时，Attestation 证明文件中的 PCR 为全 0，无法用来在外部服务上作为策略条件，进行权限控制。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli run-enclave ...... --debug-mode&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;运行 nitro-cli run-enclave 时，不加–debug-mode, 是以正常模式运行 Enclave，Attestation 证明文件中才会包含 Enclave 正常的 PCR。&lt;/p&gt; 
&lt;p&gt;首先在 KMS 密钥策略，添加相应的 Condition Key 限制 Attestation PCR ，其中&amp;nbsp;kms:RecipientAttestation:ImageSha384&amp;nbsp;与 PCR 0 为相同的值，每个 Enclave 的 PCR 0/1/2，可以在 Build Enclave 镜像的时候获取，本示例是写到所在代码目录下 EnclaveImage.log 文件中。&lt;/p&gt; 
&lt;p&gt;在 KMS NitroEnclaveDemo 这个 Key 的密钥策略中，添加以下两条 Deny 权限策略语句，到 KMS Key Policy 的 Statement 字段中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一段策略，授权只有来自 Enclave-1，且携带 Attestation 证明文件才能访问 kms:GenerateDataKey API，注意请替换为您自己的 PCR 0/1/2 Value&lt;/li&gt; 
 &lt;li&gt;第二段策略，授权只有来自 Enclave-2 ，且携带 Attestation 证明文件才能访问 kms:Decrypt API，注意请替换为您自己的 PCR 0/1/2 Value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;        {
            "Sid": "Only Allow NitroEnclaveDemo-1",
            "Effect": "Deny",
            "Principal": {
                "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"
            },
            "Action": [
                "kms:GenerateRandom",
                "kms:GenerateDataKey"
            ],
            "Resource": "*",
            "Condition": {
              "StringNotEqualsIgnoreCase": {
                "kms:RecipientAttestation:ImageSha384":"17b041934b2255ae55b07433012e4d41999feda85eb839970645458a35f8571360f32ca68b5178dca8bdecf9fd37c010",
                "kms:RecipientAttestation:PCR0":"17b041934b2255ae55b07433012e4d41999feda85eb839970645458a35f8571360f32ca68b5178dca8bdecf9fd37c010",
                "kms:RecipientAttestation:PCR1":"c35e620586e91ed40ca5ce360eedf77ba673719135951e293121cb3931220b00f87b5a15e94e25c01fecd08fc9139342", 
                "kms:RecipientAttestation:PCR2":"1fc61c8c21fb3ec93ae854341f5b9adc1e7bbc2eb437cc308e5fb2f4787393fe500fa4c894422a92d79eb3ce172c1a8e"
              }
            }
        },
        {
            "Sid": "Only Allow NitroEnclaveDemo-2",
            "Effect": "Deny",
            "Principal": {
                "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"
            },
            "Action": [
                "kms:Decrypt"
            ],
            "Resource": "*",
            "Condition": {
              "StringNotEqualsIgnoreCase": {
                "kms:RecipientAttestation:ImageSha384":"810257e9bd2ecad2181fcff508c7547ef0f3c1d446628f5465c955c4f2a2d3cfac9198919999614ffbed8e0b18c6c084",
                "kms:RecipientAttestation:PCR0":"810257e9bd2ecad2181fcff508c7547ef0f3c1d446628f5465c955c4f2a2d3cfac9198919999614ffbed8e0b18c6c084",
                "kms:RecipientAttestation:PCR1":"c35e620586e91ed40ca5ce360eedf77ba673719135951e293121cb3931220b00f87b5a15e94e25c01fecd08fc9139342", 
                "kms:RecipientAttestation:PCR2":"72457ef34f66f041996e7077f55604f0f73b1d2e3fad54881308d38da6d22bc8cd2084ab3b8810b22da629a24eef94e6"
              }
            }
        },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 在 EC2 上测试直接用 CLI 访问 KMS，提示请求被拒绝，确认密钥策略权限已生效&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;
[ec2-user@ip-172-31-33-19 ~]$ aws kms generate-data-key --key-id alias/NitroEnclaveDemo --number-of-bytes 32 --region ap-northeast-1

An error occurred (AccessDeniedException) when calling the GenerateDataKey operation: User: arn:aws:sts::xxxxxxxxxx:assumed-role/NitroEnclave-Demo/i-0e4fc2c648b901c7e is not authorized to perform: kms:GenerateDataKey on resource: arn:aws:kms:ap-northeast-1:xxxxxxxxxx:key/6390f2e0-86d6-46cb-8478-37dcfa6aa2dc with an explicit deny
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;分别在两台 EC2 上执行以下命令，终止前面步骤启动的 Enclave&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli terminate-enclave --enclave-id $(nitro-cli describe-enclaves | jq -r ".[0].EnclaveID")&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;然后在两台 EC2 上重新启动 Enclave，不添加 –debug-mode 参数&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;## NitroEnclaveDemo-1
[ec2-user@ip-172-31-33-19 GenerateToken]$ nitro-cli run-enclave --cpu-count 2 --memory 2900 --enclave-cid 10 --eif-path GenerateToken-demo.eif
Start allocating memory...
Started enclave with enclave-cid: 10, memory: 3072 MiB, cpu-ids: [1, 3]
{
  "EnclaveID": "i-0e4fc2c648b901c7e-enc17b908ba803d724",
  "ProcessID": 7565,
  "EnclaveCID": 10,
  "NumberOfCPUs": 2,
  "CPUIDs": [
    1,
    3
  ],
  "MemoryMiB": 3072
}


## NitroEnclaveDemo-2
[ec2-user@ip-172-31-36-174 SignVerify]$ nitro-cli run-enclave --cpu-count 2 --memory 2900 --enclave-cid 10 --eif-path SignVerify-demo.eif
Start allocating memory...
Started enclave with enclave-cid: 10, memory: 3072 MiB, cpu-ids: [1, 3]
{
  "EnclaveID": "i-0558cbee6ea7a393c-enc17b908f0730bcb2",
  "ProcessID": 7533,
  "EnclaveCID": 10,
  "NumberOfCPUs": 2,
  "CPUIDs": [
    1,
    3
  ],
  "MemoryMiB": 3072
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;然后分别在两台 EC2 的父实例上，运行client.py，确认代码能正常运行。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;## NitroEnclaveDemo-1
[ec2-user@ip-172-31-33-19 GenerateToken]$ python3 client.py alias/NitroEnclaveDemo u010
{"userid": "u010", "encrypted_privatekey": "h08szIyVaTrjH1TF95+aXooPKC/QZwGRDaZv7Cp/LmFG2FQumbZR49NrnsOYBsS+VxsvPtSlBE2s\nnEYQLMI9lQ==\n", "publickey": "9552c9f2c51be3b7143e3cfe9c71f7dcac028d368530ffbbdb34512092611e4996e9e1bcab27e4a879ff630629d7f930d2db84c295e97334d1f3335d31e7ac87", "encrypted_datakey": "AQIBAHhVM1N8G00xz9DVe3FbnRAxaxNCkCaRYV6/wLYxbwj04QFKhpZ//ap2EgINgILddtu0AAAAdjB0BgkqhkiG9w0BBwagZzBlAgEAMGAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMScLI1DYM6y6hd0d4AgEQgDO2pbbcrEEd+trVcqiqkFdlhXY/ZVEMoRqRsQAUMdJq24zwGgl6UYOjLCviBHs2wI8jC5A="}
Write User Token to DynamoDB Successfully
[ec2-user@ip-172-31-33-19 GenerateToken]$

## NitroEnclaveDemo-2
[ec2-user@ip-172-31-36-174 SignVerify]$ python3 client.py u010 'Hello World'
Signed Message: b27a5c527e218774b316f674eae537ce88b3f986b7f5df583906b1c9a9ba9bb00d2975fe4a065d5a1e74bb6947fe11c8fc90d3ac389be638b2745431de04ebd9
Signed message verified by public key: True
[ec2-user@ip-172-31-36-174 SignVerify]$
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在 CloudTrail 中，查看 KMS API 的请求记录，在来自 Enclave 的请求记录中，将会存在额外的 Attestation 数据。&lt;/p&gt; 
&lt;p&gt;来自第一台 Enclave 请求 kms:GenerateDataKey 的 CloudTrail：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 来自第二台 Enclave 请求 kms:Decrypt 的 CloudTrail：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;Nitro Enclave 使用户可以在 亚马逊云科技上，简便，安全地运行隔离的可信计算环境，用于处理私钥，PII等敏感数据。另外 Nitro Enclave 不需要强制绑定 CPU 芯片，支持 Intel，AMD 芯片的计算实例，没有任何额外费用，具备更好的灵活性和成本效益，且与云原生的安全服务 KMS，ACM 直接集成，为用户提供更好的使用体验和安全性保障。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/hxh.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;胡新华&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责金融行业基于AWS的云计算架构咨询和设计。加入AWS之前就职于IBM，在数据中心IT基础架构相关的解决方案设计和交付方面，具有十多年经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>增强Amazon Athena对历史查询记录的统计分析功能</title>
		<link>https://aws.amazon.com/cn/blogs/china/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records/</link>
				<pubDate>Thu, 02 Sep 2021 03:11:56 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Athena]]></category>

		<guid isPermaLink="false">5d41f51e363379c2c35c97dc1c407cec8f874090</guid>
				<description>Amazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 分析 Amazon S3 中的数据。Athena 采用无服务器架构，因此您无需管理任何基础设施，且只需为您运行的查询付费。Athena 简单易用，只需指向您存储在 Amazon S3 中的数据，定义架构并使用标准 SQL 开始查询。</description>
								<content:encoded>&lt;h2&gt;背景介绍&lt;/h2&gt; 
&lt;p&gt;Amazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 分析 Amazon S3 中的数据。Athena 采用无服务器架构，因此您无需管理任何基础设施，且只需为您运行的查询付费。Athena 简单易用，只需指向您存储在 Amazon S3 中的数据，定义架构并使用标准 SQL 开始查询。就可在数秒内获取最多的结果。您可以使用Athena 控制台查看成功和失败的查询、下载成功查询结果文件以及查看失败查询的错误详细信息。Athena 将查询历史记录保留 45 天。如果要将查询历史记录保留超过 45 天，您可以检索查询历史记录并将其保存到等 Amazon S3 等数据存储中。本方案自动执行此过程，使用 Athena 和 Amazon S3 API将数据导入到Amazon S3，并使用Athena分析历史数据，结合Amazon CloudTrail的Athena API调用日志可以对Athena的历史SQL执行记录进行多个维度的分析，以便用于评估Athena的使用和优化线上SQL等。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;部署架构&lt;/h2&gt; 
&lt;p&gt;利用CloudWatch Event定时触发Lambda代码同步Athena历史查询日志到Amazon S3，利用DynamoDB记录每次增量同步的记录位置，Amazon CloudTrail记录Athena API call日志，创建CloudTrail的跟踪，将日志持续导入到S3中，最终通过Athena多维分析历史查询日志和CloudTrail日志并利用Amazon QuickSight进行图表展现。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;方案部署步骤&lt;/h2&gt; 
&lt;h3&gt;导出Athena查询历史记录日志到Amazon S3&lt;/h3&gt; 
&lt;p&gt;因为Athena历史查询记录日志只保留45天，我们通过一段Python代码将Athena历史查询记录日志持续的，增量的导入到Amazon S3中，利用DynamoDB记录每次导出的最近位置，下次导出的时候，从上次导出的最新位置开始增量导出，避免产生重复数据，我们也可以将这段代码部署在在Lambda上，通过CloudWatch Event定时触发同步日志到Amazon S3。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;创建&lt;/strong&gt;&lt;strong&gt;DynamoDB表，保存每次增量导入的最新位置&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;表名称：athena_his_sql&lt;/p&gt; 
&lt;p&gt;主分区键：workgroup&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;创建&lt;/strong&gt;&lt;strong&gt;Lambda函数athena_his_fun&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;将下面的脚本复制到Lambda的入口脚本lambda_function.py（Lambda函数执行的角色需要具备操作Amazon S3读写，DynamoDB读写的权限）并修改Lambda的内存（500M）和超时时间（10min）。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import boto3
import time
import io
import json
import uuid
from datetime import datetime, date
def lambda_handler(event, context):
    # TODO implement
    to_scrape=5000
    page_size=50
    bucket = "quandata1"
    prefix = "athena_his/"
    s3_client = boto3.client('s3')
    ath = boto3.client('athena')
    paginator = ath.get_paginator("list_query_executions")
    dynamodb = boto3.resource('dynamodb')
    def json_serial(obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        raise TypeError("Type %s not serializable" % type(obj))
    df = []
    break_flag = False
    for workgroup in [w['Name'] for w in ath.list_work_groups()['WorkGroups']]:
        print(f'running {workgroup}')
        i=0
        table = dynamodb.Table('athena_his_sql')
        response = table.get_item(Key={'workgroup': workgroup,})
        curr_query_id = ''
        if  ("Item" in response): curr_query_id = response['Item']['curr_query_id']
        print("get ddb curr_id: " + workgroup + curr_query_id)
        args = {"WorkGroup": workgroup, "PaginationConfig": {"MaxItems": to_scrape, "PageSize": page_size}}
        for page in paginator.paginate(**args):
            query_ids = page['QueryExecutionIds']
            for query_id in query_ids:
                print("query_id:" + query_id)
                if i == 0:
                    table.update_item(
                        Key={'workgroup': workgroup,},
                        UpdateExpression='SET curr_query_id = :val1',
                        ExpressionAttributeValues={':val1': query_id})
                    print("update ddb curr_id: " + query_id)
                if query_id == curr_query_id:
                    break_flag=True
                    break
                query_metadata = ath.get_query_execution(QueryExecutionId=query_id)['QueryExecution']
                df.append(query_metadata)
                i += 1
            if break_flag==True:
                break
            time.sleep(1)
    json_writer = io.BytesIO()
    for record in df:
        line = json.dumps(record, default=json_serial) + "\n"
        json_writer.write(line.encode())
    s3_client.put_object(
        Bucket=bucket,
        Key=prefix + "%s.json" % uuid.uuid4(),
        ContentType='text/json',
        Body=json_writer.getvalue()
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;部署完毕后设置利用CloudWatch Event定时触发执行（例如按小时触发）&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 脚本执行后，会在DynamoDB的表athena_his_sql中更新当前最新的查询ID，方便后续增量导出。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 利用Amazon CLI或者控制台检查Amazon S3路径下是否正确上传了日志文件，（注：本方案没有对上传到S3的数据进行分区存放，可以参考下文CloudTrail日志的方式利用Athena的分区投影功能实现自动分区管理）。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;创建Athena历史记录日志表&lt;/h3&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE EXTERNAL TABLE athena_queries (
    QueryExecutionId string,
    Query string,
    StatementType string,
    Status struct&amp;lt;State:string,SubmissionDateTime:string,CompletionDateTime:string&amp;gt;,
    Statistics struct&amp;lt;EngineExecutionTimeInMillis:int,DataScannedInBytes:int, TotalExecutionTimeInMillis:int, QueryQueueTimeInMillis:int, QueryPlanningTimeInMillis:int, ServiceProcessingTimeInMillis:int&amp;gt;,
    WorkGroup string
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
LOCATION 's3://quandata1/athena_his';
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;创建CloudTrail日志表&lt;/h3&gt; 
&lt;p&gt;开启CloudTrail跟踪，将CloudTrail日志通过跟踪功能持续保存到S3中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建CloudTrail日志表cloudtrail_logs，建表语句中LOCATION根据实际跟踪配置的S3路径填写。使用Athena分区投影功能自动进行分区管理，降低查询时间和数据扫描量。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE EXTERNAL TABLE cloudtrail_logs(
    eventVersion STRING,
    userIdentity STRUCT&amp;lt;
        type: STRING,
        principalId: STRING,
        arn: STRING,
        accountId: STRING,
        invokedBy: STRING,
        accessKeyId: STRING,
        userName: STRING,
        sessionContext: STRUCT&amp;lt;
            attributes: STRUCT&amp;lt;
                mfaAuthenticated: STRING,
                creationDate: STRING&amp;gt;,
            sessionIssuer: STRUCT&amp;lt;
                type: STRING,
                principalId: STRING,
                arn: STRING,
                accountId: STRING,
                userName: STRING&amp;gt;&amp;gt;&amp;gt;,
    eventTime STRING,
    eventSource STRING,
    eventName STRING,
    awsRegion STRING,
    sourceIpAddress STRING,
    userAgent STRING,
    errorCode STRING,
    errorMessage STRING,
    requestParameters STRING,
    responseElements STRING,
    additionalEventData STRING,
    requestId STRING,
    eventId STRING,
    readOnly STRING,
    resources ARRAY&amp;lt;STRUCT&amp;lt;
        arn: STRING,
        accountId: STRING,
        type: STRING&amp;gt;&amp;gt;,
    eventType STRING,
    apiVersion STRING,
    recipientAccountId STRING,
    serviceEventDetails STRING,
    sharedEventID STRING,
    vpcEndpointId STRING
  )
PARTITIONED BY (
   `timestamp` string)
ROW FORMAT SERDE 'com.amazon.emr.hive.serde.CloudTrailSerde'
STORED AS INPUTFORMAT 'com.amazon.emr.cloudtrail.CloudTrailInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  's3://bucket/AWSLogs/account-id/CloudTrail/aws-region'
TBLPROPERTIES (
  'projection.enabled'='true', 
  'projection.timestamp.format'='yyyy/MM/dd', 
  'projection.timestamp.interval'='1', 
  'projection.timestamp.interval.unit'='DAYS', 
  'projection.timestamp.range'='2021/01/01,NOW', 
  'projection.timestamp.type'='date', 
  'storage.location.template'='s3://bucket/AWSLogs/account-id/CloudTrail/aws-region/${timestamp}')
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;使用Athena对数据进行分析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;查看不同&lt;/strong&gt;&lt;strong&gt;SQL语句的执行总次数排名&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select count(*),query from athena_queries group by query order by 1 desc limit 10&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看执行状态失败的&lt;/strong&gt;&lt;strong&gt;SQL总数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select count(*) from athena_queries where status.state='FAILED'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看执行超过特定执行时长的历史&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select query from athena_queries where statistics.totalexecutiontimeinmillis &amp;gt;=5000&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看超过特定数据扫描量的历史&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select query from athena_queries where statistics.datascannedinbytes &amp;gt;=10741612544&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;根据&lt;/strong&gt;&lt;strong&gt;IAM用户统计数据扫描量&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;select sum(b.statistics.datascannedinbytes),
a.userIdentity.username 
from 
cloudtrail_logs a,
athena_queries b 
where 
a.eventsource='athena.amazonaws.com' and a.eventName='StartQueryExecution' and 
a.responseElements != 'null' and substr(a.responseElements,22,36) = b.queryexecutionid 
group by 
a.userIdentity.username
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;使用Amazon Quicksight可视化分析结果&lt;/h2&gt; 
&lt;p&gt;利用SQL的方式（将cloudtrail_logs和athena_queries两张表联表查询）创建QuickSight中Athena数据集，然后根据实际需要在Amazon QuickSight创建可视化图表。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.queryexecutionid,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.query,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statementtype,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.State,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.SubmissionDateTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.CompletionDateTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.EngineExecutionTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.DataScannedInBytes,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.TotalExecutionTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.QueryQueueTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.QueryPlanningTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.ServiceProcessingTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.workgroup,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.userIdentity.username&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;from&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;cloudtrail_logs a,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;athena_queries b&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;where&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.eventsource='athena.amazonaws.com' and a.eventName='StartQueryExecution' and&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.responseElements != 'null' and substr(a.responseElements,22,36) = b.queryexecutionid&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;创建可视化图表如下&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;通过本文介绍的方案可以更长时间的保留Athena查询历史日志，通过对Athena历史查询日志的分析，让我们可以直观的了解和掌握Athena的使用细节，查看Top SQL，检测应用性能问题，在时间、用户、SQL语句等多个维度增强对Athena使用的洞察。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/querying.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/querying.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/monitor-with-cloudtrail.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/monitor-with-cloudtrail.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html"&gt;https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xiangqua.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;柳向全&lt;/h3&gt; 
  &lt;p&gt;AWS 解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，目前主要专注于容器和大数据技术领域研究和AWS云服务在国内和全球的应用和推广。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>云原生编排数据分析管道初探</title>
		<link>https://aws.amazon.com/cn/blogs/china/preliminary-study-on-cloud-native-data-analysis-pipeline-orchestration/</link>
				<pubDate>Tue, 31 Aug 2021 09:38:55 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[AWS Glue]]></category>
		<category><![CDATA[AWS Step Functions]]></category>

		<guid isPermaLink="false">0b70c5edda6b82f38e382a0cee30e9d3989f70d1</guid>
				<description>公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL) 过程进行任务编排。要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施。二是编排好数据管道的 ETL 任务顺序。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。</description>
								<content:encoded>&lt;h2&gt;摘要&lt;/h2&gt; 
&lt;p&gt;公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL) 过程进行任务编排。亚马逊云科技（亚马逊）的 Step Functions 状态机和开源社区的 Airflow 是其中的典型代表。要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施，例如部署好 Airflow 的调度器和执行器等。二是编排好数据管道的 ETL 任务顺序，例如状态机的 JSON 定义文件或者 Airflow 的有向无环图定义。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。&lt;/p&gt; 
&lt;h2&gt;Abstract&lt;/h2&gt; 
&lt;p&gt;Public cloud is one of the most suitable platforms for data analysis and big data processing. In recent years, many excellent workflow orchestration tools have proliferated in cloud services and open source communities to facilitate orchestration of complex ETL jobs in data analysis. AWS Step Functions and Airflow from open source community are two typical examples. To run the data analysis pipelines successfully, at least two steps are necessary. Firstly, to build the infrastructure to support running the data pipelines, such as the deployment of Airflow’s schedulers and executors. Secondly, to orchestrate the ETL tasks in the data pipelines, such as the JSON definition of the state machine or Airflow’s directed acyclic graph definition. The former involves dev-ops, while the latter is related to application. From the perspective of data analysis, it is ideal that the difficulty of dev-ops is minimized, and the user-friendliness of application is maximized. This article analyzes how well Airflow and Step Functions support data analysis pipelines from the above two points of view, and preliminarily discusses the methodology and significance of cloud-native services for orchestrating data pipelines.&lt;/p&gt; 
&lt;h3&gt;目标读者&lt;/h3&gt; 
&lt;p&gt;本文预期读者需要掌握以下技术的基础知识：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache Airflow 及其相关概念&lt;/li&gt; 
 &lt;li&gt;亚马逊开发包：CDK, SDK&lt;/li&gt; 
 &lt;li&gt;亚马逊服务：CloudTrail, EventBridge, Glue, Lambda, MWAA, Redshift, S3, Step Functions, VPC, 密码管理器&lt;/li&gt; 
 &lt;li&gt;语言：Javascript, JSON, Python&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;开放源代码&lt;/h3&gt; 
&lt;p&gt;本文所述解决方案源代码开放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline"&gt;https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;绪论&lt;/h2&gt; 
&lt;p&gt;2020年11月，亚马逊发布了托管的 Airflow 服务，全称为 Managed Workflows for Apache Airflow (MWAA)，支持 1.10.12 版。2021年5月开始支持 2.0.2 版。但截至目前（2021年8月），中国北京区、宁夏区和香港区皆未提供托管服务。如果要使用 Airflow，则需要自行搭建部署，例如利用 Elastic Container Service。或者换成其他云原生的编排服务，例如 Step Functions 状态机或 Simple Workflow Service。本文以某 MWAA 的数据分析指导教程为引子，介绍 MWAA 资源代码化的方法，并对如何在中国区使用云原生服务达到类似编排数据分析管道的目的，进行初探。&lt;/p&gt; 
&lt;h2&gt;教程简介&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;是指导利用 MWAA 搭建数据分析管道的教程。该分析管道较简单，线性分为五步，分别是监控文件，爬元数据，转换数据，整合数据，保存结果。简单起见，本文将第四步改造为 Glue 任务，不使用 Elastic MapReduce 集群。部署好的数据管道有向无环图如下：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.png" width="624"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以 MWAA 为基础的架构图如下所示。虚线和编号表示该数据管道运行时的数据流向和任务执行顺序。此处不同服务的调用是通过 Airflow 的操作符间接完成的，以 Python 定义在数据管道的有向无环图中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.png" width="500"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;根据该教程介绍，完成时间为一小时左右。抛开初学者的因素，所用时间较长主要是因为所涉及的资源及其配置都是在亚马逊控制台上手工完成，非常耗时，效率低下。如果利用资源代码化技术，则部署时间可以在数分钟内完成（排除 MWAA 自身启动需要的约半小时），提高工作效率，尤其在需要多环境部署测试的情况下。&lt;/p&gt; 
&lt;h3&gt;资源代码化&lt;/h3&gt; 
&lt;p&gt;利用亚马逊云开发包 (Cloud Development Kit)，可快速构建云资源部署程序。结合相关代码仓库管理工具如 github，可代码化管理资源的创建和修改过程，方便协同工作和排错溯源。限于篇幅以下仅展示关键代码。完整代码请参阅开放源代码。首先建立 Redshift 集群。云开发包建立好集群后，会自动在密码管理器中新建一密码项，即为该集群的连接密码，全程密码无暴露。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCluster(landingZone, subnetGroup) {
    return new redshift.Cluster(this, "MainCluster", {
        masterUser: { masterUsername: "admin" },
        vpc: landingZone.vpc,
        numberOfNodes: 2,
        publiclyAccessible: false,
        defaultDatabaseName: RedshiftStack.DB_NAME,
        securityGroups: [landingZone.securityGroup],
        nodeType: redshift.NodeType.DC2_LARGE,
        roles: [this.role],
        subnetGroup: subnetGroup
    })
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其次是建立 MWAA 环境。简化起见配置为可以公网访问。实际生产中建议配置为私网访问。MWAA 对网络配置有特别要求，若不达标环境可能无法启动。子网建议配置为私有子网，即有路由到 NAT 网关。具体请参阅使用手册。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createEnvironment(envName, role, landingZone, bucket) {
    return new airflow.CfnEnvironment(this, "Lab", {
        name: envName,
        airflowVersion: "2.0.2",
        environmentClass: "mw1.small",
        executionRoleArn: role.roleArn,
        sourceBucketArn: bucket.bucketArn,
        webserverAccessMode: "PUBLIC_ONLY",
        dagS3Path:           "airflow/lab/dags",
        pluginsS3Path:       "airflow/lab/plugins/awsairflowlib_202.zip",
        requirementsS3Path:  "airflow/lab/requirements/requirements.txt",
        networkConfiguration: {
            securityGroupIds: [landingZone.securityGroup.securityGroupId],
            subnetIds: landingZone.vpc.privateSubnets.map(subnet =&amp;gt; subnet.subnetId)
        }
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;MWAA 配置好以后，还需要把有向无环图定义文件上传到存储桶指定位置。利用云开发包的 S3 部署模块完成：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;uploadDagFile(bucket) {
    new deploy.BucketDeployment(this, "DagScript",
        sources: [deploy.Source.asset(path.join(__dirname, '../../scripts/airflow/lab/dags/'))],
        destinationBucket: bucket,
        destinationKeyPrefix: 'airflow/lab/dags/'
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;至此就完成了 MWAA 相关资源的部署程序。部署上述 MWAA 大约耗时半小时，因为涉及服务器的启动连接等。部署耗时长也凸显出非无服务器服务的弊端。当环境状态变为“可用”后，点击“打开 Airflow UI”即可打开 Airflow 的控制台。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.png" width="800"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;部署完成后，根据教程即可完成数据分析管道相关操作。Airflow 控制台可以显示数据管道完成时间甘特图，形象展示各任务耗时多寡。这是其亮点之一。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.png" width="800"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;安全隐患&lt;/h3&gt; 
&lt;p&gt;最后一步把存储桶文件复制到 Redshift，需要在 Airflow 控制台配置到 Redshift 的连接。连接属性包含用户名和密码明文。此处有暴露密码明文的安全隐患。下面介绍的云原生技术通过密码管理器实现无缝连接，可有效规避密码暴露风险，切实提高系统安全水平。&lt;/p&gt; 
&lt;h2&gt;云原生编排&lt;/h2&gt; 
&lt;p&gt;目前 MWAA 尚不支持中国区，故需要自行搭建并维护 Airflow 环境，例如在 ECS Fargate 上。但是运维难度不容小觑。亚马逊提供了其他编排服务，例如状态机，完全可以代替 Airflow 对数据管道进行编排。此外状态机是无服务器的，毋需关心并事先设定服务器数量性能等运维难题。使用云原生服务，和其他服务紧密集成，可最大化服务效益，增强安全性。和教程数据分析管道等价的状态机工作流如下所示。状态机跨服务集成支持直接启动 Glue 任务，较为简单。其他步骤需做些许变通。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.png" width="400"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以云原生服务为基础的架构图如下所示。状态机在各服务之间调度，其中 Glue 任务可以直接执行。爬虫任务需要通过 Lambda 函数辅助。把存储桶的数据载入到 Redshift 可以有多种方法完成，例如 Glue 任务可以直接连接 Redshift 并保存数据。为了和教程中的步骤一一对应，此处利用 Lambda 函数来辅助完成。存储桶文件监控则通过跟踪与规则联合完成。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.png" width="500"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;爬元数据&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成目前暂不支持调用 Glue 爬虫，需替代方案。此处利用两个 Lambda 函数和轮询机制实现相同功能。启动爬虫很简单：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;await glue.startCrawler({Name: crawlerName}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫状态查询，如果不是“就绪”状态，则等待十秒后再次查询，直至成功或者超时。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;exports.handler = async event =&amp;gt; {
    response = await glue.getCrawler({Name: event.crawlerName}).promise();
    const state = response.Crawler.State;
    return state == "READY";
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫调用代替方案的其他两步可以利用状态机的“选择”和“等待”原生操作符完成。这里传入变量 next 作为爬虫轮询结束后的下一步操作。以下代码可作为爬虫调用的模版使用。若想提高响应速度可缩短等待时长。一个典型的爬虫任务需时数分钟。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCrawlerStep(next) {
    const crawlTask = new task.LambdaInvoke(this, "Crawl", {
        lambdaFunction: this.lambda("CrawlLambda", role, "../lambda/crawler/crawl"),
        payload: sf.TaskInput.fromObject({CrawlerTagName: "NF1-Airflow-Lab-RawGreenCrawler"}),
        payloadResponseOnly: true,
        resultPath: "$.crawlerName",
    });
    const checkCrawled = new task.LambdaInvoke(this, "Check if crawled", {
        lambdaFunction: this.lambda("CheckCrawledLambda", role, "../../lambda/crawler/check"),
        payloadResponseOnly: true,
        resultPath: "$.crawled",
    });
    const wait = 10;
    crawlTask.next(checkCrawled)
    .next(new sf.Choice(this, "Is crawled?")
        .when(sf.Condition.booleanEquals("$.crawled", true), next)
        .otherwise(new sf.Wait(this, `Wait for ${wait} Seconds`, {
            time: sf.WaitTime.duration(core.Duration.seconds(wait)),
        }).next(checkCrawled)));
    return crawlTask;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;保存结果&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成尚未对 Redshift 提供支持，对保存结果需要替代方案。Airflow 提供 S3ToRedshiftOperator 操作符将数据从存储桶复制到 Redshift 表中。本质上是通过 Redshift 的 COPY 命令实现的。替代方案亦遵循此思路。利用亚马逊软件开发包的 RedshiftData 模块，可以执行 SQL 语言和数据操作命令。此处通过密码 ARN 获取密码，完全规避密码明文暴露的问题。此外 Glue 也提供应用接口支持直接把数据保存到 Redshift。在保存数据到数据仓库之前可多做一步，将目标表做清空操作（truncate 或 delete），避免因原表中有数据导致冗余。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;await data.executeStatement({
    ClusterIdentifier: event.ClusterIdentifier,
    Database: event.Database,
    SecretArn: event.SecretArn,
    Sql: event.Sql
}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;状态机保存结果的替代方案可以一个 Lambda 函数实现。在生产环境，此处建议以更细粒度和最小化原则配置该函数所赋予的权限，夯实系统安全性。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCopyS3ToRedshift(bucket, redshift) {
    const dir = bucket.s3UrlForObject("airflow/lab/data/aggregated");
    const sql = `copy nyc.green from '${dir}' iam_role '${redshift.role.roleArn}' format as parquet;`;

    return new task.LambdaInvoke(this, "Copy S3 to Redshift", {
        lambdaFunction: this.lambda("CopyToRedshiftLambda", role, "../lambda/redshift/execute"),
        payloadResponseOnly: true,
        payload: sf.TaskInput.fromObject({
            ClusterIdentifier: redshift.cluster.clusterName,
            Database: RedshiftStack.DB_NAME,
            SecretArn: redshift.cluster.secret.secretArn,
            Sql: sql,
        })
    });
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;监控文件&lt;/h3&gt; 
&lt;p&gt;最后还需要处理对存储桶文件的监控任务。Airflow 提供 S3PrefixSensor 来监控文件上传到某个桶，进而触发数据管道进行数据处理。此处有多种方式监控存储桶里面的文件。例如 S3 自带的事件通知功能。不过事件通知的目标不支持启动状态机，还需要 Lambda 辅助。或者可以通过 CloudTrail 跟踪桶写入操作，然后通过 EventBridge 的个规则来捕获事件进而触发状态机执行。跟踪只需要关注特定桶特定目录的写入即可。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createTrail(logBucket, monitorBucket) {
    const trail = new cloudtrail.Trail(this, 'CloudTrail', {
        bucket: logBucket,
        s3KeyPrefix: "data-trail",
    });
    trail.addS3EventSelector(
        [{bucket: monitorBucket, objectPrefix: "airflow/lab/data/raw"}],
        {readWriteType: cloudtrail.ReadWriteType.WRITE_ONLY});
    return trail;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;捕获规则和跟踪一样，只需要捕获特定桶特定目录的写入即可，此处利用 prefix 前缀操作符来限定。规则目标可以直接启动状态机，开启数据分析管道进程。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createS3Event(machine, bucket) {
    new events.Rule(this, "S3StepFunctions", {
        description: "S3 invoke StepFunctions",
        eventPattern: {
            source: [ "aws.s3" ],
            detailType: [ "AWS API Call via CloudTrail" ],
            detail: {
                "eventSource": [ "s3.amazonaws.com" ],
                "eventName": [ "PutObject" ],
                "requestParameters": {
                    "bucketName": [ bucket.bucketName ],
                    "key": [{ "prefix": "airflow/lab/data/raw" }]
                }}},
        targets: [ new targets.SfnStateMachine(machine) ]
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;方案对比&lt;/h2&gt; 
&lt;p&gt;至此云原生编排数据分析管道的改造宣告完成。回顾本文，重新审视和对比各项方案的利弊得失，可以更好的帮助读者选择更适合业务场景的方案。例如，如果在中国区新建数据分析管道项目，则建议使用状态机。如果从 Airflow 的老环境迁移上云，则建议使用 MWAA 或者自建 Airflow，这样可以复用积累的代码。亦可两者并行，对新的数据管道用云原生方案。&lt;/p&gt; 
&lt;table style="border-collapse: collapse;border: 3px solid grey" border="1"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;状态机&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MWAA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;自建 Airflow&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;编写语言&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;JSON 及云开发包支持的所有语言&lt;br&gt; (TypeScript, JavaScript, Python, Java, and C#)&lt;/td&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;支持中国区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;无服务器&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;托管服务&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;连接密码暴露&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;开源社区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;部署时间（近似值）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;开箱即用&lt;/td&gt; 
   &lt;td&gt;一小时&lt;/td&gt; 
   &lt;td&gt;数小时到数天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Airflow &lt;/strong&gt;&lt;strong&gt;最新版本&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;（2021&lt;/strong&gt;&lt;strong&gt;年8&lt;/strong&gt;&lt;strong&gt;月）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;不适用&lt;/td&gt; 
   &lt;td&gt;2.0.2&lt;/td&gt; 
   &lt;td&gt;2.1.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;服务调度集成&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;云原生&lt;/td&gt; 
   &lt;td&gt;通过操作符&lt;/td&gt; 
   &lt;td&gt;通过操作符&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;本文从 MWAA 的数据分析管道指导教程为引子，介绍利用云开发包快速搭建部署程序的方法，并以状态机为编排平台，尝试改造其为云原生编排的数据管道，辅以几个关键操作的替代方案介绍。本文初步探讨云原生编排数据分析管道的方法，借此抛砖引玉，供读者讨论。从“方案对比”一节可以看出，云原生的编排方案有诸多优势，尤其表现在零部署时间，无服务器化管理，多语言支持和增强安全性上。相信随着跨服务集成的深度和广度越来越高，云原生的编排优势会如虎添翼，成为数据分析管道编排平台的不二选择。&lt;/p&gt; 
&lt;h3&gt;工作展望&lt;/h3&gt; 
&lt;p&gt;有几个有趣的展开方向。首先就 Airflow 的诸多操作符，研究云原生改造方法，以期对所有 Airflow 有向无环图皆可支持改造，利于迁移。能自动化改造更佳。其次研究将 Airflow 的数据分析管道以 Glue 的蓝图和工作流为基础进行改造。Glue 蓝图的编排平台和状态机的编排平台是一对有趣的对比。再者就自建 Airflow 的方案如何高效搭建基础设施并降低运维难度亦值得关注。&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/clementy.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;袁文俊&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务部顾问。曾在亚马逊美国西雅图总部工作多年，就职于 Amazon Relational Database Service (RDS) 关系型数据库服务开发团队。拥有丰富的后端开发及运维经验。现负责业务持续性及可扩展性运行、企业应用及数据库上云迁移、云上灾难恢复管理系统等架构咨询、方案设计及项目实施工作。他拥有复旦大学理学学士学位和香港大学哲学硕士学位。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xzhom.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;赵鑫&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务团队数据架构师，专注于生命科学、自动驾驶领域的数据架构与数据分析&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
	</channel>
</rss>