<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>亚马逊AWS官方博客</title>
	<atom:link href="https://aws.amazon.com/cn/blogs/china/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/cn/blogs/china/</link>
	<description>Just another AWS Brew Blogs  site</description>
	<lastBuildDate>Wed, 08 Sep 2021 04:54:01 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>一文看懂 Amazon EKS 中的网络规划</title>
		<link>https://aws.amazon.com/cn/blogs/china/understand-the-network-planning-in-amazon-eks-in-one-article/</link>
				<pubDate>Wed, 08 Sep 2021 04:54:01 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Containers]]></category>
		<category><![CDATA[eks]]></category>
		<category><![CDATA[vpc]]></category>

		<guid isPermaLink="false">2afe2bed89eb3683fe48c4483dd3c2c946b9fb1b</guid>
				<description>在我们的某些业务场景中，我们需要对整个 K8S 的集群网络配置进行一定的定制化，比如我们在多个区域进行 K8S 集群的部署，并且已经规划好每个区域所使用的 IP 地址网段，比如 Node 节点网段，Service 服务网段，Pod 容器网段，那么在创建和管理 K8S 集群的时候，我们就需要对这些网段进行定制化的配置。另外，如果我们随着云上的负载越来越多，可能会遇到前期规划的 VPC 网络地址池太小的问题，我们也可以使用自定义 Pod 网段的方法来扩展 Pod 能使用的网络地址池。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://www.amazonaws.cn/eks"&gt;Amazon Elastic Kubernetes Service&lt;/a&gt; (EKS)是一项云上的托管 Kubernetes (K8S) 服务，使用该服务您可以轻松地在亚马逊云上部署、管理和扩展容器化的应用程序。Amazon EKS 会在一个亚马逊区域中的不同可用区内托管 Kubernetes 的管理节点，并提供一定的 SLA 保证，从而消除单点故障和管理节点的运维管理工作。用户只需要管理自己的工作节点，以及底层的 &lt;a href="https://www.amazonaws.cn/ec2/?nc2=h_ql_prod_cp_ec2"&gt;EC2 实例&lt;/a&gt;或者是无服务器化的 &lt;a href="https://www.amazonaws.cn/fargate/?nc2=h_ql_prod_ct_far"&gt;Fargate&lt;/a&gt; 即可。&lt;/p&gt; 
&lt;p&gt;在我们的某些业务场景中，我们需要对整个 K8S 的集群网络配置进行一定的定制化，比如我们在多个区域进行 K8S 集群的部署，并且已经规划好每个区域所使用的 IP 地址网段，比如 Node 节点网段，Service 服务网段，Pod 容器网段，那么在创建和管理 K8S 集群的时候，我们就需要对这些网段进行定制化的配置。&lt;/p&gt; 
&lt;p&gt;另外，如果我们随着云上的负载越来越多，可能会遇到前期规划的 VPC 网络地址池太小的问题，我们也可以使用自定义 Pod 网段的方法来扩展 Pod 能使用的网络地址池。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文包含的主要内容有：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如何自定义 Node 节点网段和 Service 服务网段&lt;/li&gt; 
 &lt;li&gt;如何自定义 Pod 容器网段&lt;/li&gt; 
 &lt;li&gt;一个 Node 节点如何创建无数量限制的 Pod&lt;/li&gt; 
 &lt;li&gt;每一个 Pod 绑定单独的公网地址&lt;/li&gt; 
 &lt;li&gt;一个 Pod 如何绑定多张网卡&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;子网设计&lt;/h2&gt; 
&lt;p&gt;我们先在美东1区按照下面的网络规划创建环境。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;VPC 网络：&lt;/strong&gt;16.0.0/16&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pod&lt;/strong&gt; &lt;strong&gt;网段&lt;/strong&gt;：172.16.10.0/24 和 172.16.11.0/24&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Node 网段&lt;/strong&gt;：172.16.1.0/24 和 172.16.2.0/24&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;公有网段&lt;/strong&gt;：172.16.100.0/24和172.16.101.0/24&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;服务网段&lt;/strong&gt;：172.17.0.0/24，这是一个虚拟的网段，不需要在VPC子网里面&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;最佳实践：&lt;/strong&gt;所有的网段最好在至少两个可用区内进行构造，这样方便后期做任何高可用的设置。以及万一一个可用区挂了，不影响另外一个可用区的工作负载，也不影响整个 EKS 集群（EKS 集群的管理节点默认是跨域3个可用区的）。&lt;/p&gt; 
&lt;p&gt;我们首先需要根据这个设置手动创建相应的 VPC，子网，Internet 网关，NAT 网关和相应的路由表，具体就不在这里展开描述了。需要特别注意的是，NAT 网关创建的时候需要选择公有子网，公有子网的路由表需要有一条默认路由去往 Internet 网关。私有子网创建一条默认路由去往 NAT 网关。&lt;/p&gt; 
&lt;p&gt;整个设计的网络规划图如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 子网创建如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;准备工作&lt;/h2&gt; 
&lt;p&gt;EKS集群创建涉及非常多权限，安全组，IAM 角色和策略的创建，强烈建议使用 EKSCTL 来创建，而不是控制台来创建。另外，如果使用控制台来创建集群，目前还不支持自定义 Service 服务网络，所以对 Service 服务网络有 CIDR 定制需求的话，必须用 EKSCTL 来创建集群。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;安装 AWS CLI：&lt;a href="https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/install-cliv2.html"&gt;https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/install-cliv2.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;安装 eksctl：&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html"&gt;https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;安装 kubectl：&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html"&gt;https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;使用 IAM 创建一个管理员账号（或者使用当前管理员账号），然后将该管理员账号的 AKSK (Access Key ID, Secret Access KEY) 配置到 AWS CLI 中，并且后面保持使用该 AKSK 权限操作集群。具体在这里就不详细讲解了，需要的话可以参考&lt;a href="https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/cli-configure-quickstart.html"&gt;配置基础知识&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;如何定义 Node 节点网段和 Service 服务网段&lt;/h2&gt; 
&lt;p&gt;首先创建文件cluster-demo.yaml，其中serviceIPv4CIDR这个参数定义了我们的 Service 网段的地址，vpc下的参数设置了我们 Node 的网段，并且定义了它是跨域2个可用区的。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: cluster-demo
  region: us-east-1

kubernetesNetworkConfig:
  serviceIPv4CIDR: 172.17.0.0/24

vpc:
  id: "vpc-0b051aa1e4d39f9c3"
  cidr: "172.16.0.0/16" 
  subnets:
    private:
      us-east-1a:
        id: "subnet-07c2254d23e8c3607"
        cidr: "172.16.1.0/24"
      us-east-1b:
        id: "subnet-08957bf56343de13a"
        cidr: "172.16.2.0/24" 

managedNodeGroups:
  - name: ng-1-workers
    labels: { role: workers }
    instanceType: m5.xlarge
    desiredCapacity: 2
    volumeSize: 80
    privateNetworking: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过以下命令来创建 EKS 的集群以及和一个节点组。eksctl 后台会使用 &lt;a href="https://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt; 来创建底层的依赖资源，我们也可以随时通过控制台找到这个服务来查看部署状态或者部署细节。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create cluster --config-file=cluster-demo.yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;等待20分钟左右，集群创建好后，可以看到 service 和 node 的地址已经是在自己定义的地址范围内了。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 从上图可以看出来，Service 网段已经分配到我们定义的172.17.0.0/24这个网段了，Node 节点的网络也已经是在172.16.1.0/24 和 172.16.2.0/24这两个网段了。&lt;/p&gt; 
&lt;p&gt;在这个基础上，我们通过命令&lt;code&gt;kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1&lt;/code&gt;直接创建一个 Pod，这个 Pod 的地址会自动在 Node 所在的子网地址中进行分配。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 我们可以看到新部署的 Pod 也是在 172.16.1.0/24 这个网段，&lt;strong&gt;默认情况下 Pod 获取的地址是和 Node 在同一个地址池，如果需要自定义 Pod 网段，我们需要接着往下看。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;如何自定义 Pod 容器网段&lt;/h2&gt; 
&lt;p&gt;如前面所说的，我们可以在一个 VPC 中定义我们 Node 所在的网段，我们可以通过 VPC 的路由表来控制所有 Node 节点之间的通信（不管是 VPC 内部的通信，还是 VPC 与 VPN 或者本地 IDC 的通信）。但是对于 K8S 集群来说，它有自己的网络，比如通过 kubenet 我们可以在 Linux 中创建一个 Linux Bridge，通过这个来解决 Pod 之间通信的问题。但是如果我们要跨不同的节点进行 Pod 之间的通信，我们还需要用到 Container Network Plugins (CNI) 插件，比如常见的 &lt;a href="https://www.tigera.io/project-calico/"&gt;Calico&lt;/a&gt;, &lt;a href="https://github.com/flannel-io/cni-plugin"&gt;Flannel&lt;/a&gt;, &lt;a href="https://www.weave.works/oss/net/"&gt;Weave Net&lt;/a&gt; (EKS 使用的插件）, Canal, kube-router, romana等。&lt;/p&gt; 
&lt;p&gt;以 EKS 中的 CNI 为例子，每一个 Pod 都会和所在的 Node 节点上的 ENI 网卡上的 Secondary IP 地址做一个1对1的映射，所有的 Pod 在 VPC 层级的网络都会以这个地址作为呈现。也就是说，通过 CNI，我们可以将 Pod 的网络和其他 VPC 内的资源一样，打成一个扁平的大三层网络。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; EKS VPC CNI 架构图&lt;/p&gt; 
&lt;p&gt;默认情况下，如前面所说，Pod 所获取的 IP 地址是和 Node 处在同一个子网和可用区的，如果我们需要对 Pod 进行自定义的化，需要用到 &lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/cni-custom-network.html"&gt;CNI Custom Networking&lt;/a&gt; 的方法。&lt;/p&gt; 
&lt;p&gt;首先执行以下简要操作：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true&lt;/code&gt;&lt;br&gt; &lt;code&gt;kubectl describe daemonset aws-node --namespace kube-system | grep Image | cut -d "/" -f 2&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;接着创建文件 us-east-1a.yaml， 需要修改以下的securityGroups的 ID（这个是集群的安全组，如果是通过 eksctl 创建的集群的化，可以到安全组内寻找名字后缀是ClusterSharedNodeSecurityGroup的安全组，记录其 ID 填到下面），subnet（找到给 Pod 分配的子网，记录下其ID到下面）和 name（改为可用区的名字）。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;apiVersion: crd.k8s.amazonaws.com/v1alpha1
kind: ENIConfig
metadata: 
  name: us-east-1a
spec: 
  securityGroups: 
    - sg-0cea1cf2ed938xxxx
  subnet: subnet-0295e90ae9985xxxx&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;同样在另一个可用区也创建一个类似的文件us-east-1b.yaml如下&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;apiVersion: crd.k8s.amazonaws.com/v1alpha1
kind: ENIConfig
metadata: 
  name: us-east-1b
spec: 
  securityGroups: 
    - sg-0cea1cf2ed938xxxx
  subnet: subnet-0566721793f91xxxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;strong&gt;以上的文件名需要和 YAML 文件内的 name 保持一致。如果实际情况还涉及到多个可用区，则需要在每一个可用区都创建一个相应的文件。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;然后我们应用这两个配置文件。这样操作之后，Pod 在启动的时候会自动根据其可用区来分配相应的网段地址。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl apply -f us-east-1a.yaml&lt;/code&gt;&lt;br&gt; &lt;code&gt;kubectl apply -f us-east-1b.yaml&lt;/code&gt;&lt;br&gt; &lt;code&gt;kubectl set env daemonset aws-node -n kube-system ENI_CONFIG_LABEL_DEF=failure-domain.beta.kubernetes.io/zone&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;使用控制台或者 EKSCTL 删除原来的 NodeGroup，使用命令行的话可参照如下：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete nodegroup --cluster cluster-demo --name ng-1-workers&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;创建一个新的 Node Group 让我们自定义网段的配置生效，首先创建新 NodeGroup 的配置文件new-nodegroup.yaml。这里定义了一个名字为ng-2-workers的节点组，以及它的规格和数量。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: cluster-demo
  region: us-east-1

managedNodeGroups:
  - name: ng-2-workers
    labels: { role: workers }
    instanceType: m5.xlarge
    desiredCapacity: 2
    volumeSize: 80
    privateNetworking: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;创建完文件之后，我们用命令创建该 Node Group。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create nodegroup --config-file=new-nodegroup.yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;等待节点组创建成功，然后我们再去查看 Pod 的状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;strong&gt;这个时候我们看到 Pod 已经从我们自定义的网段 172.16.11.0/24 上创建了。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;但注意，有一部分 EKS 的自带的 Pod（aws-node，kube-proxy等）地址是用 host networking，地址是不能变的。&lt;/p&gt; 
&lt;h2&gt;一个 Node 节点如何创建无数量限制的 Pod&lt;/h2&gt; 
&lt;p&gt;在前面的操作中我们会发现，当 Pod 创建出来后，相应的 Node 节点上会出现一个新的 ENI 网卡，网卡上会多出很多 Seconadry IP 地址。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 但不同家族和大小的实例，所能添加的网卡数量，以及每个网卡上能支持的 Secondary IP 的数量是有限的，因此在这个节点上能创建的 Pod 数量也是有限的。比如我们 m5.xlarge 实例类型只能最多创建58个 Pod。具体每个实例的数量限制可以&lt;a href="https://github.com/awslabs/amazon-eks-ami/blob/master/files/eni-max-pods.txt"&gt;查看链接&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;但是在2021年7月份，亚马逊云科技官方&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/07/amazon-vpc-cni-plugin-increases-pods-per-node-limits/"&gt;发布了一个新的特性&lt;/a&gt;，来解决这个问题，&lt;strong&gt;让我们原本只能创建58个 Pod 的 m5.large实例可以创建110个 Pod，甚至更多！&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;确保我们的 VPC CNI 的版本&lt;/h3&gt; 
&lt;p&gt;要使用这个新的功能，首先我们需要确保我们的 VPC CNI 的版本要高于 1.9.0，首先使用以下命令查看目前的版本。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl describe daemonset aws-node --namespace kube-system | grep Image | cut -d "/" -f 2&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 我们看到目前集群的 VPC CNI 版本是 1.75，接下来我们先做一下升级。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;curl -o aws-k8s-cni.yaml https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.9/config/v1.9/aws-k8s-cni.yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl apply -f aws-k8s-cni.yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;升级后再查看 VPC CNI 版本，已经是1.90了。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article9.png" width="624" height="78"&gt;&lt;/a&gt;开启 Prefix 这个新功能。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl set env daemonset aws-node -n kube-system ENABLE_PREFIX_DELEGATION=true&lt;/code&gt;&lt;br&gt; &lt;code&gt;kubectl set env ds aws-node -n kube-system WARM_PREFIX_TARGET=1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;创建一个新的节点组，我们先&lt;strong&gt;定义最大 Pod 数量是110个&lt;/strong&gt;。前面我们用了一个 YAML 文件创建节点组，这次我们直接用 eksctl 命令来创建节点组。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create nodegroup \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --cluster cluster-demo \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --region us-east-1 \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --name ng-3-workers \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --node-type m5.xlarge \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --nodes 1 \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --managed \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --node-private-networking \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --max-pods-per-node 110&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;创建好新的节点之后，我们通过命令 kubectl describe node &amp;lt;Node_NAME&amp;gt; 可以看到我们的 Pod 限制已经生效了。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article10.png" width="624" height="78"&gt;&lt;/a&gt;这里定义的数量是110个，也是开源社区比较推荐的一个节点运行 Pod 数量的最佳实践，当然，也可以根据自己的需要调大这个数值。&lt;/p&gt; 
&lt;h2&gt;每一个 Pod 绑定单独的公网地址&lt;/h2&gt; 
&lt;p&gt;在一些场景中，我们可能需要让每一个 Pod 绑定单独的公网地址（即一个公网地址不被多个 Pod 共享）或者甚至是每一个 Pod 绑定一个固定的公网地址。比如一些电商的场景，会用到类似功能。&lt;/p&gt; 
&lt;p&gt;要做到这个效果，首先我们需要了解到每一个 Pod 都是对应一个 ENI 网卡的 Secondary IP 的，但是针对每一个 Secondary IP，我们可以绑定一个 EIP，来达到每一个 Pod 都能分配一个单独的公网 IP 的效果。&lt;/p&gt; 
&lt;p&gt;首先保证 Pod 需要在一个公有子网（即这个子网有一个默认路由去往 Internet 网关），这样它才能路由出去，如果 Pod 在私有子网，那么它对外的 IP 地址永远是 NAT 网关的 IP 地址。因为前面的测试中，我们的 Pod 是在私有子网的，我们需要先将其变成公有子网。这里为了方便起见，我们重新创建一个公有子网的 EKS 集群，直接把节点启动在原来创建的公有子网就可以了。&lt;/p&gt; 
&lt;p&gt;创建文件cluster-demo-2.yaml，并且输入如下内容，创建新的集群 cluster-demo-2。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: cluster-demo-2
  region: us-east-1

kubernetesNetworkConfig:
  serviceIPv4CIDR: 172.17.0.0/24

vpc:
  id: "vpc-0b051aa1e4d39f9c3"
  cidr: "172.16.0.0/16" 
  subnets:
    public:
      us-east-1a:
        id: "subnet-0bac7fc918a4a3383"
        cidr: "172.16.100.0/24"
      us-east-1b:
        id: "subnet-025da2132adf0b740"
        cidr: "172.16.101.0/24"

managedNodeGroups:
  - name: ng-1-workers
    labels: { role: workers }
    instanceType: m5.xlarge
    desiredCapacity: 2
    volumeSize: 80
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;然后执行&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create cluster --config-file=cluster-demo-2.yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;然后，我们需要将 &lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/external-snat.html"&gt;External SNAT&lt;/a&gt;(Source Network Address Translation) 关闭掉，原因是如果 Pod 的流量要离开 VPC 网络（比如去往互联网，其他 VPC，或者本地 IDC），那么 SNAT 会将这个 Pod 的源 IP 地址转换成这个 Pod 所在的 ENI 上的 Primary IP 地址。因此如果不关闭 SNAT 功能，Pod 去访问互联网的话，会默认使用这个 Pod 所在节点的 Public IP 地址或者 EIP 地址。&lt;/p&gt; 
&lt;p&gt;使用如下命令来关闭 External SNAT：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl set env daemonset -n kube-system aws-node AWS_VPC_K8S_CNI_EXTERNALSNAT=true&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;External SNAT 关闭后，我们删除原来的节点组，重新创建一个新的节点组，然后启动一些新的 Pod 进行测试。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete nodegroup --cluster cluster-demo-2 --name ng-1-workers&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create nodegroup \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --cluster cluster-demo-2 \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --region us-east-1 \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --name ng-2-workers \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --node-type m5.xlarge \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --nodes 1 \&lt;/code&gt;&lt;br&gt; &lt;code&gt;&amp;nbsp; --managed&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article11.png" width="624" height="78"&gt;&lt;/a&gt;可以看到我们的 Pod 获得了 IP 地址 172.16.100.177，接着我们去到 EC2 控制台的 ENI 界面找到这个 IP 地址。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 然后我们给这个地址绑定一个弹性 IP（EIP），选中这个网卡，点击 Actions → Associate Address 即可。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 关联好后，我们试下进去 Pod 查看这个公有 IP 地址是否生效吧。&lt;/p&gt; 
&lt;p&gt;通过命令 &lt;code&gt;kubectl get pods -A -o wide&lt;/code&gt; 我们可以找到运行的 Pod 的名字，然后通过&lt;code&gt;kubectl exec kubernetes-bootcamp-57978f5f5d-qp9hg — curl&amp;nbsp;cip.cc&lt;/code&gt; 来进入到容器查看自己的一个公网 IP 地址。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/understand-the-network-planning-in-amazon-eks-in-one-article14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 我们发现，这个容器已经对外是用 34.196.240.56 这个公网 IP 地址了，这个就是我们刚才关联的 EIP。&lt;/p&gt; 
&lt;p&gt;除了以上的方式之外，我们还可以通过 AWS CLI 的方法来关联 EIP 和我们的 Pod。这样，我们可以做到不同的 Pod 对外的公网地址是不一样的，或者我们可以根据业务的逻辑来对不同的应用绑定不同的 IP 地址。&lt;/p&gt; 
&lt;h2&gt;一个 Pod 如何绑定多张网卡&lt;/h2&gt; 
&lt;p&gt;默认情况下，一个 Pod 会绑定一个 VPC 的 ENI 网卡，并消耗一个 Secondary IP 地址，如果需要一个 Pod 绑定多个地址或者网卡的话，需要用到 Multus 的 CNI 插件，具体可以&lt;a href="https://github.com/aws-samples/eks-install-guide-for-multus/blob/main/README.md"&gt;查看官方文档&lt;/a&gt;，在这里就不再详细展开了。通过 Multus 插件结合上面一小节讲解的公网 IP 映射方法，我们也可以做到一个 Pod 绑定多个公网 IP 地址。&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;通过这篇博客，我们了解到了在多区域，多 VPC 或者是混合云的容器场景中，我们往往需要对 K8S 网络进行提前的规划，以防止未来需要紧急扩容的情况。对不同 K8S 环境，我们可以自定义 Service 服务网络，Node 节点网络，Pod 容器网络，以及每一个 Pod 挂单独的公有 IP 地址甚至是多个公有 IP。另外，通过在 VPC 内附加新的网段，或者利用新的 EKS IP Address Prefix 功能，我们可以在有限的网段或者有限的节点上跑更多数量的 Pod。&lt;/p&gt; 
&lt;h2&gt;参考文献&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.weave.works/technologies/kubernetes-on-aws/"&gt;https://www.weave.works/technologies/kubernetes-on-aws/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://chrislovecnm.com/kubernetes/cni/choosing-a-cni-provider/"&gt;https://chrislovecnm.com/kubernetes/cni/choosing-a-cni-provider/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#kubenet"&gt;https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#kubenet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://eksctl.io/introduction/"&gt;https://eksctl.io/introduction/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awslabs/amazon-eks-ami/blob/master/files/eni-max-pods.txt"&gt;https://github.com/awslabs/amazon-eks-ami/blob/master/files/eni-max-pods.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/prefix-and-ip-target.md"&gt;https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/prefix-and-ip-target.md&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/managing-vpc-cni.html"&gt;https://docs.aws.amazon.com/eks/latest/userguide/managing-vpc-cni.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/external-snat.html"&gt;https://docs.aws.amazon.com/eks/latest/userguide/external-snat.html&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/peiqingx.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;肖培庆&lt;/h3&gt; 
  &lt;p&gt;亚马逊AWS解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，同时致力于AWS云服务在国内的应用和推广。现主要负责初创企业行业解决方案，曾任职于IBM，联想，Avnet，多年大型企业网络架构和运维经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用 Amazon Athena 做漏斗分析</title>
		<link>https://aws.amazon.com/cn/blogs/china/athena-funnel-sum-funnel-count/</link>
				<pubDate>Wed, 08 Sep 2021 04:24:15 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Athena]]></category>

		<guid isPermaLink="false">e8c529c5ad3f136a70bf921b1d3e8a9ecc593671</guid>
				<description>本文介绍了如何使用 Amazon Athena 做漏斗分析，并给出了完整 SQL 设计方案和思路。</description>
								<content:encoded>&lt;p&gt;在日常的业务运营过程中，管理者常常需要快速了解业务的运转健康状况，识别出瓶颈和问题，并制订应对的计划。要概览业务全景，我们可以借助一些统计工具。「漏斗分析」就是一种常见的工具，它很适合多个环节按时间顺序串联的业务。&lt;/p&gt; 
&lt;p&gt;现实生活中，很多业务都是多环节串联。比如电商用户可能会浏览推荐的物品、比价、加入购物车、下单购买、评价；再比如培训机构的客户可能会看到广告、咨询、试课、购买、正式上课、续费。&lt;/p&gt; 
&lt;p&gt;对于这类业务，我们可以把触达每个环节的人数统计出来，并形成一个逐渐递减的「漏斗」，就能看到每个环节的转化情况，定位到目前转化主要是卡在哪个步骤，再针对这个步骤补充定质的调研来确定解决方案。&lt;/p&gt; 
&lt;p&gt;在这篇文章中，我们将使用 Amazon Athena 来编写这样的一个漏斗分析工具，把一系列的时序数据（访问日志）转化成为每个环节的数量，再把数量转化成递减的漏斗。除了展示最终效果之外，我也会展示整个设计过程，帮助读者调整、设计自己的 SQL 语句。&lt;/p&gt; 
&lt;h2&gt;Amazon Athena 介绍&lt;/h2&gt; 
&lt;p&gt;Amazon Athena 是数据湖查询服务。它让用户可以使用 SQL 语句对存在 S3 上的半结构化数据（JSON、CSV、Parquet 等）进行查询。此外，它还是无服务器的服务，这意味着用户无需关心底层硬件资源，仅按照扫描数据的数量来进行收费。不扫描则没有其他闲置费用。&lt;/p&gt; 
&lt;p&gt;Amazon Athena 是&lt;a href="https://docs.aws.amazon.com/athena/latest/ug/presto-functions.html"&gt;&lt;em&gt;基于 Presto 实现&lt;/em&gt;&lt;/a&gt;的。用户可以使用 Presto 的 SQL 语法和部分内置函数进行查询。&lt;/p&gt; 
&lt;h2&gt;漏斗分析介绍&lt;/h2&gt; 
&lt;p&gt;接下来我们来看漏斗分析。&lt;/p&gt; 
&lt;p&gt;在本文中，「漏斗分析」指的是：统计触达业务流程上每个关键环节的用户人数，并分析每个步骤的留存、转化、跳出率，以找到转化瓶颈。&lt;/p&gt; 
&lt;p&gt;漏斗分析包含的输入如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;分析者关心的事件路径&lt;/strong&gt;。比如我们关心「注册、浏览、下单」，那用户必须严格按照这个顺序来执行每个环节；例如：用户可以只执行「注册」，算走了 1 步，或者执行「注册、浏览」，算走了 2 步，但「注册、搜索、下单」只能算走了 1 步，因为「搜索」不在我们关心的路径内，从而打断了漏斗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;漏斗的时间区间&lt;/strong&gt;。比如设置为 10 天，则漏斗包含的环节必须在 10 天内走完，如果用户第 1 天注册了，也浏览了，但是一直到第 20 天才下单，那么这个也只能算走了 1 步。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;漏斗分析的输出有两个：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;漏斗步骤计数&lt;/strong&gt;（FUNNEL_COUNT）。比如 A 用户走了 1 步，B 用户走了 3 步，C 用户走了 2 步，等等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;漏斗人数统计&lt;/strong&gt;。（FUNNEL_SUM）。比如走到第 1 步的有 1000 人，这其中走到第 2 步的有 300 人，而这其中走到第 3 步的又有 50 人，等等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;测试数据准备&lt;/h2&gt; 
&lt;p&gt;我提前准备好了测试数据。数据结构如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;数据字段如下。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;event_name 是事件名字，中英文均可&lt;/li&gt; 
 &lt;li&gt;user_id 是用户名&lt;/li&gt; 
 &lt;li&gt;timestamp 是时间戳&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;数据是 JSON 格式，使用 Glue 爬虫进行爬取，录入为数据表，读者也可以自行创建外部表。如果手上没有现成数据，也可以使用 generatedata.com 等模拟数据生成工具来生成简单的测试数据。&lt;/p&gt; 
&lt;h2&gt;漏斗语句设计过程&lt;/h2&gt; 
&lt;p&gt;接下来我们来看如何一步步设计出漏斗分析语句。&lt;/p&gt; 
&lt;h3&gt;简单分类统计&lt;/h3&gt; 
&lt;p&gt;先来做步骤计数。先按用户来计算事件数量，这是一个分类统计的操作。既然是分类统计，我们直觉可能就会想到使用 GROUP BY 语句，比如：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT user_id, COUNT(1) AS events_count
FROM events_table
GROUP BY user_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;这个语句的意思是，计算每个用户分别触发了多少事件。语句执行后，结果如下图：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;限制时间窗口&lt;/h3&gt; 
&lt;p&gt;这里有一个问题，就是它会统计这个用户所有触发过的事件，包括超出了我们设定的事件窗口范围的事件，所以，我们还需要做一次过滤。比如我们设定的时间区间是 5 天，那么下面示意图中 2020-11-23 以后的事件就必须被过滤掉。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;需要注意的是，这个要求无法用简单的条件判断来解决，因为窗口的起始时间需要根据用户触发第一条事件的时间而定。比如用户 A 是 11 月 21 日触发第一条事件，那么窗口就从 11 月 21 日开始，而用户 B 是 12 月 1 日触发第一条事件，这个窗口则从 12 月 1 日开始。&lt;/p&gt; 
&lt;p&gt;要做到这一点，我们需要借助一个中间表。这个中间表只包含用户 ID 和这个用户的窗口结束时间，然后再用这个表来联结原来的事件表，从而可以用一个简单的条件判断来过滤掉超过时间窗口的数据。&lt;/p&gt; 
&lt;p&gt;包含窗口结束的中间表语句如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT user_id,
  DATE_ADD('second', 3600 * 24 * 5, MIN(timestamp)) AS max_span
FROM events_table
GROUP BY user_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们首先使用 GROUP BY 按照把每个用户的事件分组，然后使用 MIN() 函数获取每个用户的第一条事件的时间，再使用 DATE_ADD() 函数，在这个时间的基础上增加了 5 天（假设窗口是 5 天），就得到了每个用户窗口结束的时间。&lt;/p&gt; 
&lt;p&gt;把这个表和简单统计的表联结起来，语句如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;WITH max_spans_table AS
(
  SELECT user_id,
    DATE_ADD('second', 3600 * 24 * 5, MIN(timestamp)) AS max_span
  FROM events_table
  GROUP BY user_id
)
SELECT e.user_id, COUNT(1) AS event_count
FROM events_table e
JOIN max_spans_table m ON e.user_id = m.user_id
WHERE e.timestamp &amp;lt;= m.max_span
GROUP BY e.user_id
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;可以看出，这有点类似给第一个表做了一个遍历，并且给用户 ID 相同的条目加上了一个 max_span 参数，然后过滤掉了小于等于这个参数的行。&lt;/p&gt; 
&lt;h3&gt;指定行为路径&lt;/h3&gt; 
&lt;p&gt;不过这样还是有问题。虽然我们过滤了窗口外的数据，但并没有办法指定事件路径。我们关心的漏斗可能是「注册、浏览、下单」，但用户的行为可能是「搜索、浏览、下单」。我们还需要指定行为路径。&lt;/p&gt; 
&lt;p&gt;要在 SQL 语句里面对几条数据的顺序进行判断并不容易。因为 SQL 原本是用于操作和查询集合的，所以对顺序并不敏感。不过，还好事件名称只是简单的字符串，所以我们可以采用取巧的做法，把用户在某个时间窗口内的事件全部拼接成一个长的字符串，然后和我们预期的路径进行对比。&lt;/p&gt; 
&lt;p&gt;要把多条数据中的字段拼接到一起，我们需要两个函数。首先是 ARRAY_AGG()，用于把多条数据中的某个字段值取出来，组成一个数组。然后是 ARRAY_JOIN()，用于把数组中的字符串拼接到一起。&lt;/p&gt; 
&lt;p&gt;这里，我们假设我们关心的路径是「注册、询问客服、加入购物车、下单」。&lt;/p&gt; 
&lt;p&gt;此时的语句如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;WITH max_spans_table AS
(
  SELECT user_id,
    DATE_ADD('second', 3600 * 24 * 5, MIN(timestamp)) AS max_span
  FROM events_table
  GROUP BY user_id
)
SELECT e.user_id, ARRAY_JOIN(ARRAY_AGG(e.event_name ORDER BY e.timestamp ASC), ',') AS event_seq, COUNT(1) AS event_count
FROM events_table e
JOIN max_spans_table m ON e.user_id = m.user_id
WHERE e.timestamp &amp;lt;= m.max_span
GROUP BY e.user_id
HAVING ARRAY_JOIN(ARRAY_AGG(e.event_name), ',') = 'REGISTER,INQUIRY,CART,ORDER'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;注意虽然我们在 SELECT 时使用了别名 event_seq，但是给列取别名这个动作是在查询完成后在结果集中执行，所以 HAVING 语句中还是需要重复一遍 ARRAY_JOIN() 函数。此外，在 ARRAY_AGG() 函数中，我们还用 timestamp 字段做了排序，确保这些事件名字按照时间顺序拼接。&lt;/p&gt; 
&lt;p&gt;查询结果如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;计算用户的漏斗路径长度&lt;/h3&gt; 
&lt;p&gt;观察结果，会发现只有 7 个用户，而我们的测试数据集中有数千个用户，这明显不正常。究其原因，是因为我们只简单地比对拼接好的字符串和输入的行为路径，就只能查到全部路径都走完的用户。&lt;/p&gt; 
&lt;p&gt;比如，我们设定的输入是「A,B,C」，那么按顺序正好触发了这三个事件的用户就会拼接出「A,B,C」字符串从而比对成功。而只触发了 A，或者 A、B 的用户则无法匹配上。此外，A 事件如果不是第一个事件，而是在中间（「D,A,B,C」），又或者在目标事件路径后又触发了别的事件（「A,B,C,D」），简单的匹配都无法对比到。&lt;/p&gt; 
&lt;p&gt;此时我们需要做两件事：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;找出某个用户的行为路径中第一个事件（比如「A」）所在的行，过滤掉它之前的行，否则路径在中间或者尾部就无法匹配（退一步说，即便可以匹配，我们也无法正确计算窗口时间）&lt;/li&gt; 
 &lt;li&gt;只保留能以「A」「A,B」和「A,B,C」开头的事件路径，这是我们关心的目标路径&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这时候我们就会触及 SQL 语言的表现力天花板。在普通编程语言中要做到这两件事很容易，因为我们可以多次循环，使用临时变量，再按需要过滤。而要在 SQL 中做到这样的过滤，就需要曲线救国了。&lt;/p&gt; 
&lt;p&gt;要做到第一点，我们需要把每个用户的事件单独提出来，删掉我们输入行为路径的第一个事件之前的其他事件。拿下图为例，如果我们关心的事件路径第 1 步是「注册」，那么在「注册」之前的步骤就都要删掉。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;好在 SQL 中有提供「窗口函数」这样的概念。我们可以把每个用户的事件做成一个「窗口」，并且用 ROW_NUMBER() 函数给窗口中的每条数据一个行编号。接下来，我们要找到第一个事件所在的行编号，记录下来。然后，再联结原表，过滤掉这个用户下编号小于我们记录下的编号的行。这和前面的时间窗口过滤异曲同工。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;窗口函数部分语句如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT *,
  ROW_NUMBER() OVER (PARTITION BY id ORDER BY timestamp ASC) AS row_number
FROM events_table&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;使用 OVER () 语句，就形成了一个「窗口」，窗口由 PARTITION BY 指示的字段来作为划分，并且窗口内的数据条目可以排序。这有点像 GROUP BY 的逻辑，只不过 GROUP BY 只能用来做统计，而窗口函数则可以不做统计，只附加行编号。&lt;/p&gt; 
&lt;p&gt;执行结果如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以看出，我们给每个用户自己的事件进行了编号，后续只需要查找到我们关心的事件所在的编号并联结原表做过滤即可。&lt;/p&gt; 
&lt;p&gt;过滤事件做到了，要做到第二点，多重匹配，则相对麻烦。&lt;/p&gt; 
&lt;p&gt;也许你会想到 LIKE ‘%%’ 等通配语句，但它只能匹配完整包含全部事件步骤的路径，无法匹配仅包含部分步骤的路径。如果使用 STRPOS()，再把两个参数反过来，那么确实可以匹配「A」「A,B」「A,B,C」以及「A,B,C,D,E」，但是却无法匹配「A,E,F,G」这样只以「A」开头的但后续是其他事件的路径。&lt;/p&gt; 
&lt;p&gt;幸好，我们还有 REDUCE() 函数，可以循环处理数组数据。只需先把行为路径字符串拆成一个数组，然后利用 REDUCE() 函数，使用递归的方式，把后一个字符串附加在前一个结果上，就能得到包含「A」「A,B」「A,B,C」等路径子集的数组，从而进行多重匹配。&lt;/p&gt; 
&lt;p&gt;要做到这一点，我们除了需要拿到数组中的字符串值，还需要拿到这个值所对应的下标。如果下标为 1 说明是第一个元素，原封不动，否则把当前的字符串取出来，和上一轮的字符串合并，添加到输出数组内。这个用 IF() 函数来做。&lt;/p&gt; 
&lt;p&gt;REDUCE() 函数本身没有提供下标参数，所以我们需要借助 CARDINALITY() 函数获取数组长度，再用 SEQUENCE() 函数来生成一个顺序数字的数组作为下标列表。遍历这个数组，就达到了类似其他语言的 for 循环或者 enumerate() 的效果。&lt;/p&gt; 
&lt;p&gt;这部分的语句如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT REDUCE(
    SEQUENCE(1, CARDINALITY(event_steps)), ARRAY [], 
    (s, i) -&amp;gt; 
      IF(
        i &amp;gt; 1, 
        s || (CAST(s[i-1] AS VARCHAR) || ',' || event_steps[i]),
        s || event_steps[i]), 
    s -&amp;gt; s) AS event_step_combos
FROM (
  SELECT SPLIT('REGISTER,INQUIRY,CART,ORDER', ',') AS event_steps
)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;这里用到了 CAST() 函数来把数组值设定为字符串，再使用 || 操作符来做字符串的连接。&lt;/p&gt; 
&lt;p&gt;下面是本轮的输出示例。因为控制台输出没有明确标明字符串，所以我把输出的部分用红线标记区分了一下。可以看出输出的数组中包含四个字符串，符合我们的要求。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;不过，虽然有了这样一个数组，我们还需要对所有的事件路径做匹配，并且记录下匹配到的到底是「A」、「A,B」还是「A,B,C」，这样我们才能做后续的统计。要做到这一点，我们需要结合几个函数。&lt;/p&gt; 
&lt;p&gt;首先还是 REDUCE() 和 SEQUENCE() 函数，用于执行循环操作，最后输出一个数字，代表到底匹配到哪一个字符串。最后是 IF()，用于判断是否已经匹配到，如果已经匹配到，则维持原输入什么都不做，而如果没匹配到，则使用 STRPOS() 进行匹配。&lt;/p&gt; 
&lt;p&gt;因为一旦匹配出结果，就不会再进行匹配，所以我们必须先匹配最长的字符串。这就要求我们使用 REVERSE() 函数把字符串按照从长到短，反向排列。&lt;/p&gt; 
&lt;p&gt;这又引发一个问题，那就是因为我们的输入时数组反过来了，所以得出的数组下标也是反的。我们还必须再它下标反过来，也即是把下标 1、2、3、4 换成 4、3、2、1。通过分析可知，用数组长度减去下标再加 1 就可以把下标顺序反过来，所以我们把这部分添加上去。&lt;/p&gt; 
&lt;p&gt;把前面部分代码都融合到一起，此时代码如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;WITH 
-- 拆分输入的事件路径
params AS
(
  SELECT REVERSE(REDUCE(
      SEQUENCE(1, CARDINALITY(event_steps)), ARRAY [], 
      (s, i) -&amp;gt; 
        IF(
          i &amp;gt; 1, 
          s || (CAST(s[i-1] AS VARCHAR) || ',' || event_steps[i]),
          s || event_steps[i]), 
      s -&amp;gt; s)) AS event_step_combos
  FROM (
    SELECT SPLIT('REGISTER,INQUIRY,CART,ORDER', ',') AS event_steps
  )
),
-- 给各个用户触发的事件进行独立行编号
events_with_row_numbers_table AS
(
  SELECT *,
    ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY timestamp ASC) AS row_number
  FROM events_table
),
-- 找到用户触发的漏斗中的第一个事件并记录行编号
events_starter_event_with_row_number AS (
  SELECT user_id, MAX(row_number) AS starter_event_row_number
  FROM events_with_row_numbers_table
  WHERE event_name = 'REGISTER'
  GROUP BY user_id
),
-- 过滤掉漏斗中第一个事件之前的事件
events_trimmed_table AS (
  SELECT e.user_id, e.event_name, e.timestamp
  FROM events_with_row_numbers_table e
  JOIN events_starter_event_with_row_number er ON e.user_id = er.user_id
  WHERE e.row_number &amp;gt;= er.starter_event_row_number
),
-- 找到时间窗口终点
max_spans_table AS
(
  SELECT user_id,
    DATE_ADD('second', 3600 * 24 * 5, MIN(timestamp)) AS max_span
  FROM events_trimmed_table
  GROUP BY user_id
),
-- 把用户的事件组合成一个字符串
events_seq_table AS
(
  SELECT e.user_id, 
    ARRAY_JOIN(ARRAY_DISTINCT(ARRAY_AGG(e.event_name ORDER BY e.timestamp ASC)), ',') AS event_seq
  FROM events_trimmed_table e
  JOIN max_spans_table m ON e.user_id = m.user_id
  WHERE e.timestamp &amp;lt;= m.max_span
  GROUP BY e.user_id
)
-- 找出用户停在了哪一步
SELECT e.user_id, e.event_seq, REDUCE(
  SEQUENCE(1, CARDINALITY(p.event_step_combos)), 
  0, 
  (s, i) -&amp;gt; IF(
    s &amp;gt; 0, 
    s, 
    IF(
      STRPOS(e.event_seq, p.event_step_combos[i]) = 1, 
      CARDINALITY(p.event_step_combos)-i+1, 
      0
    )
  ), 
  s -&amp;gt; s
) AS funnel_step
FROM events_seq_table e
CROSS JOIN params p&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;可以看出因为中间表的出现和函数的增加，查询语句已经变得很长了。我加入了注释，帮助读者看清楚每个中间表的目的。&lt;/p&gt; 
&lt;p&gt;此时结果如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以看出，能匹配路径中的几个步骤，funnel_step 就是几。这样，我们就获得了每个用户走过的事件路径长度。&lt;/p&gt; 
&lt;h3&gt;漏斗人数统计&lt;/h3&gt; 
&lt;p&gt;接下来我们对每个步骤的人数做统计。&lt;/p&gt; 
&lt;p&gt;我们先计算每个步骤的用户数量，这是一个简单的统计。这部分代码如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT COUNT(1) AS funnel_step_count
FROM events_funnel_step_table
GROUP BY funnel_step&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;可这个语句得出的结果是每个步骤单独的人数，但我们需要的不是单独的人数，而是漏斗，所以我们希望最后呈现的是环环相扣的统计。比如 1000 个人注册，其中 200 个人浏览，其中 15 个人下单。这意味着我们需要对步骤做累加。&lt;/p&gt; 
&lt;p&gt;这时候我们又需要借助窗口函数。窗口函数中有个特殊版的 SUM() 函数，这个版本的 SUM() 函数会把原来的「求和」变成「窗口间累加」，这符合我们的需要。此时我们省略了 PARTITION BY 语句，这就意味着每条记录自己就是一个窗口，而 SUM() 也变成了「按记录累加」的意思。&lt;/p&gt; 
&lt;p&gt;这部分代码如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT 
  SUM(funnel_step_count) 
    OVER (ORDER BY funnel_step ASC) 
    AS funnel_step_acc_sum
FROM events_funnel_step_count_table&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;观察结果我们会发现，这和我们想的漏斗反过来了。因为漏斗是越来越少，而累加则是越来越多，我们需要用一个总数，逐步减去这个累加值。&lt;/p&gt; 
&lt;p&gt;这部分代码如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT (funnel_total_sum-funnel_step_acc_count) AS funnel_step_converts
FROM events_funnel_step_acc_count_table
CROSS JOIN (
  SELECT SUM(funnel_step_count) AS funnel_total_sum
  FROM events_funnel_step_count_table
)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;再次观察结果我们会发现，此时的漏斗最后会变成 0。这是因为我们的累加是从 0 开始，最后也会减到 0，而我们实际上希望只减到倒数第二步然后停止。换句话说，就是我们要用本行的值，去减上一行的累加值。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;对于 SQL 来说，这就意味着一个表对自身做一个联结，但是要错开一行。用语句来表示如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT e.funnel_step, (funnel_total_sum-e2.funnel_step_acc_count) AS funnel_step_converts
FROM events_funnel_step_acc_count_table e
LEFT JOIN events_funnel_step_acc_count_table e2 ON e.funnel_step = e2.funnel_step+1
CROSS JOIN (
  SELECT SUM(funnel_step_count) AS funnel_total_sum
  FROM events_funnel_step_count_table
)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;结果如下。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;观察结果又会发现一个问题，那就是第 1 行的值是空的。这是因为当左表是第 1 行时，右表的上一行不存在，所以 LEFT JOIN 的结果是 NULL，而针对 NULL 做数学运算，结果也只能是 NULL。&lt;/p&gt; 
&lt;p&gt;为解决这个问题，我们使用 COALESCE() 函数。这个函数可以帮助我们设置默认值。它会返回它的参数中第一个非 NULL 的值。我们把这个默认值设置为 0，这样，我们就可以对它进行正常计算。&lt;/p&gt; 
&lt;p&gt;加上后语句如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;SELECT e.funnel_step, (funnel_total_sum-COALESCE(e2.funnel_step_acc_count, 0)) AS funnel_step_converts
FROM events_funnel_step_acc_count_table e
LEFT JOIN events_funnel_step_acc_count_table e2 ON e.funnel_step = e2.funnel_step+1
CROSS JOIN (
  SELECT SUM(funnel_step_count) AS funnel_total_sum
  FROM events_funnel_step_count_table
)
ORDER BY funnel_step ASC
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;效果如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/athena-funnel-sum-funnel-count12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;参数提取&lt;/h3&gt; 
&lt;p&gt;现在我们的目标就达成了。还剩下最后一个问题，那就是我们需要在不同语句，多次手动插入我们的参数。最好是我们能把参数都一次写到第一条语句中，使用起来更方便。&lt;/p&gt; 
&lt;p&gt;要做到这一点，我们使用 VALUES 来创建一个只有一行的临时表用于存储参数，然后用 AS 来给字段命名。使用时只需要从这个临时表 SELECT 需要的字段即可。&lt;/p&gt; 
&lt;p&gt;至此，我们用 Amazon Athena 的 SQL 编写了漏斗分析统计函数。因为 Amazon Athena 的底层是基于 Presto，所以这个语句也可以运行于兼容版本的 SQL 引擎上。&lt;/p&gt; 
&lt;p&gt;最终完整 SQL 语句如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;WITH 
-- 原始参数
input AS
(
  SELECT time_window, SPLIT(event_chain, ',') AS event_steps
  FROM (VALUES ('REGISTER,INQUIRY,CART,ORDER', 3600 * 24 * 5))
  AS input (event_chain, time_window)
),
-- 拆分输入的事件路径
params AS
(
  SELECT time_window, event_steps, REVERSE(
    REDUCE(
      SEQUENCE(1, CARDINALITY(event_steps)), ARRAY [], 
      (s, i) -&amp;gt; 
        IF(
          i &amp;gt; 1, 
          s || (CAST(s[i-1] AS VARCHAR) || ',' || event_steps[i]),
          s || event_steps[i]), 
      s -&amp;gt; s
    )
  ) AS event_step_combos
  FROM input
),
-- 给各个用户触发的事件进行独立行编号
events_with_row_numbers_table AS
(
  SELECT *,
    ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY timestamp ASC) AS row_number
  FROM events_table
),
-- 找到用户触发的漏斗中的第一个事件并记录行编号
events_starter_event_with_row_number AS (
  SELECT user_id, MAX(row_number) AS starter_event_row_number
  FROM events_with_row_numbers_table
  WHERE event_name = (SELECT event_steps[1] FROM params)
  GROUP BY user_id
),
-- 过滤掉漏斗中第一个事件之前的事件
events_trimmed_table AS (
  SELECT e.user_id, e.event_name, e.timestamp
  FROM events_with_row_numbers_table e
  JOIN events_starter_event_with_row_number er ON e.user_id = er.user_id
  WHERE e.row_number &amp;gt;= er.starter_event_row_number
),
-- 找到时间窗口终点
max_spans_table AS
(
  SELECT user_id,
    DATE_ADD('second', (SELECT time_window FROM params), MIN(timestamp)) AS max_span
  FROM events_trimmed_table
  GROUP BY user_id
),
-- 把用户的事件组合成一个字符串
events_seq_table AS
(
  SELECT e.user_id, 
    ARRAY_JOIN(ARRAY_DISTINCT(ARRAY_AGG(e.event_name ORDER BY e.timestamp ASC)), ',') AS event_seq
  FROM events_trimmed_table e
  JOIN max_spans_table m ON e.user_id = m.user_id
  WHERE e.timestamp &amp;lt;= m.max_span
  GROUP BY e.user_id
),
-- 计算每个用户走完的事件路径长度
events_funnel_step_table AS
(
  SELECT e.user_id, e.event_seq, REDUCE(
    SEQUENCE(1, CARDINALITY(p.event_step_combos)), 
    0, 
    (s, i) -&amp;gt; IF(
      s &amp;gt; 0, 
      s, 
      IF(
        STRPOS(e.event_seq, p.event_step_combos[i]) = 1, 
        CARDINALITY(p.event_step_combos)-i+1, 
        0
      )
    ), 
    s -&amp;gt; s
  ) AS funnel_step
  FROM events_seq_table e
  CROSS JOIN params p
),
-- 计算走完不同事件路径长度的人数
events_funnel_step_count_table AS
(
  SELECT funnel_step, COUNT(1) AS funnel_step_count
  FROM events_funnel_step_table
  GROUP BY funnel_step
),
-- 按顺序累加事件路径上每个步骤的人数
events_funnel_step_acc_count_table AS
(
  SELECT funnel_step, SUM(funnel_step_count) OVER (ORDER BY funnel_step ASC) AS funnel_step_acc_count
  FROM events_funnel_step_count_table
),
-- 给用户事件路径长度统计增加一个常用的别名
funnel_count AS (
  SELECT * FROM events_funnel_step_count_table
),
-- 把累加变成错一行累减获得步骤转化
funnel_sum AS (
  SELECT e.funnel_step, (funnel_total_sum-COALESCE(e2.funnel_step_acc_count, 0)) AS funnel_step_converts
  FROM events_funnel_step_acc_count_table e
  LEFT JOIN events_funnel_step_acc_count_table e2 ON e.funnel_step = e2.funnel_step+1
  CROSS JOIN (
    SELECT MAX(funnel_step_acc_count) AS funnel_total_sum
    FROM events_funnel_step_acc_count_table
  )
  ORDER BY funnel_step ASC
)
SELECT *
FROM funnel_sum&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;每个中间表都可以单独 SELECT 出来作为调试优化之用。最后的 funnel_count 和 funnel_sum 表则可以用于做漏斗分析。&lt;/p&gt; 
&lt;h2&gt;更多的思考&lt;/h2&gt; 
&lt;p&gt;使用 SQL 虽然达到了目的，但这个方案仍有改善空间。比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;当事件重复时，比如「A,A,B,B,C,C」，应该如何处理和判断？&lt;/li&gt; 
 &lt;li&gt;当漏斗重复时，比如「A,B,C,A,B,C」，应该如何处理？&lt;/li&gt; 
 &lt;li&gt;如果允许中间插入其他步骤，比如「A,B,X,C」，应该如何处理？&lt;/li&gt; 
 &lt;li&gt;如果参数输入有误，应该如何处理和提示？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些问题没有标准答案。有的问题也许可以在 SQL 内解决，有的问题可能要留给前期 ETL 流程，有的则可能需要专门的应用程序逻辑来判断。读者可以根据实际的情况，对症下药解决。&lt;/p&gt; 
&lt;p&gt;此外，漏斗分析通常需要对数据做多次扫描，以确保数据连贯发生，并且发生在同一个时间区间，这会直接影响扫描的数据量以及语句执行效率。读者也可以根据自身需要，对原始数据和语句本身进行修改、调整、优化，提升整体执行效率。&lt;/p&gt; 
&lt;p&gt;最后值得一提的是，从结果可以看出，虽然我们写出来了这样的函数，但是它的可读性并不强。诸如 IF() 函数的嵌套，REDUCE() + SEQUENCE() + CARDINALITY() 的方式来表示简单的 for 循环让人眼花缭乱。使用单行表再加 CROSS JOIN 的方式传递参数，意图也不是很清晰。&lt;/p&gt; 
&lt;p&gt;诚然，对于日常、固化的分析任务，很多时候我们可以通过 ETL 把数据转换成更方便的统计方式。这不仅更好读、更好维护，也可以提升分析的效率。&lt;/p&gt; 
&lt;p&gt;不过，笔者认为 SQL 作为相对简单的语言，其快速试错、探索的功能仍然能在业务梳理和设计期极大地提升效率。在数据湖的时代，数据的结构变化很快，可探索的空间也更大，熟练掌握 SQL 就更显得重要。&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;本文介绍了如何使用 Amazon Athena 来进行漏斗分析，并重点介绍了完整的思考过程和中间用到的 SQL 语法及函数。希望能帮助读者对数据湖进行更高效的探索。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/daizhan.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;张玳&lt;/h3&gt; 
  &lt;p&gt;AWS 解决方案架构师。十余年企业软件研发、设计和咨询经验，专注企业业务与 AWS 服务的有机结合。译有《软件之道》《精益创业实战》《精益设计》《互联网思维的企业》，著有《体验设计白书》等书籍。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>基于AWS machine learning bot 的 named-entity recognition (NER) 快速解决方案</title>
		<link>https://aws.amazon.com/cn/blogs/china/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot/</link>
				<pubDate>Wed, 08 Sep 2021 04:04:19 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon SageMaker]]></category>

		<guid isPermaLink="false">5140953572669cbfb16f7aa1438626e1bf0a9022</guid>
				<description>本文重点介绍了如何运用ML的 命名实体识别（name entity recognition）来快速构建自然语言处理的API功能。具体内容如下：</description>
								<content:encoded>&lt;p&gt;Amazon machine learning bot为用户提供了一种快速的开箱即用的解决方案，其底层基于Amazon SageMaker 将机器学习模型的定制及部署实现了高效的自动化。并且， ML bot 提供了可视化、易操作的web user interface界面。用户可以上传具体应用场景的图片或文字数据，快速完成从数据标注，模型训练到模型效果评估的全部流程。&lt;/p&gt; 
&lt;p&gt;本文重点介绍了如何运用ML的 命名实体识别（name entity recognition）来快速构建自然语言处理的API功能。具体内容如下：&lt;/p&gt; 
&lt;h2&gt;1. Machine learning bot 框架介绍&lt;/h2&gt; 
&lt;p&gt;ML bot是一个一键式的打包封装的机器学习解决方案，它提供了多种不同类型的原始机器学习模型，并且可以根据需求通过互相交互来评价模型。在一键式应用的基础上，ML bot也确保了数据的安全性，基于Amazon云技术的加密和授权，用户可以把数据储存在Amazon的云端并直接导入到ML bot的模型当中。ML bot不仅拥有用户友好的人性化交互界面，也为用户提供了实时更新的最新机器学习模型。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;本文中我们采用了ML bot下的命名实体识别模型（NER）。命名实体识别是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。命名实体识别是信息提取、问答系统、句法分析、机器翻译等应用领域的重要基础工具，作为结构化信息提取的重要步骤，该模型可以在后续阶段通过对不同文本内容的分析然后被应用于快速消费品，金融和医疗等领域中。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;2. 数据集说明&lt;/h2&gt; 
&lt;p&gt;为了在ML bot上展示我们的模型，我们采用了从社交媒体上采集来的包含命名实体的公开数据集作为我们的训练集。该数据集中的文本采用UTF-8进行编码，每行为一个段落标注，共包括2000段落。所有的实体以如下的格式进行标注： {{实体类型：实体文本}}&lt;/p&gt; 
&lt;p&gt;标注的实体类别包括以下六种：time: 时间 location: 地点 person_name: 人名 org_name: 组织名 company_name: 公司名 product_name: 产品名。&lt;/p&gt; 
&lt;p&gt;例：此次{{location:中国}}个展，{{person_name:苏珊菲利普斯}}将与她80多岁高龄的父亲一起合作，哼唱一首古老的{{location:威尔士}}民歌{{product_name:《白蜡林》}}。届时在{{location:画廊大厅}}中将安放6个音箱进行播放，艺术家还特意回到家乡{{location:格拉斯哥}}，同父亲一起在{{org_name:中国音乐学院}}里为作品录制了具有{{location:中国}}元素的音乐片段。&lt;/p&gt; 
&lt;h2&gt;3. Machine learning bot的named-entity recognition (NER)使用步骤&lt;/h2&gt; 
&lt;p&gt;由于我们大部分的数据都存储在Amazon海外区的Simple Storage Service（S3）中，本文将着重介绍通过海外区Amazon来部署ML bot，详细的步骤可以参考&lt;a href="http://ml-bot.s3-website.cn-north-1.amazonaws.com.cn/deploy/"&gt;ML bot的documentations&lt;/a&gt;（http://ml-bot.s3-website.cn-north-1.amazonaws.com.cn/deploy/）。首先，我们需要在&lt;a href="https://console.aws.amazon.com/cloudformation/home#/stacks/create/template?stackName=ml-bot&amp;amp;templateURL=https://aws-gcr-solutions.s3.amazonaws.com/ml-bot/v1.1.2/aws-ml-bot.template"&gt;Amazon CloudFormation&lt;/a&gt;上创建一个新的堆栈，并导入预先设置好的ML bot的模板。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;随后在&lt;a href="https://console.aws.amazon.com/cloud9/home"&gt;Cloud9控制台&lt;/a&gt;里面，为刚刚创建好的堆栈新建一个环境，在新建过程始终保持使用默认配置并在完成后为该环境赋予一个具有administrator access的identity and access management（IAM） role，有关Amazon Web Service（AWS）的详细信息可以参考相关的&lt;u&gt;Amazon documentations&lt;/u&gt;（https://aws.amazon.com/iam/）。&lt;/p&gt; 
&lt;p&gt;最后，在Amazon的&lt;a href="https://console.aws.amazon.com/cognito/users/"&gt;Cognito&lt;/a&gt;用户池中找到与之前创建的堆栈相同UserPoolId的用户池，在该用户池的配置页面中选择“用户和组”并点击“创建用户”，输入用户名和密码等必要信息之后进行邮件确认。从Amazon Cloudformation下找到创建好的堆栈并在Outputs标签下找到CloudFrontDomain，点击进入该页面并使用刚刚设置好的用户名和密码登录并开始使用ML bot。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 在ML bot的主页面下选择“Get Started”并在下一个页面中选中“Named Entity Recognition”模型，上传训练用的数据集所在的S3地址。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;点击“Start Model Training”并等待模型训练完成，在训练过程中可以通过点击“View logs in CloudWatch”来查看模型的训练情况及accuracy的评分（如下图），ML bot的NER模型在使用我们提供的training data下，accuracy基本稳定在0.9以上并在训练过程中逐渐向1.0接近，说明该模型相对比较稳定。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;训练完成的模型可以使用任意的中文文本字段来进行测试，具体结果如下图。经过训练的ML bot的NER模型成功学习了并预测和提取出了时间和组织名相关的命名实体。该条测试用的文本来自于当天的热门新闻。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;4. API部署及测试&lt;/h2&gt; 
&lt;p&gt;在ML bot的NER模型结果页面的右下角的“Deploy to SageMaker Endpoint”选项可以一键把已经训练好的NER模型部署到Amazon SageMaker Endpoint上作为可调用的API使用，具体的调用方法和结果如下图所示。对比直接在ML bot网站使用NER模型，将模型打包成API使得模型具有更多的灵活性，可以将封装好的模型作为命名实体预测的环节来嵌入到不同的模型流水线中。这一套逻辑和流程不仅操作简单，代码实现也较容易，更可以被应用于多样化的业务场景中，具有一定的普适性。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/quick-solution-of-named-entity-recognition-ner-based-on-aws-machine-learning-bot9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;5. 结论&lt;/h2&gt; 
&lt;p&gt;本文介绍了如何运用Amazon ML bot来快速建立NER模型。用户可以把数据安全的储存在Amazon S3上并导入到该模型中来实现机器学习模型的训练。训练完成的模型在预测准确度上表现良好。模型的调用不仅可以在简易操作的Amazon ML bot页面上直接实现，也可以部署到Amazon Sagemaker Endpoint上作为一个独立的API来调用。我们认为该套方案在具备易操作和易实现的前提下，更具有非常广泛的适用性，能够很好的解决一些企业需要机器学习解决方案同时又缺乏相关领域技术经验与积累的商业痛点。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/andyli.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Andy Li&lt;/h3&gt; 
  &lt;p&gt;现任PwC U.S. Acceleration Center Shanghai office的director，是一位专注于数字化、新兴技术（例如：区块链，增强现实/虚拟现实，人工智能）和基于机器学习以及深度学习的高级分析的创新型领袖。行业经验包括金融服务，医疗和高科技领域。同时也是云技术的积极倡导者，热衷于为客户提供领先的服务交付。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/seanli.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Sean Li&lt;/h3&gt; 
  &lt;p&gt;现任PwC U.S. Acceleration Center Shanghai office的senior data scientist，在解决复杂大数据问题方面的经验丰富同时热衷于研究学习最前端的人工智能技术。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>专为构建者打造：AWS 和开放式 3D 引擎的故事 — 开发人员预览</title>
		<link>https://aws.amazon.com/cn/blogs/china/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview/</link>
				<pubDate>Wed, 08 Sep 2021 03:47:29 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Industries]]></category>
		<category><![CDATA[Amazon Lumberyard]]></category>
		<category><![CDATA[Amazon O3DE]]></category>

		<guid isPermaLink="false">abdd7308ae3dfe43ed919999f44f58c185ad5771</guid>
				<description>我们从游戏和模拟开发人员那里听说，他们想要更多的选项，以便在生产管道中进行协作、自定义和创造性控制。从头开始构建 3D 工具成本高昂，需要数年的开发时间，并需要大量的资源来维护。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 我们从游戏和模拟开发人员那里听说，他们想要更多的选项，以便在生产管道中进行协作、自定义和创造性控制。从头开始构建 3D 工具成本高昂，需要数年的开发时间，并需要大量的资源来维护。这些开发人员最终要么将关键资金花费在重复做别人或者自己已经做过的事情上，要么只好使用难以定制的专有解决方案。&lt;/p&gt; 
&lt;p&gt;为了解决其中一些挑战，我们在 2016 年推出了 Lumberyard 游戏引擎。Lumberyard 提供了完全免费（无特许权使用费或席位许可证）、源代码可用的实时 3D 开发引擎，以便通过云集成进行快速构建、部署和扩展。过去 5 年中，我们不断地为客户改进产品。我们构建了功能强大的组件实体系统和备受欢迎的 Script Canvas 可视化脚本引擎。我们还收购了 Emotion FX 动画编辑器，创建了模块化 Gem 系统，并实施了许多 Twitch 和 AWS 集成。但有一件事从未改变，那就是我们的使命：为所有人提供世界一流的免费 3D 渲染工具。现在，我们要更进一步。&lt;/p&gt; 
&lt;h2&gt;开源之旅&lt;/h2&gt; 
&lt;p&gt;当开始构建 Lumberyard 的后继产品时，我们意识到我们可以做更多事情。如果最终目标是创新，则我们希望使游戏和模拟开发人员能够在开放的社群中与我们并肩合作，这样他们就可以访问技术，为技术做出贡献并推动技术发展。这就是 Linux Foundation &lt;a href="https://youtu.be/6ccjR9qI5YU"&gt;宣布成立 Open 3D Foundation&lt;/a&gt; 的原因，AWS 借助&lt;a href="https://docs.o3de.org/"&gt;开放式 3D 引擎&lt;/a&gt; (O3DE) 为该基金会提供支持。O3DE 是一款支持构建 AAA 级游戏的跨平台开源游戏引擎。作为开源社群的一部分，O3DE 可以提供开发人员实现实时 3D 环境所需的所有工具来扩展游戏和模拟的 3D 开发。该引擎在 Apache 2.0 许可证下授权使用，因此，任何人都可以构建和保留自己的智力资产，并选择回馈项目。&lt;/p&gt; 
&lt;p&gt;我们花了一年多时间来招募合作伙伴，这些合作伙伴拥有相应的资源和专业知识，最重要的是，他们有动力培养自维护社群。我们与 &lt;a href="https://www.linuxfoundation.org/"&gt;Linux Foundation&lt;/a&gt; 合作，将其作为我们值得信赖的专家开源组织机构，因为它是全球管理大型开源项目最好的机构之一。Linux Foundation 可以提供如此大规模开源项目所需的专家管理水平。我们很高兴能够得到众多合作伙伴的支持，他们与我们一样大力支持为游戏和模拟开发人员提供的选择。这些合作伙伴包括：Accelbyte、Adobe、Apocalypse Studios、Audiokinetic、Backtrace.io、Carbonated、Futurewei、GAMEPOCH、Genvid Technologies、Hadean、Huawei、HERE Technologies、Intel、International Game Developers Association、Kythera AI、Niantic、Open Robotics、PopcornFX、Red Hat、Rochester Institute of Technology、SideFX、Tafi、TLM Partners 和 Wargaming。与成熟的开源基金会合作还意味着打造平衡的生态系统，推动双方共同取得成功。这将产生飞轮效应，影响开源社群的方向和创新以及构建产品的合作伙伴和项目开发人员。最终，这种协作会推动更新的创新。这种模式让我们持续将工作重点放在客户对 Amazon 和 AWS 的期望上，包括大规模支持、云渲染、云中的工作室以及引擎本身的许多原生功能等创新。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;那么发生了什么变化？ 这是使用开源许可证的 Lumberyard 吗？&lt;/h3&gt; 
&lt;p&gt;简单来说，有很多变化！ 没错，它是开源引擎，根据宽松的 Apache 2.0 许可证授予许可。但是，O3DE 与之前的 Lumberyard 截然不同。我们在很大程度上依赖构建 Lumberyard 的经验，迭代和改进了 O3DE，以实现最终的协作和创造性控制。我们保留了客户最喜欢的 Lumberyard 相关部分，并对其余部分进行了重大修改。我们的目标是构建一款能够在开源环境中经受住时间考验的引擎。由于游戏引擎往往是整体式的，因此，我们在很大程度上倾向于构建具有可扩展性的模块化引擎，从一开始就采用开放标准工具。但是，我们仍然不满意，因此，我们添加了新预制系统、新构建系统、可扩展的 UI、许多新云功能、大量数学库优化、新网络功能以及许许多多的性能改进。此外，我们甚至添加了全新的 PBR 渲染器，它能够通过光线追踪和 GI 支持实现前向+ 和延迟渲染！&lt;/p&gt; 
&lt;h2&gt;模块化&lt;/h2&gt; 
&lt;p&gt;我们从头开始将该引擎重新设计为模块化引擎，因此，几乎所有引擎部件都是一个库。开发人员可以完全替换图形渲染器、音频子系统、编辑器、语言支持、网络堆栈、物理系统和其他库，而不影响其他库。核心引擎模块和任何附加组件或插件统称为“Gem”。开发人员可以通过引入 30 多种功能和工具中的任何一种（而不是引入所有功能和工具）来精简项目。他们也可以将这些功能和工具作为独立库来实施。如果开发人员已经拥有引擎并希望减少技术债务或更新代码，可以从开源项目中轻松选择所需的功能，然后将其实施到自己的技术堆栈中。他们也可以创建并合并自己的堆栈。借助 O3DE 的模块化架构添加新功能非常简单，这样开发人员就可以持续创新。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;开源友好型构建系统&lt;/h2&gt; 
&lt;p&gt;对于开发人员来说，模块化还必须易于理解并允许快速开发，因此，我们决定将整个构建系统移到开源 CMake 系统中。这一选择为各种 IDE（例如 Visual Studio、XCode 等）提供了更好的 CTest、插件库、分析、编辑并继续、快速代码生成及本机项目生成的支持。这种新方法通过适当的依赖关系树来构建所选的目标，并确保只重新构建实际的依赖关系，以便提高迭代开发的速度，进而节省时间。这种模块化特性还允许我们简化项目和 Gem 管理，方法是：删除所有二进制格式，然后将其移到可使用 CMake 编写脚本的人类可读的 JSON 文件。因此，只需简单地更改 JSON 文件中的某一行，即可在项目中添加或删除 Gem。通过博客&lt;a href="https://aws.amazon.com/blogs/gametech/lumberyard-build-system/"&gt;详细了解&lt;/a&gt; Lumberyard 构建系统的未来。&lt;/p&gt; 
&lt;h2&gt;引擎即 SDK&lt;/h2&gt; 
&lt;p&gt;Lumberyard 开发人员会发现引擎已经发生了很大的变化。它的构建类似于 SDK，因为对于引擎模块和 Gem，它可以以预编译的形式提供，这可被视为是一种“引擎即 SDK”方法。同样，在项目发生变化时，不需要重新编译预编译的库或 Gem。而且，当新引擎版本发布时，开发人员可以更新核心 Gem，只需解决项目代码本身的编译问题即可。工作室现在可以轻松自定义引擎组件，并根据需要用特定自定义模块替换预构建组件。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Atom 渲染器&lt;/h2&gt; 
&lt;p&gt;另一个重大变化是 Atom 渲染器，正如预期的那样，它作为 Gem 交付。该渲染器通过提供基于物理的现代渲染器 (PBR) 来支持多个平台，该渲染器符合 ACES 色彩空间标准并完全支持 Vulkan、Metal（开发中）和 DirectX 12 的光线追踪。Atom 随附全局光照 (GI) 和前向+ 渲染，开箱即用，并支持延迟渲染管道。与 O3DE 本身一样，Atom 具有模块化、可编写脚本和数据驱动等特点。我们甚至编写了一种全新的着色语言，称为 AZSL。这种语言利用 Atom 的数据驱动功能，因此，开发人员可以随着新硬件接口的出现不断创新。没错，Atom 是开源且免费的，就像 O3DE 中的其他所有功能一样。请参阅&lt;a href="https://aws.amazon.com/blogs/gametech/splitting-the-atom-introducing-lumberyards-new-photorealistic-renderer/"&gt;这篇博文&lt;/a&gt;，详细了解 Atom 渲染器。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;网络&lt;/h2&gt; 
&lt;p&gt;O3DE 中包含了全新的网络堆栈，它具有高度灵活的数据驱动模型，支持 TCP/UDP，并在简单的 API 背后抽象了低延迟传输层。该堆栈支持加密和压缩，并具有内置模拟器，用于延迟、抖动、重新排序和丢失。为了确保最低延迟和最高保真度，它支持通过无序不可靠的数据复制进行实体复制、本地预测延迟补偿、针对服务器权限的向后协调，及支持自动去同步检测和修正的可拆分玩家行为。为了确保开发人员可以使用不同的服务器型号，该堆栈支持开箱即用的玩家托管服务器和专用服务器型号。请参阅&lt;a href="https://aws.amazon.com/blogs/gametech/building-battle-tested-network-transport/"&gt;这篇博文&lt;/a&gt;，获取更多开发详情。&lt;/p&gt; 
&lt;h2&gt;更快、更轻、性能更高&lt;/h2&gt; 
&lt;p&gt;相较于它的前辈 Lumberyard，O3DE 更轻便、速度更快、性能更高。我们的工程师删除了超过 200 万行旧代码冗余，为开源做好准备。我们创建了新的高性能数学库，这些库利用现代 CPU 和当前 SIMD 指令集。数学是精彩游戏和模拟的核心，我们确保了我们的客户、贡献者和社群拥有非常坚实的工作基础。最终结果将是，帧率提高，平台支持得到改进（尤其是在 ARM 设备上），准确性提高，及可用于动画、特效和游戏运行的计算资源增加。毕竟，3D 引擎中的几乎所有内容都与数学有关！ 请参阅&lt;a href="https://aws.amazon.com/blogs/gametech/building-a-smarter-foundation-math-improvements-in-lumberyard/"&gt;这篇博文&lt;/a&gt;，详细了解我们的高性能数学工作。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;支持云&lt;/h2&gt; 
&lt;p&gt;我们额外添加了云功能，包括对 Amazon Kinesis、AWS Lambda、Amazon Cognito、Amazon CloudWatch、AWS CloudTrail、AWS IAM、Amazon GameLift 和更新的 AWS C++ SDK 的新支持。借助这些与云服务的深度集成，开发人员能够交付具有可自定义支持功能的游戏和模拟，快速创新，并吸引和留住现有玩家和新玩家。随着合作伙伴和社群不断增加 AWS 之外的更多选项，O3DE 的云功能将进一步增加。此外，在未来几个月里，AWS 将继续构建更多云功能，并支持其他文件格式，涵盖一系列新用例。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;生产力和可扩展性&lt;/h2&gt; 
&lt;p&gt;工具和管道实施对于简化生产所需的时间同样至关重要。为了帮助加速自定义，我们扩展了 UI 工具，它使用可访问代码接口的 Python 扩展和 Qt 来创建自定义编辑器组件。我们通过新的步骤前和步骤后 Python 绑定极大地更新了资产创建，以允许 FBX 和材料处理的动态处理和自定义行为。这些绑定使技术类游戏艺术家能够编写可拆分、分配或重新定位资产的 Python 脚本，以及从任何输入源创建自定义材料。&lt;/p&gt; 
&lt;p&gt;许多其他功能也发生了变化，以便社群以新方式对其扩展。Script Canvas 现在支持通过未来本机代码支持编译为 Lua，并通过我们的可扩展行为上下文管理器进行脚本绑定。我们已经从 Lumberyard 管理游戏内部资产的“切片”模型转向了大家都很熟悉的预制模型。我们的模块化标准接口使开发人员能够针对其他 Gem 接口执行直接函数调用，并提供 IDE 自动完成支持。总体而言，我们的目标之一是使开发人员能够在自己的项目中发现和实施功能（无论是整个还是部分功能）。&lt;/p&gt; 
&lt;h2&gt;后续行动&lt;/h2&gt; 
&lt;p&gt;开放式 3D 引擎目前已提供开发人员预览版，我们的团队正在努力工作，争取在今年晚些时候提供生产就绪型版本。我们很高兴能与社群和其他 Open 3D Foundation 合作伙伴合作，在未来几个月和几年里不断为引擎添加更多内容。我们将与 Linux Foundation、合作伙伴和大学合作，以帮助实现更多创新，开展令人兴奋的即将宣布的年度 O3DE 新活动，以及举办全球行业展览和骇客马拉松。&lt;/p&gt; 
&lt;p&gt;我们希望这项开源工作提供游戏和模拟开发平台，任何人都可以利用该平台快速构建更加精彩的游戏和实时模拟。我们相信，现在正是发展 3D 可视化和工具业务的理想时机，希望您能加入我们的旅程。正如我们在 Amazon 常说的那样，现在我们仍然在“第一天”。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/built-for-builders-the-story-of-aws-and-the-open-3d-engine-developer-preview8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;请访问 &lt;a href="https://docs.o3de.org/"&gt;docs.o3de.org&lt;/a&gt; 并&lt;a href="https://youtu.be/6ccjR9qI5YU"&gt;观看视频&lt;/a&gt;，详细了解开放式 3D 引擎计划。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;h3 class="lb-h4"&gt;Amar Mehta&lt;/h3&gt; 
  &lt;p&gt;Amar Mehta 是 Amazon 游戏科技的模拟和视频游戏 3D 引擎技术团队领导。视频游戏、电影、汽车、建筑、工程和零售行业的开发人员使用该技术，在 AWS 业界领先的云计算服务上实时创建高保真内容。在加入 AWS 之前，Amar 曾领导 Amazon 零售视频游戏部门的多项工作，为全球数十亿玩家带来 AAA 级游戏和独立游戏体验。他曾在初创公司和财富 500 强公司担任技术和业务领导职务。Mehta 先生热衷于促进公平和多元化，他坚信游戏能够降低社会壁垒，改善所有人获得技术的能力。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;h3 class="lb-h4"&gt;Royal O’Brien&lt;/h3&gt; 
  &lt;p&gt;Royal O’Brien 是 Amazon 的一位负责人，其工作是与内部和外部客户合作，解决他们的技术和业务需求。他的大部分时间花在与合作伙伴合作上，为 Open 3D Foundation 创建开源实践和程序。在加入 Amazon 之前，Royal 曾在美国海军陆战队服役，并在模拟和视频游戏行业工作超过 25 年。他曾担任工程师和高管，负责企业发展、风险投资、企业谈判和战略营销计划。他创立并退出了多家公司，帮助为多家财富 500 强公司提供服务和许可技术。作为一名工程师，他拥有视频、电话和数字分发技术领域的多项专利。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>AppSync调试方法</title>
		<link>https://aws.amazon.com/cn/blogs/china/appsync-debugging-method/</link>
				<pubDate>Mon, 06 Sep 2021 04:34:16 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[AWS AppSync]]></category>

		<guid isPermaLink="false">4c5a3c82b2b52a29bbb651679d6013515f529091</guid>
				<description>GraphQL是一种新的API规范及查询语言，它按照客户的查询需求“不多不少”准确返回查询结果。它通过简明的类型系统描述查询及返回结果。GraphQL 通常通过单入口来提供 HTTP 服务的完整功能，这一实现方式与暴露一组 URL 且每个 URL 只暴露一个资源的 REST API 不同。GraphQL可以通过 GraphQL schema 的持续演进来避免版本控制。</description>
								<content:encoded>&lt;h2&gt;一. GraphQL简介&lt;/h2&gt; 
&lt;p&gt;GraphQL是一种新的API规范及查询语言，它按照客户的查询需求“不多不少”准确返回查询结果。它通过简明的类型系统描述查询及返回结果。GraphQL 通常通过单入口来提供 HTTP 服务的完整功能，这一实现方式与暴露一组 URL 且每个 URL 只暴露一个资源的 REST API 不同。GraphQL可以通过 GraphQL schema 的持续演进来避免版本控制。&lt;/p&gt; 
&lt;p&gt;关于GraphQL的规范请参考：&lt;a href="https://graphql.org/"&gt;https://graphql.org/&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;二.&amp;nbsp; AppSync简介&lt;/h2&gt; 
&lt;p&gt;AWS AppSync 是一项完全托管的服务，通过处理与 AWS DynamoDB、Lambda 等数据源之间繁重的安全连接任务来简化 GraphQL API 的开发。添加缓存以提高性能、订阅以支持实时更新以及客户端数据存储以使离线客户端保持同步等操作也一样轻松简单。&lt;/p&gt; 
&lt;p&gt;通过托管的 GraphQL 订阅，AWS AppSync 可以通过 Websocket 向数百万客户端推送实时数据更新。对于移动和 Web 应用程序，AppSync 还可在设备离线时提供本地数据访问，并在它们重新上线后提供支持自定义冲突解决方案的数据同步功能。&lt;/p&gt; 
&lt;p&gt;关于AppSync的更详细的介绍请参考：&lt;a href="https://aws.amazon.com/cn/appsync/"&gt;https://aws.amazon.com/cn/appsync/&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;三. AppSync常见调试工具&lt;/h2&gt; 
&lt;p&gt;AppSync支持以下认证授权方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;API Key&lt;/li&gt; 
 &lt;li&gt;IAM&lt;/li&gt; 
 &lt;li&gt;OpenID Connect&lt;/li&gt; 
 &lt;li&gt;Lambda&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不同的授权方式，直接影响调试的复杂度。本文以最为常用的API Key及IAM授权方式进行分析。&lt;/p&gt; 
&lt;table border="1" width="433"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2" width="87"&gt;tool&lt;/td&gt; 
   &lt;td colspan="2" width="173"&gt;Query and Mutation&lt;/td&gt; 
   &lt;td colspan="2" width="173"&gt;Real-time Subscription&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="87"&gt;API Key&lt;/td&gt; 
   &lt;td width="87"&gt;IAM&lt;/td&gt; 
   &lt;td width="87"&gt;API Key&lt;/td&gt; 
   &lt;td width="87"&gt;IAM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="87"&gt;Postman&lt;/td&gt; 
   &lt;td width="87"&gt;√&lt;/td&gt; 
   &lt;td width="87"&gt;√&lt;/td&gt; 
   &lt;td width="87"&gt;√&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="87"&gt;websocat&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;√&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="87"&gt;wscat&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;√&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="87"&gt;curl&lt;/td&gt; 
   &lt;td width="87"&gt;√&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="87"&gt;wget&lt;/td&gt; 
   &lt;td width="87"&gt;√&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
   &lt;td width="87"&gt;x&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;四. AppSync的WebSocket验证授权方法&lt;/h2&gt; 
&lt;p&gt;AppSync的验证授权遵循&lt;a href="https://docs.aws.amazon.com/general/latest/gr/signing_aws_api_requests.html"&gt;Amazon Web Service v4 Signature&lt;/a&gt;。但是对于real-time subscription，须遵循&lt;a href="https://docs.aws.amazon.com/appsync/latest/devguide/real-time-websocket-client.html"&gt;https://docs.aws.amazon.com/appsync/latest/devguide/real-time-websocket-client.html&lt;/a&gt;，完成websocket协议上的验证授权。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 从上述图例，我们可以明确：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Query和Mutation的endpoint协议为HTTPS。&lt;/li&gt; 
 &lt;li&gt;Real-Time subscription的endpoint协议为WebSocket。即Real-Time subscription无法接入协议为 HTTPS的endpoint。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;在进行Real-Time subscription时，我们需要指定WebSocket sub protocol：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;Sec-WebSocket-Protocol：graphql-ws&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过aws cli我们可以获得AppSync的endpoint 信息。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;aws appsync get-graphql-api --api-id b553xzgnijdtjjvli67zc3zmly
{
    "graphqlApi": {
        "name": "demo1",
        "apiId": "b553xzgnijdtjjvli67zc3zmly",
        "authenticationType": "API_KEY",
        "logConfig": {
            "fieldLogLevel": "ERROR",
            "cloudWatchLogsRoleArn": "arn:aws-cn:iam::162611943124:role/service-role/appsync-graphqlapi-logs-cn-north-1",
            "excludeVerboseContent": false
        },
        "arn": "arn:aws-cn:appsync:cn-north-1:162611943124:apis/b553xzgnijdtjjvli67zc3zmly",
        "uris": {
            "REALTIME": "wss://vlvwhsddczatlel4l4b4k4ygri.appsync-realtime-api.cn-north-1.amazonaws.com.cn/graphql",
            "GRAPHQL": "https://vlvwhsddczatlel4l4b4k4ygri.appsync-api.cn-north-1.amazonaws.com.cn/graphql"
        },
        "tags": {},
        "xrayEnabled": false
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;所有的验证授权都是在”GRAPHQL” endpoint上完成，对于Query和Mutation非常易于理解；而实时订阅首先从在”GRAPHQL” endpoint 上获得验证授权信息，然后在”REALTIME” endpoint上进行数据的交互。&lt;/p&gt; 
&lt;p&gt;客户端在handshake过程中完成与AppSync的验证授权。验证授权过程中必须携带的信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;header&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;base64编码的字符串化的JSON对象。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;payload&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;base64编码的负荷。&lt;/p&gt; 
&lt;p&gt;API KEY的验证授权&lt;/p&gt; 
&lt;p&gt;基于API KEY的验证授权，其header JSON对象为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{

&amp;nbsp;&amp;nbsp;&amp;nbsp; "host":"example1234567890000.appsync-api.us-east-1.amazonaws.com",

&amp;nbsp;&amp;nbsp;&amp;nbsp; "x-api-key":"da2-12345678901234567890123456"

}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其payload JSON对象为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;WebSocket连接串为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;wss://host/graphql?header&amp;amp;amp;payload&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;例如：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;wss://vlvwhsddczatlel4l4b4k4ygri.appsync-realtime-api.cn-north-1.amazonaws.com.cn/graphql?header=eyJob3N0IjogInZsdndoc2RkY3phdGxlbDRsNGI0azR5Z3JpLmFwcHN5bmMtYXBpLmNuLW5vcnRoLTEuYW1hem9uYXdzLmNvbS5jbiIsICJ4LWFwaS1rZXkiOiAiZGEyLWQ3YW5lcDdtYXJobnZuenp6NTQzbjY0ZHZ1In0=&amp;amp;amp;payload=e30=&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;基于IAM的验证授权&lt;/p&gt; 
&lt;p&gt;基于IAM的验证授权，验证授权http的信息汇总为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  url: "https://example1234567890000.appsync-api.us-east-1.amazonaws.com/graphql/connect",
  data: "{}",
  method: "POST",
  headers: {
    "accept": "application/json, text/javascript",
    "content-encoding": "amz-1.0",
    "content-type": "application/json; charset=UTF-8",
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;基于上述内容进行V4的签名认证，基于规范“/connect”被添加到cannocial uri后，其正确内容应为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;canonical_uri = '/graphql/connect'&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;基于上述信息完成V4签名后，基于IAM验证授权的header JSON对象为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
    "accept": "application/json, text/javascript",
    "content-encoding": "amz-1.0",
    "content-type": "application/json; charset=UTF-8",
    "host": "vlvwhsddczatlel4l4b4k4ygri.appsync-api.cn-north-1.amazonaws.com.cn",
    "x-amz-date": "20210903T065522Z",
    "Authorization": "AWS4-HMAC-SHA256 Credential=AKIASLXDNK3KFKRBJQU3/20210903/cn-north-1/appsync/aws4_request, SignedHeaders=host;x-amz-date, Signature=a50cc5ab866de3381e5c85ae0fefefb46f7522d62e0a79fb95f9340975382a75"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其payload JSON对象为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其wss链接串为：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;wss://vlvwhsddczatlel4l4b4k4ygri.appsync-realtime-api.cn-north-1.amazonaws.com.cn/graphql?header=eyJhY2NlcHQiOiAiYXBwbGljYXRpb24vanNvbiwgdGV4dC9qYXZhc2NyaXB0IiwgImNvbnRlbnQtZW5jb2RpbmciOiAiYW16LTEuMCIsICJjb250ZW50LXR5cGUiOiAiYXBwbGljYXRpb24vanNvbjsgY2hhcnNldD1VVEYtOCIsICJob3N0IjogInZsdndoc2RkY3phdGxlbDRsNGI0azR5Z3JpLmFwcHN5bmMtYXBpLmNuLW5vcnRoLTEuYW1hem9uYXdzLmNvbS5jbiIsICJ4LWFtei1kYXRlIjogIjIwMjEwOTAzVDA2NTUyMloiLCAiQXV0aG9yaXphdGlvbiI6ICJBV1M0LUhNQUMtU0hBMjU2IENyZWRlbnRpYWw9QUtJQVNMWEROSzNLRktSQkpRVTMvMjAyMTA5MDMvY24tbm9ydGgtMS9hcHBzeW5jL2F3czRfcmVxdWVzdCwgU2lnbmVkSGVhZGVycz1ob3N0O3gtYW16LWRhdGUsIFNpZ25hdHVyZT1hNTBjYzVhYjg2NmRlMzM4MWU1Yzg1YWUwZmVmZWZiNDZmNzUyMmQ2MmUwYTc5ZmI5NWY5MzQwOTc1MzgyYTc1In0=&amp;amp;amp;payload=e30=&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;五. Postman调试&lt;/h2&gt; 
&lt;h3&gt;（一）基于API Key的Query调试&lt;/h3&gt; 
&lt;p&gt;选择授权类型为：API Key，设置key：x-api-key，及其值。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 输入查询内容：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;返回查询结果：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;（二）基于API Key的Real-Time Subscription&lt;/h3&gt; 
&lt;p&gt;第一步，选择New&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 第二步，选择WebSocket Request Beta&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 第三步，在“Params”内依次填入base64编码的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;header&lt;/li&gt; 
 &lt;li&gt;payload&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;第四步，在Headers内填入：&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method8.png" width="624" height="78"&gt;&lt;br&gt; 第五步，在“Enter server URL”填入wss endpoint,然后点connect。&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method9.png" width="624" height="78"&gt;第六步，在“Compose Message”内填入订阅信息：&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method10.png" width="624" height="78"&gt;然后点“Send”&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 当有数据更新时，实时接收到更新&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;（三）基于IAM的实时订阅&lt;/h3&gt; 
&lt;p&gt;由于涉及到V4签名，基于IAM的实时订阅无法通过Postman等工具进行测试。本文将基于python WebSocket进行测试。&lt;/p&gt; 
&lt;p&gt;代码可以从https://github.com/picomy/appsync-websocket下载。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import sys, os, hashlib, hmac
from base64 import b64encode, decode
from datetime import datetime
from uuid import uuid4
import websocket
import threading
import json

# ************************** Reference **************************
# https://docs.aws.amazon.com/appsync/latest/devguide/real-time-websocket-client.html
# https://docs.aws.amazon.com/general/latest/gr/sigv4-signed-request-examples.html
# https://docs.aws.amazon.com/apigateway/api-reference/signing-requests/
# ************************** Reference **************************

# The client connect to wss_url through websocket protocol 
wss_url = 'wss://vlvwhsddczatlel4l4b4k4ygri.appsync-realtime-api.cn-north-1.amazonaws.com.cn/graphql'

# The client will authenticate itself from http_url through http protocol
# Query and mutation will be ran within http_url endpoint
http_url = 'https://vlvwhsddczatlel4l4b4k4ygri.appsync-api.cn-north-1.amazonaws.com.cn/graphql'

host = http_url.replace('https://','').replace('/graphql','')
# IAM authentication method
method = 'POST'
region = 'cn-north-1'
service = 'appsync'
access_key = 'xxxxxxxxxx'
secret_key = 'xxxxxxxxxx'
canonical_uri = '/graphql/connect' 
canonical_querystring = ''
# payload type has to be string
payload = '{}'
accept = "application/json, text/javascript"
content_encoding = "amz-1.0"
content_type = "application/json; charset=UTF-8"

# ********************************** AWS V4 Signature **********************************
def sign(key, msg):
    return hmac.new(key, msg.encode('utf-8'), hashlib.sha256).digest()

def getSignatureKey(key, dateStamp, regionName, serviceName):
    kDate = sign(('AWS4' + key).encode('utf-8'), dateStamp)
    kRegion = sign(kDate, regionName)
    kService = sign(kRegion, serviceName)
    kSigning = sign(kService, 'aws4_request')
    return kSigning

def gen_auth(servic_name, region_name, ak, sk, canonical_uri, canonical_querystring, payload):
    t = datetime.utcnow()
    amzdate = t.strftime('%Y%m%dT%H%M%SZ')
    datestamp = t.strftime('%Y%m%d') # Date w/o time, used in credential scope
    payload_hash = hashlib.sha256(payload.encode('utf-8')).hexdigest()
    canonical_headers = 'host:' + host + '\n' + 'x-amz-date:' + amzdate + '\n'
    signed_headers = 'host;x-amz-date'
    canonical_request = method + '\n' + canonical_uri + '\n' + canonical_querystring + '\n' + canonical_headers + '\n' + signed_headers + '\n' + payload_hash
    algorithm = 'AWS4-HMAC-SHA256'
    credential_scope = datestamp + '/' + region + '/' + service + '/' + 'aws4_request'
    string_to_sign = algorithm + '\n' +  amzdate + '\n' +  credential_scope + '\n' +  hashlib.sha256(canonical_request.encode('utf-8')).hexdigest()
    signing_key = getSignatureKey(secret_key, datestamp, region, service)
    signature = hmac.new(signing_key, (string_to_sign).encode('utf-8'), hashlib.sha256).hexdigest()
    authorization_header = algorithm + ' ' + 'Credential=' + access_key + '/' + credential_scope + ', ' +  'SignedHeaders=' + signed_headers + ', ' + 'Signature=' + signature
    return ({'auth_date':amzdate,'auth_header':authorization_header})

# *************************** AppSync: websocket ***************************
# Generate IAM authentication header
auth = gen_auth(service,region,access_key,secret_key,canonical_uri,canonical_querystring,payload)

iam_header = {
    'accept': accept,
    'content-encoding': content_encoding,
    'content-type': content_type,
    'host': host,
    'x-amz-date': auth['auth_date'],
    'Authorization': auth['auth_header']
}

# GraphQL subscription Registration object
GQL_SUBSCRIPTION = json.dumps({
        'query': 'subscription MySubscription {subscribeToEventComments(eventId: "0534ad04-fd29-49d6-815a-fa64a80979c1") {commentId content createdAt eventId } }',
        'variables': {}
})


# Set up Timeout Globals
timeout_timer = None
timeout_interval = 10
# Subscription ID (client generated)
SUB_ID = str(uuid4())

# Calculate UTC time in ISO format (AWS Friendly): YYYY-MM-DDTHH:mm:ssZ
def header_time():
    return datetime.utcnow().isoformat(sep='T',timespec='seconds') + 'Z'

# Encode Using Base 64
def header_encode( header_obj ):
    return b64encode(json.dumps(header_obj).encode('utf-8')).decode('utf-8')

# reset the keep alive timeout daemon thread
def reset_timer( ws ):
    global timeout_timer
    global timeout_interval

    if (timeout_timer):
        timeout_timer.cancel()
    timeout_timer = threading.Timer( timeout_interval, lambda: ws.close() )
    timeout_timer.daemon = True
    timeout_timer.start()

# Socket Event Callbacks, used in WebSocketApp Constructor
def on_message(ws, message):
    global timeout_timer
    global timeout_interval

    print('### message ###')
    print('&amp;lt;&amp;lt; ' + message)

    message_object = json.loads(message)
    message_type   = message_object['type']

    if( message_type == 'ka' ):
        reset_timer(ws)

    elif( message_type == 'connection_ack' ):
        timeout_interval = int(json.dumps(message_object['payload']['connectionTimeoutMs']))
        payload = GQL_SUBSCRIPTION
        canonical_uri ='/graphql'
        sub_auth = gen_auth(service,region,access_key,secret_key,canonical_uri,canonical_querystring,payload)
        register = {
            'id': SUB_ID,
            'payload': {
                'data': GQL_SUBSCRIPTION,
                'extensions': {
                    'authorization': {
                        'host': host,
                        'Authorization': sub_auth['auth_header'],
                        'x-amz-date': sub_auth['auth_date']
                    }
                }
            },
            'type': 'start'
        }
        start_sub = json.dumps(register)
        print('&amp;gt;&amp;gt; '+ start_sub )
        ws.send(start_sub)

    elif(message_type == 'data'):
        deregister = {
            'type': 'stop',
            'id': SUB_ID
        }
        end_sub = json.dumps(deregister)
        print('&amp;gt;&amp;gt; ' + end_sub )
        ws.send(end_sub)

    elif(message_object['type'] == 'error'):
        print ('Error from AppSync: ' + message_object['payload'])
    
def on_error(ws, error):
    print('### error ###')
    print(error)

def on_close(ws):
    print('### closed ###')

def on_open(ws):
    print('### opened ###')
    init = {
        'type': 'connection_init'
    }
    init_conn = json.dumps(init)
    print('&amp;gt;&amp;gt; '+ init_conn)
    ws.send(init_conn)

if __name__ == '__main__':
    # Uncomment to see socket bytestreams
    #websocket.enableTrace(True)

    # Set up the connection URL, which includes the Authentication Header
    #   and a payload of '{}'.  All info is base 64 encoded
    connection_url = wss_url + '?header=' + header_encode(iam_header) + '&amp;amp;payload=e30='

    # Create the websocket connection to AppSync's real-time endpoint
    #  also defines callback functions for websocket events
    #  NOTE: The connection requires a subprotocol 'graphql-ws'
    print( 'Connecting to: ' + connection_url )

    ws = websocket.WebSocketApp( connection_url,
                            subprotocols=['graphql-ws'],
                            on_open = on_open,
                            on_message = on_message,
                            on_error = on_error,
                            on_close = on_close,)

    ws.run_forever()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;实际运行结果：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/AppSync debugging method13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/picomy.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;杨帅军&lt;/h3&gt; 
  &lt;p&gt;资深数据架构师，专注于数据处理。目前主要为车企提供数据治理服务。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>Amazon Managed Grafana 现已全面推出，并具有许多新功能</title>
		<link>https://aws.amazon.com/cn/blogs/china/amazon-managed-grafana-is-now-generally-available-with-many-new-features/</link>
				<pubDate>Fri, 03 Sep 2021 13:36:50 +0000</pubDate>
		<dc:creator><![CDATA[Danilo Poccia]]></dc:creator>
				<category><![CDATA[News]]></category>

		<guid isPermaLink="false">d35bdf870737959a67f2dba3bb762a65b082508d</guid>
				<description>12 月，我们推出了 Amazon Managed Grafana 的预览版，这是一项与 Grafana Labs 合作开发的完全托管服务，可让您轻松使用开源版本和企业版 Grafana 来可视化和分析多个来源的数据。借助 Amazon Managed Grafana，您可以分析指标、日志和跟踪，而无需预置服务器或配置和更新软件。</description>
								<content:encoded>&lt;p&gt;12 月，我们推出了 &lt;a href="https://aws.amazon.com/grafana/"&gt;Amazon Managed Grafana&lt;/a&gt; 的&lt;a href="https://aws.amazon.com/blogs/aws/announcing-amazon-managed-grafana-service-in-preview/"&gt;预览版&lt;/a&gt;，这是一项&lt;a href="https://grafana.com/blog/2020/12/15/announcing-amazon-managed-service-for-grafana/"&gt;与 Grafana Labs 合作开发&lt;/a&gt;的完全托管服务，可让您轻松使用开源版本和企业版 &lt;a href="https://grafana.com/"&gt;Grafana&lt;/a&gt; 来可视化和分析多个来源的数据。借助 Amazon Managed Grafana，您可以分析指标、日志和跟踪，而无需预置服务器或配置和更新软件。&lt;/p&gt; 
&lt;p&gt;在预览期间，Amazon Managed Grafana 增加了很多&lt;a href="https://aws.amazon.com/blogs/mt/amazon-managed-service-for-grafana-amg-preview-updated-with-new-capabilities/"&gt;新的功能&lt;/a&gt;。今天，我很高兴地宣布，Amazon Managed Grafana 现已&lt;strong&gt;全面推出&lt;/strong&gt;，并附加全新功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;Grafana 现已&lt;a href="https://grafana.com/docs/grafana/latest/whatsnew/whats-new-in-v8-0/"&gt;升级至版本 8&lt;/a&gt;，并提供了新的数据源、可视化和功能，包括您只需构建一次即可在多个控制面板上重复使用的库面板、一个用于快速查找和查询指标的 Prometheus 指标浏览器，以及全新的状态时间表和状态历史可视化。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;要在 Amazon Managed Grafana 工作区中集中查询其他数据源，您现在可以使用 &lt;a href="https://grafana.com/grafana/plugins/simpod-json-datasource/"&gt;JSON 数据源插件&lt;/a&gt;来查询数据。您现在还可以查询 &lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;、&lt;a href="https://www.sap.com/products/hana.html"&gt;SAP HANA&lt;/a&gt;、&lt;a href="https://www.salesforce.com/"&gt;Salesforce&lt;/a&gt;、&lt;a href="https://www.servicenow.com/"&gt;ServiceNow&lt;/a&gt;、&lt;a href="https://www.atlassian.com/software/jira"&gt;Atlassian Jira&lt;/a&gt; 以及更多数据源。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;您可以使用 &lt;a href="https://docs.aws.amazon.com/grafana/latest/userguide/Using-Grafana-APIs.html"&gt;Grafana API 密钥&lt;/a&gt;来发布您自己的控制面板或以编程方式访问您的 Grafana 工作区。例如，这是一个可用于添加数据源和控制面板的 &lt;a href="https://aws-observability.github.io/aws-o11y-recipes/recipes/amg-automation-tf/"&gt;Terraform 配方&lt;/a&gt;。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;您可以使用&lt;a href="https://en.wikipedia.org/wiki/SAML_2.0"&gt;安全断言标记语言 2.0 (SAML 2.0)&lt;/a&gt; 来启用对 Amazon Managed Grafana 工作区的单点登录。我们与以下身份提供商 (IdP) 合作，以便在启动时将其集成：&lt;a href="https://www.cyberark.com/"&gt;Cyber​​Ark&lt;/a&gt;、&lt;a href="https://www.okta.com/"&gt;Okta&lt;/a&gt;、&lt;a href="https://www.onelogin.com/"&gt;OneLogin&lt;/a&gt;、&lt;a href="https://www.pingidentity.com/"&gt;Ping Identity&lt;/a&gt; 和 &lt;a href="https://azure.microsoft.com/en-us/services/active-directory/"&gt;Azure Active Directory&lt;/a&gt;。&lt;/li&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;&lt;a title="" href="https://aws.amazon.com/cloudtrail/"&gt;AWS CloudTrail&lt;/a&gt; 会捕获来自 Amazon Managed Grafana 控制台的所有调用以及对 Amazon Managed Grafana API 操作的代码调用。通过这种方式，您可以记录用户、角色或 AWS 服务在 Amazon Managed Grafana 中执行的操作。此外，您现在可以审核 Amazon Managed Grafana 工作区中发生的突变，诸如控制面板被删除或者数据源权限被更改。&lt;/li&gt; 
 &lt;li&gt;该服务在 10 个 &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/#Regions"&gt;AWS 区域&lt;/a&gt;（完整列表位于文章末尾）推出。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;让我们快速演练一下，看看这在实践中是如何运作的。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;使用 Amazon Managed Grafana&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;在 &lt;a href="https://console.aws.amazon.com/grafana/home"&gt;Amazon Managed Grafana 控制台&lt;/a&gt;中，我选择&lt;strong&gt;创建工作区&lt;/strong&gt;。“工作区”是逻辑上隔离的、高度可用的 Grafana 服务器。我输入工作区的名称和描述，然后选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-create-workspace.png"&gt;&lt;img class="aligncenter size-large wp-image-53771" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-create-workspace-1024x567.png" alt="控制台屏幕截图。" width="1024" height="567"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我可以通过 SAML 使用 &lt;a href="https://aws.amazon.com/single-sign-on/"&gt;AWS Single Sign-On (AWS SSO)&lt;/a&gt; 或外部身份提供商对我工作区的用户进行身份验证。为简单起见，我选择 AWS SSO。在后文中，我将展示 SAML 身份验证的工作原理。如果这是您第一次使用 AWS SSO，则您可以查看&lt;a href="https://docs.aws.amazon.com/singlesignon/latest/userguide/prereqs.html"&gt;文档中的先决条件（例如，设置 AWS Organizations）&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/05/amg-auth.png"&gt;&lt;img class="aligncenter wp-image-53844 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/05/amg-auth-1024x670.png" alt="控制台屏幕截图。" width="1024" height="670"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;然后，我选择&lt;strong&gt;服务托管&lt;/strong&gt;权限类型。这样，Amazon Managed Grafana 会自动预置必要的 IAM 权限，以便访问我在下一步中要选择的 AWS 服务。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-type.png"&gt;&lt;img class="aligncenter size-large wp-image-53773" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-type-1024x346.png" alt="控制台屏幕截图。" width="1024" height="346"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;服务托管权限设置&lt;/strong&gt;中，我选择监控我当前 AWS 账户中的资源。如果您使用 &lt;a href="https://aws.amazon.com/organizations/"&gt;AWS Organizations&lt;/a&gt; 来集中管理您的 AWS 环境，您可以使用 Grafana 来监控您&lt;a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_ous.html"&gt;组织单位 (OU)&lt;/a&gt; 中的资源。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-access.png"&gt;&lt;img class="aligncenter size-large wp-image-53786" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-permission-access-1024x339.png" alt="控制台屏幕截图。" width="1024" height="339"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我可以选择我计划使用的 AWS 数据源。此配置将创建一个 &lt;a title="" href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; 角色，使 Amazon Managed Grafana 能够访问我账户中的这些资源。稍后，在 Grafana 控制台中，我可以将选定的服务设置为数据源。现在，我选择 &lt;a title="" href="https://aws.amazon.com/cloudwatch/"&gt;Amazon CloudWatch&lt;/a&gt;，以便我可以在 Grafana 控制面板中快速可视化 &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html"&gt;CloudWatch 指标&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在此，我还配置了将 &lt;a href="https://aws.amazon.com/prometheus/"&gt;Amazon Managed Service for Prometheus (AMP)&lt;/a&gt; 作为数据源的权限，并为我的应用程序提供完全托管的监控解决方案。例如，我可以使用 &lt;a href="https://aws.amazon.com/otel/"&gt;AWS Distro for OpenTelemetry&lt;/a&gt; 或 &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; 服务器作为收集代理，从 &lt;a title="" href="https://aws.amazon.com/eks/"&gt;Amazon Elastic Kubernetes Service (EKS)&lt;/a&gt; 和 &lt;a title="" href="https://aws.amazon.com/ecs/"&gt;Amazon Elastic Container Service (Amazon ECS)&lt;/a&gt; 环境中收集 Prometheus 指标。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/amg-permission-aws-data-sources.png"&gt;&lt;img class="aligncenter size-large wp-image-54028" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/amg-permission-aws-data-sources-1024x829.png" alt="控制台屏幕截图。" width="1024" height="829"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在此步骤中，我还选择 &lt;a title="" href="https://aws.amazon.com/sns/"&gt;Amazon Simple Notification Service (SNS)&lt;/a&gt; 作为通知渠道。与之前的数据源类似，此选项允许 Amazon Managed Grafana 访问 SNS，但不会设置通知渠道。我可以稍后在 Grafana 控制台中执行此操作。具体而言，此设置会将 SNS 发布权限以 &lt;code&gt;grafana&lt;/code&gt; 开头的主题添加到 Amazon Managed Grafana 控制台所创建的 IAM 角色中。如果您希望对 SNS 或任何数据源的权限进行更严格的控制，您可以在 IAM 控制台中编辑角色或对您的工作区使用客户托管权限。&lt;/p&gt; 
&lt;p&gt;最后，我查看一下所有选项并创建工作区。&lt;/p&gt; 
&lt;p&gt;几分钟后，工作区准备就绪，我找到了可用于访问 Grafana 控制台的&lt;strong&gt;工作区 URL&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-workspace-summary.png"&gt;&lt;img class="aligncenter size-large wp-image-53776" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-workspace-summary-1024x301.png" alt="控制台屏幕截图。" width="1024" height="301"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我需要至少为 Grafana 工作区分配一个用户或组才能访问工作区 URL。我选择&lt;strong&gt;分配新用户或组&lt;/strong&gt;，然后选择我的一个 AWS SSO 用户。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-auth.png"&gt;&lt;img class="aligncenter size-large wp-image-53778" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-auth-1024x289.png" alt="控制台屏幕截图。" width="1024" height="289"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;默认情况下，该用户被分配了&lt;strong&gt;查看者&lt;/strong&gt;用户类型，对工作区具有“仅查看”权限。要授予此用户创建和管理仪表板和警报的权限，我选择该用户，然后选择&lt;strong&gt;设为管理员&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-admin.png"&gt;&lt;img class="aligncenter size-large wp-image-53779" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-sso-admin-1024x400.png" alt="控制台屏幕截图。" width="1024" height="400"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;回到工作区摘要，我按照工作区 URL 并使用我的 AWS SSO 用户凭证进行登录。我现在使用的是开源版的 Grafana。如果您是一名 Grafana 用户，那么您肯定对一切都很熟悉了。就我的第一个配置，我将专注于 AWS 数据源，因此我选择左侧竖条上的 AWS 徽标。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-data-sources.png"&gt;&lt;img class="aligncenter size-large wp-image-53780" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-aws-data-sources-1024x512.png" alt="控制台屏幕截图。" width="1024" height="512"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在此，我选择 CloudWatch。权限已经设置，因为我之前在服务托管权限设置中选择了 CloudWatch。我选择默认的 AWS 区域并添加数据源。我选择 CloudWatch 数据源，然后在&lt;strong&gt;控制面板&lt;/strong&gt;选项卡上，我找到了一些 AWS 服务的控制面板，例如 &lt;a title="" href="https://aws.amazon.com/ec2/"&gt;Amazon Elastic Compute Cloud (Amazon EC2)&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/ebs/"&gt;Amazon Elastic Block Store (EBS)&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/lambda/"&gt;AWS Lambda&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/rds/"&gt;Amazon Relational Database Service (RDS)&lt;/a&gt; 和 &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html"&gt;CloudWatch LogsLogs&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-cloudwatch-dashboards.png"&gt;&lt;img class="aligncenter size-large wp-image-53781" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-cloudwatch-dashboards-1024x379.png" alt="控制台屏幕截图。" width="1024" height="379"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我导入 AWS Lambda 控制面板。我现在可以使用 Grafana 来监控我账户中 Lambda 函数的调用、错误和限制。这边就没有屏幕截图了，因为我在这个区域没有什么有趣的数据。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;使用 SAML 身份验证&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;如果我没有启用 AWS SSO，我可以在创建工作区时选择 SAML 身份验证选项，并使用外部身份提供商 (IdP) 对 Amazon Managed Grafana 工作区的用户进行身份验证。对于现有工作区，我可以在工作区摘要中选择&lt;strong&gt;设置 SAML 配置&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;首先，我必须向我的 IdP 提供工作区 ID 和 URL 信息，以便生成用于配置此工作区的 IdP 元数据。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-idp.png"&gt;&lt;img class="aligncenter size-large wp-image-53782" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-idp-1024x254.png" alt="控制台屏幕截图。" width="1024" height="254"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;配置 IdP 后，我通过指定 URL 或复制并粘贴到编辑器来导入 IdP 元数据。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-import-metadata.png"&gt;&lt;img class="aligncenter size-large wp-image-53783" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-import-metadata-1024x252.png" alt="控制台屏幕截图。" width="1024" height="252"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;最后，我可以将 IdP 中的用户权限映射到 Grafana 用户权限，诸如指定哪些用户将在我的 Amazon Managed Grafana 工作区中拥有“管理员”、“编辑者”和“查看者”权限。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-assertion-mapping.png"&gt;&lt;img class="aligncenter size-large wp-image-53784" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/03/amg-saml-assertion-mapping-1024x383.png" alt="控制台屏幕截图。" width="1024" height="383"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;可用性和定价&lt;/span&gt;&lt;br&gt; &lt;/strong&gt;&lt;a href="https://aws.amazon.com/grafana/"&gt;Amazon Managed Grafana&lt;/a&gt; 现已在 10 个 AWS 区域推出：美国东部（弗吉尼亚北部）、美国东部（俄亥俄）、美国西部（俄勒冈）、欧洲（爱尔兰）、欧洲（法兰克福）、欧洲（伦敦）、亚太地区（新加坡）、亚太地区（东京）、亚太地区（悉尼）和亚太地区（首尔）。有关更多信息，请参阅 &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/"&gt;AWS 区域服务列表&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;使用 Amazon Managed Grafana，您每月只需为每个工作区中的活跃用户付费。用于发布控制面板的 Grafana API 密钥，每月按每个工作区的 API 用户许可证计费。您可以升级到企业版 Grafana，以便直接从 Grafana Labs 获取企业版插件、支持和按需培训。有关更多信息，&lt;a href="https://aws.amazon.com/grafana/pricing/"&gt;请参阅 Amazon Managed Grafana 定价页面&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://amazon.webex.com/webappng/sites/amazon/meeting/info/d66eaebcfa2c4f448e72c583ca8dcef2?isPopupRegisterView=true"&gt;欲了解更多信息，您可以参加将于 9 月 9 日星期四上午 9:00 PDT / 12:00 pm EDT / 6:00 pm CEST 举行的网络研讨会。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/grafana/"&gt;立即开始使用 Amazon Managed Grafana，以便可视化和分析任何规模的运营数据。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;— &lt;a title="Danilo 的 Twitter" href="https://twitter.com/danilop"&gt;Danilo&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>AWS CloudFormation 的新功能 – 从故障点快速重试堆栈操作</title>
		<link>https://aws.amazon.com/cn/blogs/china/new-for-aws-cloudformation-quickly-retry-stack-operations-from-the-point-of-failure/</link>
				<pubDate>Fri, 03 Sep 2021 13:35:24 +0000</pubDate>
		<dc:creator><![CDATA[Danilo Poccia]]></dc:creator>
				<category><![CDATA[News]]></category>

		<guid isPermaLink="false">165ee27e85f79d9952436041e30c678bf6993358</guid>
				<description>AWS CloudFormation 为您提供了一种简单的方法，可以对相关 AWS 和第三方资源集合进行建模，快速、一致地预置它们，并在其整个生命周期中对它们进行管理。CloudFormation 模板描述了所需的资源及其依赖关系，以便您将它们作为堆栈共同启动和配置。您可以使用模板将整个堆栈作为单个单元创建、更新和删除，而不是单独管理资源。</description>
								<content:encoded>&lt;p&gt;云计算的巨大优势之一是您有权访问可编程基础设施。这可让您管理&lt;a href="https://docs.aws.amazon.com/whitepapers/latest/introduction-devops-aws/infrastructure-as-code.html"&gt;基础设施即代码&lt;/a&gt;，并将相同的应用程序代码开发实践应用于基础设施预置。&lt;/p&gt; 
&lt;p&gt;&lt;a title="" href="https://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt; 为您提供了一种简单的方法，可以对相关 AWS 和第三方资源集合进行建模，快速、一致地预置它们，并在其整个生命周期中对它们进行管理。CloudFormation &lt;strong&gt;模板&lt;/strong&gt;描述了所需的资源及其依赖关系，以便您将它们作为&lt;strong&gt;堆栈&lt;/strong&gt;共同启动和配置。您可以使用模板将整个堆栈作为单个单元创建、更新和删除，而不是单独管理资源。&lt;/p&gt; 
&lt;p&gt;创建或更新堆栈时，您的操作可能会由于不同的原因而失败。例如，模板、模板的参数中可能存在错误，也可能存在模板之外的问题，例如 &lt;a title="" href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; 权限错误。发生此类错误时，CloudFormation 会将堆栈回滚到之前的稳定状态。对于堆栈创建，这意味着删除直到出错点之前创建的所有资源。对于堆栈更新，这意味着恢复以前的配置。&lt;/p&gt; 
&lt;p&gt;回滚到以前状态的操作对于生产环境来说非常合适，但您可能很难理解出现错误的原因。根据模板的复杂性和所涉及资源的数量，您可能会花很多时间等待所有资源回滚，然后再使用正确的配置更新模板并重试该操作。&lt;/p&gt; 
&lt;p&gt;今天，我很高兴与大家分享的功能是，CloudFormation 目前可让您&lt;strong&gt;禁用&lt;/strong&gt;自动回滚，在错误发生之前&lt;strong&gt;保持&lt;/strong&gt;资源成功创建或更新，以及从故障点&lt;strong&gt;重试&lt;/strong&gt;堆栈操作。通过这种方式，您可以快速迭代以解决和修复错误，并大大减少在开发环境中测试 CloudFormation 模板所需的时间。您可以在创建堆栈、更新堆栈时以及执行&lt;a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html"&gt;更改集&lt;/a&gt;时应用此新功能。我们来看看这些步骤的实际操作。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;快速迭代以解决和修复 CloudFormation 堆栈问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;对于我的一个应用程序，我需要设置 &lt;a title="" href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt; 存储桶、&lt;a title="" href="https://aws.amazon.com/sqs/"&gt;Amazon Simple Queue Service (SQS)&lt;/a&gt; 队列和 &lt;a title="" href="https://aws.amazon.com/dynamodb/"&gt;Amazon DynamoDB&lt;/a&gt; 表，该表将项目级更改串流至 &lt;a title="" href="https://aws.amazon.com/kinesis/"&gt;Amazon Kinesis&lt;/a&gt; 数据流。对于此设置，我编写了 CloudFormation 模板的第一个版本。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-yaml"&gt;AWSTemplateFormatVersion: "2010-09-09"
说明：一个用于解决和修复问题的示例模板
Parameters:
  ShardCountParameter:
    Type: Number
    说明：Kinesis 流的分区数
Resources:
  MyBucket:
    Type: AWS::S3::Bucket
  MyQueue:
    Type: AWS::SQS::Queue
  MyStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount: !Ref ShardCountParameter
  MyTable：
    Type: AWS::DynamoDB::Table
    Properties:
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: "ArtistId"
          AttributeType: "S"
        - AttributeName: "Concert"
          AttributeType: "S"
        - AttributeName: "TicketSales"
          AttributeType: "S"
      KeySchema:
        - AttributeName: "ArtistId"
          "KeyType": "HASH"
        - AttributeName: "Concert"
          KeyType: "RANGE"
      KinesisStreamSpecification:
        StreamArn: !GetAtt MyStream.Arn
Outputs:
  BucketName:
    Value: !Ref MyBucket
    说明：我的 S3 存储桶的名称
  QueueName:
    Value: !GetAtt MyQueue.QueueName
    说明：我的 SQS 队列的名称
  StreamName:
    Value: !Ref MyStream
    说明：我的 Kinesis 流的名称
  TableName:
    Value: !Ref MyTable
    说明：我的 DynamoDB 表的名称&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;现在，我想用这个模板创建一个堆栈。在 &lt;a href="https://console.aws.amazon.com/cloudformation/home"&gt;CloudFormation 控制台&lt;/a&gt;上，我选择&lt;strong&gt;创建堆栈&lt;/strong&gt;。然后，我上传模板文件并选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-create-stack.png"&gt;&lt;img class="aligncenter size-large wp-image-54040" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-create-stack-1024x659.png" alt="控制台屏幕截图。" width="1024" height="659"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我输入堆栈的名称。然后，我填写堆栈参数。我的模板文件有一个参数 (&lt;code&gt;ShardCountParameter&lt;/code&gt;)，用于配置 Kinesis 数据流的&lt;a href="https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html"&gt;分区数量&lt;/a&gt;。我知道分区数量应该大于或等于 1，但错误地输入 0 并选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-name-parameters.png"&gt;&lt;img class="aligncenter size-large wp-image-54043" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-name-parameters-1024x499.png" alt="控制台屏幕截图。" width="1024" height="499"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;为了创建、修改或删除堆栈中的资源，我使用 &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html"&gt;IAM 角色&lt;/a&gt;。这样，我就明确界定了 CloudFormation 可用于堆栈操作的权限。此外，我可以使用相同的角色来在标准化和可重复的环境中自动部署堆栈。&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;权限&lt;/strong&gt;中，我选择要用于堆栈操作的 IAM 角色。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-permissions.png"&gt;&lt;img class="aligncenter size-large wp-image-54042" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-permissions-1024x325.png" alt="控制台屏幕截图。" width="1024" height="325"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在是使用新功能的时候了！ 在&lt;strong&gt;堆栈故障选项&lt;/strong&gt;中，我选择&lt;strong&gt;保留成功预置的资源&lt;/strong&gt;，以便在出错时保留已创建的资源。失败的资源始终回滚到最近一个已知的稳定状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-failure-options.png"&gt;&lt;img class="aligncenter size-large wp-image-54044" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-failure-options-1024x273.png" alt="控制台屏幕截图。" width="1024" height="273"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我将所有其他选项保留为默认值，然后选择&lt;strong&gt;下一步&lt;/strong&gt;。然后，我查看自己的配置并选择&lt;strong&gt;创建堆栈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;堆栈的创建操作会执行几秒钟，然后由于错误而失败。在&lt;strong&gt;事件&lt;/strong&gt;选项卡中，我查看事件的时间表。开始创建堆栈的事件位于底部。最近的事件位于顶部。由于分区的数量 (&lt;code&gt;ShardCount&lt;/code&gt;) 低于最小值，因此流资源的属性验证失败。因此，堆栈现在处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-parameter.png"&gt;&lt;img class="aligncenter size-large wp-image-54045" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-parameter-1024x605.png" alt="控制台屏幕截图。" width="1024" height="605"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我选择保留预置的资源，因此在错误发生之前创建的所有资源仍然存在。在&lt;strong&gt;资源&lt;/strong&gt;选项卡中，S3 存储桶和 SQS 队列处于 &lt;code&gt;CREATE_COMPLETE&lt;/code&gt; 状态，而 Kinesis 数据流处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 状态。DynamoDB 表的创建取决于 Kinesis 数据流是否可用，因为该表将数据流用于其属性之一 (&lt;code&gt;KinesisStreamSpecification&lt;/code&gt;)。因此，表的创建尚未开始，并且该表不在列表中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-preserved-resources.png"&gt;&lt;img class="aligncenter size-large wp-image-54046" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-preserved-resources-1024x408.png" alt="控制台屏幕截图。" width="1024" height="408"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;回滚现在已暂停，并且我有一些新的选项：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;重试&lt;/strong&gt; – 在不作任何更改的情况下重试堆栈操作。如果资源由于模板之外的问题而无法预置，此选项就非常有用。我可以修复这个问题，然后从故障点重试。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt; – 在重试堆栈创建之前更新模板或参数。堆栈更新从最近一个操作因错误而中断的位置开始。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;回滚&lt;/strong&gt; – 回滚到最近一个已知的稳定状态。这类似于默认的 CloudFormation 行为。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-paused-options.png"&gt;&lt;img class="aligncenter size-large wp-image-54048" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-stack-paused-options-1024x204.png" alt="控制台屏幕截图。" width="1024" height="204"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;修复参数中的问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;我很快意识到输入了错误的分区数量参数，因此选择&lt;strong&gt;更新&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;我不需要更改模板来修复此错误。&amp;nbsp;在&lt;strong&gt;参数&lt;/strong&gt;中，我修复了之前的错误并输入正确的分区数量：一个分区。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-update-stack-parameters.png"&gt;&lt;img class="aligncenter size-large wp-image-54051" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-update-stack-parameters-1024x308.png" alt="控制台屏幕截图。" width="1024" height="308"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我将所有其他选项保留为当前值，然后选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;更改集预览&lt;/strong&gt;中，我看到更新将尝试修改 Kinesis 流 (当前处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 状态) 并添加 DynamoDB 表。我查看其他配置并选择&lt;strong&gt;更新堆栈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-change-set-preview-1.png"&gt;&lt;img class="aligncenter size-large wp-image-54056" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-change-set-preview-1-1024x389.png" alt="控制台屏幕截图。" width="1024" height="389"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在更新进行中。我解决了所有问题吗？ 还没有。一段时间后，更新失败。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;修复模板之外的问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;Kinesis 流已创建，但 CloudFormation 担任的 IAM 角色没有创建 DynamoDB 表的权限。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-permissions.png"&gt;&lt;img class="aligncenter wp-image-54057 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-permissions-1024x488.png" alt="控制台屏幕截图。" width="1024" height="488"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在 &lt;a href="https://console.aws.amazon.com/iam/home"&gt;IAM 控制台&lt;/a&gt;中，我向堆栈操作使用的角色添加额外权限，以便该角色能够创建 DynamoDB 表。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-iam-permissions.png"&gt;&lt;img class="aligncenter size-large wp-image-54063" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-iam-permissions-1024x315.png" alt="控制台屏幕截图。" width="1024" height="315"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;返回 &lt;a href="https://console.aws.amazon.com/cloudformation/home"&gt;CloudFormation 控制台&lt;/a&gt;，我选择&lt;strong&gt;重试&lt;/strong&gt;选项。具备新权限后，DynamoDB 表的创建将开始，但一段时间后，出现另一个错误。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;修复模板中的问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;这一次，在定义 DynamoDB 表的模板中存在错误。在 &lt;code&gt;AttributeDefinitions&lt;/code&gt; 部分中，有一个未在架构中使用的属性 (&lt;code&gt;TicketSales&lt;/code&gt;)。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-template.png"&gt;&lt;img class="aligncenter size-large wp-image-54058" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-errors-template-1024x185.png" alt="控制台屏幕截图。" width="1024" height="185"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;对于 DynamoDB，模板中定义的属性应用于主键或索引。我更新了模板并删除 &lt;code&gt;TicketSales&lt;/code&gt; 属性定义。&lt;/p&gt; 
&lt;p&gt;由于正在编辑模板，因此我借此机会将 &lt;code&gt;MinValue&lt;/code&gt; 和 &lt;code&gt;MaxValue&lt;/code&gt; 属性添加到分区数量参数 (&lt;code&gt;ShardCountParameter&lt;/code&gt;) 中。这样，CloudFormation 可以在开始部署之前检查值是否在正确的范围内，而我可以避免进一步的错误。&lt;/p&gt; 
&lt;p&gt;我选择&lt;strong&gt;更新&lt;/strong&gt;选项。我选择更新当前模板，然后上传新的模板文件。我确认了参数的当前值。然后，我将所有其他选项保留为当前值，接下来选择&lt;strong&gt;更新堆栈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这次，堆栈成功创建，其状态为 &lt;code&gt;UPDATE_COMPLETE&lt;/code&gt;。我可以在&lt;strong&gt;资源&lt;/strong&gt;选项卡中查看所有资源，并在&lt;code&gt;输出&lt;/code&gt;选项卡中查看它们的说明 (基于模板的&lt;strong&gt;输出&lt;/strong&gt;部分)。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-outputs.png"&gt;&lt;img class="aligncenter size-large wp-image-54060" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/18/cfn-outputs-1024x354.png" alt="控制台屏幕截图。" width="1024" height="354"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以下是模板的最终版本：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-yaml"&gt;AWSTemplateFormatVersion: "2010-09-09"
说明：一个用于解决和修复问题的示例模板
Parameters:
  ShardCountParameter:
    Type: Number
    MinValue: 1
    MaxValue: 10
    说明：Kinesis 流的分区数
Resources:
  MyBucket:
    Type: AWS::S3::Bucket
  MyQueue:
    Type: AWS::SQS::Queue
  MyStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount: !Ref ShardCountParameter
  MyTable：
    Type: AWS::DynamoDB::Table
    Properties:
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: "ArtistId"
          AttributeType: "S"
        - AttributeName: "Concert"
          AttributeType: "S"
      KeySchema:
        - AttributeName: "ArtistId"
          "KeyType": "HASH"
        - AttributeName: "Concert"
          KeyType: "RANGE"
      KinesisStreamSpecification:
        StreamArn: !GetAtt MyStream.Arn
Outputs:
  BucketName:
    Value: !Ref MyBucket
    说明：我的 S3 存储桶的名称
  QueueName:
    Value: !GetAtt MyQueue.QueueName
    说明：我的 SQS 队列的名称
  StreamName:
    Value: !Ref MyStream
    说明：我的 Kinesis 流的名称
  TableName:
    Value: !Ref MyTable
    说明：我的 DynamoDB 表的名称&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这是一个简单的示例，但从故障点重试堆栈操作的新功能为我节省了大量时间。它可让我快速解决和修复问题，从而减少了反馈循环并增加了在同一时间内完成的迭代次数。除了使用其进行调试之外，该功能对于模板的增量交互式开发也非常有用。对于更复杂的应用程序，我们将可节省大量的时间！&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;使用 AWS CLI 解决和修复 CloudFormation 堆栈问题&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;我可以使用 &lt;a title="" href="https://aws.amazon.com/cli/"&gt;AWS 命令行界面 (CLI)&lt;/a&gt; 保留成功预置的资源，方法是在创建堆栈、更新堆栈或执行更改集时指定 &lt;code&gt;--disable-rollback&lt;/code&gt; 选项。例如：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;aws cloudformation create-stack --stack-name my-stack \
    --template-body file://my-template.yaml -–disable-rollback
aws cloudformation update-stack --stack-name my-stack \
    --template-body file://my-template.yaml --disable-rollback
aws cloudformation execute-change-set --stack-name my-stack --change-set-name my-change-set \
    --template-body file://my-template.yaml --disable-rollback&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;对于现有堆栈，我可以查看是否使用 describe stack 命令启用了 &lt;code&gt;DisableRollback&lt;/code&gt; 属性：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;aws cloudformation describe-stacks --stack-name my-stack&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我现在可以更新处于 &lt;code&gt;CREATE_FAILED&lt;/code&gt; 或 &lt;code&gt;UPDATE_FAILED&lt;/code&gt; 状态的堆栈。要手动回滚处于&lt;code&gt;CREATE_FAILED&lt;/code&gt; 或 &lt;code&gt;UPDATE_FAILED&lt;/code&gt; 状态的堆栈，我可以使用新的 rollback stack 命令：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;aws cloudformation rollback-stack --stack-name my-stack&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;可用性和定价&lt;br&gt; &lt;/strong&gt;&lt;/span&gt;&lt;a title="" href="https://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt; 从故障点重试堆栈操作的功能在以下 &lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/#Regions"&gt;AWS 区域&lt;/a&gt;免费提供：美国东部 (弗吉尼亚北部、俄亥俄)、美国西部 (俄勒冈、加利福尼亚北部)、AWS GovCloud (美国东部、美国西部)、加拿大 (中部)、欧洲 (法兰克福、爱尔兰、伦敦、米兰、巴黎、斯德哥尔摩)、亚太地区 (香港、孟买、大阪、首尔、新加坡、悉尼、东京)、中东 (巴林)、非洲 (开普敦) 和南美洲 (圣保罗)。&lt;/p&gt; 
&lt;p&gt;您更喜欢使用熟悉的编程语言 (例如 JavaScript、TypeScript、Python、Java、C# 和 Go) 来定义云应用程序资源吗？ 好消息！ &lt;a title="" href="https://aws.amazon.com/cdk/"&gt;AWS Cloud Development Kit (AWS CDK)&lt;/a&gt; 团队计划在接下来的几周内增加对本文中所介绍新功能的支持。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stack-failure-options.html"&gt;借助从故障点开始重试堆栈操作的新功能，可以用更少的时间来解决和修复 CloudFormation 堆栈问题。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;— &lt;a title="Danilo 的 Twitter" href="https://twitter.com/danilop"&gt;Danilo&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>使用更具体的 Amazon VPC 路由检查子网到子网的流量</title>
		<link>https://aws.amazon.com/cn/blogs/china/inspect-subnet-to-subnet-traffic-with-amazon-vpc-more-specific-routing/</link>
				<pubDate>Fri, 03 Sep 2021 04:30:44 +0000</pubDate>
		<dc:creator><![CDATA[Sébastien Stormacq]]></dc:creator>
				<category><![CDATA[Announcements]]></category>

		<guid isPermaLink="false">308ee0fb555368909267bfb075f24cf12dbcb77e</guid>
				<description>自 2019 年 12 月以来，Amazon Virtual Private Cloud（VPC）允许您将所有进站流量（也称为南北流量）路由到特定网络接口。您可能出于多种原因使用此功能。例如，使用入侵检测系统（IDS）设备检测进站流量或将进站流量路由到防火墙。</description>
								<content:encoded>&lt;p&gt;自 2019 年 12 月以来，&lt;a title="" href="https://aws.amazon.com/vpc/"&gt;Amazon Virtual Private Cloud（VPC）&lt;/a&gt;允许您将所有进站流量（也称为&lt;a href="https://en.wikipedia.org/wiki/North-south_traffic"&gt;南北流量&lt;/a&gt;）路由到特定网络接口。您可能出于多种原因使用此功能。例如，使用入侵检测系统（IDS）设备检测进站流量或将进站流量路由到防火墙。&lt;/p&gt; 
&lt;p&gt;自我们推出此功能以来，许多用户要求我们提供类似的功能来分析从一个子网流向 VPC 内的另一个子网的流量，也称为&lt;a href="https://en.wikipedia.org/wiki/East-west_traffic"&gt;东西流量&lt;/a&gt;。到今天为止，这仍然是不可能的，因为路由表中的路由不能比默认本地路由更具体（有关更多详细信息，请查看&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html"&gt;VPC 文档&lt;/a&gt;）。简单地说，这意味着任何一个路由的目标使用的 &lt;a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing"&gt;CIDR&lt;/a&gt; 范围都不能小于默认本地路由（即整个 VPC 的 CIDR 范围）。例如，当 VPC 范围为 &lt;code&gt;10.0.0/16&lt;/code&gt; 且子网有 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 时，通向 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 的路由比通向 &lt;code&gt;10.0.0/16&lt;/code&gt; 的路由更具体。&lt;/p&gt; 
&lt;p&gt;路由表不再有此限制。路由表中的路由可以有比默认本地路由更具体的路由。您可以使用此类更具体的路由将所有流量发送到专用设备或服务，以检测、分析或过滤两个子网之间的所有流量（东西流量）。路由目标可以是连接到您构建或购买的设备的网络接口（ENI）、出于性能或高可用性原因将流量分配到多个设备的 &lt;a href="https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/"&gt;AWS 网关负载均衡器&lt;/a&gt;（GWLB）终端节点、&lt;a title="" href="https://aws.amazon.com/firewall-manager/"&gt;AWS Firewall Manager&lt;/a&gt; 终端节点或 &lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html"&gt;NAT 网关&lt;/a&gt;。它还允许在子网和 &lt;a href="https://aws.amazon.com/transit-gateway/"&gt;AWS Transit Gateway&lt;/a&gt; 之间插入设备。&lt;/p&gt; 
&lt;p&gt;可以将设备链接起来，以便在源子网和目标子网之间进行多种类型的分析。例如，您可能希望首先使用防火墙（AWS 托管防火墙或&lt;a href="https://aws.amazon.com/marketplace/solutions/security"&gt;第三方防火墙设备&lt;/a&gt;）筛选流量，然后将流量发送到&lt;a href="https://aws.amazon.com/marketplace/solutions/infrastructure-software/ids-ips"&gt;入侵检测和防御系统&lt;/a&gt;，最后，执行深度数据包检测。您可以从我们的 &lt;a href="https://aws.amazon.com/partners/"&gt;AWS 合作伙伴网络&lt;/a&gt;和 &lt;a href="https://aws.amazon.com/marketplace"&gt;AWS Marketplace&lt;/a&gt; 访问虚拟设备。&lt;/p&gt; 
&lt;p&gt;链接设备时，每个设备和每个终端节点都必须位于单独的子网中。&lt;/p&gt; 
&lt;p&gt;让我们动手试试这个新功能。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;工作原理&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 在本博客文章中，我们假设我有一个具有三个子网的 &lt;span title=""&gt;VPC&lt;/span&gt;。第一个子网是公有子网，有一个堡垒主机。它需要访问资源，例如 API 或第二个子网中的数据库。第二个子网是私有子网。它托管堡垒所需的资源。我写了&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;一个简单的 CDK 脚本&lt;/a&gt;来帮助您部署此设置。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/Slide1.png"&gt;&lt;img class="aligncenter wp-image-52363 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/Slide1-e1621855971954-1024x584.png" alt="更具体的 VPC 路由" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;出于合规性原因，我们公司要求此私有应用程序的流量流经入侵检测系统。&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;CDK 脚本&lt;/a&gt;还创建了第三个子网（私有子网）来托管网络设备。它提供了三个 &lt;a title="" href="https://aws.amazon.com/ec2/"&gt;Amazon Elastic Compute Cloud（Amazon EC2）&lt;/a&gt;实例：堡垒主机、应用程序实例和网络分析设备。该脚本还创建了 NAT 网关，允许引导应用程序实例并使用 &lt;a title="" href="https://aws.amazon.com/systems-manager/"&gt;AWS Systems Manager&lt;/a&gt; Session Manager （SSM）连接到三个实例。&lt;/p&gt; 
&lt;p&gt;因为这是一个演示，所以网络设备是配置为 IP 路由器的常规 Amazon Linux &lt;span title=""&gt;EC2&lt;/span&gt; 实例。在现实生活中，您可能要使用我们的合作伙伴在 &lt;a title="" href="https://aws.amazon.com/marketplace/"&gt;AWS Marketplace&lt;/a&gt; 上提供的众多设备之一，或者&lt;a href="https://aws.amazon.com/elasticloadbalancing/gateway-load-balancer/"&gt;网关负载均衡器&lt;/a&gt;终端节点或 Network Firewall。&lt;/p&gt; 
&lt;p&gt;让我们修改路由表以通过设备发送流量。&lt;/p&gt; 
&lt;p&gt;使用 &lt;a title="" href="https://console.aws.amazon.com"&gt;AWS 管理控制台&lt;/a&gt;或 &lt;a title="" href="https://aws.amazon.com/cli/"&gt;AWS 命令行界面（CLI）&lt;/a&gt;，我向 &lt;code&gt;10.0.0.0/24&lt;/code&gt; 和 &lt;code&gt;10.0.1.0/24&lt;/code&gt; 子网路由表添加了更具体的路由。这些路由指向 &lt;code&gt;eni0&lt;/code&gt;，即流量检测设备的网络接口。&lt;/p&gt; 
&lt;p&gt;使用 CLI，我首先收集设备的 VPC ID、子网 ID、路由表 ID 和 ENI ID。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;VPC_ID=$(aws                                                    \
    --region $REGION cloudformation describe-stacks             \
    --stack-name SpecificRoutingDemoStack                       \
    --query "Stacks[].Outputs[?OutputKey=='VPCID'].OutputValue" \
    --output text)
echo $VPC_ID

APPLICATION_SUBNET_ID=$(aws                                                                      \
    --region $REGION ec2 describe-instances                                                      \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='application']].NetworkInterfaces[].SubnetId" \
    --output text)
echo $APPLICATION_SUBNET_ID

APPLICATION_SUBNET_ROUTE_TABLE=$(aws                                                             \
    --region $REGION  ec2 describe-route-tables                                                  \
    --query "RouteTables[?VpcId=='${VPC_ID}'] | [?Associations[?SubnetId=='${APPLICATION_SUBNET_ID}']].RouteTableId" \
    --output text)
echo $APPLICATION_SUBNET_ROUTE_TABLE

APPLIANCE_ENI_ID=$(aws                                                                           \
    --region $REGION ec2 describe-instances                                                      \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='appliance']].NetworkInterfaces[].NetworkInterfaceId" \
    --output text)
echo $APPLIANCE_ENI_ID

BASTION_SUBNET_ID=$(aws                                                                         \
    --region $REGION ec2 describe-instances                                                     \
    --query "Reservations[].Instances[] | [?Tags[?Key=='Name' &amp;amp;&amp;amp; Value=='BastionHost']].NetworkInterfaces[].SubnetId" \
    --output text)
echo $BASTION_SUBNET_ID

BASTION_SUBNET_ROUTE_TABLE=$(aws \
 --region $REGION ec2 describe-route-tables \
 --query "RouteTables[?VpcId=='${VPC_ID}'] | [?Associations[?SubnetId=='${BASTION_SUBNET_ID}']].RouteTableId" \
 --output text)
echo $BASTION_SUBNET_ROUTE_TABLE&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接下来，我会添加两条更具体的路由。一条路由通过设备网络接口将来自堡垒公有子网的流量发送到应用程序私有子网。&amp;nbsp;第二条路由与路由回复的方向相反。它通过设备网络接口将更具体的流量从应用程序私有子网路由到堡垒公有子网。&amp;nbsp;感到困惑？ 让我们看看下图：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/illustration-1.png"&gt;&lt;img class="aligncenter wp-image-52368 size-large" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/24/illustration-1-1024x584.png" alt="更具体的 VPC 路由" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;首先，让我们修改堡垒路由表：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;aws ec2 create-route                                  \
     --region $REGION                                 \
     --route-table-id $BASTION_SUBNET_ROUTE_TABLE     \
     --destination-cidr-block 10.0.1.0/24             \
     --network-interface-id $APPLIANCE_ENI_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接下来，让我们修改应用程序路由表：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;aws ec2 create-route                                  \
    --region $REGION                                  \
    --route-table-id $APPLICATION_SUBNET_ROUTE_TABLE  \
    --destination-cidr-block 10.0.0.0/24              \
    --network-interface-id $APPLIANCE_ENI_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我还可以使用 Amazon VPC 控制台进行这些修改。只需从 Routes (路由) 选项卡中选择“Bastion”(堡垒) 路由表，然后单击 Edit routes (编辑路由) 即可。&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-33-52.png"&gt;&lt;img class="aligncenter size-large wp-image-52421" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-33-52-1024x584.png" alt="MSR：选择路由表" width="1024" height="584"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我添加了一个路由，用于将 &lt;code&gt;10.0.1.0/24&lt;/code&gt;（应用程序子网）的流量发送到设备 ENI（&lt;code&gt;eni-055...&lt;/code&gt;）。&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-35-20.png"&gt;&lt;img class="aligncenter size-large wp-image-52422" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-35-20-1024x494.png" alt="MSR：创建路由" width="1024" height="494"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下一步是定义相反的回复路由，将 &lt;code&gt;10.0.0.0/24&lt;/code&gt; 的流量从应用程序子网发送到设备 ENI（&lt;code&gt;eni-05...&lt;/code&gt;）。&amp;nbsp;完成后，应用程序子网路由表应如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-36-34.png"&gt;&lt;img class="aligncenter size-large wp-image-52423" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/26/2021-05-26_15-36-34-1024x559.png" alt="MSR：最终路由表" width="1024" height="559"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;配置设备实例&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 最后，我将设备实例配置为转发其接收的所有流量。您的软件设备通常会为您完成此操作。当您使用 &lt;a title="" href="https://aws.amazon.com/marketplace/"&gt;AWS Marketplace&lt;/a&gt; 设备或&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;我为此演示提供的 CDK 脚本&lt;/a&gt;创建的实例时，无需执行额外步骤。如果您使用的是普通 Linux 实例，请完成以下两个额外步骤：&lt;/p&gt; 
&lt;p&gt;1.连接到 &lt;span title=""&gt;EC2&lt;/span&gt; 设备实例并在内核中配置 IP 流量转发：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;sysctl -w net.ipv4.ip_forward=1
sysctl -w net.ipv6.conf.all.forwarding=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2.将 &lt;span title=""&gt;EC2&lt;/span&gt; 实例配置为接受除本身之外的其他目标的流量（称为&lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html#EIP_Disable_SrcDestCheck"&gt;源/目标检查&lt;/a&gt;）：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;APPLIANCE_ID=$(aws --region $REGION ec2 describe-instances                     \
     --filter "Name=tag:Name,Values=appliance"                                 \
     --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
     --output text)

aws ec2 modify-instance-attribute --region $REGION     \
                         --no-source-dest-check        \
                         --instance-id $APPLIANCE_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;测试设置&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 设备现已做好将流量转发到其他 &lt;span title=""&gt;EC2&lt;/span&gt; 实例的准备。&lt;/p&gt; 
&lt;p&gt;如果您使用的是&lt;a href="https://github.com/sebsto/cdkv2-vpc-example"&gt;演示设置&lt;/a&gt;，则堡垒主机上未安装 SSH 密钥。通过 &lt;a title="" href="https://aws.amazon.com/systems-manager/"&gt;AWS Systems Manager&lt;/a&gt; Session Manager 进行访问。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;BASTION_ID=$(aws --region $REGION ec2 describe-instances                      \
    --filter "Name=tag:Name,Values=BastionHost"                               \
    --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
    --output text)

aws --region $REGION ssm start-session --target $BASTION_ID&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;连接到堡垒主机后，发出以下 &lt;code&gt;cURL&lt;/code&gt; 命令以连接到应用程序主机：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;sh-4.2$ curl -I 10.0.1.239 # use the private IP address of your application host
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Mon, 24 May 2021 10:00:22 GMT
Content-Type: text/html
Content-Length: 12338
Last-Modified: Mon, 24 May 2021 09:36:49 GMT
Connection: keep-alive
ETag: "60ab73b1-3032"
Accept-Ranges: bytes&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;要验证流量是否真正流经设备，您可以再次对实例启用源/目标检查。将 &lt;code&gt;--source-dest-check&lt;/code&gt; 参数与上面的 &lt;code&gt;modify-instance-attribute&lt;/code&gt; CLI 命令一起使用。当源/目标检查启用时，流量将受阻。&lt;/p&gt; 
&lt;p&gt;我还可以连接到设备主机并使用 &lt;code&gt;tcpdump&lt;/code&gt; 命令检测流量。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-zsh"&gt;(on your laptop)
APPLIANCE_ID=$(aws --region $REGION ec2 describe-instances     \
                   --filter "Name=tag:Name,Values=appliance" \
		   --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" \
  		   --output text)

aws --region $REGION ssm start-session --target $APPLIANCE_ID

(on the appliance host)
tcpdump -i eth0 host 10.0.0.16 # the private IP address of the bastion host

08:53:22.760055 IP ip-10-0-0-16.us-west-2.compute.internal.46934 &amp;gt; ip-10-0-1-104.us-west-2.compute.internal.http: Flags [S], seq 1077227105, win 26883, options [mss 8961,sackOK,TS val 1954932042 ecr 0,nop,wscale 6], length 0
08:53:22.760073 IP ip-10-0-0-16.us-west-2.compute.internal.46934 &amp;gt; ip-10-0-1-104.us-west-2.compute.internal.http: Flags [S], seq 1077227105, win 26883, options [mss 8961,sackOK,TS val 1954932042 ecr 0,nop,wscale 6], length 0
08:53:22.760322 IP ip-10-0-1-104.us-west-2.compute.internal.http &amp;gt; ip-10-0-0-16.us-west-2.compute.internal.46934: Flags [S.], seq 4152624111, ack 1077227106, win 26847, options [mss 8961,sackOK,TS val 4094021737 ecr 1954932042,nop,wscale 6], length 0
08:53:22.760329 IP ip-10-0-1-104.us-west-2.compute.internal.http &amp;gt; ip-10-0-0-16.us-west-2.compute.internal.46934: Flags [S.], seq 4152624111, ack 1077227106, win 26847, options [mss &lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;清理&lt;/strong&gt;&lt;/span&gt;&lt;br&gt; 如果您使用了&lt;a href="https://github.com/sebsto/cdkv2-vpc-example/blob/main/lib/specific-routing-demo-stack.ts"&gt;我为此博文提供的 CDK 脚本&lt;/a&gt;，请务必在完成后运行 &lt;code&gt;cdk destroy&lt;/code&gt;，这样就无需为我用于此演示的三个 EC2 实例和 NAT 网关付费。在 &lt;code&gt;us-west-2&lt;/code&gt; 中运行演示脚本的&lt;a href="https://calculator.aws/#/estimate?id=a460f21b3c6a0e271aae860ce4482c02389747bd"&gt;费用&lt;/a&gt;为每小时 0.062 美元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;注意事项。&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; 在使用更具体的 &lt;span title=""&gt;VPC&lt;/span&gt; 路由时，请记住以下几点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;您要向其发送流量的网络接口或服务终端节点必须位于专用子网中。它不能位于流量的源子网或目标子网中。&lt;/li&gt; 
 &lt;li&gt;您可以将设备链接起来。每台设备必须位于其专用子网中。&lt;/li&gt; 
 &lt;li&gt;您添加的每个子网都会占用一个 IP 地址块。&amp;nbsp;如果您使用的是 IPv4，请注意所用的 IP 地址数量（一个 /24 子网使用来自您的 VPC 的 256 个地址）。子网中允许的最小 CIDR 范围是 /28，它只使用 16 个 IP 地址。&lt;/li&gt; 
 &lt;li&gt;设备的安全组必须有规则接受所需端口上的传入流量。同样，应用程序的安全组必须授权来自设备安全组或 IP 地址的流量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此新功能在所有 AWS 区域均可使用，无需额外付费。&lt;/p&gt; 
&lt;p&gt;您可以立即开始使用。&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>Amazon Textract 更新：8 个亚马逊云科技区域的价格降幅达 32％，异步任务处理时间缩短近 50％</title>
		<link>https://aws.amazon.com/cn/blogs/china/amazon-textract-updates-up-to-32-price-reduction-in-8-aws-regions-and-up-to-50-reduction-in-asynchronous-job-processing-times/</link>
				<pubDate>Fri, 03 Sep 2021 04:28:17 +0000</pubDate>
		<dc:creator><![CDATA[Channy Yun]]></dc:creator>
				<category><![CDATA[Price Reduction]]></category>

		<guid isPermaLink="false">1d79dcc8d4d08e74c3b32607ec6ca943b1d1b3b6</guid>
				<description>在亚马逊云科技 re:Invent 2018 上推出的 Amazon Textract 是一项机器学习服务，它可以从扫描的文档中自动提取文本、手写和数据，并超越了简单的光学字符识别 (OCR) 来识别、理解和提取表单和表格中的数据。</description>
								<content:encoded>&lt;p&gt;在亚马逊云科技 re:Invent 2018 上推出的 &lt;a href="https://aws.amazon.com/textract/"&gt;Amazon Textract&lt;/a&gt; 是一项机器学习服务，它可以从扫描的文档中自动提取文本、手写和数据，并超越了简单的光学字符识别 (OCR) 来识别、理解和提取表单和表格中的数据。&lt;/p&gt; 
&lt;p&gt;在过去的几个月中，我们推出了处理&lt;a href="https://aws.amazon.com/blogs/machine-learning/announcing-expanded-support-for-extracting-data-from-invoices-and-receipts-using-amazon-textract/"&gt;发票和收据&lt;/a&gt;的专业技术支持，并提高了基础计算机视觉模型的质量，该模型支持&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/07/amazon-textract-announces-improvements-detection-handwritten-text-digits-dates-phone-numbers/"&gt;手写文本&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/06/amazon-textract-announces-quality-updates-to-its-forms-extraction-feature/"&gt;表单&lt;/a&gt;和&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-textract-announces-quality-update-table-extraction-feature/"&gt;表格&lt;/a&gt;的提取，并支持英语、西班牙语、德语、意大利语、葡萄牙语和法语的打印文本。&lt;/p&gt; 
&lt;p&gt;作为多个亚马逊云科技合规性计划的一部分，第三方审计员将评估 Amazon Textract 的安全性和合规性。我们还添加了 &lt;a href="https://aws.amazon.com/blogs/security/new-2021-h1-irap-report-is-now-available-on-aws-artifact-for-australian-customers/"&gt;IRAP&lt;/a&gt; 合规性技术支持并实现 &lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-textract-achieves-fedramp-compliance/"&gt;US FedRAMP&lt;/a&gt; 授权，以添加到现有的列表中，如 &lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/10/amazon-textract-is-now-a-hipaa-eligible-service/"&gt;HIPAA&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/12/amazon-textract-is-now-pci-dss-certified-and-extracts-even-more-data-from-tables-and-forms/"&gt;PCI DSS&lt;/a&gt;、&lt;a href="https://aws.amazon.com/about-aws/whats-new/2020/06/amazon-textract-is-now-soc-and-iso-compliant/?nc1=h_ls"&gt;ISO SCO&lt;/a&gt; 和 &lt;a href="https://aws.amazon.com/blogs/security/aws-extends-its-mtcs-level-3-certification-scope-to-cover-united-states-regions/"&gt;MTCS&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-54262" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/24/2021-textract-price-reduction.png" alt="" width="2018" height="546"&gt;&lt;/p&gt; 
&lt;p&gt;客户使用 Amazon Textract 自动执行关键业务流程工作流（例如，在索赔和纳税表处理、贷款申请和应付账款方面）。这样可以缩短人工审核时间、提高准确性、降低成本并加快全球范围的创新步伐。与此同时，&lt;a href="https://aws.amazon.com/textract/customers/"&gt;Textract 客户&lt;/a&gt;告诉我们，我们可以做更多的工作来降低成本和改善延迟现象。&lt;/p&gt; 
&lt;p&gt;今天，我们很高兴地宣布对 Amazon Textract 的两项主要更新：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;8 个亚马逊云科技区域的价格降幅达 32%，帮助&lt;/strong&gt;全球客户通过 Textract 节省更多成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Textract 全球&lt;/strong&gt;异步操作的端到端任务处理时间减少近 50%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;8 个亚马逊云科技区域的价格降幅达 32％&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; 我们很高兴地宣布，8 个亚马逊云科技区域的价格降幅达 32％：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、加拿大（中部）、欧洲（法兰克福）、欧洲（伦敦）和欧洲（巴黎）。&lt;/p&gt; 
&lt;p&gt;这些亚马逊云科技区域中 &lt;code&gt;DetectDocumentText&lt;/code&gt; (OCR) 和 &lt;code&gt;AnalyzeDocument&lt;/code&gt;（表单和表格）的 API 定价现在与美国东部（弗吉尼亚北部）区域的定价相同。这些已确定区域的客户将看到 API 定价下降 9-32％。&lt;/p&gt; 
&lt;p&gt;在降价之前，客户对 &lt;code&gt;DetectDocumentText&lt;/code&gt; 和 &lt;code&gt;AnalyzeDocument&lt;/code&gt; API 的使用情况将按不同的费率、按区域及其使用套餐收费。无论从哪个亚马逊云科技商业区域 Textract 调用，现在都将按同样的费率向该客户收费。&lt;/p&gt; 
&lt;table style="width: 100%;border: 1px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto;text-align: right"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border: 1px solid black;background-color: #eee"&gt; 
   &lt;td style="text-align: center;border: 1px solid black" rowspan="2"&gt;&lt;strong&gt;亚马逊云科技区域&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="text-align: center;border: 1px solid black" colspan="3"&gt;&lt;strong&gt;DetectDocumentText API&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="text-align: center;border: 1px solid black" colspan="3"&gt;&lt;strong&gt;AnalyzeDocument API&lt;/strong&gt;&lt;strong&gt;（表单+表格）&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;原价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;新价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;减少&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;原价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;新价格&lt;/td&gt; 
   &lt;td style="border: 1px solid black;text-align: center"&gt;减少&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（孟买）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.830 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black" rowspan="8"&gt;1.50 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;18%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;79.30 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black" rowspan="8"&gt;65.0 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;18%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（首尔）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.845 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;19%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;79.95 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;19%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（新加坡）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;2.200 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;32%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;95.00 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;32%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;亚太地区（悉尼）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.950 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;23%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;84.50 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;23%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;加拿大（中部）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.655 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;9%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;72.15 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;10%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（法兰克福）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.875 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;20%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;81.25 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;20%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（伦敦）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.750 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;14%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;75.00 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;13%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border: 1px solid black"&gt; 
   &lt;td style="border: 1px solid black;text-align: left"&gt;欧洲（巴黎）&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;1.755 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;15%&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;76.05 美元&lt;/td&gt; 
   &lt;td style="border: 1px solid black"&gt;15%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;此表显示了每 1,000 页的两个有效价格示例，用于在降价之前和之后处理前 100 万个按月填的页面。每月页面使用量超过 100 万个套餐的客户还会看到类似的价格下降信息，其详细信息位于 &lt;a href="https://aws.amazon.com/textract/pricing/"&gt;Amazon Textract 定价页面&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;新定价将于 &lt;strong&gt;2021 年 9 月 1 日&lt;/strong&gt;生效。新价格将自动应用于您的账单。此定价变更不适用于欧洲（爱尔兰）、美国商业区域和美国 GovCloud 区域。近期推出的 &lt;code&gt;AnalyzeExpense&lt;/code&gt; API 发票和收据的定价没有任何变化。&lt;/p&gt; 
&lt;p&gt;作为&lt;a href="https://aws.amazon.com/free/"&gt;亚马逊云科技免费套餐&lt;/a&gt;的一部分，您可以免费开始使用 Amazon Textract。&amp;nbsp;免费套餐持续 3 个月，新的 AWS 客户可以使用 Detect Document Text API 每月分析多达 1,000 页，使用 Analyze Document API 或 Analyze Expense API 每月可分析 100 页。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;端到端任务处理时间减少近 50％&lt;/u&gt;&lt;/strong&gt;&lt;br&gt; 客户可以同步（在单页文档中）和异步（在多页文档中）调用 Textract 来检测打印和手写的行和单词（通过 &lt;code&gt;DetectDocumentText &lt;/code&gt;API）以及提取表单和表格（通过 &lt;code&gt;AnalyzeDocument&lt;/code&gt; API）。我们看到，如今绝大多数客户异步调用 Textract 来对他们的文档管道进行大规模处理。&lt;/p&gt; 
&lt;p&gt;根据客户反馈，我们对 Textract 的异步 API 操作进行了多项改善和提高，这些功能将端到端延迟减少了近 50％。具体而言，这些更新将 Textract 客户在全球异步操作中经历的端到端任务处理时间缩短了近 50％。处理时间越短，客户处理文档、实现规模和提高总体生产力的速度就越快。&lt;/p&gt; 
&lt;p&gt;要深入了解 Amazon Textract，请参阅本&lt;a href="https://aws.amazon.com/getting-started/hands-on/extract-text-with-amazon-textract/"&gt;教程中关于从文档&lt;/a&gt;中提取文本和结构性数据、GitHub 中的&lt;a href="https://github.com/aws-samples/amazon-textract-code-samples"&gt;此代码示例&lt;/a&gt;、&lt;a href="https://docs.aws.amazon.com/textract/"&gt;Amazon Textract 文档&lt;/a&gt;，以及 Amazon Web Services Machine Learning 博客&lt;a href="https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-textract/"&gt;中关于 Amazon Textract 的&lt;/a&gt;博客帖子。&lt;/p&gt; 
&lt;p&gt;– &lt;a href="https://twitter.com/channyun"&gt;Channy&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>Announcing the latest AWS Heroes – August 2021</title>
		<link>https://aws.amazon.com/cn/blogs/china/announcing-the-latest-aws-heroes-august-2021/</link>
				<pubDate>Fri, 03 Sep 2021 04:09:00 +0000</pubDate>
		<dc:creator><![CDATA[Ross Barich]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">07b49b3d09f57f003e99de21de38d56a06c40a92</guid>
				<description>AWS 勇士们不遗余力地与社群分享知识，并帮助其他人在 AWS 上更好、更快地进行构建。上个月，我们推出了 AWS 勇士内容库，这是一个资源汇集之地，构建者可以在这里找到灵感并从 AWS 勇士撰写的教学内容中学习，包括博客、视频、幻灯片演示、播客、开源项目等。随着技术社群的日益发展，新的勇士不断涌现，每个季度我们都会表彰来自世界各地的一群杰出人士，他们对社群知识的共享产生重大影响，并受到高度赞赏。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士们&lt;/a&gt;不遗余力地与社群分享知识，并帮助其他人在 AWS 上更好、更快地进行构建。上个月，我们推出了 &lt;a href="https://aws.amazon.com/developer/community/heroes/content-library/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士内容库&lt;/a&gt;，这是一个资源汇集之地，构建者可以在这里找到灵感并从 AWS 勇士撰写的教学内容中学习，包括博客、视频、幻灯片演示、播客、开源项目等。随着技术社群的日益发展，新的勇士不断涌现，每个季度我们都会表彰来自世界各地的一群杰出人士，他们对社群知识的共享产生重大影响，并受到高度赞赏。&lt;/p&gt; 
&lt;p&gt;今天，我们很高兴地介绍最新的 AWS 勇士们，包括位于喀麦隆和马来西亚的首批勇士：&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Denis Astahov – 加拿大温哥华&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/denis-astahov/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/denis-astahov.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士 &lt;a href="https://aws.amazon.com/developer/community/heroes/denis-astahov/" target="_blank" rel="noopener noreferrer"&gt;Denis Astahov&lt;/a&gt; 是 OpsGuru 的一名解决方案构架师，在那里，他使用 Terraform 利用基础设施即代码自动化和开发各种云解决方案。Denis 拥有 YouTube 频道 ADV-IT，他通过该频道向人们讲授各种 IT 知识，尤其是有关 DevOps 的话题，包括 AWS、Terraform、Kubernetes、Ansible、Jenkins、Git、Linux、Python 及许多其他主题。他的频道拥有 7 万多个订阅者和 700 多万观看次数，使其成为俄语社群中 AWS 和 DevOps 知识最受欢迎的免费来源之一。Denis 拥有 10 多项云认证，其中包括 7 项 AWS Certification。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Ivonne Roberts — 美国坦帕&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/ivonne-roberts/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/ivonne-roberts.jpg" width="175" height="263"&gt;&lt;/a&gt;无服务器勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/ivonne-roberts/" target="_blank" rel="noopener noreferrer"&gt; Ivonne Roberts&lt;/a&gt; 是一名首席软件工程师，拥有逾 15 年的软件开发经验，其中包括十年与 AWS 合作的经验以及五年以上构建无服务器应用程序的经验。近年来，Ivonne 已开始与范围更广的软件工程界分享这些行业知识。在其博客 ivonneroberts.com 和 YouTube 频道 DevWidgets 上，Ivonne 专注于揭开采用无服务器架构的神秘面纱并消除障碍，以及简化软件开发生命周期。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Kaushik Mohanraj — 马来西亚吉隆坡&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/kaushik-mohanraj/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/kaushik-mohanraj.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/kaushik-mohanraj/" target="_blank" rel="noopener noreferrer"&gt; Kaushik Mohanraj&lt;/a&gt; 是马来西亚一家名为 Blazeclan Technologies 的公司的董事。Kaushik 是一位狂热的云从业者，在评估架构良好的解决方案方面拥有丰富的经验，并且是云技术和数字化转型大使。Kaushik 持有 10 项有效的 AWS Certification，这有助于他提供最有针对性且且最佳的解决方案。Kaushik 热衷于打造一个他得以在其中充分发展的社群，因此在 2019 年作为联合组织者加入了马来西亚 AWS 用户组。他还是“大数据中的女性 — 马来西亚分会”的联合总监，旨在为科技领域的女性构建和提供一个平台。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Luc van Donkersgoed — 荷兰乌得勒支&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/luc-van-donkersgoed/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/luc-van-donkersgoed.jpg" width="175" height="263"&gt;&lt;/a&gt;DevTools 勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/luc-van-donkersgoed/" target="_blank" rel="noopener noreferrer"&gt; Luc van Donkersgoed&lt;/a&gt; 在内心里是一位技术狂热爱好者，他是一名解决方案构架师、软件开发人员，同时也是一位企业家。他着迷于尖端技术。不在 AWS 上设计和构建强大的应用程序时， Luc 很可能正在博客、文章、视频、会议、培训课程和 Twitter 上分享知识。他撰写了一个 共16 节课的 AWS 解决方案构架师专业课程，内容涉及各种主题，包括 AWS CDK 将如何助力新一代无服务器开发人员，他也曾出现在 AWS 开发人员播客中，同时他也在维护 AWS 博客 Twitter Bot。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Rick Hwang — 台湾台北市&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/rick-hwang/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/rick-hwang.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/rick-hwang/" target="_blank" rel="noopener noreferrer"&gt; Rick Hwang&lt;/a&gt; 是位于台湾的 91APP 的一名云与基础设施架构师。他为开发人员授课的热情已在内部通过年度 AWS 培训项目负责人的身份得以彰显，在外部又通过 SRE Taiwan 社群拥有者的身份得以证明。Rick 独立创办了 SRE Taiwan，在过去的 4 年里，通过点对点互动、不断分享内容和主办年度学习小组聚会，招募了 3,600 多名成员。Rick 乐于帮助人们加深对 AWS 和整个云的了解。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Rosius Ndimofor — 喀麦隆杜阿拉&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/rosius-ndimofor/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/23/rosius-ndimofor.jpg" width="175" height="263"&gt;&lt;/a&gt;无服务器勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/rosius-ndimofor/" target="_blank" rel="noopener noreferrer"&gt; Rosius Ndimo&lt;/a&gt; 是 Serverless Guru 的一名软件开发人员。8 年来，他始终在为各种客户构建桌面、Web 和移动应用程序。2020 年，Rosius 的朋友向他介绍了 AWS，他随即便被吸引住了，并开始尽可能地学习如何构建 AWS 无服务器应用程序。您会看到 Rosius 在当地每月一次的 AWS 聚会活动中发表演讲，或者从事他的强项：构建无服务器 Web 或移动应用程序并在其博客上记录整个过程。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Setia Budi — 印度尼西亚万隆&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/setia-budi/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/19/setia-budi.jpg" width="175" height="263"&gt;&lt;/a&gt;社群勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/setia-budi/" target="_blank" rel="noopener noreferrer"&gt; Setia Budi&lt;/a&gt; 是一名来自印度尼西亚的学者。他经营着一个名为 Indonesia Belajar 的 YouTube 频道，该频道提供与计算机科学和云计算相关的学习资料（以印度尼西亚语提供）。他对 AWS 社区的热情还体现在他在 AWS DevAx Connect 上发表演讲，他正在积极构建一系列与 AWS 服务相关的学习材料，并每周直播 AWS 专家探论云计算的直播会议。&lt;/p&gt; 
&lt;h2 style="clear: both"&gt;Vinicius Caridá — 巴西圣保罗&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/developer/community/heroes/vinicius-carida/" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/vinicius-carida.jpg" width="175" height="263"&gt;&lt;/a&gt;机器学习勇士&lt;a href="https://aws.amazon.com/developer/community/heroes/vinicius-carida/" target="_blank" rel="noopener noreferrer"&gt; Vinicius Caridá（Vini）&lt;/a&gt;是一名计算机工程师，他相信技术、数据和人工智能可以影响人们，进而创造一个更公平、更进步的世界。他喜欢在社交媒体上、YouTube 频道上以及 AWS 圣保罗用户组（他是社群主管）等各种聚会上分享自己关于 AI、NLP 和 MLOps 的知识。Vini 还是开源机器学习框架 TensorFlow 圣保罗的社群主管。他定期参加会议，并为不同背景（学术界、科学界、技术界）和不同成熟程度（初级、中级和高级）的受众撰写文章。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如果您想了解有关这些新勇士的详情，或者与附近的勇士联系，请访问 &lt;a href="https://aws.amazon.com/developer/community/heroes/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士网站&lt;/a&gt;或浏览 &lt;a href="https://aws.amazon.com/developer/community/heroes/content-library/" target="_blank" rel="noopener noreferrer"&gt;AWS 勇士内容库&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://twitter.com/rossbarich" target="_blank" rel="noopener noreferrer"&gt;Ross&lt;/a&gt;；&lt;/p&gt;</content:encoded>
										</item>
	</channel>
</rss>