<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>亚马逊AWS官方博客</title>
	<atom:link href="https://aws.amazon.com/cn/blogs/china/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/cn/blogs/china/</link>
	<description>Just another AWS Brew Blogs  site</description>
	<lastBuildDate>Tue, 31 Aug 2021 04:25:44 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>云原生编排数据分析管道初探</title>
		<link>https://aws.amazon.com/cn/blogs/china/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline/</link>
				<pubDate>Tue, 31 Aug 2021 04:25:44 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[AWS Glue]]></category>
		<category><![CDATA[AWS Step Functions]]></category>

		<guid isPermaLink="false">0b70c5edda6b82f38e382a0cee30e9d3989f70d1</guid>
				<description>公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL) 过程进行任务编排。要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施。二是编排好数据管道的 ETL 任务顺序。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。</description>
								<content:encoded>&lt;h2&gt;摘要&lt;/h2&gt; 
&lt;p&gt;公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL)&amp;nbsp;过程进行任务编排。亚马逊云科技（亚马逊）的 Step Functions 状态机和开源社区的 Airflow 是其中的典型代表。 要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施，例如部署好 Airflow 的调度器和执行器等。二是编排好数据管道的&amp;nbsp;ETL 任务顺序，例如状态机的 JSON 定义文件或者 Airflow 的有向无环图定义。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。&lt;/p&gt; 
&lt;h2&gt;Abstract&lt;/h2&gt; 
&lt;p&gt;Public cloud is one of the most suitable&amp;nbsp;platforms for data analysis and big data processing. In recent years, many excellent workflow orchestration tools have&amp;nbsp;proliferated in cloud services and open source communities to facilitate orchestration of complex ETL jobs in data analysis. AWS Step Functions and Airflow from open source community are two typical examples. To run the data analysis pipelines successfully, at least two steps are necessary. Firstly, to build the infrastructure to support running the data pipelines, such as the deployment of Airflow’s schedulers and executors. Secondly, to orchestrate the ETL tasks in the data pipelines, such as the JSON definition of the state machine or Airflow’s directed acyclic graph definition. The former involves dev-ops, while the latter is related to application. From the perspective of data analysis, it is ideal that the difficulty of dev-ops is minimized, and the user-friendliness of application is maximized. This article analyzes how well Airflow and Step Functions support data analysis pipelines from the above two points of view, and preliminarily discusses the methodology and significance of cloud-native services for orchestrating data pipelines.&lt;/p&gt; 
&lt;h3&gt;目标读者&lt;/h3&gt; 
&lt;p&gt;本文预期读者需要掌握以下技术的基础知识：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache Airflow 及其相关概念&lt;/li&gt; 
 &lt;li&gt;亚马逊开发包：CDK, SDK&lt;/li&gt; 
 &lt;li&gt;亚马逊服务：CloudTrail, EventBridge, Glue, Lambda, MWAA, Redshift, S3, Step Functions, VPC, 密码管理器&lt;/li&gt; 
 &lt;li&gt;语言：Javascript, JSON, Python&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;开放源代码&lt;/h3&gt; 
&lt;p&gt;本文所述解决方案源代码开放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline"&gt;https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;绪论&lt;/h2&gt; 
&lt;p&gt;2020年11月，亚马逊发布了托管的 Airflow 服务，全称为 Managed Workflows for Apache Airflow (MWAA)，支持 1.10.12 版。2021年5月开始支持 2.0.2 版。但截至目前（2021年8月），中国北京区、宁夏区和香港区皆未提供托管服务。如果要使用 Airflow，则需要自行搭建部署，例如利用 Elastic Container Service。或者换成其他云原生的编排服务，例如 Step Functions 状态机或 Simple Workflow Service。本文以某 MWAA 的数据分析指导教程为引子，介绍 MWAA 资源代码化的方法，并对如何在中国区使用云原生服务达到类似编排数据分析管道的目的，进行初探。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;教程简介&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;是指导利用 MWAA 搭建数据分析管道的教程。该分析管道较简单，线性分为五步，分别是监控文件，爬元数据，转换数据，整合数据，保存结果。简单起见，本文将第四步改造为 Glue 任务，不使用 Elastic MapReduce 集群。部署好的数据管道有向无环图如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以 MWAA 为基础的架构图如下所示。虚线和编号表示该数据管道运行时的数据流向和任务执行顺序。此处不同服务的调用是通过 Airflow 的操作符间接完成的，以 Python 定义在数据管道的有向无环图中。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;根据该教程介绍，完成时间为一小时左右。抛开初学者的因素，所用时间较长主要是因为所涉及的资源及其配置都是在亚马逊控制台上手工完成，非常耗时，效率低下。如果利用资源代码化技术，则部署时间可以在数分钟内完成（排除 MWAA 自身启动需要的约半小时），提高工作效率，尤其在需要多环境部署测试的情况下。&lt;/p&gt; 
&lt;h3&gt;资源代码化&lt;/h3&gt; 
&lt;p&gt;利用亚马逊云开发包 (Cloud Development Kit)，可快速构建云资源部署程序。结合相关代码仓库管理工具如 github，可代码化管理资源的创建和修改过程，方便协同工作和排错溯源。限于篇幅以下仅展示关键代码。完整代码请参阅开放源代码。首先建立 Redshift 集群。云开发包建立好集群后，会自动在密码管理器中新建一密码项，即为该集群的连接密码，全程密码无暴露。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;createCluster(landingZone, subnetGroup) {
    return new redshift.Cluster(this, &amp;quot;MainCluster&amp;quot;, {
        masterUser: { masterUsername: &amp;quot;admin&amp;quot; },
        vpc: landingZone.vpc,
        numberOfNodes: 2,
        publiclyAccessible: false,
        defaultDatabaseName: RedshiftStack.DB_NAME,
        securityGroups: [landingZone.securityGroup],
        nodeType: redshift.NodeType.DC2_LARGE,
        roles: [this.role],
        subnetGroup: subnetGroup
    })
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其次是建立 MWAA 环境。简化起见配置为可以公网访问。实际生产中建议配置为私网访问。MWAA 对网络配置有特别要求，若不达标环境可能无法启动。子网建议配置为私有子网，即有路由到 NAT 网关。具体请参阅使用手册。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;createEnvironment(envName, role, landingZone, bucket) {
    return new airflow.CfnEnvironment(this, &amp;quot;Lab&amp;quot;, {
        name: envName,
        airflowVersion: &amp;quot;2.0.2&amp;quot;,
        environmentClass: &amp;quot;mw1.small&amp;quot;,
        executionRoleArn: role.roleArn,
        sourceBucketArn: bucket.bucketArn,
        webserverAccessMode: &amp;quot;PUBLIC_ONLY&amp;quot;,
        dagS3Path:           &amp;quot;airflow/lab/dags&amp;quot;,
        pluginsS3Path:       &amp;quot;airflow/lab/plugins/awsairflowlib_202.zip&amp;quot;,
        requirementsS3Path:  &amp;quot;airflow/lab/requirements/requirements.txt&amp;quot;,
        networkConfiguration: {
            securityGroupIds: [landingZone.securityGroup.securityGroupId],
            subnetIds: landingZone.vpc.privateSubnets.map(subnet =&amp;gt; subnet.subnetId)
        }
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;MWAA 配置好以后，还需要把有向无环图定义文件上传到存储桶指定位置。利用云开发包的 S3 部署模块完成：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;uploadDagFile(bucket) {
    new deploy.BucketDeployment(this, &amp;quot;DagScript&amp;quot;,
        sources: [deploy.Source.asset(path.join(__dirname, '../../scripts/airflow/lab/dags/'))],
        destinationBucket: bucket,
        destinationKeyPrefix: 'airflow/lab/dags/'
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;至此就完成了 MWAA 相关资源的部署程序。部署上述 MWAA 大约耗时半小时，因为涉及服务器的启动连接等。部署耗时长也凸显出非无服务器服务的弊端。当环境状态变为“可用”后，点击“打开 Airflow UI”即可打开 Airflow 的控制台。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;部署完成后，根据教程即可完成数据分析管道相关操作。Airflow 控制台可以显示数据管道完成时间甘特图，形象展示各任务耗时多寡。这是其亮点之一。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;安全隐患&lt;/h3&gt; 
&lt;p&gt;最后一步把存储桶文件复制到 Redshift，需要在&amp;nbsp;Airflow 控制台配置到 Redshift 的连接。连接属性包含用户名和密码明文。此处有暴露密码明文的安全隐患。下面介绍的云原生技术通过密码管理器实现无缝连接，可有效规避密码暴露风险，切实提高系统安全水平。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;云原生编排&lt;/h2&gt; 
&lt;p&gt;目前 MWAA 尚不支持中国区，故需要自行搭建并维护&amp;nbsp;Airflow 环境，例如在 ECS Fargate 上。但是运维难度不容小觑。亚马逊提供了其他编排服务，例如状态机，完全可以代替&amp;nbsp;Airflow 对数据管道进行编排。此外状态机是无服务器的，毋需关心并事先设定服务器数量性能等运维难题。使用云原生服务，和其他服务紧密集成，可最大化服务效益，增强安全性。和教程数据分析管道等价的状态机工作流如下所示。状态机跨服务集成支持直接启动 Glue 任务，较为简单。其他步骤需做些许变通。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以云原生服务为基础的架构图如下所示。状态机在各服务之间调度，其中 Glue 任务可以直接执行。爬虫任务需要通过 Lambda 函数辅助。把存储桶的数据载入到 Redshift 可以有多种方法完成，例如 Glue 任务可以直接连接 Redshift 并保存数据。为了和教程中的步骤一一对应，此处利用 Lambda 函数来辅助完成。存储桶文件监控则通过跟踪与规则联合完成。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;爬元数据&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成目前暂不支持调用 Glue 爬虫，需替代方案。此处利用两个 Lambda 函数和轮询机制实现相同功能。启动爬虫很简单：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;await glue.startCrawler({Name: crawlerName}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫状态查询，如果不是“就绪”状态，则等待十秒后再次查询，直至成功或者超时。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;exports.handler = async event =&amp;gt; {
    response = await glue.getCrawler({Name: event.crawlerName}).promise();
    const state = response.Crawler.State;
    return state == &amp;quot;READY&amp;quot;;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫调用代替方案的其他两步可以利用状态机的“选择”和“等待”原生操作符完成。这里传入变量 next 作为爬虫轮询结束后的下一步操作。以下代码可作为爬虫调用的模版使用。若想提高响应速度可缩短等待时长。一个典型的爬虫任务需时数分钟。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;createCrawlerStep(next) {
    const crawlTask = new task.LambdaInvoke(this, &amp;quot;Crawl&amp;quot;, {
        lambdaFunction: this.lambda(&amp;quot;CrawlLambda&amp;quot;, role, &amp;quot;../lambda/crawler/crawl&amp;quot;),
        payload: sf.TaskInput.fromObject({CrawlerTagName: &amp;quot;NF1-Airflow-Lab-RawGreenCrawler&amp;quot;}),
        payloadResponseOnly: true,
        resultPath: &amp;quot;$.crawlerName&amp;quot;,
    });
    const checkCrawled = new task.LambdaInvoke(this, &amp;quot;Check if crawled&amp;quot;, {
        lambdaFunction: this.lambda(&amp;quot;CheckCrawledLambda&amp;quot;, role, &amp;quot;../../lambda/crawler/check&amp;quot;),
        payloadResponseOnly: true,
        resultPath: &amp;quot;$.crawled&amp;quot;,
    });
    const wait = 10;
    crawlTask.next(checkCrawled)
    .next(new sf.Choice(this, &amp;quot;Is crawled?&amp;quot;)
        .when(sf.Condition.booleanEquals(&amp;quot;$.crawled&amp;quot;, true), next)
        .otherwise(new sf.Wait(this, `Wait for ${wait} Seconds`, {
            time: sf.WaitTime.duration(core.Duration.seconds(wait)),
        }).next(checkCrawled)));
    return crawlTask;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;保存结果&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成尚未对 Redshift 提供支持，对保存结果需要替代方案。Airflow 提供 S3ToRedshiftOperator 操作符将数据从存储桶复制到 Redshift 表中。本质上是通过 Redshift 的 COPY 命令实现的。替代方案亦遵循此思路。利用亚马逊软件开发包的 RedshiftData 模块，可以执行 SQL 语言和数据操作命令。此处通过密码 ARN 获取密码，完全规避密码明文暴露的问题。此外 Glue 也提供应用接口支持直接把数据保存到 Redshift。在保存数据到数据仓库之前可多做一步，将目标表做清空操作（truncate 或 delete），避免因原表中有数据导致冗余。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;await data.executeStatement({
    ClusterIdentifier: event.ClusterIdentifier,
    Database: event.Database,
    SecretArn: event.SecretArn,
    Sql: event.Sql
}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;状态机保存结果的替代方案可以一个 Lambda 函数实现。在生产环境，此处建议以更细粒度和最小化原则配置该函数所赋予的权限，夯实系统安全性。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;createCopyS3ToRedshift(bucket, redshift) {
    const dir = bucket.s3UrlForObject(&amp;quot;airflow/lab/data/aggregated&amp;quot;);
    const sql = `copy nyc.green from '${dir}' iam_role '${redshift.role.roleArn}' format as parquet;`;

    return new task.LambdaInvoke(this, &amp;quot;Copy S3 to Redshift&amp;quot;, {
        lambdaFunction: this.lambda(&amp;quot;CopyToRedshiftLambda&amp;quot;, role, &amp;quot;../lambda/redshift/execute&amp;quot;),
        payloadResponseOnly: true,
        payload: sf.TaskInput.fromObject({
            ClusterIdentifier: redshift.cluster.clusterName,
            Database: RedshiftStack.DB_NAME,
            SecretArn: redshift.cluster.secret.secretArn,
            Sql: sql,
        })
    });
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;监控文件&lt;/h3&gt; 
&lt;p&gt;最后还需要处理对存储桶文件的监控任务。Airflow 提供 S3PrefixSensor&amp;nbsp;来监控文件上传到某个桶，进而触发数据管道进行数据处理。此处有多种方式监控存储桶里面的文件。例如 S3 自带的事件通知功能。不过事件通知的目标不支持启动状态机，还需要 Lambda 辅助。或者可以通过 CloudTrail 跟踪桶写入操作，然后通过 EventBridge 的个规则来捕获事件进而触发状态机执行。跟踪只需要关注特定桶特定目录的写入即可。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;createTrail(logBucket, monitorBucket) {
    const trail = new cloudtrail.Trail(this, 'CloudTrail', {
        bucket: logBucket,
        s3KeyPrefix: &amp;quot;data-trail&amp;quot;,
    });
    trail.addS3EventSelector(
        [{bucket: monitorBucket, objectPrefix: &amp;quot;airflow/lab/data/raw&amp;quot;}],
        {readWriteType: cloudtrail.ReadWriteType.WRITE_ONLY});
    return trail;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;捕获规则和跟踪一样，只需要捕获特定桶特定目录的写入即可，此处利用 prefix&amp;nbsp;前缀操作符来限定。规则目标可以直接启动状态机，开启数据分析管道进程。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;createS3Event(machine, bucket) {
    new events.Rule(this, &amp;quot;S3StepFunctions&amp;quot;, {
        description: &amp;quot;S3 invoke StepFunctions&amp;quot;,
        eventPattern: {
            source: [ &amp;quot;aws.s3&amp;quot; ],
            detailType: [ &amp;quot;AWS API Call via CloudTrail&amp;quot; ],
            detail: {
                &amp;quot;eventSource&amp;quot;: [ &amp;quot;s3.amazonaws.com&amp;quot; ],
                &amp;quot;eventName&amp;quot;: [ &amp;quot;PutObject&amp;quot; ],
                &amp;quot;requestParameters&amp;quot;: {
                    &amp;quot;bucketName&amp;quot;: [ bucket.bucketName ],
                    &amp;quot;key&amp;quot;: [{ &amp;quot;prefix&amp;quot;: &amp;quot;airflow/lab/data/raw&amp;quot; }]
                }}},
        targets: [ new targets.SfnStateMachine(machine) ]
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;方案对比&lt;/h2&gt; 
&lt;p&gt;至此云原生编排数据分析管道的改造宣告完成。回顾本文，重新审视和对比各项方案的利弊得失，可以更好的帮助读者选择更适合业务场景的方案。例如，如果在中国区新建数据分析管道项目，则建议使用状态机。如果从 Airflow 的老环境迁移上云，则建议使用 MWAA 或者自建 Airflow，这样可以复用积累的代码。亦可两者并行，对新的数据管道用云原生方案。&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;&lt;strong&gt;状态机&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="86"&gt;&lt;strong&gt;MWAA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="106"&gt;&lt;strong&gt;自建 Airflow&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;编写语言&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;JSON 及云开发包支持的所有语言&lt;br /&gt; (TypeScript, JavaScript, Python, Java, and C#)&lt;/td&gt; 
   &lt;td width="86"&gt;Python&lt;/td&gt; 
   &lt;td width="106"&gt;Python&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;支持中国区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;是&lt;/td&gt; 
   &lt;td width="86"&gt;否&lt;/td&gt; 
   &lt;td width="106"&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;无服务器&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;是&lt;/td&gt; 
   &lt;td width="86"&gt;否&lt;/td&gt; 
   &lt;td width="106"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;托管服务&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;是&lt;/td&gt; 
   &lt;td width="86"&gt;是&lt;/td&gt; 
   &lt;td width="106"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;连接密码暴露&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;否&lt;/td&gt; 
   &lt;td width="86"&gt;是&lt;/td&gt; 
   &lt;td width="106"&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;开源社区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;否&lt;/td&gt; 
   &lt;td width="86"&gt;是&lt;/td&gt; 
   &lt;td width="106"&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;部署时间（近似值）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;开箱即用&lt;/td&gt; 
   &lt;td width="86"&gt;一小时&lt;/td&gt; 
   &lt;td width="106"&gt;数小时到数天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt; &lt;p&gt;&lt;strong&gt;Airflow &lt;/strong&gt;&lt;strong&gt;最新版本&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;（2021&lt;/strong&gt;&lt;strong&gt;年8&lt;/strong&gt;&lt;strong&gt;月）&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;不适用&lt;/td&gt; 
   &lt;td width="86"&gt;2.0.2&lt;/td&gt; 
   &lt;td width="106"&gt;2.1.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="158"&gt;&lt;strong&gt;服务调度集成&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="240"&gt;云原生&lt;/td&gt; 
   &lt;td width="86"&gt;通过操作符&lt;/td&gt; 
   &lt;td width="106"&gt;通过操作符&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;本文从 MWAA 的数据分析管道指导教程为引子，介绍利用云开发包快速搭建部署程序的方法，并以状态机为编排平台，尝试改造其为云原生编排的数据管道，辅以几个关键操作的替代方案介绍。本文初步探讨云原生编排数据分析管道的方法，借此抛砖引玉，供读者讨论。从“方案对比”一节可以看出，云原生的编排方案有诸多优势，尤其表现在零部署时间，无服务器化管理，多语言支持和增强安全性上。相信随着跨服务集成的深度和广度越来越高，云原生的编排优势会如虎添翼，成为数据分析管道编排平台的不二选择。&lt;/p&gt; 
&lt;h3&gt;工作展望&lt;/h3&gt; 
&lt;p&gt;有几个有趣的展开方向。首先就 Airflow 的诸多操作符，研究云原生改造方法，以期对所有 Airflow 有向无环图皆可支持改造，利于迁移。能自动化改造更佳。其次研究将 Airflow 的数据分析管道以 Glue 的蓝图和工作流为基础进行改造。Glue 蓝图的编排平台和状态机的编排平台是一对有趣的对比。再者就自建 Airflow 的方案如何高效搭建基础设施并降低运维难度亦值得关注。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/clementy.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;袁文俊&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务部顾问。曾在亚马逊美国西雅图总部工作多年，就职于 Amazon Relational Database Service (RDS) 关系型数据库服务开发团队。拥有丰富的后端开发及运维经验。现负责业务持续性及可扩展性运行、企业应用及数据库上云迁移、云上灾难恢复管理系统等架构咨询、方案设计及项目实施工作。他拥有复旦大学理学学士学位和香港大学哲学硕士学位。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xzhom.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;赵鑫&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务团队数据架构师，专注于生命科学、自动驾驶领域的数据架构与数据分析&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用托管节点组结合启动模板简化EKS升级与运维</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance/</link>
				<pubDate>Tue, 31 Aug 2021 04:09:59 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Containers]]></category>
		<category><![CDATA[Amazon EKS]]></category>
		<category><![CDATA[Amazon EKS Managed Node Group]]></category>
		<category><![CDATA[EC2 Launch Template]]></category>

		<guid isPermaLink="false">c7a2915de4f1e2f686bc64ad252f93fc8fe230e0</guid>
				<description>随着应用容器化不断流行与深入，采用Kubernetes（K8S）作为容器编排方式的应用也随之增加。作为亚马逊云科技的用户，在云上使用Amazon Web Service托管的K8S服务Elastic Kubernetes Service（EKS）服务的客户也在不断增加。同时根据K8S社区的发布规则K8S每年会有三个小版本的发布， 相应的EKS也会跟随上游K8S的版本发布3个版本，目前支持的版本以及相应终止支持的时间信息可以参考亚马逊EKS发布日历。</description>
								<content:encoded>&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;随着应用容器化不断流行与深入，采用Kubernetes（K8S）作为容器编排方式的应用也随之增加。作为亚马逊云科技的用户，在云上使用Amazon Web Service托管的K8S服务Elastic Kubernetes Service（EKS）服务的客户也在不断增加。同时根据K8S社区的发布规则K8S每年会有三个小版本的发布， 相应的EKS也会跟随上游K8S的版本发布3个版本，目前支持的版本以及相应终止支持的时间信息可以参考&lt;a href="https://docs.aws.amazon.com/zh_cn/eks/latest/userguide/kubernetes-versions.html"&gt;亚马逊EKS发布日历&lt;/a&gt;。每个上游的K8S版本都会有1年支持窗口加上2个月升级过渡窗口，为了保持与K8S社区版本的同步来获得社区的支持，客户每隔一段时间都要对现有的K8S或者EKS集群做升级，也就是说K8S与EKS的升级已经成为常态。&lt;/p&gt; 
&lt;p&gt;在EKS上这个升级主要涉及到控制平面升级、数据平面升级与插件组件升级。其中以数据平面的升级最为繁琐与复杂，所以本着减少无差别的繁重的运维工作为出发点，本文通过一个端到端的实验详细介绍通过使用托管节点组与启动模板简化客户的升级操作的过程与方法，从而为运维人员减负。并实现应用的平滑升级与灵活回退，进而保证应用与业务的稳定和可用性。&lt;/p&gt; 
&lt;p&gt;了解EKS的用户或者读者知道EKS的数据平面可以分为有服务器与无服务器两大类：有服务器即采用EC2的方式来运行K8S的应用；无服务器的方式即EKS Fargete，客户将工作负载部署在Fargate的环境而不是自己的VPC内，EKS节点对客户透明。有服务器EC2的节点管理方式又分为两种模式：&lt;a href="https://eksctl.io/usage/eks-managed-nodes/"&gt;托管节点组&lt;/a&gt;（Managed Node Group）与&lt;a href="https://eksctl.io/usage/nodegroup-upgrade/"&gt;非托管节点组&lt;/a&gt;（Unmanaged Node Group）。非托管节点组的命名来自于官方的EKS创建与维护工具eksctl.io文档中Unmanaged Node Group的中文直译，根据EKS官方文档， 非托管节点组模式被称为自行管理的节点（Self-managed nodes），为了简化与对比起见本文统一称为非托管节点组。托管节点组即将集群EC2节点的创建与生命周期管理由EKS服务来自动化管理，不需要客户干预。根据&lt;a href="https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability"&gt;eksctl对非托管节点组的设计原则&lt;/a&gt;，非托管节点组中的节点除了可以做扩缩容其他配置均不可变。下表列出了两种模式的主要区别：&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;项目&lt;/td&gt; 
   &lt;td width="198"&gt;托管节点组&lt;/td&gt; 
   &lt;td width="331"&gt;非托管节点组&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;升级方法&lt;/td&gt; 
   &lt;td width="198"&gt;原地升级&lt;/td&gt; 
   &lt;td width="331"&gt; &lt;p&gt;需要创建新的非托管节点组&lt;/p&gt; &lt;p&gt;（注：适用于通过eksctl创建的非托管节点组，其他方式可以通过更新CloudFormation&lt;/p&gt; &lt;p&gt;栈的方法更新AMI来升级，细节可以参考：&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/update-workers.html"&gt;官方文档&lt;/a&gt;）&lt;/p&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;EKS管理控制台可见&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;配置变更支持&lt;/td&gt; 
   &lt;td width="198"&gt; &lt;p&gt;是（可以变更的选项有：Min Size，Max Size，Desired Size, Kubernetes labels, taints, tags,&lt;/p&gt; &lt;p&gt;Maximum unavailable等配置，其他配置项变更需要通过切换启动模板版本实现。）&lt;/p&gt;&lt;/td&gt; 
   &lt;td width="331"&gt;否（除节点数量扩缩）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;支持关联启动模板&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;自定义AMI支持&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;考虑到EKS 1.17将于2021年11月终止支持，同时目前绝大部分客户使用的还是EC2的方式，并且因为非托管节点组相对于托管节点组的功能是更早发布，加上早期的托管节点组功能较少的原因，一部分客户还停留在非托管节点组的模式，所以本文的实验通过将非托管节点组转换为托管节点组结合启动模板的方式简化EKS 集群从1.17升级到1.18的升级过程（虽然本实验进行的的是1.17到1.18的升级，但过程和其中的方法对其他EKS版本的升级同样适用，比如从1.15升级到1.16或者1.18升级到1.19）。其中主要内容涵盖：控制平面升级、数据平面非托管节点组迁移到托管节点组、托管节点组升级与变更等。&lt;/p&gt; 
&lt;p&gt;在升级路径的选择上，也可以先将控制平面由1.17升级到1.18，然后创建托管节点组，再将工作负载由非托管节点组迁移到托管节点组，这样可以减少一次数据平面托管节点组的升级，加快集群整体升级的过程。因为本文的重点是介绍推广托管节点组结合启动模板的实践方法，先升级控制平面再创建托管节点组的做法，笔者测试下来对于文中简单的样例应用Nginx是可以的，遵从K8S官方的&lt;a href="https://kubernetes.io/releases/version-skew-policy/"&gt;Version Skew Policy&lt;/a&gt;：kubelet must not be newer than kube-apiserver, and may be up to two minor versions older。笔者尝试过将控制平面从1.17升级到1.18再连续升级到1.19，然后再创建托管节点组与迁移工作负载也是可以成功通过的，但如果集群中有对1.17到1.18/1.19版本变化敏感或者需要改造的应用，稳妥起见还是建议按照本实验的顺序来操作，并引入必要的测试。有兴趣的读者可以自行测试验证。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;本文目标读者：EKS运维与管理人员&lt;/p&gt; 
&lt;p&gt;实验所需时长：3小时&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;操作步骤&lt;/h2&gt; 
&lt;p&gt;前提：当前使用的用户具有Administrator Access权限&lt;/p&gt; 
&lt;h3&gt;准备Cloud9实验环境&lt;/h3&gt; 
&lt;p&gt;在AWS管理控制台中选择Cloud9服务，然后创建一个名称为：eksworkshop的环境，将Cost-saving setting选项设置为：After four hours，其他配置保持默认。创建完毕后关闭Welcome和底部的工作区页面，然后在主工作区中打开一个新的Terminal。&lt;/p&gt; 
&lt;p&gt;在IAM服务中，使用&lt;a href="https://console.aws.amazon.com/iam/home#/roles$new?step=type&amp;amp;commonUseCase=EC2%2BEC2&amp;amp;selectedUseCase=EC2&amp;amp;policies=arn:aws:iam::aws:policy%2FAdministratorAccess"&gt;链接&lt;/a&gt;创建一个名称为：eksworkshop-admin的角色，确认：AWS service和EC2被选中，点击下一步，确认AdministratorAccess策略被选中，点击下一步，跳过Tag选项，点击下一步在Review页面中输入eksworkshop-admin作为新角色的名称，点击创建角色完成创建。&lt;/p&gt; 
&lt;p&gt;点击&lt;a href="https://console.aws.amazon.com/ec2/v2/home?#Instances:tag:Name=aws-cloud9-eksworkshop;sort=desc:launchTime"&gt;链接&lt;/a&gt;在EC2服务中查看刚刚创建的Cloud9环境对应的EC2实例，选中该实例，然后在菜单选择：Actions / Security / Modify IAM Role，在IAM Role的下拉列表中选择eksworkshop-admin的角色，点击保存。&lt;/p&gt; 
&lt;p&gt;返回刚刚创建好的Cloud9环境，点击页面右上角的齿轮，打开首选项设置页面，然后选择AWS SETTINGS，关闭AWS managed temporary credentials单选框，最后关闭首选项设置页面。&lt;/p&gt; 
&lt;p&gt;在打开的终端中运行以下命令确认临时的秘钥凭证已经被删除干净，并验证在返回结果的ARN 中包含eksworkshop-admin。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;rm -vf ${HOME}/.aws/credentials&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws sts get-caller-identity&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列脚本安装实验所需的Kubernetes 工具：eksctl，kubectl，helm，jq，aws cli&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;# create a folder for the scripts
mkdir ~/environment/scripts
# tools script
cat &amp;gt; ~/environment/scripts/install-tools &amp;lt;&amp;lt;-&amp;quot;EOF&amp;quot;
#!/bin/bash -ex
sudo yum install -y jq gettext bash-completion

# install kubectl
sudo curl --silent --location -o /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.18.10/bin/linux/amd64/kubectl
sudo chmod +x /usr/local/bin/kubectl
echo 'source &amp;lt;(kubectl completion bash)' &amp;gt;&amp;gt;~/.bashrc
source ~/.bashrc
# install eksctl
curl --silent --location &amp;quot;https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz&amp;quot; | tar xz -C /tmp
sudo mv -v /tmp/eksctl /usr/local/bin
if ! [ -x &amp;quot;$(command -v jq)&amp;quot; ] || ! [ -x &amp;quot;$(command -v envsubst)&amp;quot; ] || ! [ -x &amp;quot;$(command -v kubectl)&amp;quot; ] || ! [ -x &amp;quot;$(command -v eksctl)&amp;quot; ] || ! [ -x &amp;quot;$(command -v ssm-cli)&amp;quot; ]; then
  echo 'ERROR: tools not installed.' &amp;gt;&amp;amp;2
  exit 1
fi
#pip install awscli --upgrade --user
# install aws cli v2
curl &amp;quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&amp;quot; -o &amp;quot;awscliv2.zip&amp;quot;
unzip awscliv2.zip
sudo ./aws/install
. ~/.bash_profile
# install helm 3
curl -sSL https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
helm version --short
helm repo add stable https://charts.helm.sh/stable
helm completion bash &amp;gt;&amp;gt; ~/.bash_completion
. /etc/profile.d/bash_completion.sh
. ~/.bash_completion
source &amp;lt;(helm completion bash)
helm repo update
EOF
chmod +x ~/environment/scripts/install-tools
~/environment/scripts/install-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;创建EKS集群（版本：1.17）&lt;/h3&gt; 
&lt;p&gt;配置创建集群需要的环境变量&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account)
export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r '.region')
export EKS_CLUSTER_NAME=eksworkshop
export EKS_UNMANAGED_NODEGROUP_NAME=ung-1
export EKS_MANAGED_NODEGROUP_NAME=mng-1
export AWS_DEFAULT_REGION=$AWS_REGION
echo &amp;quot;export ACCOUNT_ID=${ACCOUNT_ID}&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
echo &amp;quot;export AWS_REGION=${AWS_REGION}&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
echo &amp;quot;export AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;quot;export EKS_CLUSTER_NAME=${EKS_CLUSTER_NAME}&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;quot;export EKS_MANAGED_NODEGROUP_NAME=${EKS_MANAGED_NODEGROUP_NAME}&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;quot;export EKS_UNMANAGED_NODEGROUP_NAME=${EKS_UNMANAGED_NODEGROUP_NAME}&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
aws configure set default.region ${AWS_REGION}
aws configure get default.region
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;运行下列命令创建EKS集群配置模板文件 eks-cluster.yml.template&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;cat &amp;gt; ~/environment/scripts/eks-cluster.yml.template &amp;lt;&amp;lt;-&amp;quot;EOF&amp;quot;
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: $EKS_CLUSTER_NAME
  region: $AWS_REGION
  version: &amp;quot;1.17&amp;quot;
nodeGroups:
  - name: $EKS_UNMANAGED_NODEGROUP_NAME
    minSize: 1
    maxSize: 3
    desiredCapacity: 2
    labels: {role: unmanaged-ng-worker}
    tags:
      Name: unmanaged-ng-worker
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;利用 &lt;a href="https://eksctl.io/"&gt;eksctl &lt;/a&gt;工具来创建 EKS 集群，运行下列命令创建一个 EKS 1.17 的集群，同时会创建一个新的 VPC，并且在该VPC中创建 一个含有2个节点的非托管节点组，整个过程大概需要 20 分钟左右（集群和节点组各10分钟左右）。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;envsubst &amp;lt; ~/environment/scripts/eks-cluster.yml.template &amp;gt; ~/environment/scripts/eks-cluster.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create cluster -f ~/environment/scripts/eks-cluster.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在EKS服务界面上验证集群eksworkshop已经成功创建。运行下列命令验证 EKS 集群节点组ung-1已经成功创建&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl get nodegroup --cluster $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令测试 EKS 集群节点是否正常工作&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get nodes --show-labels&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令将当前登录管理控制台的用户加入到EKS集群管理员组中，这样使得当前登录用户可以在EKS服务界面上查看集群信息。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;c9builder=$(aws cloud9 describe-environment-memberships --environment-id=$C9_PID | jq -r '.memberships[].userArn')
if echo ${c9builder} | grep -q user; then
	rolearn=${c9builder}
        echo Role ARN: ${rolearn}
elif echo ${c9builder} | grep -q assumed-role; then
        assumedrolename=$(echo ${c9builder} | awk -F/ '{print $(NF-1)}')
        rolearn=$(aws iam get-role --role-name ${assumedrolename} --query Role.Arn --output text) 
        echo Role ARN: ${rolearn}
fi
eksctl create iamidentitymapping --cluster $EKS_CLUSTER_NAME --arn ${rolearn} --group system:masters --username admin
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们可以在EC2控制台看到新创建了2个名称为eksworkshop-ung-1-Node类型为m5.large 的EC2实例，也可以在管理控制台的EKS服务的集群列表中查看刚刚创建好的集群节点、网络和其他集群配置信息。因为我们刚刚创建的是一个非托管节点组，所以如下图所示在EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute界面查看托管节点组为空&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 同时，因为eksctl工具的底层实现是依赖CloudFormation服务的，所以可以再CloudFormation服务的管理界面查看为了创建集群而新建的2个CloudFormaiton模板：集群控制平面CloudFormaiton Stack、非托管节点组CloudFormaiton Stack。+&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;部署样例工作负载&lt;/h3&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;cat &amp;gt; ~/environment/scripts/nginx.yaml &amp;lt;&amp;lt;-&amp;quot;EOF&amp;quot;
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 10
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: &amp;quot;nginx&amp;quot;
spec:
  selector:
    app: nginx
  type: ClusterIP
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
EOF
kubectl apply -f ~/environment/scripts/nginx.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过下列命令参考样例Nginx程序已经成功部署&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get deploy&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;创建启动模板&lt;/h3&gt; 
&lt;p&gt;进入EC2服务，选择Launch Templates &amp;gt; Create launch template，分别填入&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Launch template name：demo&lt;/li&gt; 
 &lt;li&gt;Instance type：large&lt;/li&gt; 
 &lt;li&gt;Security groups：在EKS集群管理控制台 EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Networking中显示Cluster security groupInfo的安全组ID&lt;/li&gt; 
 &lt;li&gt;Resource Tags Key: Name, Value: eksworkshop-mng-1, Resource types: Instances&lt;/li&gt; 
 &lt;li&gt;User Data: 如果某些客户在使用非托管节点组的配置YAML文件中有使用：preBootstrapCommands或者overrideBootstrapCommand之类的一些自定义命令，那么在转换到托管节点组加启动模板这种方式后将不再支持，如果继续使用会出现错误：cannot set instanceType, ami, …, preBootstrapCommands, overrideBootstrapCommand, placement in managedNodeGroup when a launch template is supplied。用户可以将这些选项中配置的SHELL命令迁移到User Data中。如果有使用自定义AMI，则必须在User Data中填入下列命令将节点加入到集群，否则会出现错误：node bootstrapping script (UserData) must be set when using a custom AMI。具体User Data输入的MIME格式要求请参考这里的&lt;a href="https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html"&gt;官方文档&lt;/a&gt;。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;#!/bin/bash&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/eks/bootstrap.sh cluster_name&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;点击Create launch template创建启动模板。在启动模板的版本列表中查看刚刚创建好的版本号为1的启动模板，因为启动模板的版本是不可变的，只能通过选择版本1后点击Actions &amp;gt; Modify template (Create new version)来创建新的版本。&lt;/p&gt; 
&lt;p&gt;如果在EKS集群中有使用自定义AMI，那么可以在创建模板过程中指定已经定义好的AMI。需要注意的是，根据&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html"&gt;EKS升级官方文档&lt;/a&gt;在升级控制平面之前要求自定义AMI的节点版本需要与控制平面的版本相同。在本实验中来说就是要求自定义AMI及kubelet版本必须是1.17。这样当控制平面升级到1.18以后就会导致托管节点组还停留在1.17版本，存在一个小版本的差异。这样在托管节点组升级到1.18之前是不能将控制平面升级到版本1.19，否则得到错误提示：Nodegroups xxx must be updated to match cluster version 1.1x before updating cluster version。如果自定义AMI的节点组比控制平面低一个版本，则不能直接在界面上通过点击“Update now”操作来升级节点组。如果后续有继续将版本从1.18升级到更高版本的需求则需要根据目标EKS版本的EKS优化AMI重新定义自己的AMI，通过创建新的启动模板版本来指定这个新的AMI，然后再托管节点组中切换启动模板版本即可完成升级。具体切换启动模板版本的流程可以参考下面的章节“切换启动模板版本”。&lt;/p&gt; 
&lt;h3&gt;创建托管节点组&lt;/h3&gt; 
&lt;p&gt;运行下列命令设置环境变量并创建托管节点组&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;export LT_ID=$(aws ec2 describe-launch-templates --launch-template-name demo --output json | jq -r '.LaunchTemplates[0].LaunchTemplateId')
cat &amp;gt; ~/environment/scripts/mng-1.yml.template &amp;lt;&amp;lt;-&amp;quot;EOF&amp;quot;
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: $EKS_CLUSTER_NAME
  region: $AWS_REGION
  version: &amp;quot;1.17&amp;quot;
managedNodeGroups:
  - name: $EKS_MANAGED_NODEGROUP_NAME
    minSize: 1
    maxSize: 3
    desiredCapacity: 2
    labels: {role: managed-ng-worker}
    launchTemplate:
      id: $LT_ID
      version: &amp;quot;1&amp;quot;
EOF
envsubst &amp;lt; ~/environment/scripts/mng-1.yml.template &amp;gt; ~/environment/scripts/mng-1.yml
eksctl create nodegroup -f ~/environment/scripts/mng-1.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;整个过程大概需要 3分钟左右。之后我们可以在EC2控制台看到新创建了2个名称为eksworkshop-mng-1类型为m5.large 的EC2实例。同时因为我们刚刚创建的是一个托管节点组，所以如下图所示在EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute界面可以查看到刚刚创建的托管节点组。&lt;/p&gt; 
&lt;p&gt;注意上述托管节点组的配置文件中设置的版本1.17是与控制平面一致的版本，如果托管节点组配置的版本与EKS集群控制平面不一致时，eksctl会自动使用控制平面版本。&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 从选中的部分可以看出托管节点组mng-1对应的启动模本名称为demo版本为1。也可以运行下列命令验证 EKS 集群节点组mng-1已经成功创建&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl get nodegroup --cluster $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令测试 EKS 集群新加入的两个节点是否正常工作&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get nodes --show-labels&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;需要特别指出的是启动模板对于创建托管节点组是一个推荐的可选项。不预先配置启动模板，而是直接利用下列的配置文件也可以创建托管节点组。因为在配置中没有显示的配置启动模板，eksctl会根据配置自动生成一个名称为“eksctl-集群名称-nodegroup-托管节点组名称 (N)”的一个启动模板，这个启动模板是由eksctl创建、管理和维护，因此不建议手动创建新版本修改或者复用。这种方式下创建的每个托管节点组的启动模板都是独立的，不能复用，如果有统一配置的需求和后续针对单个节点组的修改需求就更加麻烦。同时因为没有在配置文件中显示的指定启动模板，需要根据命名规则或者在EKS的托管节点组控制界面上查询这个启动模板，所以这种方式不利于配置变更的跟踪。而显示的声明在多个托管节点组中可以共用一个启动模板，当出现不同的配置需求时又可以通过新建启动模板版本来解决，相对于隐式的方式更加灵活高效，所以在本实验中托管节点组采用的是显示的启动模板。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: eksworkshop
  region: us-east-1
  version: &amp;quot;1.17&amp;quot;
  availabilityZones: [&amp;quot;us-east-1a&amp;quot;, &amp;quot;us-east-1b&amp;quot;, &amp;quot;us-east-1c&amp;quot;]
managedNodeGroups:
- name: nodegroup
  minSize: 1
  maxSize: 3
  desiredCapacity: 3
  instanceType: m5.large
  ssh:
    enableSsm: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;迁移工作负载并删除非托管节点组&lt;/h3&gt; 
&lt;p&gt;因为非托管节点组的&lt;a href="https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability"&gt;不可变性&lt;/a&gt;，除了改变节点数量无法更改其配置，所以当遇到升级集群版本的情况是需要创建新的非托管节点组然后迁移负载再删除旧的节点组的方法来实现升级节点组。而托管节点组可以做到原地（In place）升级，所以本实验先将样例工作负载迁移到托管节点组再做集群的升级。&lt;/p&gt; 
&lt;p&gt;运行下列命令查验当前的nginx pod运行在非托管节点组的节点上&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令将在非托管节点组的节点上的工作负载驱逐到刚刚创建的托管节点组&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl drain nodegroup --cluster=$EKS_CLUSTER_NAME --name=$EKS_UNMANAGED_NODEGROUP_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行命令：&lt;code&gt;kubectl get no&lt;/code&gt;可以发现旧节点组的状态已经变为：Ready,SchedulingDisabled，重新运行下列命令查验当前的nginx pod运行在托管节点组的节点上&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令删除非托管节点组&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete nodegroup --cluster $EKS_CLUSTER_NAME --name $EKS_UNMANAGED_NODEGROUP_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令监视节点删除情况直至非托管节点组被完全删除。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get no -w&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;升级集群控制平面&lt;/h3&gt; 
&lt;p&gt;如下图所示在EKS集群控制台上点击Update Now升级集群控制平面，因为K8S需要逐个版本升级，所以只有1.18目标版本是可选状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 升级后如下图所示集群处于Updating状态，整个升级过程大约需要30~40分钟。这步升级操作也可以通过eksctl命令或者aws cli来完成，具体做法请参考&lt;a href="https://docs.amazonaws.cn/eks/latest/userguide/update-cluster.html"&gt;官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 升级成功后可以看到集群版本变为1.18。&lt;/p&gt; 
&lt;p&gt;需要注意的是如果有多个托管节点组，在升级控制平面之前，需要确认所有的托管节点组都已经升级到控制平面的版本，否则升级时会得到错误提示：Nodegroups xxx must be updated to match cluster version 1.1x before updating cluster version。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;升级托管节点组&lt;/h3&gt; 
&lt;p&gt;如下图所示进入EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute可以看到New AMI Release versios are avaiable for 1 Node Group的提示，并且在Node Groups中mng-1的AMI release version列的旁边出现了Update now的链接&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;点击Update now升级托管节点组到1.18&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance8.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在上面的弹出的对话框中可以看到Update Strategy设置为Rolling update，也即滚动更新，点击Update开始节点组升级更新，整个过程需要约20分钟。&lt;/p&gt; 
&lt;p&gt;其间可以在EC2控制台中查看新旧节点的变化情况，在新启动的实例细节信息里查验AMI name已经改为amazon-eks-node-1.18-v2021xxxx。通过运行命令：kubectl get no可以看到旧的节点被设置为SchedulingDisabled状态，Nginx Pod在被逐步迁移到新的节点上。&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance9.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以通过如下图所示的编辑托管节点组 EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Node Group: mng-1 &amp;gt; Edit Node Group的Node Group update configuration来设置最大不可用节点数目或者比例数，从而控制滚动更新的颗粒度。当然也可以变更最小、最大、期望节点数，k8s labels，taints和tags等其他配置。&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance10.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相比之下，如果我们这里使用的依旧是非托管节点组，那么在这个步骤中我们就要重新创建一个与控制平面版本一致的1.18的新的非托管节点组，然后将工作负载从旧的1.17的节点组迁移到新的1.18的节点组再删除1.17的非托管节点组，这个过程相对于上述托管节点组的一键升级的流程复杂许多，而且存在一个新旧非托管节点组同时存在的时间窗口给集群的管理与维护增加了难度与不确定性。更令运维人员头疼的是，这个升级过程在后续的版本升级中（比如1.18到1.19）仍然需要重复一遍。对比可见数据平面的升级在托管节点组的支持下变得非常简单方便。&lt;/p&gt; 
&lt;h3&gt;切换启动模板版本&lt;/h3&gt; 
&lt;p&gt;在日常集群的维护中，我们经常会有一些变更需求，比如切换实例类型，修改各种资源比如EC2的名称等，这些在非托管节点组是无法实现的，而在配置了启动模板的托管节点组中可以轻松实现，下面将演示将节点组实例类型切换为m5.2xlarge的方法。&lt;/p&gt; 
&lt;p&gt;基于启动模板demo的版本1新创建一个新版本：version 2，将实例类型设置为m5.2xlarge同时保持其他选项不变。&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance11.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;等待托管节点组mng-1升级到1.18完成后，可以看到节点组的AMI release version改为1.18.20-xxxx，同时因为我们增加了一个新的启动模板的版本，点击Change version将mng-1节点组切换到新创建的版本2从而修改节点组的实例类型到m5.2xlarge。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance12.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance13.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 点击Update开始节点组滚动更新，类似的整个过程需要约20分钟。等待更新完毕后，按照相同的方法可以重新切换回版本1。启动模版的版本信息可以通过下列命令导出到yaml作为配置变更管理的一部分通过git等源代码版本管理工具来管理。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws ec2 describe-launch-template-versions --launch-template-name demo --output yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;需要注意的是在启动模板的不同版本间做切换目前不支持在有使用EKS优化AMI与自定义AMI的不同版本间切换。否则会得到错误：You cannot specify an image id within the launch template, since your nodegroup is configured to use an EKS optimized AMI（默认EKS优化版本改为自定义AMI版本）或者The request must contain the parameter ImageId（自定义AMI版本改为默认EKS优化版本）。如果有将默认AMI替换为自定义AMI的需求，可以通过创建一个新的托管节点组来引用配置有自定义AMI的启动模板的版本来解决。&lt;/p&gt; 
&lt;h3&gt;删除EKS集群和Cloud9环境&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete cluster --name $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;最后，在AWS控制台的Cloud9服务的环境列表中删除eksworkshop。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;本文通过一个端到端的例子说明了将非托管节点组转换到托管节点组来实现工作负载的迁移。同时完成集群和托管节点组从 1.17到1.18的版本升级。最后通过在不同启动模板版本间切换的方法实现了节点组配置的灵活原地更新。需要特别指出虽然上述实验进行的的是1.17到1.18的升级，但过程对于其他EKS版本的升级同样适用，比如从1.18升级到1.19。&lt;/p&gt; 
&lt;p&gt;相比EKS集群的托管节点组，非托管节点组具有不可变性，所以必须通过新建节点组然后迁移工作负载的方式来更新。而托管节点组则可以通过改变启动模板的版本然后进行滚动更新来实现常用配置的变更，同时在出现失败的情况下支持回退，所以在日常变更管理与集群版本升级上更加简便。并且一个集群或者多个集群中的多个节点组可以共用一个启动模板，极大的简化了维护与管理的成本。另外将多项节点组配置选项转移到启动模板中，实现了节点组配置一定程度的解耦。最后因为启动模板支持多个版本，同一托管节点组可以在同一个启动模板的不同版本间灵活切换，也极大的方便了日常节点组的变更与维护。关于更多托管节点组的新功能请参考&lt;a href="https://aws.amazon.com/blogs/containers/catching-up-with-managed-node-groups-in-amazon-eks/"&gt;托管节点组最新动态博客&lt;/a&gt;与&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html"&gt;EKS官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;最后需要指出的是EKS升级的范畴远大于文中介绍的内容，鉴于篇幅所限，其他方面的升级方法请读者自行参考官方K8S升级手册与官方EKS升级文档。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html&lt;/li&gt; 
 &lt;li&gt;https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability&lt;/li&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html&lt;/li&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html&lt;/li&gt; 
 &lt;li&gt;https://aws.amazon.com/blogs/containers/catching-up-with-managed-node-groups-in-amazon-eks/&lt;/li&gt; 
 &lt;li&gt;https://aws.amazon.com/blogs/containers/introducing-launch-template-and-custom-ami-support-in-amazon-eks-managed-node-groups/&lt;/li&gt; 
 &lt;li&gt;https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html&lt;/li&gt; 
 &lt;li&gt;https://www.eksworkshop.com/&lt;/li&gt; 
 &lt;li&gt;https://eksctl.io/usage/schema/&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/dapengt.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;田大鹏&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责帮助客户进行上云架构的设计和咨询。在电商及互联网行业有丰富的咨询和架构设计经验。加入 AWS 前曾于全球领先的存储和虚拟化企业，担任研发主管工程师及研发经理多种职位，负责在线存储及备份系统的多个子系统的高并发、高可用系统架构设计，应用微服务化等敏捷项目。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/guili.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;何归丽&lt;/h3&gt; 
  &lt;p&gt;AWS高级解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，同时致力于AWS云服务在国内的应用和推广。加入AWS之前在外企软件部门担任系统架构师，有十多年的软件研发和架构设计经验，在微服务架构和容器、企业应用信息安全、DevOps等领域有丰富的经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/panwenmi.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;潘文明&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责基于 AWS 的云计算方案的咨询与架构设计。专注于游戏行业，帮助客户利用AWS全球基础设施与强大的技术能力打造爆款游戏，降低游戏运行成本。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>如何将您的自定义容器镜像导入Amazon SageMaker Studio notebooks</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks/</link>
				<pubDate>Tue, 31 Aug 2021 03:41:59 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon SageMaker Studio]]></category>

		<guid isPermaLink="false">75a8705bab975b942b359066fef42d5d15ceef5c</guid>
				<description>Amazon SageMaker Studio是第一套用于机器学习（ML）的全集成开发环境（IDE）。Amazon SageMaker Studio可帮助数据科学家们快速启动Studio notebooks以探索数据、构建模型、启动Amazon SageMaker训练作业并部署托管端点。Studio notebooks中随附一组预构建镜像，这些镜像由Amazon SageMaker Python SDK&amp;nbsp;与IPython运行时或内核的最新版本构成。凭借此项新功能，您可以轻松将自定义镜像导入Amazon SageMaker notebooks当中。在本文中，我们将具体探讨如何将自定义容器镜像导入Amazon SageMaker notebooks。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://aws.amazon.com/sagemaker/"&gt;Amazon SageMaker Studio&lt;/a&gt;是第一套用于机器学习（ML）的全集成开发环境（IDE）。Amazon SageMaker Studio可帮助数据科学家们快速启动Studio notebooks以探索数据、构建模型、启动Amazon SageMaker训练作业并部署托管端点。Studio notebooks中随附一组预构建镜像，这些镜像由&lt;a href="https://sagemaker.readthedocs.io/en/stable/"&gt;Amazon SageMaker Python SDK&lt;/a&gt;&amp;nbsp;与IPython运行时或内核的最新版本构成。凭借此项新功能，您可以轻松将自定义镜像导入Amazon SageMaker notebooks当中。在本文中，我们将具体探讨如何将自定义容器镜像导入Amazon SageMaker notebooks。&lt;/p&gt; 
&lt;p&gt;开发人员与数据科学家一般需要在以下几种不同用例内使用自定义镜像：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;访问流行机器学习框架（包括TensorFlow、MXNet以及PyTorch等）的特定或最新版本。&lt;/li&gt; 
 &lt;li&gt;将本地开发的自定义代码或算法引入Studio notebooks内以进行快速迭代及模型训练。&lt;/li&gt; 
 &lt;li&gt;通过API访问数据湖或本地数据存储，且管理员需要在镜像中添加相应驱动程序。&lt;/li&gt; 
 &lt;li&gt;访问后端运行时（也称内核）；除IPython之外，还有R、Julia或其它环境等。您也可以使用本文中概述的方法安装其他自定义内核。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在大型企业中，机器学习平台管理员往往需要保证安全团队预先批准第三方软件包及代码，而非直接通过互联网下载。在常见的工作流示例中，机器学习平台团队会批准一组要使用的软件包与框架，使用这些软件包构建自定义容器、测试容器中的漏洞，而后将核准后的镜像推送至私有容器注册表内，例如&lt;a href="https://aws.amazon.com/ecr/"&gt;Amazon Elastic Container Registry&lt;/a&gt;&amp;nbsp;(Amazon ECR)。现在，机器学习平台团队可以将经过核准的镜像直接附加至Studio域内（请参见以下工作流程图）。您只需在Studio中选定所需的获准自定义镜像即可。在当前版本中，单一Studio域最多可以包含30个自定义镜像，您可以根据需求添加新版本或删除镜像。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在，我们将逐步介绍如何使用此项功能将自定义容器镜像导入Amazon SageMaker Studio notebooks当中。这里主要演示在互联网上使用时的默认方法，您也可以对其稍加修改以配合&lt;a href="https://aws.amazon.com/vpc/"&gt;Amazon Virtual Private Cloud&lt;/a&gt;&amp;nbsp;(Amazon VPC)进行使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;先决条件&lt;/h2&gt; 
&lt;p&gt;在开始之前，大家需要满足以下先决条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;亚马逊云科技账户。&lt;/li&gt; 
 &lt;li&gt;确保用于访问Amazon SageMaker的角色拥有以下Amazon Web Services身份与访问管理（IAM）权限，使Amazon SageMaker Studio能够在Amazon ECR中以smstudio为前缀创建一个repo，并面向此repo进行镜像推送与提取。要使用现有repo，请将其中的Resource部分替换为您的repo ARN。要构建容器镜像，您可以使用本地Docker客户端，或者直接在Amazon SageMaker Studio中创建镜像。本文采用后一种方法。要在Amazon ECR内创建repo，Amazon SageMaker Studio需要使用&lt;a href="https://aws.amazon.com/codebuild/"&gt;Amazon CodeBuild&lt;/a&gt;；您还需要拥有使用CodeBuild的权限，具体如下所示。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;ecr:CreateRepository&amp;quot;,
                &amp;quot;ecr:BatchGetImage&amp;quot;,
                &amp;quot;ecr:CompleteLayerUpload&amp;quot;,
                &amp;quot;ecr:DescribeImages&amp;quot;,
                &amp;quot;ecr:DescribeRepositories&amp;quot;,
                &amp;quot;ecr:UploadLayerPart&amp;quot;,
                &amp;quot;ecr:ListImages&amp;quot;,
                &amp;quot;ecr:InitiateLayerUpload&amp;quot;,
                &amp;quot;ecr:BatchCheckLayerAvailability&amp;quot;,
                &amp;quot;ecr:GetDownloadUrlForLayer&amp;quot;,
                &amp;quot;ecr:PutImage&amp;quot;
            ],
            &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:ecr:*:*:repository/smstudio*&amp;quot;
        },
        {
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: &amp;quot;ecr:GetAuthorizationToken&amp;quot;,
            &amp;quot;Resource&amp;quot;: &amp;quot;*&amp;quot;
           }
{
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;codebuild:DeleteProject&amp;quot;,
                &amp;quot;codebuild:CreateProject&amp;quot;,
                &amp;quot;codebuild:BatchGetBuilds&amp;quot;,
                &amp;quot;codebuild:StartBuild&amp;quot;
            ],
            &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:codebuild:*:*:project/sagemaker-studio*&amp;quot;
}
{
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: &amp;quot;iam:PassRole&amp;quot;,
            &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:iam::*:role/*&amp;quot;,
            &amp;quot;Condition&amp;quot;: {
                &amp;quot;StringLikeIfExists&amp;quot;: {
                    &amp;quot;iam:PassedToService&amp;quot;: &amp;quot;codebuild.amazonaws.com&amp;quot;
                }
            }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;您的Amazon SageMaker角色还应在Amazon CodeBuild中拥有信任策略，具体如下所示。关于更多详细信息，请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/"&gt;使用Amazon SageMaker Studio镜像构建CLI在Studio notebooks中构建容器镜像&lt;/a&gt;。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Principal&amp;quot;: {
        &amp;quot;Service&amp;quot;: [
          &amp;quot;codebuild.amazonaws.com&amp;quot;
        ]
      },
      &amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;在您的本地机器上安装Amazon Web Services命令行界面（Amazon CLI）。关于详尽操作说明，请参阅&lt;a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html"&gt;安装Amazon&lt;/a&gt; Web Services。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;准备一个SageMaker Studio域。要创建此域，请使用&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateDomain.html"&gt;CreateDomain&lt;/a&gt;&amp;nbsp;API或者&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/cli/latest/reference/sagemaker/create-domain.html"&gt;create-domain&lt;/a&gt;&amp;nbsp;CLI命令。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果您希望使用自有VPC以安全引入自定义容器，则需要完成以下操作：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;带有专有子网的VPC。&lt;/li&gt; 
 &lt;li&gt;用于以下服务的VPC端点： 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service&lt;/a&gt;&amp;nbsp;(Amazon S3)&lt;/li&gt; 
   &lt;li&gt;Amazon SageMaker&lt;/li&gt; 
   &lt;li&gt;Amazon ECR&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html"&gt;Amazon Security Token Service&lt;/a&gt;&amp;nbsp;(Amazon STS)&lt;/li&gt; 
   &lt;li&gt;用于构建Docker容器的CodeBuild&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;要设置上述资源，请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/securing-amazon-sagemaker-studio-connectivity-using-a-private-vpc/"&gt;使用专用VPC保护Amazon SageMaker Studio连接&lt;/a&gt;以及相关&lt;a href="https://github.com/aws-samples/amazon-sagemaker-studio-vpc-blog"&gt;GitHub repo&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;创建Dockerfile&lt;/h2&gt; 
&lt;p&gt;为了体现数据科学家使用最新框架进行试验的普遍性需求，我们在本次演练中使用以下Dockerfile，其选择最新的TensorFlow 2.3版本作为基础镜像。您也可以使用自己指定的Dockerfile进行替换。目前，Amazon SageMaker Studio已经能够支持多种基础镜像，例如Ubuntu、Amazon Linux 2等等。Dockerfile将安装运行Juypter notebooks所需要的IPython运行时，同时安装Amazon SageMaker Python SDK与boto3。&lt;/p&gt; 
&lt;p&gt;除了笔记本电脑之外，除了notebooks之外，数据科学家与机器学习工程师们还经常使用各种流行IDE（例如Visual Studio Code或者Py&amp;Ccedil;harm）在本地notebooks上进行迭代与试验。您可能希望将这些脚本引入云端，借此进行扩展化训练或数据处理。您可以将这些脚本打包进Docker容器之内，并在Amazon SageMaker Studio的本地存储中查看。在以下Dockerfile中，我们复制的train.py&amp;nbsp;脚本是一套用于在MNIST数据集上训练简单深度学习模型的基础脚本。您也可以使用自己的脚本或包含代码的软件包替换此脚本。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;FROM tensorflow/tensorflow:2.3.0
RUN apt-get update 
RUN apt-get install -y git
RUN pip install --upgrade pip
RUN pip install ipykernel &amp;amp;&amp;amp; \
    python -m ipykernel install --sys-prefix &amp;amp;&amp;amp; \
    pip install --quiet --no-cache-dir \
    'boto3&amp;gt;1.0&amp;lt;2.0' \
    'sagemaker&amp;gt;2.0&amp;lt;3.0'&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;COPY train.py /root/train.py #可以替换为您的自定义脚本或软件包&lt;/p&gt; 
&lt;p&gt;以下代码为train.py脚本：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import tensorflow as tf
import os 

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=1)
model.evaluate(x_test, y_test)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;除了自定义脚本之外，您也可以添加其他文件，例如可通过&lt;a href="https://aws.amazon.com/secrets-manager/"&gt;Amazon Secrets Manage&lt;/a&gt;r 或&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html"&gt;Amazon Systems Manager Parameter Store&lt;/a&gt;访问客户端secrets以及环境变量的Python文件、用于连接私有PyPi repo的config文件、或者其他软件包管理工具。您也可以使用自定义镜像复制脚本，但在这种情况下，Dockerfile中的一切ENTRYPOINT或CMD命令均无法运行。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;设置安装文件夹&lt;/h2&gt; 
&lt;p&gt;您需要在本地机器上创建一个文件夹，并向其中添加以下文件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在上一步中创建完成的Dockerfile。&lt;/li&gt; 
 &lt;li&gt;名为&amp;nbsp;app-image-config-input.json&amp;nbsp;的文件，具体内容如下：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;&amp;quot;AppImageConfigName&amp;quot;: &amp;quot;custom-tf2&amp;quot;,
    &amp;quot;KernelGatewayImageConfig&amp;quot;: {
        &amp;quot;KernelSpecs&amp;quot;: [
            {
                &amp;quot;Name&amp;quot;: &amp;quot;python3&amp;quot;,
                &amp;quot;DisplayName&amp;quot;: &amp;quot;Python 3&amp;quot;
            }
        ],
        &amp;quot;FileSystemConfig&amp;quot;: {
            &amp;quot;MountPath&amp;quot;: &amp;quot;/root/data&amp;quot;,
            &amp;quot;DefaultUid&amp;quot;: 0,
            &amp;quot;DefaultGid&amp;quot;: 0
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们将此Dockerfile的后端内核设置为IPython内核，并提供指向&lt;a href="https://aws.amazon.com/efs/"&gt;Amazon Elastic File System&lt;/a&gt;&amp;nbsp;(Amazon EFS)的挂载路径。Amazon SageMaker可以识别出Juypter定义的内核。例如，对于R内核，您可以将之前代码中的Name部分设置为ir。请注意保证其中的Uid、Gid以及内核名称与Docker镜像中的kernelspecs及用户信息相匹配。要获取这些值，请参阅本&lt;a href="https://github.com/aws-samples/sagemaker-studio-custom-image-samples/blob/main/DEVELOPMENT.md"&gt;文档&lt;/a&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用以下内容创建一个名为&amp;nbsp;default-user-settings.json&amp;nbsp;的文件。如果您需要添加多个自定义镜像，请直接将其添加至&amp;nbsp;CustomImages列表。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  &amp;quot;DefaultUserSettings&amp;quot;: {
    &amp;quot;KernelGatewayAppSettings&amp;quot;: {
      &amp;quot;CustomImages&amp;quot;: [
          {
                   &amp;quot;ImageName&amp;quot;: &amp;quot;tf2kernel&amp;quot;,
                   &amp;quot;AppImageConfigName&amp;quot;: &amp;quot;custom-tf2&amp;quot;
                }
            ]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;创建镜像并将其附加至您的Studio域&lt;/h2&gt; 
&lt;p&gt;如果您已经拥有现成的域，则直接使用新镜像进行更新即可。在本节中，我们将演示现有Studio用户如何进行镜像附加。关于启动新用户的说明，请参阅&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-iam.html"&gt;使用IAM登入Amazon SageMaker Studio&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;首先，我们使用Amazon SageMaker Studio Docker构建CLI构建Dockerfile，并将其推送至Amazon ECR。请注意，您也可以使用其他方法将容器推送至ECR，例如通过本地Docker客户端以及AWS CLI。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用您的用户信息登录至Studio。&lt;/li&gt; 
 &lt;li&gt;将您的Dockerfile、以及其他需要复制到容器当中的代码或依赖项上传至Studio域。&lt;/li&gt; 
 &lt;li&gt;导航至包含Dockerfile的文件夹。&lt;/li&gt; 
 &lt;li&gt;在终端窗口或notebook内 —&amp;gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;!pip install sagemaker-studio-image-build&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;导出一个名为IMAGE_NAME的变量，并将其设定为您在&amp;nbsp;default-user-settings.json当中所指定的值。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;sm-docker build . –repository smstudio-custom:IMAGE_NAME&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果要使用其他repo，请将以上代码中的smstudio-custom替换为您的repo名称。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Amazon SageMaker Studio将为您构建Docker镜像，将该镜像推送至Amazon ECR当中一个名为smstudio-custom的repo内，并为其标记适当的镜像名称。要进一步自定义此项功能（例如提供详细的文件路径或其他选项），请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/"&gt;使用Amazon SageMaker Studio镜像构建CLI在Studio notebooks中构建容器镜像&lt;/a&gt;。要让以上pip命令在专用VPC环境下起效，您需要设置互联网路由或访问专用repo内的相应软件包。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在之前的安装文件夹中，创建一个名为&amp;nbsp;create-and-update-image.sh的新文件：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;ACCOUNT_ID=AWS ACCT ID # 替换为您的AWS账户ID
REGION=us-east-2 # 替换为您的区域
DOMAINID=d-####### # 替换为您的SageMaker Studio域名称
IMAGE_NAME=tf2kernel # 替换为您的镜像名称

# 使用Amazon SageMaker Studio
## 使用ECR中的镜像创建SageMaker镜像（根据需求修改镜像名称）
ROLE_ARN='The Execution Role ARN for the execution role you want to use'

aws --region ${REGION} sagemaker create-image \
    --image-name ${IMAGE_NAME} \
    --role-arn ${ROLE_ARN}

aws --region ${REGION} sagemaker create-image-version \
    --image-name ${IMAGE_NAME} \
    --base-image &amp;quot;${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/smstudio-custom:${IMAGE_NAME}&amp;quot;
    
## 为此镜像创建AppImageConfig（根据需要修改app-image-config-input.json中的AppImageConfigName与KernelSpecs参数）
aws --region ${REGION} sagemaker create-app-image-config --cli-input-json file://app-image-config-input.json

## 提供镜像与AppImageConfig以更新此域
aws --region ${REGION} sagemaker update-domain --domain-id ${DOMAINID} --cli-input-json file://default-user-settings.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;请参阅Amazon CLI以了解可在&amp;nbsp;&lt;a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker/create-image.html"&gt;create-image&lt;/a&gt;&amp;nbsp;API中使用的各项参数的详细信息。要检查当前状态，请导航至您的Amazon SageMaker控制台，并在导航面板中选择Amazon SageMaker Studio。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;使用Studio UI附加镜像&lt;/h2&gt; 
&lt;p&gt;您也可以通过UI完成将镜像附加至Studio域的最后一步。在此用例中，UI将处理镜像与镜像版本的创建操作，并使用附加的镜像完成域更新。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在Amazon SageMaker控制台上，选择Amazon SageMaker Studio。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在Control Panel页面上，可以看到已经置备完成的Studio域以及您所创建的所有用户配置。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Attach image&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;选择要附加新镜像，还是附加原有镜像。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ol&gt; 
   &lt;li style="list-style-type: none"&gt; 
    &lt;ol&gt; 
     &lt;li&gt;如果您选择Existing image，请从Amazon SageMaker镜像库中选择一个镜像。&lt;/li&gt; 
     &lt;li&gt;如果您选择New image，请提供Docker镜像的Amazon ECR注册表路径。此路径需要与Studio域处于同一区域内。ECR repo还需要与您的Studio域处于同一账户内；如果需要跨账户操作，则Studio必须具备相应权限。&lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Next&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;在&lt;/strong&gt;&lt;strong&gt;Image name&lt;/strong&gt;部分，输入名称。&lt;/li&gt; 
 &lt;li&gt;在&lt;strong&gt;Image display name&lt;/strong&gt;部分，输入描述性名称。&lt;/li&gt; 
 &lt;li&gt;在&amp;nbsp;&lt;strong&gt;Description&lt;/strong&gt;部分，输入标签定义。&lt;/li&gt; 
 &lt;li&gt;在IAM role部分，选择Amazon SageMaker用于向Amazon SageMaker镜像附加Amazon ECR镜像的IAM角色。&lt;/li&gt; 
 &lt;li&gt;此外，您也可以对镜像做出其他标记。&lt;/li&gt; 
 &lt;li&gt;选择&amp;nbsp;&lt;strong&gt;Next&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在Kernel name部分，输入Python 3。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Submit&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;绿色复选框代表镜像已被成功附加至域内。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker镜像存储将自动对镜像进行版本控制。您可以选择一个预先附加的镜像，而后选择Detach以分离该镜像及所有相关版本，或者选择Attach image以附加新版本。各镜像的版本数量或分离镜像的功能不受限制。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;自定义镜像用户体验&lt;/h2&gt; 
&lt;p&gt;下面，我们尝试Studio的实际用户体验。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用您的用户资料登录至Studio。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;要启动新活动，请选择&lt;/strong&gt;&lt;strong&gt;Launcher&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;在&lt;strong&gt;Select a SageMaker image to launch your activity&lt;/strong&gt;&lt;strong&gt;部分，选择&lt;/strong&gt;&lt;strong&gt;tf2kernel&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Notebook&lt;/strong&gt;图标，使用自定义内核打开一个新notebook。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Notebook内核需要几分钟才能启动完成，之后即可开始使用！&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;在notebook中测试您的自定义容器&lt;/h2&gt; 
&lt;p&gt;在内核启动并开始运行之后，您即可在notebook中运行代码。首先，我们测试Dockerfile中指定的TensorFlow是否为正确版本。在以下截屏中，可以看到我们刚刚创建的notebook正在使用tf2kernel。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks8.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker notebooks还会显示本地CPU与内存使用量。&lt;/p&gt; 
&lt;p&gt;接下来，我们直接在notebook中使用自定义训练脚本。将训练脚本复制到notebook单元中并运行。此脚本会从tf.keras.datasets处下载mnist数据集，并将数据拆分为训练数据集与测试数据集，自定义一项定制化深度神经网络算法，在训练数据集上训练算法，并在测试数据集上测试算法。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks9.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要尝试使用TensorFlow 2.3框架，大家可能希望测试新发布的API，例如Keras中提供的预处理实用程序等新功能。在以下截屏中，我们导入了随TensorFlow 2.3版本发布的keras.layers.experimental&amp;nbsp;库，其中包含用于数据预处理的新API。我们加载其中一个API，而后在notebook中重新运行脚本。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks10.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker还能够在代码运行过程中动态修改CPU与内存使用率。通过引入自定义容器与训练脚本，此功能使您能够直接在Amazon SageMaker notebook中尝试自定义训练脚本与算法。如果您对Studio notebook中的试验结果感到满意，则可立即启动训练作业。&lt;/p&gt; 
&lt;p&gt;Docker file中所包含的、使用COPY命令的Python文件或其他自定义文件运行情况如何？Amazon SageMaker Studio会挂载app-image-config-input.json所提供的文件路径中的弹性文件系统，在本示例中我们将其设定为root/data。为了避免Studio覆盖掉需要包含的自定义文件，COPY命令会将train.py文件加载至路径/root当中。要访问此文件，请打开终端或notebook并运行以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;! cat /root/train.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;这时您应看到以下截屏所示的输出结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks11.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以看到train.py&amp;nbsp;文件位于指定位置。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;CloudWatch中的日志记录&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker Studio还会将内核指标发布至Amazon CloudWatch供您进行故障排查。这些指标将被捕捉至/aws/sagemaker/studio命名空间之内。&lt;/p&gt; 
&lt;p&gt;要访问日志，请在CloudWatch控制台上选择CloudWatch Logs。在Log groups页面中，输入命名空间以查看与Jupyter服务器及内核网关相关的日志记录。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks12.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;分离镜像或版本&lt;/h2&gt; 
&lt;p&gt;您可以从域中分离镜像或特定镜像版本。&lt;/p&gt; 
&lt;p&gt;要分离镜像及其全部版本，请在Custom images attached to domain表内选定该镜像，而后选择Detach。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks13.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;您还可以选择删除镜像及所有版本，这不会影响到Amazon ECR中的镜像。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks14.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要分离镜像的特定版本，请选定该镜像。在Image details页面上，从Image versions attached to domain表中选择目标镜像版本（一个或者多个版本），而后选择Detach。您会看到如上所示的警告及操作选项。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker Studio使您能够更轻松地对机器学习模型进行协作、实验、训练及部署。在这之前，数据科学家往往需要通过公共及私有代码repo以及软件包管理工具才能访问最新机器学习框架、自定义脚本以及软件包。现在，您可以将所有相关代码打包进自定义镜像之内，并使用Studio notebook启动这些镜像。这些镜像可供Studio域内的所有用户使用。您也可以使用此项功能使用Python之外的其他流行语言及运行时，包括R、Julia以及Scala等。您可以在&lt;a href="https://github.com/aws-samples/sagemaker-studio-custom-image-samples"&gt;GitHub repo&lt;/a&gt;中找到示例文件。关于此项功能的更多详细信息，请参阅&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html"&gt;自带SageMaker镜像&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/stenatu.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Stefan Natu&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技公司高级机器学习专家。他致力于帮助金融服务客户在亚马逊云科技上构建端到端机器学习解决方案。在业余时间，他喜欢阅读机器学习技术博客、演奏吉他和探索纽约当地的各种美食。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/jaipreet.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Jaipreet Singh&lt;/h3&gt; 
  &lt;p&gt;Amazon SageMaker Studio团队高级软件工程师。他自2017年立项以来就一直从事Amazon SageMaker的开发工作，并为多个Jupyter开源项目做出贡献。业余时间，他喜欢远足和滑雪。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/huonguh.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Huong Nguyen&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技公司高级产品经理。她负责Amazon SageMaker Studio的用户体验工作。她在企业级及消费级领域拥有13年客户体验与数据驱动产品开发经验。在业余时间，她喜欢读书、享受自然风光和陪伴家人。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>如何注册成为亚马逊云科技 Marketplace海外区卖家</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace/</link>
				<pubDate>Tue, 31 Aug 2021 03:38:57 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Marketplace]]></category>

		<guid isPermaLink="false">6caba9bb2943867da8c579fee4e0fc54dae15eb7</guid>
				<description>亚马逊云科技Marketplace(以下简称Marketplace)是一个提供甄选的数字化产品的平台，分海外区和中国区，产品类型包括AMI映像，CloudFormation Template，SaaS，容器，SageMaker等。Marketplace海外区是中国ISV (Independent Software Vendor)触达亚马逊云科技庞大的海外用户群，拓展海外业务的绝佳选择。为了能够上架产品，首先需要注册成为Marketplace海外区卖家。本文将介绍注册成为卖家的具体流程。</description>
								<content:encoded>&lt;h2&gt;&lt;strong&gt;1. 概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;亚马逊云科技Marketplace(以下简称Marketplace)是一个提供甄选的数字化产品的平台，分海外区和中国区，产品类型包括AMI映像，CloudFormation Template，SaaS，容器，SageMaker，DataExchange，Professional Service等。Marketplace海外区是中国ISV (Independent Software Vendor)触达亚马逊云科技庞大的海外用户群，拓展海外业务的绝佳选择。为了能够上架产品，首先需要注册成为Marketplace海外区卖家。本文将介绍注册成为卖家的具体流程。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2. 注册只售卖免费产品的卖家&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果您的产品是完全免费的，不收取用户任何软件费用，您和用户之间没有资金往来，您可以注册成为只售卖免费产品的卖家。&lt;a href="https://aws.amazon.com/marketplace/search/results?PRICING_MODEL=FREE&amp;amp;filters=PRICING_MODEL"&gt;Marketplace上的免费产品&lt;/a&gt;包括操作系统，开源软件等。具体注册步骤如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;登录&lt;a href="https://aws.amazon.com/marketplace/partners/management-tour"&gt;Marketplace海外区主页&lt;/a&gt;，点击“Register Now”&lt;/li&gt; 
 &lt;li&gt;登录您用于注册卖家的亚马逊云科技账号&lt;/li&gt; 
 &lt;li&gt;登录后您会进入&lt;a href="https://aws.amazon.com/marketplace/management/homepage/"&gt;AWS Marketplace Management Portal(AMMP)&lt;/a&gt;，继续填写您的Public Profile，包括公司Logo，公司简称，主页，公司介绍等，这些信息将会对所有用户可见。&lt;/li&gt; 
 &lt;li&gt;提交后，即可完成注册。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3. 注册售卖收费产品的卖家&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果您的软件产品是Buy Your Own License(BYOL)或者在线收取用户的软件费用，都属于付费产品。要在Marketplace海外区售卖付费的产品，卖家的公司实体必须为以下&lt;a href="https://docs.aws.amazon.com/marketplace/latest/userguide/user-guide-for-sellers.html#eligible-jurisdictions"&gt;Eligible Location&lt;/a&gt;之一：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Australia&lt;/li&gt; 
 &lt;li&gt;Bahrain&lt;/li&gt; 
 &lt;li&gt;European Union (EU) member state&lt;/li&gt; 
 &lt;li&gt;Hong Kong SAR&lt;/li&gt; 
 &lt;li&gt;Japan&lt;/li&gt; 
 &lt;li&gt;New Zealand&lt;/li&gt; 
 &lt;li&gt;Norway&lt;/li&gt; 
 &lt;li&gt;Qatar&lt;/li&gt; 
 &lt;li&gt;Switzerland&lt;/li&gt; 
 &lt;li&gt;United Arab Emirates (UAE)&lt;/li&gt; 
 &lt;li&gt;United Kingdom (UK)&lt;/li&gt; 
 &lt;li&gt;United States (US)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;您在以下两个地方所设置的Location必须保持一致，且同时为以上Location之一。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Billing Console里的Location。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/marketplace/management/seller-settings/account"&gt;AWS Marketplace Management Portal&lt;/a&gt;里的location&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;3.1 设置Billing Console里的Location&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;基于用户在Billing Console里输入的信息，Amazon Web Service是基于以下逻辑来判断一个账号的location的：&lt;/p&gt; 
&lt;p&gt;如果您公司实体所在国家有TRN (Tax Registration Number)，则在Billing Console的Tax Setting里填写TRN。后台会根据TRN所在国家决定Location。假如所在国家没有TRN (例如美国，日本，中国等)，则根据优先级，按以下逻辑判断：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;如果Billing Address和所存档信用卡的location一致，则使用Billing Address的location。例如：绑定的美国信用卡，Billing Address也是在美国。那location就是美国。&lt;/li&gt; 
 &lt;li&gt;假如以上条件1不满足，且如果Contact Address和所存档信用卡的location一致，则使用Contact Address的location。&lt;/li&gt; 
 &lt;li&gt;假如以上条件1和2都不满足，则使用Billing Address的&lt;/li&gt; 
 &lt;li&gt;假如以上条件1、2和3都不满足，则使用Contact Address的&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;更多详细信息，请参考&lt;a href="https://aws.amazon.com/cn/tax-help/location/"&gt;https://aws.amazon.com/cn/tax-help/location/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1.1 设置TRN(Tax Registration Number) – 只对于有TRN的国家和地区适用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;美国、日本、中国和香港地区没有TRN，不能进行设置。如果您的公司实体在这些国家和地区，请通过设置Billing Address和Contract Address来完成对location的设置。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1.2 设置Billing Address&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;进入AWS控制台，点左侧导航栏的Payment Method，选中Billing Address，点Edit，修改地址为满足要求的location。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1.3 设置Contact Address&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;点击控制台右上方的My Account，在Contact Information部分，点击Edit，修改Contact Address为满足要求的location。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;3.2 设置AWS Marketplace Management Portal上的location&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;注册成为marketplace卖家过程中，需要在AWS Marketplace Management Portal(AMMP)里设置公司实体相关信息。公司实体所在国家或区域必须和Billing Console里的保持一致，且也是&lt;a href="https://docs.aws.amazon.com/marketplace/latest/userguide/user-guide-for-sellers.html#eligible-jurisdictions"&gt;Eligible Location&lt;/a&gt;之一。&lt;/p&gt; 
&lt;p&gt;以下是在AMMP中设置location的方法：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ol&gt; 
   &lt;li&gt;登录您海外区Amazon Web Service账户，打开AMMP主页: &lt;a href="https://aws.amazon.com/marketplace/management"&gt;https://aws.amazon.com/marketplace/management&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;点击上方的Setting&lt;/li&gt; 
   &lt;li&gt;点击Payment Information标签页&lt;/li&gt; 
   &lt;li&gt;设置Tax Information。在Tax Information中设置的国家,必须是&lt;a href="https://docs.aws.amazon.com/marketplace/latest/userguide/user-guide-for-sellers.html#eligible-jurisdictions"&gt;Eligible Location&lt;/a&gt; 之一，且和前面Billing Console中的国家或地区保持一致。&lt;/li&gt; 
   &lt;li&gt;查看下图框4中显示的business location是否正确，如果不正确，请返回AWS Billing Console，参考1节的内容进行设置。&lt;/li&gt; 
   &lt;li&gt;假如所有的设置都正确，在框五中，会显示“Publish paid and free products”。表示该卖家可以售卖付费产品。&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;3.3 在AWS Marketplace Management Portal里设置用于接收软件售卖款的美国银行账户&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;卖家需要设置一个银行账户，用于接收售卖软件所得款，Marketplace要求这个账号必须是美国银行账户。如果没有实体的美国银行账户，用户可以通过与Maketplace有合作关系的HyperWallet开通虚拟美国银行账户。在HyperWallet里绑定自己美国之外的银行账户，这样款会先进入HyperWallet的虚拟美国账户，然后再转给卖家在美国外的实体银行账户。具体开通方式如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;登录&lt;a href="https://aws.amazon.com/marketplace/management/homepage/"&gt;Amazon Marketplace Management Portal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;点Setting。点页面下端的Payment Information标签，点Complete Banking Information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;选项： Do you have a US bank account?&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;选：NO&lt;/li&gt; 
 &lt;li&gt;选项: Are you Register with HyperWallet Already?&amp;nbsp;&amp;nbsp;&amp;nbsp; 选: NO&lt;/li&gt; 
 &lt;li&gt;复制Pin Code, 点Sign Up For HyperWallet&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;跳转到hyperwallet，用pincode注册账号&lt;/li&gt; 
 &lt;li&gt;点add transfer method。选择从HyperWallet收款的银行账户所在国家。例如如果您有香港银行账户，请选 Hong Kong SAR China.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;填写Account Information: bank code, branch code, account number。&lt;/li&gt; 
 &lt;li&gt;下面的address会自动填写。&lt;/li&gt; 
 &lt;li&gt;注意：Account Holder的公司名，必须和Bank account的公司名是一样的。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace8.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;香港的银行账户请注意：account number应该是9位数字。如果您的account number是8位数字，多数是内部账号，请咨询开户银行获取外部的9位数account number。如果您的account number是12位，请确认前3位是否为branch code。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;点submit。成功的话，系统返回HyperWallet创建的virtual US account。把文件保存好。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace9.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;回到AMMP里的Payment Information 页面，填写US Bank Account&lt;/li&gt; 
 &lt;li&gt;填写HyperWallet里所填的银行账号地址，前面保存的文件里也有。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace10.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;填写HyperWallet虚拟美国账户信息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace11.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;点击提交即可&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当您完成以上设置后，您就可以在AMMP里创建相应的付费产品，开始产品上架流程了。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/hanliang.png" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;韩亮&lt;/h3&gt; 
  &lt;p&gt;AWS Marketplace技术客户经理&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>在 Amazon Kinesis Data Analytics Studio 中尝试的十大 Flink SQL 查询</title>
		<link>https://aws.amazon.com/cn/blogs/china/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio/</link>
				<pubDate>Tue, 31 Aug 2021 02:59:22 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Kinesis Data Analytics Studio]]></category>

		<guid isPermaLink="false">acb214406d1f4bb95baa1ee2f61dfc4b5983668f</guid>
				<description>通过 Amazon Kinesis Data Analytics Studio，您可以轻松地实时分析流数据并使用标准 SQL、Python 和 Scala 构建流处理应用程序。只需在亚马逊云科技管理控制台上单击几下，就可以启动无服务器笔记本来查询数据流，只需几秒钟即可获得结果。</description>
								<content:encoded>&lt;p&gt;通过&lt;a href="https://aws.amazon.com/kinesis/data-analytics/"&gt;&amp;nbsp;Amazon Kinesis Data Analytics Studio&lt;/a&gt;，您可以轻松地实时分析流数据并使用标准 SQL、Python 和 Scala 构建流处理应用程序。只需在&lt;a href="http://aws.amazon.com/console"&gt;亚马逊云科技管理控制台&lt;/a&gt;上单击几下，就可以启动无服务器笔记本来查询数据流，只需几秒钟即可获得结果。Kinesis Data Analytics 降低了构建和管理 Apache Flink 应用程序的复杂性。Apache Flink 是一个用于处理数据流的开源框架和引擎。它具有高可用性和可扩展性，为流处理应用程序提供了高吞吐量和低延迟。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/overview/"&gt;Apache Flink SQL&lt;/a&gt;&amp;nbsp;支持&lt;a href="https://calcite.apache.org/"&gt;&amp;nbsp;Apache Calcite&lt;/a&gt;，它执行 SQL 标准，使您能够编写简单的 SQL 语句来创建、转换数据并将其插入 Apache Flink 中定义的流数据表中。在本文中，我们将讨论一些可以在 Kinesis Data Analytics Studio 中运行的 Flink SQL 查询。&lt;/p&gt; 
&lt;p&gt;Flink SQL 接口可与&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/tableapi/"&gt;&amp;nbsp;Apache Flink Table API&lt;/a&gt; 以及 Apache Flink&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/datastream/overview/"&gt;&amp;nbsp;DataStream&lt;/a&gt;&amp;nbsp;和&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/dataset/overview/"&gt;&amp;nbsp;Dataset&lt;/a&gt;&amp;nbsp;API 无缝协作。为了以适合当前操作的方式处理流数据，流工作负载通常会在这些抽象层中切换。一个简单的过滤器模式可能需要 Flink SQL 语句，而涉及以对象为导向的状态控制的更复杂的聚合可能需要 DataStream API。工作负载可使用 DataStream API 从数据流中提取模式，然后使用 Flink SQL API 对模式进行分析、扫描、过滤和聚合。&lt;/p&gt; 
&lt;p&gt;有关 Flink SQL 和 Table API 的更多信息，请参阅&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/common/"&gt;概念和常见 API&lt;/a&gt;，尤其是关于解释器使用的不同计划器以及如何构建 Apache Flink SQL 或 Table API 程序的章节。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;在&lt;/strong&gt;&lt;strong&gt; Kinesis Data Analytics Studio 编写 Apache Flink SQL 应用程序&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;通过Amazon Kinesis Data Analytics Studio，您每秒可查询数百万条流记录，笔记本也可以得到相应的扩展。通过 Apache Flink 强大的Amazon Kinesis Data Analytics 功能，只需几个简单的 SQL 语句，您就能够拥有强大的 Apache Flink 应用程序或分析控制面板。&lt;/p&gt; 
&lt;p&gt;需要入门指导？&amp;nbsp;&lt;a href="https://aws.amazon.com/kinesis/data-analytics/getting-started/#It.E2.80.99s_easy_to_get_started_with_Amazon_Kinesis_Data_Analytics_Studio_"&gt;Amazon Kinesis Data Analytics Studio&lt;/a&gt;&amp;nbsp;很容易上手。在接下来的部分中，我们将介绍多种与传入数据流交互的方法 — 在Amazon Kinesis Data Analytics Studio 笔记本中查询、聚合、接收和处理数据。首先，为数据流创建一个内存表。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;为传入的数据创建一个内存表&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先使用 CREATE 语句注册内存表。您可以将这些语句配置为连接到&lt;a href="https://aws.amazon.com/kinesis/data-streams/"&gt;&amp;nbsp;Amazon Kinesis Data Streams&lt;/a&gt;、&lt;a href="https://aws.amazon.com/msk/"&gt;Amazon Managed Streaming for Apache Kafka&lt;/a&gt;&amp;nbsp;(Amazon MSK) 集群或 Apache Flink 中目前受支持的任何其他连接器，例如&lt;a href="http://aws.amazon.com/s3"&gt;&amp;nbsp;Amazon Simple Storage Service&lt;/a&gt;（Amazon S3）。&lt;/p&gt; 
&lt;p&gt;您需要在段落开头指出使用的是 Flink SQL 解释器，该解释器由&lt;a href="https://zeppelin.apache.org/docs/0.9.0/interpreter/flink.html"&gt;&amp;nbsp;Zeppelin&lt;/a&gt;&amp;nbsp;magic&amp;nbsp;%&amp;nbsp;指示，后跟&amp;nbsp;flink.ssql&amp;nbsp;和段落的类型。在大多数情况下是更新段落 type=update，会持续更新输出。如果查询的结果只有一行，可以使用&amp;nbsp;type=single；如果需要将查询的输出附加到现有结果后面，则可以使用&amp;nbsp;type=append。请参阅以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CREATE TABLE stock_table (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ticker VARCHAR(6),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;price DOUBLE,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;event_time TIMESTAMP(3),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;PARTITIONED BY (ticker)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WITH (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'connector' = 'kinesis',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'stream' = 'input-stream',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'aws.region' = 'us-east-1',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'scan.stream.initpos' = 'LATEST',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'format' = 'json',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'json.timestamp-format.standard' = 'ISO-8601')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此示例展示了创建一个名为&amp;nbsp;stock_table&amp;nbsp;的表，其中包含股票、价格和表示记录股票价格时间的&amp;nbsp;event_time&amp;nbsp;列。WATERMARK&amp;nbsp;子句根据&amp;nbsp;event_time&amp;nbsp;(row_time) 列定义了用于生成水位线的水位线策略。event_time&amp;nbsp;列被定义为&amp;nbsp;Timestamp(3)，是与水位线一起使用的顶级列。WATERMARK定义后面的语法 —&amp;nbsp;FOR event_time AS event_time – INTERVAL ‘5’ SECOND&amp;nbsp;— 声明水位线是根据&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/datastream/event-time/built_in/#fixed-amount-of-lateness"&gt;&amp;nbsp;bounded-out-of-orderness&lt;/a&gt; 策略发出的，允许&amp;nbsp;event_time&amp;nbsp;数据有 5 秒的延迟。该表使用 Kinesis 连接器从最新的流位置读取&amp;nbsp;us-east-1&amp;nbsp;区域中名为&amp;nbsp;input-stream&amp;nbsp;的 Kinesis 数据流。&lt;/p&gt; 
&lt;p&gt;在 Zeppelin 笔记本中运行此语句时，将会根据 CREATE 语句中的声明创建一个&lt;a href="https://aws.amazon.com/glue"&gt;&amp;nbsp;Amazon Glue&lt;/a&gt;&amp;nbsp;数据目录表，该表可立即用于来自 Kinesis Data Streams 的查询。&lt;/p&gt; 
&lt;p&gt;如果数据目录已包含该表，则无需完成此步骤。您可以如前文所述创建表，也可以使用现有的数据目录表。&lt;/p&gt; 
&lt;p&gt;以下屏幕截图展示了在 Amazon Glue 数据目录中创建的表。&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;使用实时更新查询数据流&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;创建表后，可以通过编写 SELECT 语句来执行简单的数据流查询，该语句允许以表格形式或条形图、饼图等显示数据：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM stock_table;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;从不同图表中选择不同的可视化效果非常简单，可以直接从结果集的左上角选择。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要删除或重新创建此表，您可以导航到 Amazon Glue 控制台中的表目录，手动将其从数据目录中删除，也可以从Amazon Kinesis Data Analytics Studio 笔记本中显式地删除此表：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;DROP TABLE stock_table;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;过滤函数&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您可以使用关键字“WHERE”对数据流执行简单的过滤操作。在以下代码示例中，从所有股票代码记录过滤出以“AM”开头的流数据：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM stock_table WHERE ticker LIKE 'AM%'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;用户定义函数&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您可以在笔记本中注册用户定义函数 (UDF)，以便在我们的 Flink SQL 查询中使用。必须在表环境中注册才能供Amazon Kinesis Data Analytics Studio 应用程序中的 Flink SQL 使用。UDF 是可以在 Flink SQL 范围之外定义的函数，它们使用自定义逻辑或频繁的转换，通常这些内容不方便在 SQL 中表达出来。&lt;/p&gt; 
&lt;p&gt;UDF在Amazon Kinesis Data Analytics Studio 中是通过 Scala 实现的，其中 Python UDF 支持即将推出。UDF 可使用任意库处理数据。&lt;/p&gt; 
&lt;p&gt;让我们定义一个将股票符号转换为小写字母的 UDF 和一个将&amp;nbsp;event_time&amp;nbsp;转换为epoch seconds的 UDF：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;import java.time.LocalDateTime&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;import java.time.format.DateTimeFormatter._&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;import java.time.ZoneOffset&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;class DateTimeToEpoch extends ScalarFunction {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;def eval(datetime: LocalDateTime) = datetime.toEpochSecond(ZoneOffset.UTC)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;stenv.registerFunction(&amp;quot;dt_to_epoch&amp;quot;, new DateTimeToEpoch())&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;class ScalaLowerCase extends ScalarFunction {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;def eval(str: String) = str.toLowerCase&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;stenv.registerFunction(&amp;quot;to_lower&amp;quot;, new ScalaLowerCase())&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在每个 UDF 定义的底部，Scala 中的&amp;nbsp;stenv(StreamingTableEnvironment) 用于注册指定名称的函数。&lt;/p&gt; 
&lt;p&gt;注册后，您只需在 Flink SQL 段落中调用 UDF 即可转换我们的数据：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT to_lower(ticker) as lowercase_ticker, price, dt_to_epoch(event_time) as epoch_time from stock_table;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;使用外部数据源（&lt;/strong&gt;&lt;strong&gt;join）来扩充数据&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您可能需要使用存储在数据流之外的静态或参考数据来扩充流数据。例如，除了股票交易之外，公司地址和元数据可能流入到关系数据库或Amazon S3上的文件。为了扩充数据流，Flink SQL 允许您将参考数据连接到流数据源。这种扩充静态数据可能有或没有与之关联的时间元素。如果没有关联的时间元素，您可能需要向从外部读取的数据添加时间处理元素，以便将其与基于时间的流连接起来。这是为了避免得到过时的数据，在扩充数据时应注意这一点。&lt;/p&gt; 
&lt;p&gt;让我们定义一个扩充文件作为数据源，该文件位于 Amazon S3 中。存储桶包含一个 CSV 文件，其中包含股票代码和关联公司的元数据 — 全称、城市和州：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CREATE TABLE company_details_table (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; ticker_symbol VARCHAR(6),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; company_name VARCHAR,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; company_city VARCHAR,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; company_state_abbrev VARCHAR&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&amp;nbsp; WITH (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; 'connector' = 'filesystem',&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; 'path' = 's3a://interactive-applications/data-mapping-stock-enrichment.csv',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; 'format' = 'csv'&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此 CSV 文件被一次性读取，且任务被标记为已完成。现在，您可以将它与现有的&amp;nbsp;stock_table&amp;nbsp;连接：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT ticker, price, company_name, event_time, company_city, company_state_abbrev FROM (SELECT CAST(event_time AS TIMESTAMP) as event_time, ticker, price from stock_table)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;JOIN company_details_table cd&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ON ticker=ticker_symbol;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在撰写本文时，Flink 存在一个&lt;a href="https://issues.apache.org/jira/browse/FLINK-10211"&gt;限制&lt;/a&gt;，它无法区分间隔连接（两个表都需要时间戳）和常规连接。因此，您需要将&amp;nbsp;rowtime&amp;nbsp;列 event_time 显式转换为常规时间戳，以免其被纳入常规连接中。如果两个表都有时间戳，理想的情况是将它们包含在连接语句的 WHERE 子句中。如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;滚动（&lt;/strong&gt;&lt;strong&gt;Tumbling）窗口&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;可将滚动窗口视为在不重叠的时间窗口中的小批次聚合。例如，计算 30 秒内的最高价格，或10 秒内的股票计数。要使用 Apache Flink SQL 执行此功能，请使用以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT ticker_symbol, COUNT(ticker_symbol) AS ticker_symbol_count&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;FROM stock_ticker_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;GROUP BY TUMBLE(processing_time, INTERVAL '10' second), ticker_symbol;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;以下截图显示了我们的输出。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;滑动（&lt;/strong&gt;&lt;strong&gt;Sliding）窗口&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;滑动窗口（也称为跳跃窗口）与滚动窗口基本相同，区别在于这些窗口可能会重叠。滑动窗口可以每隔 X 秒发出窗口大小为 Y 秒的数据。例如，对于上述使用案例，您可以每隔 5 秒发出一次 10 秒的数据统计：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT ticker_symbol, COUNT(ticker_symbol) AS ticker_symbol_count&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;FROM stock_ticker_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;GROUP BY HOP(processing_time, INTERVAL '5' second, INTERVAL '10' second), ticker_symbol;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio8.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;带过滤警报的滑动窗口&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;要过滤数据流中的记录，以触发某种警报或在下游使用它们，以下示例展示了如何将过滤出的滑动窗口插入聚合计数表中，该表的配置为写入数据流。之后可以使用&lt;a href="http://aws.amazon.com/cloudwatch"&gt;&amp;nbsp;Amazon CloudWatch&lt;/a&gt;&amp;nbsp;或其他触发机制来发出高交易率或其他指标的警报。&lt;/p&gt; 
&lt;p&gt;以下 CREATE TABLE 语句连接到 Kinesis 数据流，其后的插入语句将过滤出所有以&amp;nbsp;AM&amp;nbsp;开头的代码记录，其中 1 分钟间隔内有 750 条记录：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CREATE TABLE stock_ticker_count_table (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; ticker_symbol VARCHAR(4),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; ticker_symbol_count INTEGER&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WITH (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'connector' = 'kinesis',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'stream' = 'output-stream',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'aws.region' = 'us-east-1',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'scan.stream.initpos' = 'LATEST',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'format' = 'json',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'json.timestamp-format.standard' = 'ISO-8601');&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;INSERT INTO&amp;nbsp; stock_ticker_count_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; (SELECT ticker_symbol, CAST(COUNT(ticker_symbol) AS INTEGER) AS ticker_symbol_count&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; FROM stock_ticker_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; WHERE ticker_symbol like 'AM%'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; GROUP BY HOP(processing_time, INTERVAL '30' second, INTERVAL '1' minute), ticker_symbol)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WHERE ticker_symbol_count &amp;gt; 750;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;事件时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果传入的数据包含时间戳信息，您的数据管道将使用事件时间而不是处理时间，从而更好地反映实际情况。这两种时间的区别在于，事件时间反映的是生成记录的时间，而处理时间指 Apache Flink 的Amazon Kinesis Data Analytics 收到记录的时间。&lt;/p&gt; 
&lt;p&gt;要在 Flink SQL 创建语句中指定事件时间，用于事件时间的元素必须为&amp;nbsp;TIMESTAMP(3)类型，并且必须伴随水位线策略表达式。如果事件时间列不是&amp;nbsp;TIMESTAMP(3)类型，也可以&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/create/#columns"&gt;计算出来&lt;/a&gt;。定义水位线策略表达式将事件时间字段标记为事件时间属性，并说明如何处理迟到的数据。&lt;/p&gt; 
&lt;p&gt;水位线策略表达式定义了水位线策略。计算为每条记录生成的水位线，并相应地处理数据的顺序。&lt;/p&gt; 
&lt;p&gt;流数据工作负载中的迟到数据很常见，大多数情况下是不可避免的。数据之所以迟到，可能是因为网络滞后、数据缓冲或处理速度缓慢以及介于它们之间的任何其他原因。对于可能引入迟到数据的升序的时间戳工作负载，您可以使用以下水位线策略：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL '0.001' SECOND&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此代码发出观察到的最大时间戳减去一条记录的水位线。时间戳早于或等于最大时间戳的行不会被视为迟到。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Bounded-out-of-orderness 时间戳&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;要发出观察到的最大时间戳减去指定延迟的水位线，可以通过Bounded-out-of-orderness时间戳定义允许的数据流中的记录延迟：&lt;/p&gt; 
&lt;p&gt;WATERMARK FOR rowtime_column AS rowtime_column – INTERVAL ‘3’ SECOND&lt;/p&gt; 
&lt;p&gt;上面的代码发出 3 秒延迟水位线。可以在本文的简介部分找到这个例子。水位线指示数据流处理迟到的数据。思考以下场景：股票代码每 5 秒钟用实时数据更新实时控制面板。如果数据延迟 10 秒（根据事件时间）到达数据流，我们会丢弃该数据，而不会反映在控制面板中。水位线指导 Apache Flink 处理迟到的数据。,&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;MATCH_RECOGNIZE&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;流数据中的一个常见模式是能够检测模式。Apache Flink 具有复杂的事件处理库，能够检测数据中的模式，而且 Flink SQL API 允许在关系查询语法中进行检测。&lt;/p&gt; 
&lt;p&gt;通过 Flink SQL 中的&amp;nbsp;MATCH_RECOGNIZE&amp;nbsp;查询能够实现逻辑分区并识别流表中的模式。以下示例演示了如何操作我们的股票表：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT *&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;FROM stock_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; MATCH_RECOGNIZE(&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; PARTITION BY ticker&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ORDER BY event_time&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; MEASURES&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; A.event_time AS initialPriceTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; C.event_time AS dropTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; A.price - C.price AS dropDiff,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; A.price as initialPrice,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; C.price as lastPrice&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ONE ROW PER MATCH&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; AFTER MATCH SKIP PAST LAST ROW&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; PATTERN (A B* C) WITHIN INTERVAL '10' MINUTES&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; DEFINE&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; B AS B.price &amp;gt; A.price - 500&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; )&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在此查询中，我们识别了 10 分钟内某只下跌了 500 美元的股票。让我们将&amp;nbsp;MATCH_RECOGNIZE&amp;nbsp;查询细分为几个组件。&lt;/p&gt; 
&lt;p&gt;以下代码查询我们现有的&amp;nbsp;stock_table：&lt;/p&gt; 
&lt;p&gt;SELECT * FROM stock_table&lt;/p&gt; 
&lt;p&gt;MATCH_RECOGNIZE&amp;nbsp;关键字开始将模式与查询子句相匹配。这表示我们正在识别表中的模式。&lt;/p&gt; 
&lt;p&gt;下面的代码定义了表的逻辑分区，类似于 GROUP BY 表达式：&lt;/p&gt; 
&lt;p&gt;PARTITION BY ticker&lt;/p&gt; 
&lt;p&gt;以下代码定义了如何对传入数据进行排序。所有&amp;nbsp;MATCH_RECOGNIZE&amp;nbsp;模式都需要分区和排序方案才能识别模式。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ORDER BY event_time&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;MEASURES&amp;nbsp;定义了查询的输出。您可以将其视为 SELECT 语句，因为这是模式的最终结果。&lt;/p&gt; 
&lt;p&gt;在下面的代码中，我们从模式识别中选择要输出的行：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;A.event_time AS initialPriceTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;C.event_time AS dropTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;A.price - C.price AS dropDiff,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;A.price as initialPrice,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;C.price as lastPrice&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;我们使用以下参数：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A.event_time&lt;/strong&gt;&amp;nbsp;— 记录在模式中的第一个时间，500 美元的价格从这个时间开始下跌&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C.event_time&lt;/strong&gt;&amp;nbsp;— 记录在模式中的最后一个时间，这个时间的价格比&amp;nbsp;A.price&amp;nbsp;下跌了至少 500 美元&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A.price – C.price&lt;/strong&gt;&amp;nbsp;— 记录在模式中的第一个时间到最后一个时间的价差&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A.price&lt;/strong&gt;&amp;nbsp;— 记录在模式中的第一个价格，500 美元的价格开始下跌&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C.price&lt;/strong&gt;&amp;nbsp;— 记录在模式中的最后一个价格，比&amp;nbsp;A.price&amp;nbsp;下跌了至少 500 美元&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ONE ROW PER MATCH&amp;nbsp;定义了输出模式 — 每找到一个匹配应发出多少行。从 Apache Flink 1.12 开始，这是唯一受支持的输出模式。有关当前不支持的替代方案，请参阅&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/match_recognize/#output-mode"&gt;输出模式&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;以下代码定义了匹配后策略&lt;strong&gt;：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;AFTER MATCH SKIP PAST LAST ROW&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此代码指导 Flink SQL 在找到匹配后启动新的匹配过程。这个特定的定义跳过当前模式中的所有行，然后转到数据流中的下一行。这可以确保模式事件中不存在重叠。有关&amp;nbsp;AFTER MATCH SKIP&amp;nbsp;替代策略，请参阅&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/match_recognize/#after-match-strategy"&gt;匹配后策略&lt;/a&gt;。可将这种策略视为一种滚动窗口类型的聚合，因为模式的结果相互不重叠。&lt;/p&gt; 
&lt;p&gt;在下面的代码中，我们定义了模式&amp;nbsp;A B* C，表示我们将有一个序列的连接记录：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;PATTERN (A B* C) WITHIN INTERVAL '10' MINUTES&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;我们使用以下顺序：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A&lt;/strong&gt;&amp;nbsp;— 序列中的第一条记录&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;B*&lt;/strong&gt;&amp;nbsp;— 与 DEFINE 子句中定义的约束相匹配的零或多条记录&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C&lt;/strong&gt;&amp;nbsp;— 序列中的最后一条记录&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些变量的名称在 PATTERN 子句中得到定义，并遵循类似正则的语法。有关详细信息，请参见&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/match_recognize/#defining-a-pattern"&gt;定义模式&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在下面的代码中，我们将&amp;nbsp;B&amp;nbsp;模式变量定义为记录的价格，只要该价格大于模式中第一条记录减 500 的值：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;DEFINE&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; B AS B.price &amp;gt; A.price - 500&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;例如，假设我们有以下模式。&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;row&lt;/td&gt; 
   &lt;td width="88"&gt;ticker&lt;/td&gt; 
   &lt;td width="88"&gt;price&lt;/td&gt; 
   &lt;td width="88"&gt;event_time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;1&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;800&lt;/td&gt; 
   &lt;td width="88"&gt;10:00 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;2&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;400&lt;/td&gt; 
   &lt;td width="88"&gt;10:01 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;3&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;500&lt;/td&gt; 
   &lt;td width="88"&gt;10:02 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;4&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;350&lt;/td&gt; 
   &lt;td width="88"&gt;10:03 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;5&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;200&lt;/td&gt; 
   &lt;td width="88"&gt;10:04 am&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;我们定义以下内容：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A&lt;/strong&gt;&amp;nbsp;— 第 1 行&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;B&lt;/strong&gt;&amp;nbsp;— 第 2—4 行，它们都匹配 DEFINE 子句中的条件&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C&lt;/strong&gt;&amp;nbsp;— 第 5 行，它打破了匹配 B 条件的模式，因此是模式中的最后一行&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以下屏幕截图展示了完整的例子。&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio9.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Top-N&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/topn/"&gt;Top-N 查询&lt;/a&gt;识别按列排序的 N 个最小值或最大值。例如，在需要识别数据流中前 10 个项目或最后 10 个项目的情况下，此查询非常有用。&lt;/p&gt; 
&lt;p&gt;Flink 可使用&amp;nbsp;OVER&amp;nbsp;窗口子句和筛选表达式的组合来生成 Top-N 查询。OVER / PARTITION&amp;nbsp;BY 子句还可以支持每组的 Top-N。请参阅以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;SELECT * FROM (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; SELECT *, ROW_NUMBER() OVER (PARTITION BY ticker_symbol ORDER BY price DESC) as row_num&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; FROM stock_table)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WHERE row_num &amp;lt;= 10;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;数据去重&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果生成到数据流中的数据可能存在重复条目，有多种策略可消除这些条目。要实现这一目的，最简单的方法是&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/deduplication/"&gt;数据去重&lt;/a&gt;，您可以在窗口中删除行，并根据时间戳仅保留第一个或最后一个元素。&lt;/p&gt; 
&lt;p&gt;Flink 可使用&amp;nbsp;ROW_NUMBER&amp;nbsp;来删除重复项，正如 Top-N 示例所展示的方法一样。只需编写&amp;nbsp;OVER / PARTITION&amp;nbsp;BY 查询，然后在 WHERE 子句中指定第一行的编号：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; SELECT *, ROW_NUMBER OVER (PARTITION BY ticker_symbol ORDER BY price DESC) as row_num&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; FROM stock_table)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WHERE row_num = 1;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;最佳实践&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;与任何数据流工作负载一样，为了解工作负载的进展情况，您需要测试和监控策略。&lt;/p&gt; 
&lt;p&gt;以下是需要监控的关键领域：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;源&lt;/strong&gt;&amp;nbsp;— 确保源数据流具有足够的吞吐量，并且在使用Amazon Kinesis 的情况下，您没有收到&amp;nbsp;ThroughputExceededExceptions，或源系统的高内存或 CPU 使用率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;目标&lt;/strong&gt;&amp;nbsp;— 与数据源一样，确保 Flink SQL 应用程序的输出不会塞满下游系统。在使用Amazon Kinesis 的情况下，请确保您没有收到任何&amp;nbsp;ThroughputExceededExceptions。如果收到，应添加分片或者更均匀地分配数据。否则可能会对管道造成背压。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;扩缩&lt;/strong&gt;&amp;nbsp;— 在分配和扩缩Amazon Kinesis Data Analytics Studio 应用程序时，请确保数据管道有足够的Amazon Kinesis 处理单元。您可以启用基于 CPU 的自动扩缩功能，或者实施&lt;a href="https://github.com/aws-samples/kda-flink-app-autoscaling"&gt;自定义自动扩缩程序&lt;/a&gt;，以便在大量数据流入时扩展应用程序。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;测试&lt;/strong&gt;&amp;nbsp;— 在将新的数据管道部署到生产规模数据之前，先开展小规模的测试。如果可能，请使用真实的生产数据来测试管道，或者使用模拟生产数据来了解应用程序的反应，之后再将其部署到生产环境中。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;笔记本内存&lt;/strong&gt;&amp;nbsp;— 运行应用程序的 Zeppelin 笔记本受浏览器可用内存量的限制，因此，不要向控制台发出太多行，这会导致浏览器的内存冻结笔记本。虽然不会丢失数据和计算，但表示层会变得无法访问。相反，在将数据传到表示层之前，应尝试聚合数据，获取代表性样本，或者限制返回的记录量，以缓解笔记本内存不足的情况。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;只需几分钟，您就可以使用 Flink SQL 在Amazon Kinesis Data Analytics Studio 中查询数据流并创建数据管道。在本文中，我们讨论了多种不同的查询数据流的方法，&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/overview/"&gt;Apache Flink SQL 文档&lt;/a&gt;还提供了大量的其他示例。&lt;/p&gt; 
&lt;p&gt;您可以将这些样本传入自己的Amazon Kinesis Data Analytics Studio 笔记本中，然后在自己的流数据上试用！ 务必让 AWS 了解您对这项新功能的体验，我们期待看到用户使用Amazon Kinesis Data Analytics Studio 从数据中获得见解。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/jdber.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Jeremy Ber&lt;/h3&gt; 
  &lt;p&gt;在过去 5 年中一直从事于遥测数据领域，担任软件工程师、机器学习工程师，最近还担任数据工程师。过去，Jeremy 支持并构建了每天流式传输 TB 级数据的系统，并实时处理复杂的机器学习算法。在 亚马逊云科技，他是解决方案架构师和流数据处理专家，为 Managed Streaming for Kafka (Amazon MSK) 和 Amazon Kinesis 提供支持。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>基于云的数据网格技术如何实现金融监管数据采集</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection/</link>
				<pubDate>Tue, 31 Aug 2021 02:42:10 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Data Exchange]]></category>
		<category><![CDATA[Amazon EMR]]></category>

		<guid isPermaLink="false">046f3ffc6e562813d8739670002e72b339163bd9</guid>
				<description>实践证明，现代云技术可以通过汇集数据并使用数据仓库和大数据工具进行分析，以经济高效的方式实现有价值的见解。例如，使用 Amazon EMR 之类的大数据分析工具整合来自证券交易的数据，以实现增强风险管理。对监管机构来说，面临的挑战在于能够通过以受控、高度灵活且经济高效的方式分析各种大型数据集来获取见解和有价值的信息。随着市场的演变和经济风险的变化，监管机构和中央银行的需求也将发生变化，因此监管生态系统必须继续适应所有参与者并具有成本效益。</description>
								<content:encoded>&lt;h2&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;中央银行和金融监管机构依赖于从银行和保险公司等受监管的金融机构获取高质量、最新的数据。这些受监管的实体拥有各种各样且不断变化的运营环境，每个机构都独立运营，但必须与监管机构协调交换相关数据。今天，银行支持监管机构提出的数据请求所产生的成本非常高。例如，&lt;a href="https://www.bankofengland.co.uk/-/media/boe/files/report/2019/future-of-finance-report.pdf?la=en&amp;amp;hash=59CEFAEF01C71AA551E7182262E933A699E952FC"&gt;英格兰银行提及了麦肯锡公司 2019 年的一项研究&lt;/a&gt;，该研究估计，英国银行在监管报告方面的每年的支出在 20 亿英镑至 45 亿英镑之间。&lt;/p&gt; 
&lt;p&gt;实践证明，现代云技术可以通过汇集数据并使用数据仓库和大数据工具进行分析，以经济高效的方式实现有价值的见解。例如，使用&amp;nbsp;&lt;a href="https://aws.amazon.com/emr/"&gt;Amazon EMR&lt;/a&gt;&amp;nbsp;之类的大数据分析工具整合来自证券交易的数据，以实现增强风险管理。对监管机构来说，面临的挑战在于能够通过以受控、高度灵活且经济高效的方式分析各种大型数据集来获取见解和有价值的信息。随着市场的演变和经济风险的变化，监管机构和中央银行的需求也将发生变化，因此监管生态系统必须继续适应所有参与者并具有成本效益。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;介绍数据网格&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 martinFowler.com 发表的一篇文章：“&lt;a href="https://martinfowler.com/articles/data-monolith-to-mesh.html"&gt;如何从单体数据湖迁移到分布式数据网格&lt;/a&gt;”中，Zhamak Dehghani 解释了需要对以数据为中心的系统采用新方法的一些原因。Dehghani 认为，每一代“数据平台”都导致了一个集中化的单体，却忽略了生产者（例如大型组织内的部门）在如何优化数据结构为业务目的服务的个性化需求。虽然单体数据湖对于具有直观业务模式的组织来说可以奏效，但随着数据血缘和治理问题管理难度的增加，这对于更复杂的企业而言变得越来越困难。对于参与监管报告和数据收集的独立实体的生态系统来说，问题更为严重。&lt;/p&gt; 
&lt;p&gt;与“数据网格”概念结合使用的云技术为解决监管报告问题提供了一种有希望的方法。数据网格可以自然地解决与联合监管生态系统相关的数据所有权、治理和血缘问题。在数据网格方法中，每个数据生产者（例如商业银行）都独立维护和更新其已发布的数据。只有当银行选择“发布”新版本的数据集时，订阅的数据消费者（例如 FSI 监管机构）才能看到更改。每个生产者都会控制每个已发布数据集的结构，此结构由数据模式描述。同时，数据消费者可能会从多个数据生产者（例如监管机构管辖下的每家银行）收集公布的数据。然后，数据消费者可以根据需要使用各种不同的云技术来填充数据湖或数据仓库。因此，以灵活而经济高效的方式，监管数据网格使受监管实体能够“弥合其人员、流程和生成数据的系统之间的差距”。&lt;/p&gt; 
&lt;p&gt;这种数据网格方法的一个关键推动因素是使用自我描述数据。我们可以设想一个基于集中定义的数据模式、包含多个数据生产者和消费者的数据生态系统。但是，鉴于数据生产者运营的内部 IT 系统种类繁多，保持所有参与者的数据严格同步是不现实的——这种方法的执行成本高昂，而且对持续变化非常脆弱。相反，解决此问题的办法是由每个生产者创建一个嵌入式数据模式，以描述每个已发布数据集的当前结构。在监管生态系统中，此元数据可以参考标准术语和监管机构定义的一组数据字段来描述数据，例如“银行综合报告词典”(BIRD) 和欧洲中央银行系统 (ESCB) 的综合报告框架 (IReF) 中定义的数据字段。只要他们遵守法定命名法并提供所有必填的数据字段，数据生产者就可以自由采用自己的数据架构。然后，每当生产者对数据集的内容或结构进行更改时，这些更改都会反映在嵌入式数据模式中。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;实施方法概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/data-exchange/"&gt;Amazon Data Exchange&lt;/a&gt;&amp;nbsp;为创建这些安全的多方数据网格环境提供了必要的基础。使用 Amazon Data Exchange “Private”（私有）发布选项，只有经生产者授权的特定数据消费者（例如监管机构）才能查看数据产品并订阅该数据产品。AWS Data Exchange 上发布的每个视图都开启了版本控制，因此，数据消费者可以使用可审计的数据更改记录。数据消费者可以访问此自描述数据，并使用工具（例如 AWS Glue）将其转换为通过数据仓库、数据库或数据湖进行下游处理所需的格式。&lt;/p&gt; 
&lt;p&gt;最近的博客&lt;a href="https://aws.amazon.com/blogs/apn/analyzing-covid-19-data-with-aws-data-exchange-amazon-redshift-and-tableau/"&gt;分析 COVID-19 数据&lt;/a&gt;展示了以这种方式使用 Amazon Data Exchange 的力量。在此示例中，亚马逊云科技与亚马逊云科技的合作伙伴 Salesforce、Tableau 和 MuleSoft 汇集了可信赖的 COVID-19 数据来源，使其能够通过 Amazon Data Exchange 与感兴趣的第三方共享。这使得数据消费者能够将相关数据提取到他们的分析数据湖中，并根据需要提取和转换数据。Amazon Data Exchange 内的相关数据生产者可以随时提供新版本的数据，并且这些新版本数据的可用性将传达给所有数据消费者。该资源可公开提供，用于支持组织的 COVID 救助工作。在其他使用案例中，也可以使用 Amazon Identity and Access Management 控件严格限制访问权限。&lt;/p&gt; 
&lt;p&gt;图 1 显示了联合监管报告数据网格环境的概念概述；其中每家受监管银行都是 AWS Data Exchange 数据生产者，每个监管机构都是 Amazon Data Exchange 数据消费者。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;em&gt;图&lt;/em&gt;&lt;em&gt; 1：监管机构报告数据网格&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;图 2 所示的这种环境的实施包括以下阶段：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;受监管银行（Amazon Data Exchange 数据生产者）策划和上传所需的数据构件，以创建其 Amazon Data Exchange 监管报告数据产品。请参阅 AWS Data Exchange 最佳实践。&lt;/li&gt; 
 &lt;li&gt;在适当或需要时，每个数据生产者都会发布其报告数据产品的新修订版本（例如监管数据）。这个新发布的修订版本可能只包括已更改的数据、所有数据或者所有数据和完整的更改历史记录。每个数据生产者可以随时创建和发布修订。&lt;/li&gt; 
 &lt;li&gt;监管机构（数据消费者）会收到更新通知，他们可以自行决定对更新采取行动，在需要时将修订内容纳入报告分析基础设施中。由于每个数据生产者的修订都是自我描述的，因此将这些不同来源映射到数据消费者的标准化数据结构中是一个简单的过程。&lt;/li&gt; 
 &lt;li&gt;可以使用一系列工具和技术对标准化数据进行分析，以搜索特定信息或提取见解。选项包括图关系分析 (Amazon Neptune)、AI/ML 模式识别 (Amazon SageMaker)、传统数据仓库搜索/查询（Amazon Redshift 或 Amazon Athena）和报告生成。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="text-align: center"&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;em&gt;图&lt;/em&gt;&lt;em&gt; 2：联合监管报告数据网格环境的示例实施&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;机会和益处&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Amazon Data Exchange 方法可以用作高度自适应性和可扩展性的“常用输入层”的基础，监管机构认为这是一个理想的属性（例如，参见 2020 年 1 月发布的英格兰银行关于“&lt;a href="https://www.bankofengland.co.uk/-/media/boe/files/paper/2020/transforming-data-collection-from-the-uk-financial-sector.pdf?la=en&amp;amp;hash=6E6132B4F7AF681CCB425B0171B4CF43D82E7779"&gt;转型数据收集&lt;/a&gt;”的咨询意见）。该文讨论的考虑因素之一是，常用输入层是应采取“推送”还是“拉取”的方法（例如，受监管实体应按照要求向监管机构“推送”数据），或者在必要时，监管机构从每个受监管实体中“提取”数据。监管数据网格架构提供了这两种方法的优势。它为数据生产者提供了“推送”系统的益处，它可以抽象自己底层 IT 系统的复杂性以及更新的时间，而无需直接与监管机构协调。它还允许监管机构在需要时“拉取”所需数据，从而使每家银行免于根据监管机构的要求不断生成新报告或数据提取的负担。&lt;/p&gt; 
&lt;p&gt;它还为双方提供了进一步的优势。数据生产者有一个本地数据存储库，对于数据生产者来说，它具有作为参考数据存储的潜在价值，并且数据生产者不用承担必须根据监管机构的要求不断生成新报告或数据提取的负担。监管机构的优势是能够创建新的组合数据集并按需分析它们，而无需构建永久的集中式数据湖。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;监管机构为实现监管目标而需要收集的数据的数量、及时性和准确性给监管机构和受监管公司带来了挑战。但是，面临的许多业务问题有切实可行的解决方案，可以使用云技术来安全、经济高效且可扩展地开发这些解决方案。我们尤其相信，各方都可以从数据网格技术的应用中受益，以便能够以足够灵活的方式适应不断变化的需求，从而减轻大小型组织的数据收集负担。&lt;/p&gt; 
&lt;p&gt;基于云的数据网格技术还可以成功地应用于各种其他数据管理要求，从获取第三方和公共数据以帮助进行内部决策制定，到确保内部数据集之间的一致性。这只是云计算改变企业看待他们面临的一些最艰难的数据挑战的方式之一，从而帮助他们创建更敏捷和可持续的解决方案。&lt;/p&gt; 
&lt;p&gt;要了解有关云计算如何帮助改进监管报告和数据收集的更多信息，请联系：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/rcnic.png" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Richard Nicholson&lt;/h3&gt; 
  &lt;p&gt;Richard 是亚马逊云科技金融服务 EMEA 业务和市场开发团队的首席解决方案架构师。Richard 的工作领域非常广泛，比如前台风险系统架构和后台核心大型机迁移。在加入亚马逊云科技之前，Richard 在自己的公司工作了 18 年，专注于金融服务和工业 IoT 等不同行业的运行时自适应软件系统的开发和使用。作为一名经过培训的天体物理学家，Richard 于 1995 年进入金融服务行业，担任 Salomon Brothers 的基础设施系统管理员。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/rcaven.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Richard Caven&lt;/h3&gt; 
  &lt;p&gt;Richard Caven 是英国和爱尔兰以及北欧银行业领先的亚马逊云科技金融服务专家。他负责开发和执行战略计划，以帮助客户迁移到云并推动他们的数字化转型之旅。Richard 于 2018 年从 Barclays 加入亚马逊云科技，担任全球财资职能部门的总经理和首席运营官。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/dmmackei.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;David MacKeith&lt;/h3&gt; 
  &lt;p&gt;David MacKeith 负责亚马逊云科技欧洲、中东和非洲 (EMEA) 政府金融服务的业务开发。他在帮助世界各地的政府和金融服务组织转型其运营方式以更好地服务各自的客户和市场方面拥有 20 多年的经验。这包括帮助这些组织在数字货币、货币和市场分析、监管报告和数据收集自动化和优化以及财资管理职能转型等领域开发、试验和部署创新解决方案。在加入亚马逊云科技之前，MacKeith 先生曾在伦敦金融城担任商业交易律师。他拥有剑桥大学的物理学学位。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>如何使用数据网格创建现代包装消费品 (CPG)行业数据架构</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture/</link>
				<pubDate>Tue, 31 Aug 2021 02:26:48 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Glue]]></category>
		<category><![CDATA[Amazon Lake Formation]]></category>

		<guid isPermaLink="false">a155373d52ed91a040fd538dc72cae34ccf05515</guid>
				<description>在本博客文章中，我们将深入探讨大规模管理数据的主题，并解释为什么 CPG 应考虑使用数据网格进行数据管理的新方法。</description>
								<content:encoded>&lt;p&gt;自新冠肺炎 (COVID-19) 疫情以来，我们看到世界各地都在向在线购物和直接面向消费者的销售进行翻天覆地的转变。可以说，包装消费品 (CPG) 行业比任何其他行业都更能感受到这种转变。根据统计，“零售网站&lt;a href="https://www.statista.com/statistics/1112595/covid-19-impact-retail-e-commerce-site-traffic-global/"&gt;在 2020 年 6 月创造了近 220 亿次访问量&lt;/a&gt;，而 2020 年 1 月，其全球访问量为 160.7 亿次。” 网站流量在 6 个月内大幅增长 27%，这加速了公司（特别是 CPG）需要管理的数据量。&lt;/p&gt; 
&lt;p&gt;历史上，大多数 CPG 并没有直接与消费者交流，因此数据很少，且主要代表了内部信息，例如与零售合作伙伴的订单和运输详情。现在，精明的消费品公司开始跟踪最终用户客户和外部数据，例如搜索分析和社交媒体情绪。在本博客文章中，我们将深入探讨大规模管理数据的主题，并解释为什么 CPG 应考虑使用数据网格进行数据管理的新方法。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;CPG 组织之间的数据流&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先，我们从数据生态系统的概述开始。由于数据已成为竞争差异化的一个重要点，因此，很多公司允许各个业务层面的人通过分析和机器学习来使用、转换和增强数据——将数据视为不断发展、不断扩展的资产。这对于利用数据推动产品开发和营销决策的 CPG 品牌经理尤其重要。&lt;/p&gt; 
&lt;p&gt;现代数据生态系统中有三个核心组：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;数据生产者&lt;/strong&gt;&amp;nbsp;– 拥有传入数据系统或来源（订单、发票、库存等）的领域专家。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据平台构建者&lt;/strong&gt;&amp;nbsp;– IT 团队的一部分，其成员拥有不同数据技能，其要求具体取决于公司的成熟度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据消费者&lt;/strong&gt;&amp;nbsp;– 使用数据优化业务、做出决策和定义策略的分析师和运营者。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;CPG 的数据湖面临的挑战和局限&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/?nc=sn&amp;amp;loc=2"&gt;数据湖&lt;/a&gt;通常用于管理数据的快速增长。该集中式存储库存储结构化和非结构化数据。您可以批量或通过实时流式传输来注入信息。但是，当具有大量数据源的数据扩展到 PB 级时，这种经过验证的技术就有一些局限性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安全挑战&lt;/strong&gt;&amp;nbsp;– 实现大规模精细安全性非常困难。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;通用方法&lt;/strong&gt;&amp;nbsp;– 一刀切的方法不允许您针对特定数据集优化数据湖。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完整性问题&lt;/strong&gt;&amp;nbsp;– 通常，数据输入数据湖后会丢失上下文。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;手动维护&lt;/strong&gt;&amp;nbsp;– 不同的，冲突的数据集需要人工操作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些限制会转化为较长的开发周期和瓶颈，从而无法将数据输入数据湖并从中提取有意义的信息，这意味着许多 CPG IT 部门都在努力地大规模维护和挖掘数据。同时，对于数据消费者来说，访问和分析企业数据可能非常复杂且令人沮丧。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在数据湖模型中，数据被摄取到企业数据湖中。中央平台团队负责管理安全性、摄取、转换、访问和数据可用性。数据生产者和消费者需要通过集中化团队来存储和访问数据。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;从整体到可管理：一种软件类比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由中央 IT 部门管理的数据湖类似于 20 世纪 90 年代的整体软件产品。刚性、相互依赖性和缓慢的开发周期是软件开发中的微服务革命背后的驱动力，它提供了可扩展性、更短的开发周期、隔离安全性和更轻松的管理。&lt;/p&gt; 
&lt;p&gt;那么我们如何将同样的微服务设计原则应用于数据呢？ 在CPG 行业（以及其他行业）的答案是数据网格。&lt;/p&gt; 
&lt;p&gt;数据网格是一种相对较新的架构设计，它解决了单体式数据湖架构的缺点，并提供了与软件设计中的微服务类似的益处。在数据网格中，数据本身就是产品，并且由与领域无关的自助式数据基础设施提供支持。数据网格通过以下方式打破了传统数据湖的单体性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;数据即产品&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;– 在典型的数据湖中，数据湖和数据管道就是产品。在数据网格中，数据以及收集和发布数据的领域和生产者专业知识是产品。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分散式所有权&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;– 与 IT 集中管理的数据湖不同，数据网格具有分散式所有权。不同的业务领域（数据生产者）负责策划、验证、发布、维护和生命周期管理他们拥有的数据。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;精细、可扩展的访问控制&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;– 由于数据被数据网格中的生产者所拥有，因此由他们指定访问、治理和保留策略以及基于数据粒度的任何自定义访问策略。这样一来，通过将责任和访问控制策略推送给数据所有者，消除了数据湖的集中访问控制瓶颈。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可扩展的数据发现&lt;/strong&gt;&amp;nbsp;– 数据网格允许消费者根据领域、粒度、质量、频率等发现、识别和订阅数据。这使可扩展的消费者可以访问和发现，并消除对集中式团队的依赖。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当生产者在数据网格中发布数据时，他们会使用以下属性创建不可变的数据契约：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;数据类型&lt;/li&gt; 
 &lt;li&gt;物理模式&lt;/li&gt; 
 &lt;li&gt;业务特点&lt;/li&gt; 
 &lt;li&gt;分发频率&lt;/li&gt; 
 &lt;li&gt;数据质量声明&lt;/li&gt; 
 &lt;li&gt;生命周期策略&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;数据契约是一种确保在整个企业中可以发现数据的机制。合同属性与数据的整个生命周期相关联，数据消费者可以发现和订阅特定的数据契约属性。&lt;/p&gt; 
&lt;p&gt;在网格架构中，数据可以存储在生成数据的位置。中央平台团队负责管理安全性，确保契约得到执行，并提供工具和自动化。数据生产者和消费者可以访问和查看整个企业中的所有数据，并可以彼此之间进行通信。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;CPG 行业的数据网格参考架构和用法&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;以下是一种典型的数据网格实现的示例：&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 该设计使用&amp;nbsp;&lt;a href="https://aws.amazon.com/pub-sub-messaging/"&gt;pub/sub 模型&lt;/a&gt;。尽管该解决方案使用&lt;a href="https://aws.amazon.com/lake-formation"&gt;Amazon Lake Formation&lt;/a&gt;&lt;u&gt; 一种可以&lt;/u&gt;简化数据湖创建工作的服务，但您需要手动定义数据源、访问权限和安全策略。您可以使用&amp;nbsp;&lt;a href="https://aws.amazon.com/glue"&gt;Amazon Glue&lt;/a&gt;&amp;nbsp;发现数据目录中的数据，也可以使用契约中定义的属性发现元数据。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;用数据网格管理单独的微服务数据集&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;近年来，CPG 行业投入了大量资金，使用微服务和容器架构实现在线基础设施的现代化。在这种新的设计模式中，每项微服务都会创建单独的数据集（搜索、结账、排序、产品等），且新的不同数据会成倍增加。每个独特的数据流都由不同的数据生产者拥有，并且具有不同的质量、治理和生命周期属性。生产者可以配置数据流以实时或批量上传到数据平台。这种微服务设计能够自然地适合数据网格概念实施模式。&lt;/p&gt; 
&lt;p&gt;有关 CPG 行业微服务的更多信息，请务必阅读 Danny Yin 的博客文章《&lt;a href="https://aws.amazon.com/blogs/industries/use-this-success-strategy-to-move-to-a-microservice-architecture/"&gt;在 CPG 中迁移到微服务架构的成功策略&lt;/a&gt;》。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;将数据管家指定为&lt;/strong&gt;&lt;strong&gt; CPG 中的数据点人员&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;为了确保数据网格架构的可扩展性，组织通常会指定一名数据管家，他是一位对生产者生成数据的方式、数据本身的契约属性、用户访问控制、数据清洁度和预期的消费者使用模式有深入了解的专人。数据管家的任务是确保数据在整个生命周期中的契约完整性，并帮助管理任何契约修改。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;在数据清洁室中挖掘受限的&lt;/strong&gt;&lt;strong&gt; CPG 数据&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在这种新兴的使用案例中，清洁室包含原始数据，例如 PII 或 POS 交易数据，这些数据可能受到隐私限制的约束。在清洁室中，数据消费者可以通过充足的匿名化运行聚合查询。数据消费者还可以使用不受限制的数据联合匿名数据进行分析信息，同时遵守隐私要求。数据网格架构通过强制执行数据的契约限制去原生支持清洁室要求。&lt;/p&gt; 
&lt;p&gt;随着各国采用严格的数据隐私规则，例如&amp;nbsp;&lt;a href="http://www.oecd.org/"&gt;OECD&lt;/a&gt;&amp;nbsp;指南或欧盟《&lt;a href="https://www.consumersinternational.org/media/155133/gdpr-briefing.pdf"&gt;一般数据保护条例&lt;/a&gt;》，管理如何维护、保护、使用和处置数据的规则变得更加复杂。数据网格架构可以正确隔离数据、强制执行安全策略并授予对数据的访问权限。数据优先的设计和数据网格的精细访问控制提供了支持数据隐私要求的原生机制，而不需要昂贵的企业范围的数据项目。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;使用数据网格与&lt;/strong&gt;&lt;strong&gt; CPG 相关的供应商协作&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;很多 CPG 都在试图优化第三方提供商的运营，例如提供原材料和成品的供应链和物流供应商。数据网格是从头开始设计的，以在原生支持 CPG 和供应商之间的协作。内部和外部数据生产者和消费者可以通过商定的契约自由交换数据，而数据不可变性为多供应商系统的高效运行提供了完整性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;数据网格架构是单体数据湖和数据仓库的现代化方法，从而使 CPG 行业能够大规模管理数据。询问亚马逊云科技如何支持您的数据转换。立即&lt;a href="https://pages.awscloud.com/GLOBAL-other-IND-CPG-Contact-Us-2021.html"&gt;联系&lt;/a&gt;您的 Amazon Web Services 账户团队以开始行动，或访问我们的&lt;a href="https://aws.amazon.com/cpg/"&gt;消费性包装品&lt;/a&gt;页面了解更多信息。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/ilanraab.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Ilan Raab&lt;/h3&gt; 
  &lt;p&gt;Ilan Raab 是亚马逊云科技消费性包装品 (CPG) 行业的全球技术领导者。Ilan 于 2019 年加入亚马逊云科技，负责定义和执行公司的 CPG 技术策略，其中包括在制造/移动/市场业务领域构建以 CPG 为重点的解决方案。他经常与亚马逊云科技CPG 客户合作，利用尖端的亚马逊云科技技术和思想领导力来帮助他们实现业务转型。在加入 AWS 之前，Ilan 是企业软件和网络领域多家初创公司的工程副总裁兼联合创始人。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/mchiapus.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Marco Chiapusso&lt;/h3&gt; 
  &lt;p&gt;Marco Chiapusso 于 2020 年 1 月加入亚马逊云科技，担任欧洲、中东和非洲的解决方案架构经理。他与全球企业客户合作，共享云如何帮助他们提高速度和敏捷性，同时让他们能把更多的时间花在客户身上的最佳实践、技术和策略。在加入亚马逊云科技之前，Marco 担任了多个高级技术职位，领导并共同领导了多项大规模计划，将组织转变为技术赋能型现代公司。其中包括开发和部署一个拥有超过 1PB 数据的现代数据平台，从而提高客户洞察力，并大规模增强机器学习能力。Marco 在 Adidas 的经验和任期涉及多个领域，包括架构、开发、支持、数据、创新（包括 AI 和 IoT）以及组织发展。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>预处理日志以便在 Amazon ES 中进行异常检测</title>
		<link>https://aws.amazon.com/cn/blogs/china/preprocess-logs-for-anomaly-detection-in-amazon-es-2/</link>
				<pubDate>Tue, 31 Aug 2021 02:12:05 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Elasticsearch Service*]]></category>

		<guid isPermaLink="false">2cc55d31977ca5583f876f47cf0ac2e9c4c4acda</guid>
				<description>Amazon Elasticsearch Service（Amazon ES）支持实时的异常检测，它使用机器学习（ML）主动检测实时流数据中的异常情况。当分析应用程序日志时，它可以用来检测例如异常高的错误率或请求数量的突然变化等异常状况。例如，来自特定地区的食品配送订单数量的突增可能是由于天气变化或该地区用户遇到技术故障造成的。发现这种异常情况可以促进对事件的快速调查和补救。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://aws.amazon.com/elasticsearch-service/"&gt;Amazon Elasticsearch Service&lt;/a&gt;（Amazon ES）支持实时的异常检测，它使用机器学习（ML）主动检测实时流数据中的异常情况。当分析应用程序日志时，它可以用来检测例如异常高的错误率或请求数量的突然变化等异常状况。例如，来自特定地区的食品配送订单数量的突增可能是由于天气变化或该地区用户遇到技术故障造成的。发现这种异常情况可以促进对事件的快速调查和补救。&lt;/p&gt; 
&lt;p&gt;Amazon ES 的异常检测功能使用 Random Cut Forest 算法。这是一种无监督学习算法，它通过数值类型的输入数据点构造决策树，以检测数据中的离群值，这些离群值被视为异常。为了检测日志中的异常情况，我们必须将基于文本的日志文件转换为数值，以便可以用此算法解释它们。在机器学习术语中，这种转换通常称为数据预处理。有很多种数据预处理方法可供使用，在这篇博文中，我将介绍了一些适合日志的方法。&lt;/p&gt; 
&lt;p&gt;要实现本文中描述的方法，您需要一个将日志文件提取到 Amazon ES 域的日志聚合管道。有关提取 Apache Web 日志的信息，请参阅博客&lt;a href="https://aws.amazon.com/blogs/database/send-apache-web-logs-to-amazon-elasticsearch-service-with-kinesis-firehose/"&gt;使用 Kinesis Firehose 将 Apache Web 日志发送到 Amazon Elasticsearch Service&lt;/a&gt;。有关获取和分析&amp;nbsp;&lt;a href="http://aws.amazon.com/s3"&gt;Amazon Simple Storage Service&lt;/a&gt;&amp;nbsp;(Amazon S3) 服务器访问日志的类似方法，请参阅博客&lt;a href="https://aws.amazon.com/blogs/big-data/analyzing-amazon-s3-server-access-logs-using-amazon-es/"&gt;使用 Amazon ES 分析 Amazon S3 服务器访问日志&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;现在，让我们讨论一些在处理日志文件的复杂结构时可以使用的数据预处理方法。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;将行记录到&lt;/strong&gt;&lt;strong&gt; JSON 文档&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;尽管日志都是文本文件，但通常日志文件对日志消息有一些记录结构，例如每行有一个日志条目。如下图所示，可以解析日志文件中的一行并将其作为包含多个字段的文档存储在 Amazon ES 索引中。此图是如何将&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html"&gt;Amazon S3 访问日志&lt;/a&gt;中的条目转换为 JSON 文档的示例。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/preprocess-logs-for-anomaly-detection-in-amazon-es-2-1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/preprocess-logs-for-anomaly-detection-in-amazon-es-2-1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;尽管您可以将 JSON 文档（例如上图）原样提取到 Amazon ES，但是某些文本字段需要进一步的预处理才能用于执行异常检测。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;定类型（&lt;/strong&gt;&lt;strong&gt;nominal）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;假设您的应用程序收到的主要是 GET 请求，POST 请求的数量要少得多。根据&amp;nbsp;&lt;a href="https://owasp.org/www-community/attacks/Cross_Site_Tracing"&gt;OWASP 安全建议&lt;/a&gt;，也建议禁用 TRACE 和 TRACK 请求方法，因为这些方法可能被滥用于跨站点跟踪。如果您想检测服务器日志中何时出现异常的 HTTP 请求，或者先前数量通常很少的 HTTP 请求数何时出现激增，则可以使用上述 JSON 文档中的&amp;nbsp;request_uri&amp;nbsp;或&amp;nbsp;operation&amp;nbsp;字段。这些字段包含 HTTP 请求方法，但是您必须提取此类字段，然后将其转换为可用于异常检测的数值格式。&lt;/p&gt; 
&lt;p&gt;这些字段只有少数不同的值，而且这些值没有任何特定的先后顺序。如果我们简单地将 HTTP 方法转换为有序的数字列表，例如 GET = 1、POST = 2 等，我们可能会令异常检测算法误以为 POST 比 GET 大，或 GET + GET 等于 POST。预处理这些字段的更好方法是&lt;a href="https://en.wikipedia.org/wiki/One-hot"&gt;独热编码（one-hot encoding）&lt;/a&gt;。这种方法是将单个文本字段转换为多个二进制字段，每个二进制字段代表原始文本字段的一种可能值。在我们的例子中，这种独热编码的结果是一组共九个二进制字段。如果原始日志中字段的值为 HEAD，则只有预处理数据中的 HEAD 字段的值为 1，而所有其他字段均为零。下表显示了一些示例。&lt;/p&gt; 
&lt;table border="1" width="100%"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="120"&gt;原始日志消息&lt;/td&gt; 
   &lt;td colspan="9" width="428"&gt;预处理成多个独热编码字段&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="120"&gt;&lt;strong&gt;HTTP 请求方法&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="5"&gt;&lt;strong&gt;GET&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="41"&gt;&lt;strong&gt;HEAD&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="41"&gt;&lt;strong&gt;POST&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="33"&gt;&lt;strong&gt;PUT&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="54"&gt;&lt;strong&gt;DELETE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="68"&gt;&lt;strong&gt;CONNECT&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="68"&gt;&lt;strong&gt;OPTIONS&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="50"&gt;&lt;strong&gt;TRACE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="50"&gt;&lt;strong&gt;PATCH&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="120"&gt;&lt;strong&gt;GET&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="5"&gt;1&lt;/td&gt; 
   &lt;td width="41"&gt;0&lt;/td&gt; 
   &lt;td width="41"&gt;0&lt;/td&gt; 
   &lt;td width="33"&gt;0&lt;/td&gt; 
   &lt;td width="54"&gt;0&lt;/td&gt; 
   &lt;td width="68"&gt;0&lt;/td&gt; 
   &lt;td width="68"&gt;0&lt;/td&gt; 
   &lt;td width="50"&gt;0&lt;/td&gt; 
   &lt;td width="50"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="120"&gt;&lt;strong&gt;POST&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="5"&gt;0&lt;/td&gt; 
   &lt;td width="41"&gt;0&lt;/td&gt; 
   &lt;td width="41"&gt;1&lt;/td&gt; 
   &lt;td width="33"&gt;0&lt;/td&gt; 
   &lt;td width="54"&gt;0&lt;/td&gt; 
   &lt;td width="68"&gt;0&lt;/td&gt; 
   &lt;td width="68"&gt;0&lt;/td&gt; 
   &lt;td width="50"&gt;0&lt;/td&gt; 
   &lt;td width="50"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="120"&gt;&lt;strong&gt;OPTIONS&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="5"&gt;0&lt;/td&gt; 
   &lt;td width="41"&gt;0&lt;/td&gt; 
   &lt;td width="41"&gt;0&lt;/td&gt; 
   &lt;td width="33"&gt;0&lt;/td&gt; 
   &lt;td width="54"&gt;0&lt;/td&gt; 
   &lt;td width="68"&gt;0&lt;/td&gt; 
   &lt;td width="68"&gt;1&lt;/td&gt; 
   &lt;td width="50"&gt;0&lt;/td&gt; 
   &lt;td width="50"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;然后，Amazon ES 异常检测功能可以处理这些生成的字段数据，以便在应用程序接收的 HTTP 请求模式发生变化时检测到异常情况，例如，数量异常高的 DELETE 请求。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;大量定类型&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;许多日志文件包含 HTTP 响应代码、错误代码或某些其他类型的数字代码。这些代码没有任何特定的顺序，但可能取值的数量相当大。在这种情况下，单独使用独热编码不合适，因为它可能导致预处理数据中的字段数量爆炸。&lt;/p&gt; 
&lt;p&gt;以 HTTP 响应代码为例。这些值是无序的，这意味着并没有特别的理由将 200 设为 OK，400 设为错误请求。就 HTTP 响应代码而言，200 + 200 != 400。但是，字段可能的取值数量相当多 — 超过 60 个。如果我们使用独热编码技术，我们最终会在这 1 个字段中创建 60 多个字段，这会让数据迅速变得无法管理。&lt;/p&gt; 
&lt;p&gt;然而，根据对 HTTP 状态代码的了解，我们知道这些代码从定义上可以分为五个范围。范围为 100–199 的代码是信息性响应，代码 200–299 表示成功完成请求，300–399 是重定向，400–499 是客户端错误，500–599 是服务器错误。我们可以利用这些知识，将原始值减少到五个值，每个范围一个值（1xx、2xx、3xx、4xx 和 5xx）。现在，这一组五个可能值更容易处理。这些值纯粹是名义的。因此，我们还可以按照上一节所述对这些值进行独热编码。在进行这样的归类和独热编码过程之后的结果类似下表。&lt;/p&gt; 
&lt;table border="1" width="1247"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;原始日志消息&lt;/td&gt; 
   &lt;td colspan="5" width="355"&gt;在归类和独热编码后预处理成多个字段&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;HTTP 响应状态代码&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;&lt;strong&gt;1xx&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;&lt;strong&gt;2xx&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;&lt;strong&gt;3xx&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;&lt;strong&gt;4xx&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;&lt;strong&gt;5xx&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;100（继续）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;101（切换协议）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;200（OK）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;202（已接受）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;301（永久移动）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;304（未修改）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;400（错误请求）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;401（未经授权）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;404（未找到）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;500（内部服务器错误）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;502（错误网关）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="245"&gt;&lt;strong&gt;503（服务不可用）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;0&lt;/td&gt; 
   &lt;td width="71"&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;此预处理的数据现在适用于异常检测。4xx 错误数量的上升或 2xx 响应数量的下降可能对检测特别重要。&lt;/p&gt; 
&lt;p&gt;以下 Python 代码片段显示了如何对 HTTP 响应状态代码进行归类和独热编码：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-python"&gt;def http_status_bin_one_hot_encoding(http_status):
    # returns one hot encoding based on http response status bin
    # bins are: 1xx, 2xx, 3xx, 4xx, 5xx
    if 100 &amp;lt;= http_status &amp;lt;= 199: # informational responses
        return (1, 0, 0, 0, 0)
    elif 200 &amp;lt;= http_status &amp;lt; 299: # successful responses
        return (0, 1, 0, 0, 0)
    elif 300 &amp;lt;= http_status &amp;lt; 399: # redirects
        return (0, 0, 1, 0, 0)
    elif 400 &amp;lt;= http_status &amp;lt; 499: # client errors
        return (0, 0, 0, 1, 0)
    elif 500 &amp;lt;= http_status &amp;lt; 599: # server errors
        return (0, 0, 0, 0, 1)

http_1xx, http_2xx, http_3xx, http_4xx, http_5xx = http_status_bin_one_hot_encoding(status)

log_entry = {
    'timestamp': timestamp,
    'bucket': &amp;quot;somebucket&amp;quot;,
    'key': &amp;quot;somekey&amp;quot;,
    'operation': &amp;quot;REST.GET.VERSIONING&amp;quot;,
    'request_uri': &amp;quot;GET /awsexamplebucket1?versioning HTTP/1.1&amp;quot;,
    'status_code': status,
    'http_1xx': http_1xx,
    'http_2xx': http_2xx,
    'http_3xx': http_3xx,
    'http_4xx': http_4xx,
    'http_5xx': http_5xx,
    'error_code': &amp;quot;-&amp;quot;,
    'bytes_sent': 113,
    'object_size': 0
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;定序型（&lt;/strong&gt;&lt;strong&gt;ordinal）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;日志文件中的某些文本字段包含具有相对顺序的值。例如，日志级别字段可能包含 TRACE、DEBUG、INFO、WARN、ERROR 和 FATAL 等值。这也是日志消息严重性递增的顺序。如下表所示，这些字符串值可以保留此相对顺序转换为数值。&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;日志级别（原始日志消息）&lt;/td&gt; 
   &lt;td&gt;预处理的日志级别&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TRACE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;DEBUG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;INFO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;WARN&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ERROR&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FATAL&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;6&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;IP 地址&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;日志文件通常具有可以包含大量值的 IP 地址，使用上一段中描述的方法将这些值分类到一起是没有意义的。但是，从地理位置的角度来看这些 IP 地址可能是有意义的。如果应用程序开始从不寻常的地理位置访问，这对检测异常情况可能非常重要。如果日志中没有直接提供国家/地区或城市代码等地理信息，则可以通过使用第三方服务对 IP 地址进行地理定位来获取此信息。实际上，这是将大量 IP 地址分类为少得多的国家/地区或城市代码的过程。尽管这些国家/地区和城市代码仍然是定类型数值，但它们可以与 Amazon ES 的基数（cardinality）汇总一起使用。&lt;/p&gt; 
&lt;p&gt;在将这些预处理技术应用于示例 Amazon S3 服务器访问日志之后，我们将获得处理完成的 JSON 日志数据：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-json"&gt;{
    &amp;quot;bucket_owner&amp;quot;: &amp;quot;&amp;quot;, //string
    &amp;quot;bucket&amp;quot;: &amp;quot;awsexamplebucket1&amp;quot;, //string
    &amp;quot;timestamp&amp;quot;: &amp;quot;06/Feb/2019:00:00:38 +0000&amp;quot;,
    &amp;quot;remote_ip&amp;quot;: &amp;quot;192.0.2.3&amp;quot;, //string
    &amp;quot;country_code&amp;quot;: 100, //numeric field generated during pre-processing
    &amp;quot;requester&amp;quot;: &amp;quot;&amp;quot;, //string
    &amp;quot;request_id&amp;quot;: &amp;quot;3E57427F3EXAMPLE&amp;quot;,
    &amp;quot;operation&amp;quot;: &amp;quot;REST.GET.VERSIONING&amp;quot;,
    &amp;quot;key&amp;quot;: &amp;quot;-&amp;quot;,
    &amp;quot;request_uri&amp;quot;: &amp;quot;GET /awsexamplebucket1?versioning HTTP/1.1&amp;quot;,
    &amp;quot;http_method_get&amp;quot;: 1, //nine one-hot encoded fields generated during pre-processing
    &amp;quot;http_method_post&amp;quot;: 0,
    &amp;quot;http_method_put&amp;quot;: 0,
    &amp;quot;http_method_delete&amp;quot;: 0,
    &amp;quot;http_method_head&amp;quot;: 0,
    &amp;quot;http_method_connect&amp;quot;: 0,
    &amp;quot;http_method_options&amp;quot;: 0,
    &amp;quot;http_method_trace&amp;quot;: 0,
    &amp;quot;http_method_patch&amp;quot;: 0,
    &amp;quot;http_status&amp;quot;: 200,
    &amp;quot;http_1xx&amp;quot;: 0, //five one-hot encoded fields generated during pre-processing
    &amp;quot;http_2xx&amp;quot;: 1,
    &amp;quot;http_3xx&amp;quot;: 0,
    &amp;quot;http_4xx&amp;quot;: 0,
    &amp;quot;http_5xx&amp;quot;: 0,
    &amp;quot;error_code&amp;quot;: &amp;quot;-&amp;quot;,
    &amp;quot;bytes_sent&amp;quot;: 113,
    &amp;quot;object_size&amp;quot;: &amp;quot;-&amp;quot;,
    &amp;quot;total_time&amp;quot;: 7,
    &amp;quot;turn_around_time&amp;quot;: &amp;quot;-&amp;quot;,
    &amp;quot;referer&amp;quot;: &amp;quot;-&amp;quot;,
    &amp;quot;user_agent&amp;quot;: &amp;quot;S3Console/0.4&amp;quot;,
    &amp;quot;version_id&amp;quot;: &amp;quot;-&amp;quot;,
    &amp;quot;host_id&amp;quot;: &amp;quot;&amp;quot;, //string
    &amp;quot;signature_version&amp;quot;: &amp;quot;SigV2&amp;quot;,
    &amp;quot;cipher_suite&amp;quot;: &amp;quot;ECDHE-RSA-AES128-GCM-SHA256&amp;quot;,
    &amp;quot;authentication_type&amp;quot;: &amp;quot;AuthHeader&amp;quot;,
    &amp;quot;host_header&amp;quot;: &amp;quot;awsexamplebucket1.s3.us-west-1.amazonaws.com&amp;quot;,
    &amp;quot;tls_version&amp;quot;: &amp;quot;TLSV1.1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这些数据现在可以被提取并索引到 Amazon ES 域中。设置日志预处理管道后，下一个要配置的是&lt;a href="https://opendistro.github.io/for-elasticsearch-docs/docs/ad/#step-1-create-a-detector"&gt;异常检测器&lt;/a&gt;。Amazon ES 异常检测允许您在单个异常检测器中指定最多五个&lt;a href="https://opendistro.github.io/for-elasticsearch-docs/docs/ad/#step-2-add-features-to-your-detector"&gt;特征&lt;/a&gt;（数据中的字段）。这意味着异常检测器可以根据最多五个字段的值来学习数据中的模式。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;聚合&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;需要为每个特征指定适当的聚合函数。这是因为异常检测器汇总了每个检测器间隔内提取的所有文档的值以产生单个聚合值，然后该值用作自动学习数据模式的算法的输入。下图描述了此过程。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/preprocess-logs-for-anomaly-detection-in-amazon-es-2-2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/preprocess-logs-for-anomaly-detection-in-amazon-es-2-2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;配置正确的特征和相应的聚合函数后，异常检测器开始初始化。在处理足够大量的数据后，检测器进入运行状态。&lt;/p&gt; 
&lt;p&gt;为了帮助您开始对自己的日志进行异常检测，下表显示了可能对某些常见日志字段有意义的预处理技术和聚合函数。&lt;/p&gt; 
&lt;table border="1" width="1247"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;日志字段名称&lt;/td&gt; 
   &lt;td&gt;预处理&lt;/td&gt; 
   &lt;td&gt;聚合&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;HTTP 响应状态代码&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;独热编码&lt;/td&gt; 
   &lt;td&gt;总和&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;客户端&lt;/strong&gt;&lt;strong&gt; IP 地址&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;将 IP 地理位置对应到国家/地区或城市代码&lt;/td&gt; 
   &lt;td&gt;基数&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;日志消息级别（&lt;/strong&gt;&lt;strong&gt;INFO、WARN、ERR、FATAL 等）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;独热编码&lt;/td&gt; 
   &lt;td&gt;总和&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;错误或异常名称&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;如果有大量可能的值，则映射到数字代码、额外的分类和独热编码&lt;/td&gt; 
   &lt;td&gt;如果使用单个数字代码字段则用基数；如果使用独热编码则用总和&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;对象大小&lt;/strong&gt;&lt;strong&gt;/发送的字节/内容长度&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;无，使用数值本身&lt;/td&gt; 
   &lt;td&gt;最小、最大、平均&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;要监控一般流量水平，您可以使用任何数值字段（如响应代码或发送的字节数）来计算每个检测器间隔的日志条目数&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;无，使用数值本身&lt;/td&gt; 
   &lt;td&gt;count (value_count) — 只需计算在此字段中具有值的文档数&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;IT 团队可以使用 Amazon ES 的异常检测功能对应用程序和基础设施日志实施主动监控和警报。只需要基本脚本或编程技能就能够实现本文中讨论的日志预处理技术 — 无需对机器学习或数据科学有深入的了解。异常检测功能在运行 Elasticsearch 7.4 版或更高版本的 Amazon ES 域中可用。要开始使用，请参阅&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/ad.html"&gt;Amazon Elasticsearch Service 中的异常检测&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/kapilpen.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Kapil Pendse&lt;/h3&gt; 
  &lt;p&gt;Amazon Web Services（新加坡）的高级解决方案构架师，拥有超过 15 年的跨多个领域构建技术解决方案的经验，例如云计算、嵌入式系统和机器学习。在空闲时间，Kapil 喜欢沿着新加坡的沿海公园骑行，偶尔享受水獭的陪伴。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>基于AI技术的智能剪辑方案</title>
		<link>https://aws.amazon.com/cn/blogs/china/intelligent-editing-scheme-based-on-ai-technology/</link>
				<pubDate>Sun, 29 Aug 2021 14:21:08 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[Amazon DynamoDB]]></category>
		<category><![CDATA[Amazon Rekognition]]></category>
		<category><![CDATA[AWS Elemental MediaConvert]]></category>
		<category><![CDATA[AWS Lambda]]></category>
		<category><![CDATA[Media]]></category>

		<guid isPermaLink="false">ca4099e29b5c7c4211ff510b7c39fc6a512c0dee</guid>
				<description>本文描述了一种基于 AI 技术，针对人脸信息对视频文件进行智能剪辑的方案。</description>
								<content:encoded>&lt;p&gt;伴随着技术的发展，每天都有海量视频资料产生，但人们往往并不需要视频中的每一个片段。也许您只是想看到自己孩子出现的镜头，或者只关注自己喜欢的明星出演的节目，还可能需要用一些特定人员出现的镜头以制作新的视频。本文将介绍一种基于 AI 技术完成视频智能剪辑的方法。&lt;/p&gt; 
&lt;p&gt;通过这种方法，您可以从已有视频中快速剪辑出仅包含目标人物的内容。通过 AWS 所提供的托管服务，您无需了解复杂的人脸识别技术或视频编解码技术，甚至无需部署任何服务器资源。您只需要将精力集中在功能实现上。&lt;/p&gt; 
&lt;p&gt;本方案主要依赖两个核心功能。一，识别视频中的目标人物；二，针对目标任务进行剪辑。前者依赖于人脸识别技术（例如：Amazon Rekognition），后者则属于媒体行业中的视频合成技术（例如：AWS Elemental MediaConvert）。&lt;/p&gt; 
&lt;p&gt;此外，您需要预先了解 Amazon S3、Amazon DynamoDB、AWS Lambda、Amazon SNS、Amazon API Gateway 服务的基础功能。对这些服务的介绍不在本文范围内，您可以通过官方网站了解它们相关的进一步信息。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;关于人脸识别：&lt;/h2&gt; 
&lt;p&gt;Amazon Rekognition（下文简称 Rekognition）是 Amazon Web Services 提供的使用机器学习自动执行图像和视频分析的托管服务。Rekognition 提供高度精确的面孔分析和面孔搜索功能，我们将利用这个功能检测、分析并搜索视频中出现的特定面孔。&lt;/p&gt; 
&lt;h3&gt;面孔检测和分析&lt;/h3&gt; 
&lt;p&gt;为了实现特定人员的搜索，首先需要告诉 Rekognition 我们要搜索目标人脸特征是什么。这里我们无需了解诸如卷机神经网络、训练样本、迭代次数之类的技术细节，Rekognition 可以检测图像和视频中的人脸，自动提取并存储这些人脸的特征。所以我们需要做的只是向 Rekognition 提供一组目标人群的人脸照片即可。&lt;/p&gt; 
&lt;p&gt;首先，通过调用 create_collection API 在 Rekognition 中创建一个被称为“集合（以下称作：collection）“的对象，在 collection 中将会存储检测到的人脸特征。collection 只是一个逻辑上的容器，本身并不包含任何的人脸特征信息。所以接下来需要向 collection 中添加这些信息。&lt;/p&gt; 
&lt;p&gt;添加的过程需要调用 index_faces API，并提供一张保存在 Amazon S3 存储桶上的人脸照片，以及对应的 collection id。Rekognition 会完成人脸特征提取、信息保存的过程。在 collection 中不会保存完整的图片，只是保存人脸特征信息，例如：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-powershell"&gt;{
    &amp;quot;FaceModelVersion&amp;quot;: &amp;quot;5.0&amp;quot;,
    &amp;quot;Faces&amp;quot;: [
        {
            &amp;quot;BoundingBox&amp;quot;: {
                &amp;quot;Width&amp;quot;: 0.5216310024261475,
                &amp;quot;Top&amp;quot;: 0.3256250023841858,
                &amp;quot;Left&amp;quot;: 0.13394300639629364,
                &amp;quot;Height&amp;quot;: 0.3918749988079071
            },
            &amp;quot;FaceId&amp;quot;: &amp;quot;0040279c-0178-436e-b70a-e61b074e96b0&amp;quot;,
            &amp;quot;ExternalImageId&amp;quot;: &amp;quot;image1.jpg&amp;quot;,
            &amp;quot;Confidence&amp;quot;: 100.0,
            &amp;quot;ImageId&amp;quot;: &amp;quot;f976e487-3719-5e2d-be8b-ea2724c26991&amp;quot;
        }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;默认参数下，Rekognition 只提取这些人脸特征：BoundingBox、Confidence、Pose、Quality、和&amp;nbsp;Landmarks，对于本文中的应用场景已经足够。如果您还需要人脸的年龄、表情、眼睛状态、情绪等更细节的属性，可以在调用 index_faces API 时增加 DetectionAttributes=ALL 的参数设置。这可以满足更广泛的应用场景需求，当然所需要花费的处理时间也会更长。&lt;/p&gt; 
&lt;p&gt;在保存的参数中，ExternalImageId 是为当前人脸起一个便于记忆的名字。本文介绍的方法将会利用 ExternalImageId 作为在视频中搜索目标人物时使用到的标签名。每次调用 index_faces 时会向 colletion 中添加 1 张人脸信息。如果希望一次性添加多张人脸，需要自行编写代码实现多次调用。&lt;/p&gt; 
&lt;h3&gt;面孔搜索&lt;/h3&gt; 
&lt;p&gt;当建立好 collection 并向其中添加了 IndexFaces 后，就可以利用 collection 对视频进行检索。Rekognition Video 提供 start_face_search API 针对视频文件进行人脸信息检索。调用 API 时需提供视频文件存储的位置（视频需存储在 Amazon S3 存储桶中），以及所使用的 collectionId（即：需要针对哪一个人脸进行检索）。&lt;/p&gt; 
&lt;p&gt;注意，start_face_search API将搜索视频文件中所有的人脸信息。如果搜索到的人脸信息包含在 collection 中，返回结果将包含该人脸的 ExternalImageId。这是一个异步的人脸检测操作，处理时间与 collection 中包含的信息数量以及待处理的视频长度相关。API 调用成功后仅返回生成的 jobId。在调用 API 进行处理时，可以指定 Amazon SNS Topic。这样，当 Rekognition Video 完成视频检索后将会自动向 SNS Topic 发送消息进行提示。&lt;/p&gt; 
&lt;p&gt;当检索完成后，可以调用 get_face_search API 查看特定 jobId 的检索结果。返回结果示意如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-powershell"&gt;{
    &amp;quot;JobStatus&amp;quot;: &amp;quot;SUCCEEDED&amp;quot;,
    &amp;quot;NextToken&amp;quot;: &amp;quot;cbV9RaFdm…&amp;quot;,
    &amp;quot;VideoMetadata&amp;quot;: {
        &amp;quot;Codec&amp;quot;: &amp;quot;h264&amp;quot;,
        &amp;quot;DurationMillis&amp;quot;: 1800000,
        &amp;quot;Format&amp;quot;: &amp;quot;QuickTime / MOV&amp;quot;,
        &amp;quot;FrameRate&amp;quot;: 25.0,
        &amp;quot;FrameHeight&amp;quot;: 480,
        &amp;quot;FrameWidth&amp;quot;: 856
    },
    &amp;quot;Persons&amp;quot;: [
        {
            &amp;quot;Timestamp&amp;quot;: 4480,
            &amp;quot;Person&amp;quot;: {…},
	&amp;quot;FaceMatches&amp;quot;: [
                {
                    &amp;quot;Similarity&amp;quot;: 99.99900817871094,
                    &amp;quot;Face&amp;quot;: {…},
                        &amp;quot;ImageId&amp;quot;: &amp;quot;15681d6b-&amp;quot;,
                        &amp;quot;ExternalImageId&amp;quot;: &amp;quot;xxxxxx&amp;quot;,
                        &amp;quot;Confidence&amp;quot;: 99.99849700927734
                    }
                }
            ]
        },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;返回结果中包含如下主要信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;视频的元数据信息（视频时长、帧率等）；&lt;/li&gt; 
 &lt;li&gt;人脸出现的时间戳（以毫秒为单位）；&lt;/li&gt; 
 &lt;li&gt;人脸匹配信息（ExternalImageId，Confidence等）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在单次调用 get_face_search API 时，最多只返回 1000 条信息，这显然无法满足长视频的识别需要。因此对于超过 1000 条信息的检索，get_face_search API 在返回结果中会包含 NextToken字段，这是一个指向后 1000 条检索信息的 hash 指针。通过在循环调用 get_face_search API 中逐条包含 NextToken 字段可顺序获得全部检索结果。&lt;/p&gt; 
&lt;p&gt;本文中所涉及到的场景将会利用检索结果中的如下信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;视频文件的帧率；&lt;/li&gt; 
 &lt;li&gt;人脸出现的时间戳；&lt;/li&gt; 
 &lt;li&gt;人脸的 ExternalImageId。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;关于视频合成：&lt;/h2&gt; 
&lt;p&gt;现在我们已经获得了视频文件中所有人脸出现时的时间码信息，接下来的工作将是基于这些信息进行新的视频合成。这将用到 Amazon Elemental MediaConvert（下文简称 MediaConvert）服务。MediaConvert 是一款具有广播级功能的基于文件的视频转码服务。借助该服务，您能够轻松创建视频点播 (VOD) 内容，实现大规模的广播和多屏幕传输。&lt;/p&gt; 
&lt;p&gt;在这里我们将使用 MediaConvert 所提供的视频合成功能。我们只需要在创建 MediaConvert 任务时指定好每段视频的起、止时间帧，MediaConvert 将按顺序将所有时间段串行合并为一个新的视频。&lt;/p&gt; 
&lt;p&gt;Rekognition Video 返回的结果中已经包含了 ExternalImageId，基于这个标记我们直接可以选择要检索出来的人员在哪些时间点出现。然而仍然有两个细节工作需要注意。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Rekognition Video 返回的结果以毫秒为单位，而 MediaConvert 在视频处理时以帧（HH:MM:SS:FF）为单位。这就需要根据视频原始帧率，在“毫秒”与“帧”之间进行转换。&lt;/li&gt; 
 &lt;li&gt;Rekognition Video 返回的是所有时间点，而不是某个人在视频中出现的时间段。从“时间点”到“时间段”的转换需要使用者通过代码自行时间。例如：当返回结果中两个相邻的 Timestamp 之间间隔大于 1 秒时，我们就可以认为这是两段不同的时间段，如果小于 1 秒则是一段连续时间段中的不同时间点。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;完成好时间段和视频帧的转换后，可以通过调用 MediaConvert 的 create_job API 创建视频合成任务。&lt;/p&gt; 
&lt;p&gt;如前文所提到的，MediaConvert 是一款广播级功能的视频转码服务，可设置的参数、可实现的功能非常丰富。下图展示了 MediaConvert 在输出选项组中可设置的部分参数：&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 输出参数设置（部分截图）&lt;/p&gt; 
&lt;p&gt;所有参数均和可以在调用 create_job API 时进行设置，或通过指定 JSON 文件的方式传入。对于 job 所需要的 JSON 文件，使用者不必从零开始编写，只需要在控制台界面中根据自己的需要设置好各项参数，然后选择控制台界面中的“显示作业JSON”选项，将自动生成的内容复制出来生成新的 JSON 文件即可。&lt;/p&gt; 
&lt;p&gt;为实现本文所涉及的场景，只需要设置基本的输入（待处理视频位置）、输出（处理后视频位置、视频片段起止时间、输出视频名称）参数即可。需要注意的是，在输出选项中“速率控制模式”参数是必填项，支持可变比特率（VBR）、恒定比特率（CBR）以及质量定义的可变比特率（QVBR）三种模式。推荐使用 QVBR 方式，不同分辨率下 QVBR 的推荐参数值可以参考 &lt;a href="https://docs.aws.amazon.com/mediaconvert/latest/ug/cbr-vbr-qvbr.html#qvbr-guidelines"&gt;官方文档&lt;/a&gt; 中的介绍。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;整体设计架构：&lt;/h2&gt; 
&lt;p&gt;为了进一步提升整体方案的自动化程度，以及对中间数据持久化，本方案中还使用到了 Amazon DynamoDB、AWS Lambda、Amazon SNS、Amazon API Gateway 服务。方案的整体架构如下图所示：&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;方案架构图&lt;/p&gt; 
&lt;p&gt;方案中使用了如下服务：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/rekognition/"&gt;Amazon Rekognition&lt;/a&gt;：图像和视频分析服务；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/mediaconvert/"&gt;Amazon Elemental MediaConvert&lt;/a&gt;：具有广播级功能的基于文件的视频转码服务；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/api-gateway/"&gt;Amazon API Gateway&lt;/a&gt;：一种完全托管的服务，可以帮助开发人员轻松创建、发布、维护、监控和保护任意规模的 API；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/lambda/"&gt;Amazon Lambda&lt;/a&gt;：一种无服务器的计算服务，让您无需预置或管理服务器、创建可感知工作负载的集群扩展逻辑、维护事件集成或管理运行时，即可运行代码；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/dynamodb/"&gt;Amazon DynamoDB&lt;/a&gt;：是一个键/值和文档数据库，可以在任何规模的环境中提供个位数的毫秒级性能；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/s3/"&gt;Amazon S3&lt;/a&gt;：对象存储服务，提供行业领先的可扩展性、数据可用性、安全性和性能；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/cloudfront/"&gt;Amazon CloudFront&lt;/a&gt;：快速内容分发网络 (CDN) 服务，可以安全地以低延迟和高传输速度向全球客户分发数据、视频、应用程序和 API；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/sns/"&gt;Amazon SNS&lt;/a&gt;：一项用于应用与应用之间 (A2A) 以及应用与人之间 (A2P) 通信的完全托管型消息收发服务。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;方案通过 Amazon API Gateway 对外暴露 3 个 REST API：collection-create、faces-search、video-clip。&lt;/p&gt; 
&lt;p&gt;3 个 API 分别对应后端的 3 个 Amazon Lambda 函数。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Collection：创建 collection，并从指定的 S3 目录中读取照片，将照片中的人脸信息逐一添加到 collection，以照片的文件名作为人脸信息的 ExternalImageId。需调用 Rekognition 服务的 create_collection 和 index_faces API。&lt;/li&gt; 
 &lt;li&gt;Faces Search：根据指定的 collectionid，对保存在 S3 存储桶中的视频文件进行人脸检索。需调用 Rekognition 服务的 start_face_search API。&lt;/li&gt; 
 &lt;li&gt;Media Clipping：创建 MediaConvert Job，按照指定的 ExternalImageId 合成剪辑后的视频。需调用 MediaConvert 服务的 create_job API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如之前所描述的，在调用 start_face_search API 时处理时间较长，一方面需要注意将 Lambda 函数的处理时间适当增加（例如：1分钟），另一方面需要进行自动化的设置以便触发下一步的 Lambda 函数。在自动化设置方面，start_face_search API 支持设置 SNS topic，当作业完成后直接发送消息给对应的 SNS topic，通过这个 topic 触发下一步的操作。以 python 为例，调用 start_face_search API 注意进行如下设置：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-powershell"&gt;reko_client.start_face_search(
        Video={
            'S3Object': {
                'Bucket': BUCKET,
                'Name': OBJECT
            }
        },
        CollectionId=collectionId,
        NotificationChannel={
            'SNSTopicArn': snsTopic,
            'RoleArn': roleARN
        }
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;Lambda 函数 Result Save 被 SNS topic 触发，根据 NextToken 循环调用 Rekognition 的 get_face_search API 获取完整的 face_search 结果，并生成 JSON 文件保存到 S3 存储桶。&lt;/p&gt; 
&lt;p&gt;上述过程中所生成的 collectionid、jobid 等中间信息均保存在 DynamoDB Table 中。在方案架构图中显示有两个 DynamoDB Table，一个用于保存 collection 信息，另一个用于保存 face_search 的结果信息。您也可以根据自己的需要进行设置。&lt;/p&gt; 
&lt;p&gt;最后，剪辑好的视频会保存在 S3 存储桶中。为了进一步降低方案的整体成本，剪辑好的视频会通过 cloudfront 进行下载（这将降低在云上产生的流量成本）。在向 S3 存储桶中保存视频时会产生一个事件，这个事件会触发负责通知的 Lambda 函数，生成下载视频时所需要用到的 cloudfront 链接，并向 SNS topic 发送消息，通过 SNS 向订阅者发送 email 进行通知。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结：&lt;/h2&gt; 
&lt;p&gt;本文描述了一种基于 AI 技术，针对人脸信息对视频文件进行智能剪辑的方案。在使用该方案时，您可以：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;无需部署服务器资源，整个方案使用 Amazon Web Services 托管服务；&lt;/li&gt; 
 &lt;li&gt;利用 AI 技术，自动识别目标任务；&lt;/li&gt; 
 &lt;li&gt;无需准备海量训练样本，无需掌握复杂的机器学习技能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如您希望了解该方案原型的部署细节，可以从&lt;a href="https://github.com/weiping-bj/Smart-Cutting-using-AWS"&gt;这里&lt;/a&gt;获得方案源代码及架构详细说明。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/lweiping.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;刘伟平&lt;/h3&gt; 
  &lt;p&gt;AWS APN 合作伙伴解决方案架构师，主要负责 AWS (中国)合作伙伴的技术支持工作，同时致力于 AWS 云服务在国内的应用及推广。加入 AWS 前，在 HP（HPE）服务超过7年，历任存储售前工程师、电信行业售前工程师、NFV 解决方案架构师，熟悉传统企业 IT 架构、私有云及混合云部署。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用 AWS Backup Audit Manager 监控、评估和证明备份合规性</title>
		<link>https://aws.amazon.com/cn/blogs/china/monitor-evaluate-and-demonstrate-backup-compliance-with-aws-backup-audit-manager/</link>
				<pubDate>Fri, 27 Aug 2021 06:46:01 +0000</pubDate>
		<dc:creator><![CDATA[Steve Roberts]]></dc:creator>
				<category><![CDATA[Security, Identity, & Compliance]]></category>

		<guid isPermaLink="false">706a282d09cd87aa5e8c3dbb3bc555d58a002413</guid>
				<description>今天，我很高兴地宣布推出 AWS Backup Audit Manager，它是 AWS Backup 的一项新功能，可帮助您监控和评估备份的合规性状态，以满足业务和法规要求，并使您能够生成有助于向审计员和监管机构证明合规性的报告。</description>
								<content:encoded>&lt;p&gt;今天，我很高兴地宣布推出 &lt;strong&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager&lt;/strong&gt;，它是 &lt;strong&gt;&lt;a title="" href="https://aws.amazon.com/backup/"&gt;AWS Backup&lt;/a&gt;&lt;/strong&gt; 的一项新功能，可帮助您监控和评估备份的合规性状态，以满足业务和法规要求，并使您能够生成有助于向审计员和监管机构证明合规性的报告。&lt;/p&gt; 
&lt;p&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt; 是一项完全托管式服务，可启动策略驱动的 &lt;span title=""&gt;AWS&lt;/span&gt; 应用程序备份和恢复，能够简化大规模保护数据的流程，而无需自定义脚本和手动流程。但是，客户仍需使用自己的工具来验证备份策略是否得到执行，而且为了向审计员证明合规性，还需要解析备份记录，将其转换为可审计的报告。&lt;/p&gt; 
&lt;p&gt;现在，您可以通过 &lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 持续自动地跟踪备份活动，例如备份计划或备份保管库的变更，并自动生成每日报告。&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 内置了可自定义的合规性控件。简而言之，控件是具有备份策略参数（例如备份频率或保留期）的过程，这些参数与您的业务合规性和法规要求保持一致。&lt;/p&gt; 
&lt;p&gt;您可以创建一个框架，以账户和区域为范围，然后向其添加所需的控件。根据控件跟踪备份活动，自动检测违反定义的数据保护策略的情况，使您能够快速采取纠正措施。为跟踪备份活动，&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 要求您通过 &lt;a title="" href="https://aws.amazon.com/config/"&gt;AWS Config&lt;/a&gt; 监控备份计划（&lt;code&gt;AWS። Backup። BackupPlan&lt;/code&gt; 资料类型）、备份选择（&lt;code&gt;AWS። Backup። BackupSelection&lt;/code&gt;）、保管库（&lt;code&gt;AWS። Backup። BackupVault&lt;/code&gt;）、恢复点（&lt;code&gt;AWS። Backup። RecoveryPoint&lt;/code&gt;）和&lt;span title=""&gt; AWS Config&lt;/span&gt; 资源合规性（&lt;code&gt;AWS::Config::ResourceCompliance&lt;/code&gt;）。您可以使用&lt;strong&gt;框架&lt;/strong&gt;页面的&lt;strong&gt;资源跟踪&lt;/strong&gt;部分，在 &lt;a title="" href="https://aws.amazon.com/backup/"&gt;AWS Backup&lt;/a&gt; 控制台中查看这些资源的记录状态。&lt;/p&gt; 
&lt;p&gt;将所需的控件添加到框架后，就可以进行部署。如果要满足不同的内部或监管标准，可以创建和部署其他控件框架。部署框架后，您可以设置自动生成备份活动的每日报告。这些信息将显示在控制面板中，您需要时可随时请求报告。您还可以将结果导入 &lt;a title="AWS Audit Manager" href="https://aws.amazon.com/audit-manager/"&gt; 中&lt;/a&gt;，这是我于 &lt;a title="" href="https://reinvent.awsevents.com/"&gt;AWS re:Invent&lt;/a&gt; 2020 大会期间&lt;a href="https://aws.amazon.com/blogs/aws/aws-audit-manager-simplifies-audit-preparation/" target="_blank" rel="noopener noreferrer"&gt;在此新闻博客文章&lt;/a&gt;中介绍过的一项服务。&lt;/p&gt; 
&lt;p&gt;此短视频简要概述了新的&lt;span title=""&gt; AWS Backup&lt;/span&gt; Audit Manager 功能。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;可用的控件和备份报告&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 提供了五种备份治理控件模板和备份活动报告，涵盖备份任务、复制任务和还原任务。这些报告提高了对单个账户和区域备份活动的可见性，帮助您监控运营状况并确定可能需要采取进一步行动的故障。&lt;/p&gt; 
&lt;p&gt;创建框架时，您需要提供名称、可选描述，然后选择是否使用提供的 &lt;span title=""&gt;AWS Backup&lt;/span&gt; 框架类型（包括五个预定义控件），也可以选择自定义框架。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-create-framework.png"&gt;&lt;img class="alignnone size-full wp-image-54157" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-create-framework.png" alt="创建 AWS Backup Audit Manager 框架" width="900" height="564" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;选择&lt;strong&gt;自定义框架&lt;/strong&gt;将展开面板，显示可用控件、它们的参数以及将它们纳入框架或从框架中排除的选项。五种可用控件的标题分别是：&lt;strong&gt;受备份计划保护的备份资源&lt;/strong&gt;、&lt;strong&gt;备份计划最低频率和最低保留期&lt;/strong&gt;、&lt;strong&gt;备份以防恢复点手动删除&lt;/strong&gt;、&lt;strong&gt;加密的备份恢复点&lt;/strong&gt;和&lt;strong&gt;备份恢复点最短保留期限&lt;/strong&gt;。在每个控件标题的右侧，您将找到一个&lt;strong&gt;信息&lt;/strong&gt;链接，描述了控件评估的内容、频率以及资源符合控件的含义。&lt;/p&gt; 
&lt;p&gt;让我们来看看几个控件。&lt;strong&gt;受备份计划保护的备份资源&lt;/strong&gt;控件使您可以选择所有受支持的资源，或者由标签、类型或特定资源识别的资源。此控件有助于识别备份覆盖范围中的缺口。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-resoures-control.png"&gt;&lt;img class="size-full wp-image-54158 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-resoures-control.png" alt="受备份计划保护的备份资源控制资源选择" width="755" height="562" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;备份计划最低频率和最低保留期&lt;/strong&gt;控件包含的参数决定了备份计划的备份频率以及恢复点的维持时间。原定设置要求每小时进行一次备份，恢复点应保留一个月，但您可以自定义设置，以满足业务合规性要求。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-frequency-control.png"&gt;&lt;img class="size-full wp-image-54159 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-frequency-control.png" alt="设置备份频率和保留期控件" width="768" height="421" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;完成关于其余控件的选择，纳入控件并根据需要设置适当的参数值，或者将它们从框架中排除，然后单击&lt;strong&gt;创建框架&lt;/strong&gt;来完成这个过程。将创建和部署新框架，这需要几分钟的时间。如果需要，您随时可以返回并编辑框架中的控件和参数。&lt;/p&gt; 
&lt;p&gt;部署后，框架中的控件将开始评估合规性，您可以通过选择框架在控制台中检查合规性状态。摘要部分根据您部署的控制定义，报告框架的总体合规性状态以及框架中合规或不合规控件的数量。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-compliance-summary.png"&gt;&lt;img class="size-full wp-image-54162 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-compliance-summary.png" alt="框架和控件合规性摘要" width="909" height="325" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;您可以在摘要下方找到一份列表，其中包含框架中每个控件的合规性详细信息，可以按状态筛选。每个控件都详细说明了它是否合规，以及控件所监控的不合规资源的数量。单击控件标题将直接转到&lt;span title=""&gt; AWS Config&lt;/span&gt; 控制面板，您可以查看有关控件标识的资源的更多详细信息。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-control-compliance.png"&gt;&lt;img class="alignnone size-full wp-image-54163" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-control-compliance.png" alt="控件合规性详情" width="910" height="612" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;自动生成的备份活动报告可用于向审计员和监管机构证明合规性。要设置报告，首先单击导航工具栏上的&lt;strong&gt;报告&lt;/strong&gt;条目，然后单击&lt;strong&gt;创建报告计划&lt;/strong&gt;。系统将要求您选择报告模板。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-template.png"&gt;&lt;img class="alignnone size-full wp-image-54169" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-template.png" alt="选择审计报告模板" width="884" height="543" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;选择模板（我选择了&lt;strong&gt;备份任务报告&lt;/strong&gt;）后，您可以填写名称和可选描述，选择要将报告传送到 &lt;a title="" href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt; 存储桶的哪个位置以及报告的文件格式，然后单击&lt;strong&gt;创建报告计划&lt;/strong&gt;。报告将每 24 小时更新一次，您随时可以按需运行报告。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-settings.png"&gt;&lt;img class="alignnone size-full wp-image-54171" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-settings.png" alt="编辑报告设置" width="861" height="1097" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;自动或按需运行报告后，要查看报告数据，可以在&lt;strong&gt;报告计划&lt;/strong&gt;列表中选择报告，然后单击&lt;strong&gt;查看报告&lt;/strong&gt;。 将直接转到选定的报告文件的&lt;span title=""&gt; S3&lt;/span&gt; 位置，您可以按所选的文件类型查看一个对象（报告）。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-list.png"&gt;&lt;img class="alignnone size-full wp-image-54172" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-list.png" alt="选择要查看的报告" width="901" height="466" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-files.png"&gt;&lt;img class="alignnone size-full wp-image-54173" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-files.png" alt="Amazon S3 中的报告文件" width="901" height="378" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下载文件会显示资源评估的时间段、备份任务详细信息、故障或完成状态、状态消息、资源类型和备份计划等。下面，我在电子表格中打开了 CSV 格式文件。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-csv.png"&gt;&lt;img class="alignnone size-full wp-image-54174" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-csv.png" alt="备份报告数据" width="899" height="180" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;与 Raven Launch 建立合作伙伴关系&lt;/span&gt;&lt;br /&gt; &lt;/strong&gt;通过此次发布，我们很高兴&lt;a href="https://aws.amazon.com/marketplace/pp/prodview-2yil74chd7ihg?ref_=srh_res_product_title" target="_blank" rel="noopener noreferrer"&gt; Open Raven&lt;/a&gt; 成为&lt;span title=""&gt; AWS Backup&lt;/span&gt; 的合作伙伴。Open Raven 是一个云原生数据安全平台，专为保护现代数据湖和仓库而构建。通过从查找所有数据位置到主动识别暴露的各种方法，该平台可解决组织在使用大量基于云的数据时通常会面临的各种问题。&lt;/p&gt; 
&lt;p&gt;Open Raven 首席技术官 Mark Curphey 谈到了新的&lt;span title=""&gt; AWS Backup&lt;/span&gt; 功能：“要成功地从勒索软件攻击中恢复，组织需要完成两项基础任务来提前规划，即确定关键数据和系统并根据组织要求对它们进行备份，使它们得到保护且能够恢复。&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 与 Open Raven 的结合简化了这项工作，消除了猜测和数小时的手动工作。”&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;立即开始使用&lt;span title=""&gt; AWS Backup&lt;/span&gt; Audit Manager&lt;/strong&gt;&lt;/span&gt;&lt;br /&gt; &lt;a title="" href="https://aws.amazon.com/backup/"&gt;AWS Backup&lt;/a&gt; Audit Manager 现已在美国东部（弗吉尼亚北部、俄亥俄州）、美国西部（加利福尼亚北部、俄勒冈）、加拿大（中部）、欧洲（法兰克福、爱尔兰、伦敦、巴黎、斯德哥尔摩）、南美洲（圣保罗）、亚太地区（香港、孟买、首尔、新加坡、 悉尼、东京) 和中东（巴林）地区推出。&lt;/p&gt; 
&lt;p&gt;有关 &lt;span title=""&gt;Backup&lt;/span&gt; Audit Manager 的更多信息，请参阅&lt;span title=""&gt; AWS Backup&lt;/span&gt;&lt;a href="https://docs.aws.amazon.com/aws-backup/latest/devguide/" target="_blank" rel="noopener noreferrer"&gt; 开发人员指南&lt;/a&gt;中的&lt;a href="https://docs.aws.amazon.com/aws-backup/latest/devguide/aws-backup-audit-manager.html" target="_blank" rel="noopener noreferrer"&gt;此部分&lt;/a&gt;。&lt;strong&gt;要开始使用，请访问&lt;a href="https://console.aws.amazon.com/backup"&gt;&lt;span title=""&gt; AWS Backup&lt;/span&gt; 控制台。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a title="Steve 的 Twitter" href="https://twitter.com/bellevuesteve"&gt; – Steve&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
	</channel>
</rss>