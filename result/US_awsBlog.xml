<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>亚马逊AWS官方博客</title>
	<atom:link href="https://aws.amazon.com/cn/blogs/china/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/cn/blogs/china/</link>
	<description>Just another AWS Brew Blogs  site</description>
	<lastBuildDate>Fri, 03 Sep 2021 03:45:21 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>使用Python语言实现Transcribe Streaming的websocket协议</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-python-language-to-implement-the-websocket-protocol-of-transcribe-streaming/</link>
				<pubDate>Fri, 03 Sep 2021 03:45:21 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon Transcribe]]></category>

		<guid isPermaLink="false">e21e52547928d10b376260b6094480799af5ab25</guid>
				<description>Amazon Transcribe是自动语音识别（ASR）服务，可让开发人员轻松地为其应用程序添加语音转文本功能，Transcribe支持文件和流式Streaming的两种音频输入方式，Transcribe Streaming可以应用在会议记录，语音控制交互，语言实时翻译等场景，Streaming方式支持HTTP/2和WebSocket两种协议。本文介绍使用Python语言实现Transcribe Streaming的WebSocket协议。</description>
								<content:encoded>&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;Amazon Transcribe是自动语音识别（ASR）服务，可让开发人员轻松地为其应用程序添加语音转文本功能，Transcribe支持文件和流式Streaming的两种音频输入方式，Transcribe Streaming可以应用在会议记录，语音控制交互，语言实时翻译等场景，Streaming方式支持HTTP/2和WebSocket两种协议。本文介绍使用Python语言实现Transcribe Streaming的WebSocket协议。&lt;/p&gt; 
&lt;h2&gt;Streaming transcription 接口介绍&lt;/h2&gt; 
&lt;p&gt;Streaming transcription 接口可以接收音频流并且实时转换为文字，然后将结果返回客户端，同时返回数据中包含partial值，用来标示句子是否结束。&lt;/p&gt; 
&lt;p&gt;Streaming的数据是被编码的，由prelude和data组成。编码格式详见：https://docs.aws.amazon.com/transcribe/latest/dg/event-stream.html&lt;/p&gt; 
&lt;h2&gt;Python语言的实现过程和示例&lt;/h2&gt; 
&lt;p&gt;Python示例程序的运行环境是Python 3.7.9版本。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加IAM Policy到你使用到的IAM user&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "transcribestreaming",
            "Effect": "Allow",
            "Action": "transcribe:StartStreamTranscriptionWebSocket",
            "Resource": "*"
        }
    ]
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;安装Python的程序包&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Python示例程序需要安装三个程序包websocket-client，boto3和amazon_transcribe；其中boto3是AWS SDK for Python，amazon_transcribe是Amazon Transcribe Streaming SDK，这两个SDK简化了和Amazon Transcribe Service的集成过程。amazon_transcribe的详细说明见：https://github.com/awslabs/amazon-transcribe-streaming-sdk&lt;/p&gt; 
&lt;p&gt;安装程序包的命令：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;pip3 install boto3
pip3 install amazon_transcribe
pip3 install websocket-client&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;Python程序的import部分：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import hashlib
import hmac
import urllib.parse
from datetime import datetime
import time
import ssl
import json
import websocket
import _thread
from amazon_transcribe.eventstream import EventStreamMessageSerializer
from amazon_transcribe.eventstream import EventStreamBuffer
from boto3.session import Session&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;创建签名URL的函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;URL签名说明详见：&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Python的实现示例：&lt;/p&gt; 
&lt;p&gt;下列代码中主体函数是create_pre_signed_url，它将生成访问Streaming transcription 接口的URL，其中包括必要的参数和签名，它需要传入4个参数:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;参数region代表将要调用的Amazon Web Service Region。可查看Streaming支持的region，详见Docs链接的Amazon Transcribe Streaming部分（&lt;a href="https://docs.aws.amazon.com/general/latest/gr/transcribe.html"&gt;https://docs.aws.amazon.com/general/latest/gr/transcribe.html&lt;/a&gt;）&lt;/li&gt; 
 &lt;li&gt;参数language_code, media_encoding, sample_rate是stream-transcription-websocket接口的参数，定义见https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html#websocket-url&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def sign(key, msg):
    return hmac.new(key, msg.encode("utf-8"), hashlib.sha256).digest()

def getSignatureKey(key, dateStamp, region, serviceName):
    kDate = sign(("AWS4" + key).encode("utf-8"), dateStamp)
    kRegion = sign(kDate, region)
    kService = sign(kRegion, serviceName)
    kSigning = sign(kService, "aws4_request")
    return kSigning

def create_pre_signed_url(region, language_code, media_encoding, sample_rate):
    # 获得access key和secret key
    credentials = Session().get_credentials()
    access_key_id = credentials.access_key
    secret_access_key = credentials.secret_key

    method = "GET"
    service = "transcribe"
    endpoint = "wss://transcribestreaming." + region + ".amazonaws.com:8443"
    host = "transcribestreaming." + region + ".amazonaws.com:8443"
    algorithm = "AWS4-HMAC-SHA256"

    t = datetime.utcnow()
    amz_date =t.strftime('%Y%m%dT%H%M%SZ')
    datestamp =t.strftime('%Y%m%d')

    canonical_uri = "/stream-transcription-websocket"

    canonical_headers = "host:" + host + "\n"
    signed_headers = "host"

    credential_scope = datestamp + "/" + region + "/" + service + "/" + "aws4_request"

    canonical_querystring = "X-Amz-Algorithm=" + algorithm
    canonical_querystring += "&amp;amp;X-Amz-Credential=" + urllib.parse.quote_plus(access_key_id + "/" + credential_scope)
    canonical_querystring += "&amp;amp;X-Amz-Date=" + amz_date
    canonical_querystring += "&amp;amp;X-Amz-Expires=300"
    canonical_querystring += "&amp;amp;X-Amz-SignedHeaders=" + signed_headers
    canonical_querystring += "&amp;amp;language-code="+ language_code +"&amp;amp;media-encoding=" + media_encoding +"&amp;amp;sample-rate=" + sample_rate

    # Zero length string for connecting
    payload_hash = hashlib.sha256(("").encode('utf-8')).hexdigest()

    canonical_request = method + '\n' \
                        + canonical_uri + '\n' \
                        + canonical_querystring + '\n' \
                        + canonical_headers + '\n' \
                        + signed_headers + '\n' \
                        + payload_hash

    string_to_sign = algorithm + "\n" \
                     + amz_date + "\n" \
                     + credential_scope + "\n" \
                     + hashlib.sha256(canonical_request.encode("utf-8")).hexdigest()

    signing_key = getSignatureKey(secret_access_key, datestamp, region, service)

    signature = hmac.new(signing_key, string_to_sign.encode("utf-8"),
                         hashlib.sha256).hexdigest()

    canonical_querystring += "&amp;amp;X-Amz-Signature=" + signature

    request_url = endpoint + canonical_uri + "?" + canonical_querystring

    return request_url
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写main函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面代码中的loop_receiving和send_data函数，作用分别是从Amazon Transcribe Service接收消息，和向Amazon Transcribe Service发送消息。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def main():
    url = create_pre_signed_url("us-east-1", "en-US", "pcm", "16000")
    ws = websocket.create_connection(url, sslopt={"cert_reqs": ssl.CERT_NONE})

    _thread.start_new_thread(loop_receiving, (ws,))
    print("Receiving...")
    send_data(ws)

    while True:
        time.sleep(1)
main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写loop_receiving函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该函数位于main函数上方。它将接收Amazon Transcribe Streaming Service的返回数据，并且打印出来。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def loop_receiving(ws):
    try:
        while True:
            result = ws.recv()

            if result == '':
                continue

            eventStreamBuffer = EventStreamBuffer()

            eventStreamBuffer.add_data(result)
            eventStreamMessage = eventStreamBuffer.next()

            stream_payload = eventStreamMessage.payload

            transcript = json.loads(bytes.decode(stream_payload, "UTF-8"))

            print("response:",transcript)

            results = transcript['Transcript']['Results']
            if len(results)&amp;gt;0:
                for length in range(len(results)):
                    if 'IsPartial' in results[length]:
                        print('IsPartial:', results[length]['IsPartial'])

                    if 'Alternatives' in results[length]:
                        alternatives = results[length]['Alternatives']
                        if len(alternatives)&amp;gt;0:
                            for sublength in range(len(alternatives)):
                                if 'Transcript' in alternatives[sublength]:
                                    print('Transcript:', alternatives[sublength]['Transcript'])


    except Exception as e:
        if 'WebSocketConnectionClosedException' == e.__class__.__name__:
            print("Error: websocket connection is closed")
        else:
            print(f"Exception Name: {e.__class__.__name__}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;编写send_data函数&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该函数位于main函数上方。它将发送音频数据到Amazon Transcribe Streaming Service。其中testFile变量是测试音频文件地址，测试音频为pem格式，英语，采样率为16000。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;def send_data(ws):

    testFile = "xxx.pem"

    bufferSize = 1024*16

    stream_headers = {
        ":message-type": "event",
        ":event-type": "AudioEvent",
        ":content-type": "application/octet-stream",
    }

    eventstream_serializer = EventStreamMessageSerializer()

    with open(testFile, "rb") as source:
        while True:
            audio_chunk = source.read(bufferSize)
            # 将音频数据进行编码
            event_bytes = eventstream_serializer.serialize(stream_headers, audio_chunk)

            ws.send(event_bytes, opcode = 0x2) # 0 x 2 send binary

            # end with b'' data bytes
            if len(audio_chunk) == 0:
                break&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;在这篇文章中，介绍了如何使用Python语言实现Transcribe Streaming的WebSocket协议，提供了Python的例子供参考，包括签名URL、数据编码、数据流的发送和接收等部分。完整代码见：https://github.com/xuemark/transcribe/blob/master/transcribe_streaming_websocket.py&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html"&gt;https://docs.aws.amazon.com/transcribe/latest/dg/websocket.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/transcribe"&gt;https://aws.amazon.com/transcribe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awslabs/amazon-transcribe-streaming-sdk"&gt;https://github.com/awslabs/amazon-transcribe-streaming-sdk&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/markxue.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;薛召兵&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责帮助客户进行上云架构的设计和咨询。同时致力于AWS容器服务、媒体服务和机器学习服务在国内和全球商业客户的应用和推广，推进企业服务迁移上云进程。有10年以上的软件开发、售前技术支持、系统架构设计等经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>基于 Nitro Enclave 构建安全的可信执行环境</title>
		<link>https://aws.amazon.com/cn/blogs/china/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave/</link>
				<pubDate>Thu, 02 Sep 2021 03:44:40 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Security, Identity, & Compliance]]></category>
		<category><![CDATA[Amazon EC2]]></category>
		<category><![CDATA[AWS Certificate Manager]]></category>
		<category><![CDATA[AWS KMS]]></category>

		<guid isPermaLink="false">fd8724fce745fd981e91ec04870e32556afb194e</guid>
				<description>Nitro Enclave 使用户可以在亚马逊云科技上，简便，安全地运行隔离的可信计算环境，用于处理私钥，PII等敏感数据，支持 Intel，AMD 芯片的计算实例，没有任何额外费用，具备更好的灵活性和成本效益，且与云原生的安全服务 KMS，ACM 直接集成，为用户提供更好的使用体验和安全性保障。</description>
								<content:encoded>&lt;h2&gt;前言&lt;/h2&gt; 
&lt;p&gt;随着移动通信和互联网技术的发展与应用，数据泄漏可能会造成直接的收入损失，并对业务、用户信任和企业声誉产生重大影响，如何在业务更加深入地数字化的同时，在计算环境中确保数据的机密性和完整性，将是企业面临的重大挑战，尤其是在公有云的环境中。&lt;/p&gt; 
&lt;p&gt;可信执行环境（TEE: Trusted Execution Environment）的提出，正是应对这样的需求。 可信执行环境在芯片层面单独划分出来的一个隔离空间，建立与本地操作系统（例如 Android 和 Microsoft Windows）并行运行的隔离执行环境，保证加载到内部的代码和数据在机密性和完整性方面受到保护，保护敏感代码和数据免受来自本地操作系统潜在漏洞的特权攻击。&lt;/p&gt; 
&lt;p&gt;可信执行环境典型的业务场景包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;私钥安全&lt;/strong&gt;： 用户可以在隔离的安全环境中使用和处理私钥，例如加密和签名，同时阻止父实例上的用户、应用程序查看和获取这些密钥。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;敏感数据处理&lt;/strong&gt;： 可以在隔离的安全区域内运行应用程序，将个人身份，信用卡号等 PII 敏感数据进行令牌化。同时加密的数据可以发送到安全区域进行解密并处理。在整个过程中，父 EC2 实例将无法查看或访问敏感数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;业界常见的可信执行环境的技术包括，Intel SGX 和 ARM TrustZone 等，这个隔离的空间，在 Intel SGX 中被称作 Enclave，而在 ARM TrustZone 中则被称为 Secure World。&lt;/p&gt; 
&lt;p&gt;亚马逊云科技作为公有云的技术领导者，也推出了 TEE 解决方案，&lt;a href="https://aws.amazon.com/cn/ec2/nitro/nitro-enclaves/"&gt;Nitro Enclave&lt;/a&gt;，使用 Nitro Hypervisor 技术，在 EC2 实例内部，提供 CPU 和内存隔离的一个计算环境。&lt;/p&gt; 
&lt;p&gt;Nitro Enclave 主要优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;隔离和安全的运行环境: 基于 Nitro Hypervisor 实现的完全隔离的 CPU，内存计算环境，无持久化存储，交互式访问和外部网络&lt;/li&gt; 
 &lt;li&gt;加密证明: Attestation 证明文件允许用户在外部服务中，授权 Enclave 访问权限，和验证 Enclave 中的代码完整性&lt;/li&gt; 
 &lt;li&gt;灵活: 不需要绑定 CPU 厂商，支持 Intel，AMD 芯片，和任何编程语言&lt;/li&gt; 
 &lt;li&gt;成本: Nitro Enclave 运行于 EC2 中，无任何额外费用&lt;/li&gt; 
 &lt;li&gt;云原生安全集成: 与云原生的 KMS，ACM 安全服务直接集成，提供更好的用户体验和安全保障&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;1. Nitro Enclave 介绍&lt;/h2&gt; 
&lt;h3&gt;1.1 Nitro Enclave 基础介绍&lt;/h3&gt; 
&lt;p&gt;Nitro Enclaves 是一项 Amazon EC2 功能，允许您从 Amazon EC2 实例创建隔离的执行环境，称为 enclave。 Enclave 是独立的、强化的且高度受限的虚拟机，基于 Nitro Hypervisor 虚拟化技术，确保父实例无法访问隔离的 vCPU 和 enclave 的内存。Enclave 没有持久存储、交互式访问或外部网络，仅支持与其父实例的安全 Socket 连接。 用户无法通过 SSH 进入 enclave，并且父实例的进程、应用程序或用户（root 或 admin）无法访问 enclave 内的数据和应用程序。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;1.2 Attestation 证明文件&lt;/h3&gt; 
&lt;p&gt;在 Nitro Enclave 中运行程序，除了隔离环境带来的私密性之外，还提供额外的安全特性，加密证明(Cryptographic Attestation)。Attestation 是 Enclave 用来证明其身份并与外部服务建立信任的过程，以及保证数据通信的安全。&lt;/p&gt; 
&lt;p&gt;Attestation 的目的是根据在特定 enclave 中运行的代码和配置，证明 enclave 是值得信赖的实体。 Nitro Hypervisor 能够生成包含 enclave 详细信息的证明文档，包括 enclave 签名密钥、enclave 映像的哈希值、父实例 ID 的哈希值以及附加 IAM 角色的 ARN 的哈希值。&lt;/p&gt; 
&lt;p&gt;Enclave Attestation 功能是由 Nitro Hypervisor 中的 Nitro Secure Module (NSM) 组件实现。亚马逊云科技提供了&lt;a href="https://github.com/aws/aws-nitro-enclaves-nsm-api"&gt;一套 helper library&lt;/a&gt;，方便用户在开发 Enclave 程序时，与 NSM 交互， 查询 PCR 和请求 Attestation 证明文件。&lt;/p&gt; 
&lt;p&gt;关于 Nitro Enclave Attestation 生成的详细过程，可参考&lt;a href="https://github.com/aws/aws-nitro-enclaves-nsm-api/blob/main/docs/attestation_process.md"&gt;此文档&lt;/a&gt;。下面是一个 Attestation 证明文件的结构：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;AttestationDocument = {
    module_id: text,               ; issuing Nitro hypervisor module ID
    timestamp: uint .size 8,       ; UTC time when document was created, in
                                   ; milliseconds since UNIX epoch
    digest: digest,                ; the digest function used for calculating the
                                   ; register values
    pcrs: { + index =&amp;gt; pcr },      ; map of all locked PCRs at the moment the
                                   ; attestation document was generated
    certificate: cert,             ; the infrastucture certificate used to sign this
                                   ; document, DER encoded
    cabundle: [* cert],            ; issuing CA bundle for infrastructure certificate
    ? public_key: user_data,       ; an optional DER-encoded key the attestation
                                   ; consumer can use to encrypt data with
    ? user_data: user_data,        ; additional signed user data, defined by protocol
    ? nonce: user_data,            ; an optional cryptographic nonce provided by the
                                   ; aattestation consumer as a proof of authenticity
}

cert = bytes .size (1..1024)       ; DER encoded certificate
user_data = bytes .size (0..1024)
pcr = bytes .size (32/48/64)       ; PCR content
index = 0..31
digest = "SHA384"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在 Attestation 证明文件中，包含了一个 Public Key，当 Enclave 程序向外部服务发起请求时，带上证明文件，外部应用可以利用该 Public Key，对需要返回 Enclave 的 Response 进行加密， Enclave 收到该 Response 后使用 Private Key 进行解密，确保数据在传输过程中不会被嗅探，且只有发起服务请求的 Enclave 才能解密该 Response。&lt;/p&gt; 
&lt;p&gt;另外，Attestation 文件中还包括每个 Enclave 一系列属性的哈希值，被称为 PCR (Platform Configuration Registers) 。用户可以使用 PCR 的哈希值在外部服务中创建访问策略，以授予对服务请求的访问权限。 Enclave 有 6 个 PCR，分别对应 Enclave 不同的元数据，其中 PCR 0，1，2 与 Enclave 镜像文件相关，在 Enclave 创建时生成。&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PCR&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hash of&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR0&lt;/td&gt; 
   &lt;td&gt;Enclave image file&lt;/td&gt; 
   &lt;td&gt;A contiguous measure of the contents of the image file, without the section data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR1&lt;/td&gt; 
   &lt;td&gt;Linux kernel and bootstrap&lt;/td&gt; 
   &lt;td&gt;A contiguous measurement of the kernel and boot ramfs data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR2&lt;/td&gt; 
   &lt;td&gt;Application&lt;/td&gt; 
   &lt;td&gt;A contiguous, in-order measurement of the user applications, without the boot ramfs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR3&lt;/td&gt; 
   &lt;td&gt;IAM role assigned to the parent instance&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the parent instance has the correct IAM role.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR4&lt;/td&gt; 
   &lt;td&gt;Instance ID of the parent instance&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the parent instance has a specific instance ID.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PCR8&lt;/td&gt; 
   &lt;td&gt;Enclave image file signing certificate&lt;/td&gt; 
   &lt;td&gt;Ensures that the attestation process succeeds only when the enclave was booted from an enclave image file signed by a specific certificate.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Attestation 证明文件生成后，还将会由受信任Nitro Hypervisor Attestation Public Key Infrastructure (PKI) ，基于一个 ACM PCA 的根证书进行签署，有效期为 30 年。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CN=aws.nitro-enclaves, C=US, O=Amazon, OU=AWS&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;用户可以下载该&lt;a href="https://aws-nitro-enclaves.amazonaws.com/AWS_NitroEnclaves_Root-G1.zip"&gt;根证书&lt;/a&gt;，导入到您的任何外部服务中，当 Enclave 中运行的程序需要请求外部服务时，可向 Nitro Hypervisor 申请并签署证明文件，外部服务通过导入的根证书，来验证 Enclave 证明文件的有效性，确保服务请求是来自于特定的 Enclave，从而建立信任。&lt;/p&gt; 
&lt;p&gt;目前 Amazon Key Management Service (KMS) 和 Amazon Certificate Manager (ACM) 支持与 Nitro Enclave 以及 Attestation 原生集成，Enclave 可借助 vsock 以及父实例上的代理，向 KMS 或 ACM 发起 API 请求，进行加密，解密，和证书申请，更新等操作，同时 KMS 和 ACM 支持对 Enclave 签名的证明文件进行验证，并可将 API Response 用证明文件中的 Public Key 进行加密，确保数据隐私安全。&lt;/p&gt; 
&lt;p&gt;适用于 Nitro Enclaves 的 ACM 允许您将公有和私有 SSL/TLS 证书与在带有 Nitro Enclaves 的 EC2 实例上运行的 Web 应用一起使用。 亚马逊云科技提供了一个打包好的 ACM for Nitro Enclaves 程序，作为服务(aws-nitro-enclaves-acm) 运行在父实例 Linux 操作系统中，该服务将自动创建和运行 Enclave，与 ACM 交互创建安全私钥，将证书及其私钥分发到 enclave，并管理证书续订，证书的私钥在 enclave 中保持隔离，防止父实例及其用户访问它。 具体部署过程可参照&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html"&gt;官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;目前，ACM for Nitro Enclaves 支持与运行在 Amazon EC2 实例上的 NGINX 配合使用，以安装证书并无缝替换过期证书，以提供 HTTPS 服务，未来将添加对其他 Web 服务（Apache HTTP）的支持。&lt;/p&gt; 
&lt;h3&gt;1.3 Nitro Enclave Attestation 与 KMS 集成&lt;/h3&gt; 
&lt;p&gt;Amazon KMS 是一项云原生的密钥管理服务，用来创建和管理密钥，支持使用密钥进行 Server-side 的加密，解密，签名，验证等操作，还支持生成用于 client-side 加密的密钥。 KMS 内置原生支持 Nitro Enclaves，能够验证来自 Enclave 请求中携带的 Attestation 证明文件，并可以根据证明文件中的 PCR 值，定义密钥策略，来授予对特定 Enclave 的访问权限。&lt;/p&gt; 
&lt;p&gt;可以在 KMS Policy 中定义的 Condition Key ，对来自 Enclave 发起的以下三个 API 请求，进行 Attestation 验证和 API 请求授权，例如只允许来自指定 Enclave 的 KMS Decrypt API 请求。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;kms:GenerateRandom： 生成随机字符串&lt;/li&gt; 
 &lt;li&gt;kms:GenerateDataKey： 生成 Data Key，用于 Client-Side 加密&lt;/li&gt; 
 &lt;li&gt;kms:Decrypt： 对文本或 Data Key 进行解密&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  "Version": "2012-10-17",
  "Statement": [{
    "Sid" : "Enable enclave data processing",
    "Effect" : "Allow",
    "Principal" : {
      "AWS" : "arn:aws:iam::123456789012:role/data-processing"
    },
    "Action": [
      "kms:Decrypt",
      "kms:GenerateDataKey",
      "kms:GenerateRandom"
    ],
    "Resource": "*",
    "Condition": {
      "StringEqualsIgnoreCase": {
        "kms:RecipientAttestation:ImageSha384":"EXAMPLE8abcdef7abcdef6abcdef5abcdef4abcdef3abcdef2abcdef1abcdef1abcdef0abcdef1abcdEXAMPLE",
        "kms:RecipientAttestation:PCR0":"EXAMPLEbc2ecbb68ed99a13d7122abfc0666b926a79d5379bc58b9445c84217f59cfdd36c08b2c79552928702EXAMPLE",
        "kms:RecipientAttestation:PCR1":"EXAMPLE050abf6b993c915505f3220e2d82b51aff830ad14cbecc2eec1bf0b4ae749d311c663f464cde9f718aEXAMPLE", 
        "kms:RecipientAttestation:PCR2":"EXAMPLEc300289e872e6ac4d19b0b5ac4a9b020c98295643ff3978610750ce6a86f7edff24e3c0a4a445f2ff8EXAMPLE"
      }
    }
  }]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;注意： 目前使用 KMS SDK 和 CLI 请求 KMS 时，还不支持添加 attestation 证明文件，所以在 Enclave 中向 KMS 发起以上三个 API 请求时，只能用过 HTTP POST 的方式构建 API 请求，将 attestation 加入到 request parameter 中。同时，KMS将自动使用证明文件中的 Public Key 对 API Response 中的明文进行加密，Enclave 收到 Response 后，需要使用 Private Key 进行解密&lt;/p&gt; 
&lt;p&gt;例如: 在 KMS Decrypt API Request 中，新增的Recipient字段将包括AttestationDocument证明文件，同时在 API Response 中，原本的Plaintext字段将替换为加密的CiphertextForRecipient字段，明文字段默认被 KMS 使用证明文件中的 Public Key 进行加密。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;# KMS Decrypt Request (New Recipient parameter)
{
   "CiphertextBlob": blob,
   "EncryptionAlgorithm": "string",
   "EncryptionContext": { 
      "string" : "string" 
   },
   "GrantTokens": [ "string" ],
   "Recipient": { 
      "AttestationDocument": blob,
      "KeyEncryptionAlgorithm": "string"
   }
}

# KMS Decrypt Response (CiphertextForRecipient returned instead of Plaintext)
{
   "CiphertextForRecipient": blob,
   "EncryptionAlgorithm": "string",
   "KeyId": "string",
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过 Nitro Enclave 与 KMS Attestation 的集成，可以确保敏感数据只能在 Enclave 中进行处理，不会被泄漏，嗅探和篡改。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;明文数据只在 Enclave 中可见，隔离的运行环境可确保数据不会嗅探&lt;/li&gt; 
 &lt;li&gt;在 Enclave 外部只能以加密后的形态对数据进行传输和存储，确保原始数据不会被泄漏&lt;/li&gt; 
 &lt;li&gt;同时借助 Enclave 的 Attestation，确保 Enclave 中的代码不会被篡改&lt;/li&gt; 
 &lt;li&gt;通过 KMS 密钥策略，确保数据只能在特定的 Enclave 内部才能被解密&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1.4 管理和开发 Nitro Enclave 应用&lt;/h3&gt; 
&lt;p&gt;如果需要开发一个运行于 Enclave 中的应用，需要先将 Enclave 运行所需的代码，依赖包等打包成 Docker 镜像格式， 然后将 Docker 镜像转换成 Enclave 镜像 (.eif)，以启动 Enclave。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Nitro Enclave 提供一个命令行工具 Nitro-CLI，用来创建，部署和管理Enclave:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-build-enclave.html"&gt;nitro-cli build-enclave&lt;/a&gt;: 将 Docker 镜像转换成 Enclave 镜像 (.eif文件)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli build-enclave --docker-uri repository:tag --docker-dir /path_to/dockerfile_directory --output-file enclave_image_filename --private-key key.pem --signing-certificate certificate.pem&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-run-enclave.html"&gt;nitro-cli run-enclave&lt;/a&gt;: 从 Enclave 镜像文件在 EC2 上启动一个 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;每台&lt;/strong&gt;&lt;strong&gt; EC2 &lt;/strong&gt;&lt;strong&gt;上只支持运行一个&lt;/strong&gt;&lt;strong&gt; enclave &lt;/strong&gt;&lt;strong&gt;环境，且&lt;/strong&gt;&lt;strong&gt; EC2 &lt;/strong&gt;&lt;strong&gt;实例至少具备&lt;/strong&gt;&lt;strong&gt; 4 &lt;/strong&gt;&lt;strong&gt;个&lt;/strong&gt;&lt;strong&gt; CPU&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli run-enclave --cpu-count number_of_vcpus --cpu-ids list_of_vcpu_ids --memory amount_of_memory_in_MiB --eif-path path_to_enclave_image_file [--enclave-cid cid_number] [--debug-mode]&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-describe-enclaves.html"&gt;nitro-cli describe-enclaves&lt;/a&gt;: 查看当前运行的 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli describe-enclaves&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-console.html"&gt;nitro-cli console&lt;/a&gt;: 以只读模式连接到一个运行的 Enclave，获取 Console 输出.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;只有以&lt;/strong&gt;&lt;strong&gt;–debug-mode&lt;/strong&gt;&lt;strong&gt;模式运行的&lt;/strong&gt;&lt;strong&gt; enclave&lt;/strong&gt;&lt;strong&gt;，才允许&lt;/strong&gt;&lt;strong&gt; console &lt;/strong&gt;&lt;strong&gt;连接&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli console --enclave-id enclave_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/enclaves/latest/user/cmd-nitro-terminate-enclave.html"&gt;nitro-cli terminate-enclave&lt;/a&gt;: 关闭指定的 enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli terminate-enclave --enclave-id enclave_id&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;另外，亚马逊云科技提供一系列工具，方便用户开发 Enclave 应用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://aws.amazon.com/marketplace/pp/B08R69DKQ1"&gt;Nitro Enclaves Developer AMI&lt;/a&gt;: 包含开发 Enclave 应用程序和构建 Enclave 镜像文件所需的工具和组件，以及示例应用&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws/aws-nitro-enclaves-sdk-c"&gt;Nitro Enclaves SDK&lt;/a&gt;: 一组可用于开发 enclave 应用程序的 c 语言开源库，与KMS 集成，并为 attestation 证明和加密操作提供内置支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;2. 搭建一个 Nitro Enclave 示例环境，结合 KMS 实现私钥安全&lt;/h2&gt; 
&lt;p&gt;下面将以一个私钥管理应用场景的示例，使用 Python 代码演示如何在 Nitro Enclave 中处理私钥数据，并结合 KMS 和 Attestation，保证私钥在加密，解密，存储和签名过程中的安全。该示例将包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;创建和部署两个 Enclave，一个实现私钥的生成和加密，另一个实现私钥的解密和签名&lt;/li&gt; 
 &lt;li&gt;Enclave 通过 vsock 与父实例通信&lt;/li&gt; 
 &lt;li&gt;Enclave 通过父实例上运行 KMS Proxy，访问 KMS 服务&lt;/li&gt; 
 &lt;li&gt;Enclave 向 Nitro Hypervisor 请求 Attestation 证明文件&lt;/li&gt; 
 &lt;li&gt;在 Enclave 中向 KMS 发送 API 请求时，带上证明文件&lt;/li&gt; 
 &lt;li&gt;KMS 服务配置密钥策略，将密钥的访问权限仅授予特定的 Enclave&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;私钥管理应用场景示例架构图和工作流如下：&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;首先创建一个 KMS Key，启动支持 Enclave 的两台 EC2 实例，分别创建和运行 Enclave，vsock 和 KMS Proxy。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;在 Enclave-1 中通过 kms:GenerateRandom API 生成一个 256 位的私钥，利用私钥生成对应的公钥(ecdsa-p256k1)&lt;/li&gt; 
 &lt;li&gt;在 Enclave-1 中通过 kms:GenerateDataKey API 获取加密密钥（包括一个明文 DataKey 和一个KMS加密的 DataKey），使用明文 DataKey 对私钥进行 Client-Side 加密&lt;/li&gt; 
 &lt;li&gt;在 Enclave-1 中，将加密的私钥，加密的 DataKey 和公钥，通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;在 EC2-1 父实例中，将从 vsock 中收到的数据（加密的私钥，加密的 DataKey 和公钥）写入到 DynamoDB 数据库&lt;/li&gt; 
 &lt;li&gt;在 EC2-2 父实例中，从 DynamoDB 中读取一条数据（私钥ID，加密的私钥，加密的 DataKey 和公钥），通过 vsock 将加密的私钥，加密的 DataKey 和需要被签名的消息，发送给 Enclave-2&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，从vsock接收数据（加密的私钥，加密的 DataKey 和需要被签名的消息），通过 kms:Decrypt API 对加密的 DataKey 进行解密，获取明文 DataKey&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，使用明文 DataKey 对加密的私钥进行解密，并使用私钥，对消息进行签名&lt;/li&gt; 
 &lt;li&gt;在 Enclave-2 中，将签名后的消息通过通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;在 EC2-2 父实例中，对送 vsock 接收到的签名消息，使用公钥进行验证&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2.1 基础环境部署&lt;/h3&gt; 
&lt;h4&gt;2.1.1 启动两台 EC2 实例，安装依赖包&lt;/h4&gt; 
&lt;p&gt;首先创建 EC2 及 Enclave 程序所需的 IAM Role，至少需要具备 DynamoDB 的访问权限。为了简化配置，在 demo 中直接使用了 KMS 和 DynamoDB 托管的 FullAccess 策略。但在生产环境中，不能直接使用托管策略，需要自定义用户策略，进行访问行为和资源级别的精细化授权。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 启动两台 Amazon Linux2 的 m5.xlarge EC2 实例(至少 4 vCPU 的 Nitro 实例类型), 需要手动启用 Enclave (创建 EC2 时默认不启用 enclave )&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建 EC2 实例时，在User Data 中，粘贴以下信息，完成安装 Nitro-CLI ，Docker，以及其他 Enclave 程序所需的依赖包，修改 Enclave 可占用的最大内存，下载 Enclave 示例代码等。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;#!/bin/bash
amazon-linux-extras install aws-nitro-enclaves-cli -y
yum install aws-nitro-enclaves-cli-devel -y
usermod -aG ne ec2-user
systemctl start nitro-enclaves-allocator.service &amp;amp;&amp;amp; systemctl enable nitro-enclaves-allocator.service
amazon-linux-extras install docker -y
usermod -aG docker ec2-user
systemctl start docker &amp;amp;&amp;amp; systemctl enable docker
yum install git -y
pip3 install ecdsa
pip3 install requests
pip3 install boto3
sed -i "s/memory_mib: 512/memory_mib: 3072/g" /etc/nitro_enclaves/allocator.yaml
su ec2-user -c 'cd /home/ec2-user &amp;amp;&amp;amp; git clone https://github.com/hxhwing/Nitro-Enclave-Demo.git'
shutdown -r now
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;EC2 启动完成后，修改实例名称用于标记：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一台 EC2: NitroEnclaveDemo-1，用于生成，加密私钥，存储到 DynamoDB&lt;/li&gt; 
 &lt;li&gt;第二台 EC2: NitroEnclaveDemo-2，用于解密私钥，签名和验证消息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.1.2 创建 KMS Key&lt;/h4&gt; 
&lt;p&gt;在 Amazon KMS 服务中创建一个对称密钥，用于在 Enclave 中调用 KMS API，进行私钥的生成和加解密。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步： 选择对称密钥&lt;/li&gt; 
 &lt;li&gt;第二步： 为 Key 添加别名NitroEnclaveDemo&lt;/li&gt; 
 &lt;li&gt;第三步： 选择 Key 的管理员用户（只有 Key 管理员可以删除或修改 Key 的权限）&lt;/li&gt; 
 &lt;li&gt;第四步： 密钥使用权限，不选择任何用户或角色&lt;/li&gt; 
 &lt;li&gt;第五步： 修改自动生成的 Key Policy，在 Statements 中添加以下策略，为前面步骤创建的 EC2 Role 分配 “kms:Decrypt”,”kms:GenerateDataKey”,”kms:GenerateRandom” 权限，暂不配置策略条件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;       {
           "Sid": "Allow NitroEnclave-Demo Role",
           "Effect": "Allow",
           "Principal": {
               "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"  # Replace account ID
           },
           "Action": [
               "kms:GenerateRandom",
               "kms:GenerateDataKey",
               "kms:Decrypt"
               ],
           "Resource": "*"
       },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;2.1.3 创建 DynamoDB Table&lt;/h4&gt; 
&lt;p&gt;创建一个 DynamoDB Table，用于存放加密后的私钥，加密的 DataKey 和公钥。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Table Name:&amp;nbsp;UserToken&lt;/li&gt; 
 &lt;li&gt;Partition key:&amp;nbsp;userid (String)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;strong&gt;:&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;DynamoDB Table Name &lt;/strong&gt;&lt;strong&gt;和&lt;/strong&gt;&lt;strong&gt; Partition key &lt;/strong&gt;&lt;strong&gt;请与上面完全一致，如果需要修改，请同时相应修改示例程序中&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;client.py&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;的&lt;/strong&gt;&lt;strong&gt; DynamoDB &lt;/strong&gt;&lt;strong&gt;相关代码。&lt;/strong&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2.2 创建Enclave，运行示例代码&lt;/h3&gt; 
&lt;p&gt;示例代码&amp;nbsp;Nitro-Enclave-Demo&amp;nbsp;已经被自动下载到 ec2-user 用户目录下，示例代码包含两个目录&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GenerateToken: 运行在第一台 EC2 ，用于生成和加密私钥的 Enclave&lt;/li&gt; 
 &lt;li&gt;SignVerify: 运行在第二台 EC2，用于解密私钥，签名和验证消息的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 ~]$ cd Nitro-Enclave-Demo/
[ec2-user@ip-172-31-33-19 Nitro-Enclave-Demo]$ ls -l
total 4
drwxr-xr-x 2 ec2-user ec2-user  206 Aug 28 16:12 GenerateToken
drwxr-xr-x 2 ec2-user ec2-user   87 Aug 28 16:12 pics
-rw-r--r-- 1 ec2-user ec2-user 3094 Aug 28 16:12 README.md
drwxr-xr-x 2 ec2-user ec2-user  189 Aug 28 16:12 SignVerify
drwxr-xr-x 4 ec2-user ec2-user   51 Aug 28 16:12 src
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h4&gt;2.2.1 创建和运行第一个 Enclave，生成和加密私钥&lt;/h4&gt; 
&lt;p&gt;首先登录到第一台 EC2，进入 /home/ec2-user/Nitro-Enclave-Demo/GenerateToken/ 目录，主要包括以下几个文件&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;main.py: 运行在 Enclave 中的主程序文件，包括：从 KMS 生成私钥，从 KMS 获取 DataKey，加密私钥，将加密后的数据通过vsock发给父实例&lt;/li&gt; 
 &lt;li&gt;traffic-fowarder.py: 运行在 Enclave 中，用于将 Enclave 访问 KMS 的请求通过 vsock 发送到父实例&lt;/li&gt; 
 &lt;li&gt;kms.py: 用于获取 Attestation 签名，访问 KMS API，以及解密 KMS API Response&lt;/li&gt; 
 &lt;li&gt;client.py: 运行在父实例中的程序文件，包括：从 Enclave 接收加密后的数据，将数据写入到 DynamoDB&lt;/li&gt; 
 &lt;li&gt;Dockerfile: Docker 镜像文件，&lt;a href="http://main.py/"&gt;main.py&lt;/a&gt;和&amp;nbsp;&lt;a href="http://traffic-fowarer.py/"&gt;traffic-fowarer.py&lt;/a&gt;&amp;nbsp;都将被打包进容器镜像&lt;/li&gt; 
 &lt;li&gt;build.sh: 创建 Docker 镜像，将 Docker 镜像转换为 Enclave 镜像，并运行 Enclave 的自动化脚本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;运行build.sh，创建 Enclave 镜像，并以debug-mode 运行 Enclave。其中创建 Enclave 镜像完成后，将自动生成该 Enclave 的 PCR 0/1/2，保存到 EnclaveImage.log 的文件中.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 GenerateToken]$ chmod +x build.sh
[ec2-user@ip-172-31-33-19 GenerateToken]$ ./build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;build 脚本运行完成后， Enclave 将以 debug 模式运行，用户可通过 nitro-cli 连接到运行的 Enclave 控制台，查看 Enclave 运行过程输出到Console的日志，主要用于排错&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli console --enclave-id $(nitro-cli describe-enclaves | jq -r ".[0].EnclaveID")&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p style="padding-left: 40px"&gt;2. 运行 client.py 代码，运行方式如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;div class="hide-language"&gt; 
  &lt;pre&gt;&lt;code class="lang-python"&gt;python3 client.py &amp;lt;KMS Key-id&amp;gt; &amp;lt;UserID&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;其中 “KMS Key-id” 为前面步骤中创建的别名为 NitroEnclaveDemo 的 KMS Key， “UserID” 用于标示即将生成的私钥属于哪个用户。&lt;/p&gt; 
&lt;p&gt;运行&amp;nbsp;client.py&amp;nbsp;代码后，将自动返回从 Enclave 中接收到的数据，并将数据写入到 DynamoDB Table，数据字段包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;userid: 用于标示私钥属于哪个用户&lt;/li&gt; 
 &lt;li&gt;encrypted_privatekey: 在 Enclave 中，被 KMS DataKey 加密后的私钥&lt;/li&gt; 
 &lt;li&gt;publickey: 在 Enclave 中，由私钥生成的公钥&lt;/li&gt; 
 &lt;li&gt;encrypted_datakey: KMS 加密后的 DataKey，将用于解密私钥&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-33-19 GenerateToken]$ python3 client.py alias/NitroEnclaveDemo u001
 {"userid": "u001", "encrypted_privatekey": "4xiMsmD1VMw1I48HMApw4LzDSWT9lz/x74dMNCz1427hz98t0JzyrFzDd68vrKl0wKB1a/LoLyhi\nvJSgQwSfCA==\n", "publickey": "0a0756e60e112d11f0d5e4a88858251f1234e27ea37261da4698d497baa6a52bbe9a3d227534866351086d7220548a4ff00fb081c9b318361cac5dae9c661f8c", "encrypted_datakey": "AQIBAHhVM1N8G00xz9DVe3FbnRAxaxNCkCaRYV6/wLYxbwj04QFUWvIkLZ6TYPE2GTUdKvMbAAAAdjB0BgkqhkiG9w0BBwagZzBlAgEAMGAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMMhfwZjlaOr8pCQneAgEQgDNMimKpywvNdcpJIgPZUYrhE5uQvzonU5o/uYhPMmZmb/kWotQNH6KSFxuTBdx6FeM0vQs="} Write User Token to DynamoDB Successfully [ec2-user@ip-172-31-33-19 GenerateToken]$&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h4&gt;2.2.2 创建和运行第二个 Enclave，解密私钥，签名和验证消息&lt;/h4&gt; 
&lt;p&gt;登录到第二台 EC2，进入 /home/ec2-user/Nitro-Enclave-Demo/SignVerify 目录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;main.py: 运行在 Enclave 中的主程序文件，包括：从 KMS 解密 DataKey，用 DataKey 解密私钥，用私钥签名消息，将签名后的消息通过vsock发给父实例&lt;/li&gt; 
 &lt;li&gt;client.py: 运行在父实例中的程序文件，包括：从 DynamoDB 中读取数据，发送到 Enclave，然后从 Enclave 接收被私钥签名后的消息，并使用公钥验证签名消息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;运行build.sh，创建 Enclave 镜像，并以debug-mode 运行 Enclave。其中创建 Enclave 镜像完成后，将自动生成该 Enclave 的 PCR 0/1/2，保存到 EnclaveImage.log 的文件中.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-36-174 SignVerify]$ chmod +x build.sh
[ec2-user@ip-172-31-36-174 SignVerify]$ ./build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;运行client.py代码，运行格式如下：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;python3 client.py &amp;lt;UserID&amp;gt; &amp;lt;Message to be Signed&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其中 “UserID” 代表从 DynamoDB 中读取哪个用户的密钥数据，“Message to be Signed” 代表将被发送到 Enclave 中被私钥签名的消息。&lt;/p&gt; 
&lt;p&gt;运行&amp;nbsp;client.py&amp;nbsp;代码后，将自动返回从 Enclave 中接收到的数据，数据字段包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Signed Message: Enclave 中被私钥签名后的消息&lt;/li&gt; 
 &lt;li&gt;Signed message verified by public key: True/False，表示签名的消息是否可以被公钥验证，确保私钥和公钥没有被修改&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;[ec2-user@ip-172-31-36-174 SignVerify]$ python3 client.py u001 'Hellow World'
Signed Message: 6053cfc42883d03888ba175950e463c1d8164cab8b4873b85af8531a0c6f86b8ad07012107e3322d30118ea24976f8c8f70014119159101ecc1797e7a9f72915
Signed message verified by public key: True
[ec2-user@ip-172-31-36-174 SignVerify]$
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;2.3 配置 KMS 密钥策略，根据 Attestation PCR 授权&lt;/h3&gt; 
&lt;p&gt;当以&amp;nbsp;debug-mode&amp;nbsp;运行 Enclave 时，Attestation 证明文件中的 PCR 为全 0，无法用来在外部服务上作为策略条件，进行权限控制。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli run-enclave ...... --debug-mode&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;运行 nitro-cli run-enclave 时，不加–debug-mode, 是以正常模式运行 Enclave，Attestation 证明文件中才会包含 Enclave 正常的 PCR。&lt;/p&gt; 
&lt;p&gt;首先在 KMS 密钥策略，添加相应的 Condition Key 限制 Attestation PCR ，其中&amp;nbsp;kms:RecipientAttestation:ImageSha384&amp;nbsp;与 PCR 0 为相同的值，每个 Enclave 的 PCR 0/1/2，可以在 Build Enclave 镜像的时候获取，本示例是写到所在代码目录下 EnclaveImage.log 文件中。&lt;/p&gt; 
&lt;p&gt;在 KMS NitroEnclaveDemo 这个 Key 的密钥策略中，添加以下两条 Deny 权限策略语句，到 KMS Key Policy 的 Statement 字段中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一段策略，授权只有来自 Enclave-1，且携带 Attestation 证明文件才能访问 kms:GenerateDataKey API，注意请替换为您自己的 PCR 0/1/2 Value&lt;/li&gt; 
 &lt;li&gt;第二段策略，授权只有来自 Enclave-2 ，且携带 Attestation 证明文件才能访问 kms:Decrypt API，注意请替换为您自己的 PCR 0/1/2 Value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;        {
            "Sid": "Only Allow NitroEnclaveDemo-1",
            "Effect": "Deny",
            "Principal": {
                "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"
            },
            "Action": [
                "kms:GenerateRandom",
                "kms:GenerateDataKey"
            ],
            "Resource": "*",
            "Condition": {
              "StringNotEqualsIgnoreCase": {
                "kms:RecipientAttestation:ImageSha384":"17b041934b2255ae55b07433012e4d41999feda85eb839970645458a35f8571360f32ca68b5178dca8bdecf9fd37c010",
                "kms:RecipientAttestation:PCR0":"17b041934b2255ae55b07433012e4d41999feda85eb839970645458a35f8571360f32ca68b5178dca8bdecf9fd37c010",
                "kms:RecipientAttestation:PCR1":"c35e620586e91ed40ca5ce360eedf77ba673719135951e293121cb3931220b00f87b5a15e94e25c01fecd08fc9139342", 
                "kms:RecipientAttestation:PCR2":"1fc61c8c21fb3ec93ae854341f5b9adc1e7bbc2eb437cc308e5fb2f4787393fe500fa4c894422a92d79eb3ce172c1a8e"
              }
            }
        },
        {
            "Sid": "Only Allow NitroEnclaveDemo-2",
            "Effect": "Deny",
            "Principal": {
                "AWS": "arn:aws:iam::xxxxxxxxxxx:role/NitroEnclave-Demo"
            },
            "Action": [
                "kms:Decrypt"
            ],
            "Resource": "*",
            "Condition": {
              "StringNotEqualsIgnoreCase": {
                "kms:RecipientAttestation:ImageSha384":"810257e9bd2ecad2181fcff508c7547ef0f3c1d446628f5465c955c4f2a2d3cfac9198919999614ffbed8e0b18c6c084",
                "kms:RecipientAttestation:PCR0":"810257e9bd2ecad2181fcff508c7547ef0f3c1d446628f5465c955c4f2a2d3cfac9198919999614ffbed8e0b18c6c084",
                "kms:RecipientAttestation:PCR1":"c35e620586e91ed40ca5ce360eedf77ba673719135951e293121cb3931220b00f87b5a15e94e25c01fecd08fc9139342", 
                "kms:RecipientAttestation:PCR2":"72457ef34f66f041996e7077f55604f0f73b1d2e3fad54881308d38da6d22bc8cd2084ab3b8810b22da629a24eef94e6"
              }
            }
        },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 在 EC2 上测试直接用 CLI 访问 KMS，提示请求被拒绝，确认密钥策略权限已生效&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;
[ec2-user@ip-172-31-33-19 ~]$ aws kms generate-data-key --key-id alias/NitroEnclaveDemo --number-of-bytes 32 --region ap-northeast-1

An error occurred (AccessDeniedException) when calling the GenerateDataKey operation: User: arn:aws:sts::xxxxxxxxxx:assumed-role/NitroEnclave-Demo/i-0e4fc2c648b901c7e is not authorized to perform: kms:GenerateDataKey on resource: arn:aws:kms:ap-northeast-1:xxxxxxxxxx:key/6390f2e0-86d6-46cb-8478-37dcfa6aa2dc with an explicit deny
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;分别在两台 EC2 上执行以下命令，终止前面步骤启动的 Enclave&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;nitro-cli terminate-enclave --enclave-id $(nitro-cli describe-enclaves | jq -r ".[0].EnclaveID")&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;然后在两台 EC2 上重新启动 Enclave，不添加 –debug-mode 参数&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;## NitroEnclaveDemo-1
[ec2-user@ip-172-31-33-19 GenerateToken]$ nitro-cli run-enclave --cpu-count 2 --memory 2900 --enclave-cid 10 --eif-path GenerateToken-demo.eif
Start allocating memory...
Started enclave with enclave-cid: 10, memory: 3072 MiB, cpu-ids: [1, 3]
{
  "EnclaveID": "i-0e4fc2c648b901c7e-enc17b908ba803d724",
  "ProcessID": 7565,
  "EnclaveCID": 10,
  "NumberOfCPUs": 2,
  "CPUIDs": [
    1,
    3
  ],
  "MemoryMiB": 3072
}


## NitroEnclaveDemo-2
[ec2-user@ip-172-31-36-174 SignVerify]$ nitro-cli run-enclave --cpu-count 2 --memory 2900 --enclave-cid 10 --eif-path SignVerify-demo.eif
Start allocating memory...
Started enclave with enclave-cid: 10, memory: 3072 MiB, cpu-ids: [1, 3]
{
  "EnclaveID": "i-0558cbee6ea7a393c-enc17b908f0730bcb2",
  "ProcessID": 7533,
  "EnclaveCID": 10,
  "NumberOfCPUs": 2,
  "CPUIDs": [
    1,
    3
  ],
  "MemoryMiB": 3072
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;然后分别在两台 EC2 的父实例上，运行client.py，确认代码能正常运行。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;## NitroEnclaveDemo-1
[ec2-user@ip-172-31-33-19 GenerateToken]$ python3 client.py alias/NitroEnclaveDemo u010
{"userid": "u010", "encrypted_privatekey": "h08szIyVaTrjH1TF95+aXooPKC/QZwGRDaZv7Cp/LmFG2FQumbZR49NrnsOYBsS+VxsvPtSlBE2s\nnEYQLMI9lQ==\n", "publickey": "9552c9f2c51be3b7143e3cfe9c71f7dcac028d368530ffbbdb34512092611e4996e9e1bcab27e4a879ff630629d7f930d2db84c295e97334d1f3335d31e7ac87", "encrypted_datakey": "AQIBAHhVM1N8G00xz9DVe3FbnRAxaxNCkCaRYV6/wLYxbwj04QFKhpZ//ap2EgINgILddtu0AAAAdjB0BgkqhkiG9w0BBwagZzBlAgEAMGAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMScLI1DYM6y6hd0d4AgEQgDO2pbbcrEEd+trVcqiqkFdlhXY/ZVEMoRqRsQAUMdJq24zwGgl6UYOjLCviBHs2wI8jC5A="}
Write User Token to DynamoDB Successfully
[ec2-user@ip-172-31-33-19 GenerateToken]$

## NitroEnclaveDemo-2
[ec2-user@ip-172-31-36-174 SignVerify]$ python3 client.py u010 'Hello World'
Signed Message: b27a5c527e218774b316f674eae537ce88b3f986b7f5df583906b1c9a9ba9bb00d2975fe4a065d5a1e74bb6947fe11c8fc90d3ac389be638b2745431de04ebd9
Signed message verified by public key: True
[ec2-user@ip-172-31-36-174 SignVerify]$
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在 CloudTrail 中，查看 KMS API 的请求记录，在来自 Enclave 的请求记录中，将会存在额外的 Attestation 数据。&lt;/p&gt; 
&lt;p&gt;来自第一台 Enclave 请求 kms:GenerateDataKey 的 CloudTrail：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 来自第二台 Enclave 请求 kms:Decrypt 的 CloudTrail：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/build-a-secure-and-trusted-execution-environment-based-on-nitro-enclave11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;Nitro Enclave 使用户可以在 亚马逊云科技上，简便，安全地运行隔离的可信计算环境，用于处理私钥，PII等敏感数据。另外 Nitro Enclave 不需要强制绑定 CPU 芯片，支持 Intel，AMD 芯片的计算实例，没有任何额外费用，具备更好的灵活性和成本效益，且与云原生的安全服务 KMS，ACM 直接集成，为用户提供更好的使用体验和安全性保障。&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/hxh.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;胡新华&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责金融行业基于AWS的云计算架构咨询和设计。加入AWS之前就职于IBM，在数据中心IT基础架构相关的解决方案设计和交付方面，具有十多年经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>增强Amazon Athena对历史查询记录的统计分析功能</title>
		<link>https://aws.amazon.com/cn/blogs/china/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records/</link>
				<pubDate>Thu, 02 Sep 2021 03:11:56 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Athena]]></category>

		<guid isPermaLink="false">5d41f51e363379c2c35c97dc1c407cec8f874090</guid>
				<description>Amazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 分析 Amazon S3 中的数据。Athena 采用无服务器架构，因此您无需管理任何基础设施，且只需为您运行的查询付费。Athena 简单易用，只需指向您存储在 Amazon S3 中的数据，定义架构并使用标准 SQL 开始查询。</description>
								<content:encoded>&lt;h2&gt;背景介绍&lt;/h2&gt; 
&lt;p&gt;Amazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 分析 Amazon S3 中的数据。Athena 采用无服务器架构，因此您无需管理任何基础设施，且只需为您运行的查询付费。Athena 简单易用，只需指向您存储在 Amazon S3 中的数据，定义架构并使用标准 SQL 开始查询。就可在数秒内获取最多的结果。您可以使用Athena 控制台查看成功和失败的查询、下载成功查询结果文件以及查看失败查询的错误详细信息。Athena 将查询历史记录保留 45 天。如果要将查询历史记录保留超过 45 天，您可以检索查询历史记录并将其保存到等 Amazon S3 等数据存储中。本方案自动执行此过程，使用 Athena 和 Amazon S3 API将数据导入到Amazon S3，并使用Athena分析历史数据，结合Amazon CloudTrail的Athena API调用日志可以对Athena的历史SQL执行记录进行多个维度的分析，以便用于评估Athena的使用和优化线上SQL等。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;部署架构&lt;/h2&gt; 
&lt;p&gt;利用CloudWatch Event定时触发Lambda代码同步Athena历史查询日志到Amazon S3，利用DynamoDB记录每次增量同步的记录位置，Amazon CloudTrail记录Athena API call日志，创建CloudTrail的跟踪，将日志持续导入到S3中，最终通过Athena多维分析历史查询日志和CloudTrail日志并利用Amazon QuickSight进行图表展现。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;方案部署步骤&lt;/h2&gt; 
&lt;h3&gt;导出Athena查询历史记录日志到Amazon S3&lt;/h3&gt; 
&lt;p&gt;因为Athena历史查询记录日志只保留45天，我们通过一段Python代码将Athena历史查询记录日志持续的，增量的导入到Amazon S3中，利用DynamoDB记录每次导出的最近位置，下次导出的时候，从上次导出的最新位置开始增量导出，避免产生重复数据，我们也可以将这段代码部署在在Lambda上，通过CloudWatch Event定时触发同步日志到Amazon S3。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;创建&lt;/strong&gt;&lt;strong&gt;DynamoDB表，保存每次增量导入的最新位置&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;表名称：athena_his_sql&lt;/p&gt; 
&lt;p&gt;主分区键：workgroup&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;创建&lt;/strong&gt;&lt;strong&gt;Lambda函数athena_his_fun&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;将下面的脚本复制到Lambda的入口脚本lambda_function.py（Lambda函数执行的角色需要具备操作Amazon S3读写，DynamoDB读写的权限）并修改Lambda的内存（500M）和超时时间（10min）。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import boto3
import time
import io
import json
import uuid
from datetime import datetime, date
def lambda_handler(event, context):
    # TODO implement
    to_scrape=5000
    page_size=50
    bucket = "quandata1"
    prefix = "athena_his/"
    s3_client = boto3.client('s3')
    ath = boto3.client('athena')
    paginator = ath.get_paginator("list_query_executions")
    dynamodb = boto3.resource('dynamodb')
    def json_serial(obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        raise TypeError("Type %s not serializable" % type(obj))
    df = []
    break_flag = False
    for workgroup in [w['Name'] for w in ath.list_work_groups()['WorkGroups']]:
        print(f'running {workgroup}')
        i=0
        table = dynamodb.Table('athena_his_sql')
        response = table.get_item(Key={'workgroup': workgroup,})
        curr_query_id = ''
        if  ("Item" in response): curr_query_id = response['Item']['curr_query_id']
        print("get ddb curr_id: " + workgroup + curr_query_id)
        args = {"WorkGroup": workgroup, "PaginationConfig": {"MaxItems": to_scrape, "PageSize": page_size}}
        for page in paginator.paginate(**args):
            query_ids = page['QueryExecutionIds']
            for query_id in query_ids:
                print("query_id:" + query_id)
                if i == 0:
                    table.update_item(
                        Key={'workgroup': workgroup,},
                        UpdateExpression='SET curr_query_id = :val1',
                        ExpressionAttributeValues={':val1': query_id})
                    print("update ddb curr_id: " + query_id)
                if query_id == curr_query_id:
                    break_flag=True
                    break
                query_metadata = ath.get_query_execution(QueryExecutionId=query_id)['QueryExecution']
                df.append(query_metadata)
                i += 1
            if break_flag==True:
                break
            time.sleep(1)
    json_writer = io.BytesIO()
    for record in df:
        line = json.dumps(record, default=json_serial) + "\n"
        json_writer.write(line.encode())
    s3_client.put_object(
        Bucket=bucket,
        Key=prefix + "%s.json" % uuid.uuid4(),
        ContentType='text/json',
        Body=json_writer.getvalue()
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;部署完毕后设置利用CloudWatch Event定时触发执行（例如按小时触发）&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 脚本执行后，会在DynamoDB的表athena_his_sql中更新当前最新的查询ID，方便后续增量导出。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 利用Amazon CLI或者控制台检查Amazon S3路径下是否正确上传了日志文件，（注：本方案没有对上传到S3的数据进行分区存放，可以参考下文CloudTrail日志的方式利用Athena的分区投影功能实现自动分区管理）。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;创建Athena历史记录日志表&lt;/h3&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE EXTERNAL TABLE athena_queries (
    QueryExecutionId string,
    Query string,
    StatementType string,
    Status struct&amp;lt;State:string,SubmissionDateTime:string,CompletionDateTime:string&amp;gt;,
    Statistics struct&amp;lt;EngineExecutionTimeInMillis:int,DataScannedInBytes:int, TotalExecutionTimeInMillis:int, QueryQueueTimeInMillis:int, QueryPlanningTimeInMillis:int, ServiceProcessingTimeInMillis:int&amp;gt;,
    WorkGroup string
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
LOCATION 's3://quandata1/athena_his';
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;创建CloudTrail日志表&lt;/h3&gt; 
&lt;p&gt;开启CloudTrail跟踪，将CloudTrail日志通过跟踪功能持续保存到S3中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 创建CloudTrail日志表cloudtrail_logs，建表语句中LOCATION根据实际跟踪配置的S3路径填写。使用Athena分区投影功能自动进行分区管理，降低查询时间和数据扫描量。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;CREATE EXTERNAL TABLE cloudtrail_logs(
    eventVersion STRING,
    userIdentity STRUCT&amp;lt;
        type: STRING,
        principalId: STRING,
        arn: STRING,
        accountId: STRING,
        invokedBy: STRING,
        accessKeyId: STRING,
        userName: STRING,
        sessionContext: STRUCT&amp;lt;
            attributes: STRUCT&amp;lt;
                mfaAuthenticated: STRING,
                creationDate: STRING&amp;gt;,
            sessionIssuer: STRUCT&amp;lt;
                type: STRING,
                principalId: STRING,
                arn: STRING,
                accountId: STRING,
                userName: STRING&amp;gt;&amp;gt;&amp;gt;,
    eventTime STRING,
    eventSource STRING,
    eventName STRING,
    awsRegion STRING,
    sourceIpAddress STRING,
    userAgent STRING,
    errorCode STRING,
    errorMessage STRING,
    requestParameters STRING,
    responseElements STRING,
    additionalEventData STRING,
    requestId STRING,
    eventId STRING,
    readOnly STRING,
    resources ARRAY&amp;lt;STRUCT&amp;lt;
        arn: STRING,
        accountId: STRING,
        type: STRING&amp;gt;&amp;gt;,
    eventType STRING,
    apiVersion STRING,
    recipientAccountId STRING,
    serviceEventDetails STRING,
    sharedEventID STRING,
    vpcEndpointId STRING
  )
PARTITIONED BY (
   `timestamp` string)
ROW FORMAT SERDE 'com.amazon.emr.hive.serde.CloudTrailSerde'
STORED AS INPUTFORMAT 'com.amazon.emr.cloudtrail.CloudTrailInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  's3://bucket/AWSLogs/account-id/CloudTrail/aws-region'
TBLPROPERTIES (
  'projection.enabled'='true', 
  'projection.timestamp.format'='yyyy/MM/dd', 
  'projection.timestamp.interval'='1', 
  'projection.timestamp.interval.unit'='DAYS', 
  'projection.timestamp.range'='2021/01/01,NOW', 
  'projection.timestamp.type'='date', 
  'storage.location.template'='s3://bucket/AWSLogs/account-id/CloudTrail/aws-region/${timestamp}')
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;使用Athena对数据进行分析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;查看不同&lt;/strong&gt;&lt;strong&gt;SQL语句的执行总次数排名&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select count(*),query from athena_queries group by query order by 1 desc limit 10&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看执行状态失败的&lt;/strong&gt;&lt;strong&gt;SQL总数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select count(*) from athena_queries where status.state='FAILED'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看执行超过特定执行时长的历史&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select query from athena_queries where statistics.totalexecutiontimeinmillis &amp;gt;=5000&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看超过特定数据扫描量的历史&lt;/strong&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select query from athena_queries where statistics.datascannedinbytes &amp;gt;=10741612544&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;根据&lt;/strong&gt;&lt;strong&gt;IAM用户统计数据扫描量&lt;/strong&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;select sum(b.statistics.datascannedinbytes),
a.userIdentity.username 
from 
cloudtrail_logs a,
athena_queries b 
where 
a.eventsource='athena.amazonaws.com' and a.eventName='StartQueryExecution' and 
a.responseElements != 'null' and substr(a.responseElements,22,36) = b.queryexecutionid 
group by 
a.userIdentity.username
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;使用Amazon Quicksight可视化分析结果&lt;/h2&gt; 
&lt;p&gt;利用SQL的方式（将cloudtrail_logs和athena_queries两张表联表查询）创建QuickSight中Athena数据集，然后根据实际需要在Amazon QuickSight创建可视化图表。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.queryexecutionid,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.query,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statementtype,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.State,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.SubmissionDateTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.status.CompletionDateTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.EngineExecutionTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.DataScannedInBytes,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.TotalExecutionTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.QueryQueueTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.QueryPlanningTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.statistics.ServiceProcessingTimeInMillis,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;b.workgroup,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.userIdentity.username&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;from&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;cloudtrail_logs a,&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;athena_queries b&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;where&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.eventsource='athena.amazonaws.com' and a.eventName='StartQueryExecution' and&lt;/code&gt;&lt;/p&gt; 
&lt;p style="padding-left: 40px"&gt;&lt;code&gt;a.responseElements != 'null' and substr(a.responseElements,22,36) = b.queryexecutionid&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;创建可视化图表如下&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/enhance-amazon-athenas-statistical-analysis-function-for-historical-query-records7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;通过本文介绍的方案可以更长时间的保留Athena查询历史日志，通过对Athena历史查询日志的分析，让我们可以直观的了解和掌握Athena的使用细节，查看Top SQL，检测应用性能问题，在时间、用户、SQL语句等多个维度增强对Athena使用的洞察。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/querying.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/querying.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/monitor-with-cloudtrail.html"&gt;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/monitor-with-cloudtrail.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html"&gt;https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xiangqua.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;柳向全&lt;/h3&gt; 
  &lt;p&gt;AWS 解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，目前主要专注于容器和大数据技术领域研究和AWS云服务在国内和全球的应用和推广。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>云原生编排数据分析管道初探</title>
		<link>https://aws.amazon.com/cn/blogs/china/preliminary-study-on-cloud-native-data-analysis-pipeline-orchestration/</link>
				<pubDate>Tue, 31 Aug 2021 09:38:55 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[AWS Glue]]></category>
		<category><![CDATA[AWS Step Functions]]></category>

		<guid isPermaLink="false">0b70c5edda6b82f38e382a0cee30e9d3989f70d1</guid>
				<description>公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL) 过程进行任务编排。要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施。二是编排好数据管道的 ETL 任务顺序。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。</description>
								<content:encoded>&lt;h2&gt;摘要&lt;/h2&gt; 
&lt;p&gt;公有云是适合数据分析和大数据处理的天然平台。近年来，云服务和开源社区涌现出许多优秀的工作流编排工具，方便就数据分析中复杂的抽取转换加载 (ETL) 过程进行任务编排。亚马逊云科技（亚马逊）的 Step Functions 状态机和开源社区的 Airflow 是其中的典型代表。要成功运行数据分析管道，需要至少两个必要准备，一是搭建好支持运行数据管道的基础设施，例如部署好 Airflow 的调度器和执行器等。二是编排好数据管道的 ETL 任务顺序，例如状态机的 JSON 定义文件或者 Airflow 的有向无环图定义。前者涉及运维，后者事关业务。从数据分析的角度，则希望运维难度最小，业务易用度最大。本文从上述两个角度切入，就 Airflow 和状态机支持数据分析管道的情况进行分析，并初步探讨云原生编排数据管道的方法和意义。&lt;/p&gt; 
&lt;h2&gt;Abstract&lt;/h2&gt; 
&lt;p&gt;Public cloud is one of the most suitable platforms for data analysis and big data processing. In recent years, many excellent workflow orchestration tools have proliferated in cloud services and open source communities to facilitate orchestration of complex ETL jobs in data analysis. AWS Step Functions and Airflow from open source community are two typical examples. To run the data analysis pipelines successfully, at least two steps are necessary. Firstly, to build the infrastructure to support running the data pipelines, such as the deployment of Airflow’s schedulers and executors. Secondly, to orchestrate the ETL tasks in the data pipelines, such as the JSON definition of the state machine or Airflow’s directed acyclic graph definition. The former involves dev-ops, while the latter is related to application. From the perspective of data analysis, it is ideal that the difficulty of dev-ops is minimized, and the user-friendliness of application is maximized. This article analyzes how well Airflow and Step Functions support data analysis pipelines from the above two points of view, and preliminarily discusses the methodology and significance of cloud-native services for orchestrating data pipelines.&lt;/p&gt; 
&lt;h3&gt;目标读者&lt;/h3&gt; 
&lt;p&gt;本文预期读者需要掌握以下技术的基础知识：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache Airflow 及其相关概念&lt;/li&gt; 
 &lt;li&gt;亚马逊开发包：CDK, SDK&lt;/li&gt; 
 &lt;li&gt;亚马逊服务：CloudTrail, EventBridge, Glue, Lambda, MWAA, Redshift, S3, Step Functions, VPC, 密码管理器&lt;/li&gt; 
 &lt;li&gt;语言：Javascript, JSON, Python&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;开放源代码&lt;/h3&gt; 
&lt;p&gt;本文所述解决方案源代码开放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline"&gt;https://github.com/aws-samples/aws-stepfunctions-data-processing-pipeline&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;绪论&lt;/h2&gt; 
&lt;p&gt;2020年11月，亚马逊发布了托管的 Airflow 服务，全称为 Managed Workflows for Apache Airflow (MWAA)，支持 1.10.12 版。2021年5月开始支持 2.0.2 版。但截至目前（2021年8月），中国北京区、宁夏区和香港区皆未提供托管服务。如果要使用 Airflow，则需要自行搭建部署，例如利用 Elastic Container Service。或者换成其他云原生的编排服务，例如 Step Functions 状态机或 Simple Workflow Service。本文以某 MWAA 的数据分析指导教程为引子，介绍 MWAA 资源代码化的方法，并对如何在中国区使用云原生服务达到类似编排数据分析管道的目的，进行初探。&lt;/p&gt; 
&lt;h2&gt;教程简介&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;是指导利用 MWAA 搭建数据分析管道的教程。该分析管道较简单，线性分为五步，分别是监控文件，爬元数据，转换数据，整合数据，保存结果。简单起见，本文将第四步改造为 Glue 任务，不使用 Elastic MapReduce 集群。部署好的数据管道有向无环图如下：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline1.png" width="624"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以 MWAA 为基础的架构图如下所示。虚线和编号表示该数据管道运行时的数据流向和任务执行顺序。此处不同服务的调用是通过 Airflow 的操作符间接完成的，以 Python 定义在数据管道的有向无环图中。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline2.png" width="500"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;根据该教程介绍，完成时间为一小时左右。抛开初学者的因素，所用时间较长主要是因为所涉及的资源及其配置都是在亚马逊控制台上手工完成，非常耗时，效率低下。如果利用资源代码化技术，则部署时间可以在数分钟内完成（排除 MWAA 自身启动需要的约半小时），提高工作效率，尤其在需要多环境部署测试的情况下。&lt;/p&gt; 
&lt;h3&gt;资源代码化&lt;/h3&gt; 
&lt;p&gt;利用亚马逊云开发包 (Cloud Development Kit)，可快速构建云资源部署程序。结合相关代码仓库管理工具如 github，可代码化管理资源的创建和修改过程，方便协同工作和排错溯源。限于篇幅以下仅展示关键代码。完整代码请参阅开放源代码。首先建立 Redshift 集群。云开发包建立好集群后，会自动在密码管理器中新建一密码项，即为该集群的连接密码，全程密码无暴露。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCluster(landingZone, subnetGroup) {
    return new redshift.Cluster(this, "MainCluster", {
        masterUser: { masterUsername: "admin" },
        vpc: landingZone.vpc,
        numberOfNodes: 2,
        publiclyAccessible: false,
        defaultDatabaseName: RedshiftStack.DB_NAME,
        securityGroups: [landingZone.securityGroup],
        nodeType: redshift.NodeType.DC2_LARGE,
        roles: [this.role],
        subnetGroup: subnetGroup
    })
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其次是建立 MWAA 环境。简化起见配置为可以公网访问。实际生产中建议配置为私网访问。MWAA 对网络配置有特别要求，若不达标环境可能无法启动。子网建议配置为私有子网，即有路由到 NAT 网关。具体请参阅使用手册。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createEnvironment(envName, role, landingZone, bucket) {
    return new airflow.CfnEnvironment(this, "Lab", {
        name: envName,
        airflowVersion: "2.0.2",
        environmentClass: "mw1.small",
        executionRoleArn: role.roleArn,
        sourceBucketArn: bucket.bucketArn,
        webserverAccessMode: "PUBLIC_ONLY",
        dagS3Path:           "airflow/lab/dags",
        pluginsS3Path:       "airflow/lab/plugins/awsairflowlib_202.zip",
        requirementsS3Path:  "airflow/lab/requirements/requirements.txt",
        networkConfiguration: {
            securityGroupIds: [landingZone.securityGroup.securityGroupId],
            subnetIds: landingZone.vpc.privateSubnets.map(subnet =&amp;gt; subnet.subnetId)
        }
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;MWAA 配置好以后，还需要把有向无环图定义文件上传到存储桶指定位置。利用云开发包的 S3 部署模块完成：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;uploadDagFile(bucket) {
    new deploy.BucketDeployment(this, "DagScript",
        sources: [deploy.Source.asset(path.join(__dirname, '../../scripts/airflow/lab/dags/'))],
        destinationBucket: bucket,
        destinationKeyPrefix: 'airflow/lab/dags/'
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;至此就完成了 MWAA 相关资源的部署程序。部署上述 MWAA 大约耗时半小时，因为涉及服务器的启动连接等。部署耗时长也凸显出非无服务器服务的弊端。当环境状态变为“可用”后，点击“打开 Airflow UI”即可打开 Airflow 的控制台。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline3.png" width="800"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;部署完成后，根据教程即可完成数据分析管道相关操作。Airflow 控制台可以显示数据管道完成时间甘特图，形象展示各任务耗时多寡。这是其亮点之一。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline4.png" width="800"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;安全隐患&lt;/h3&gt; 
&lt;p&gt;最后一步把存储桶文件复制到 Redshift，需要在 Airflow 控制台配置到 Redshift 的连接。连接属性包含用户名和密码明文。此处有暴露密码明文的安全隐患。下面介绍的云原生技术通过密码管理器实现无缝连接，可有效规避密码暴露风险，切实提高系统安全水平。&lt;/p&gt; 
&lt;h2&gt;云原生编排&lt;/h2&gt; 
&lt;p&gt;目前 MWAA 尚不支持中国区，故需要自行搭建并维护 Airflow 环境，例如在 ECS Fargate 上。但是运维难度不容小觑。亚马逊提供了其他编排服务，例如状态机，完全可以代替 Airflow 对数据管道进行编排。此外状态机是无服务器的，毋需关心并事先设定服务器数量性能等运维难题。使用云原生服务，和其他服务紧密集成，可最大化服务效益，增强安全性。和教程数据分析管道等价的状态机工作流如下所示。状态机跨服务集成支持直接启动 Glue 任务，较为简单。其他步骤需做些许变通。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline5.png" width="400"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以云原生服务为基础的架构图如下所示。状态机在各服务之间调度，其中 Glue 任务可以直接执行。爬虫任务需要通过 Lambda 函数辅助。把存储桶的数据载入到 Redshift 可以有多种方法完成，例如 Glue 任务可以直接连接 Redshift 并保存数据。为了和教程中的步骤一一对应，此处利用 Lambda 函数来辅助完成。存储桶文件监控则通过跟踪与规则联合完成。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/a-preliminary-exploration-of-cloud-native-orchestration-data-analysis-pipeline6.png" width="500"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;爬元数据&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成目前暂不支持调用 Glue 爬虫，需替代方案。此处利用两个 Lambda 函数和轮询机制实现相同功能。启动爬虫很简单：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;await glue.startCrawler({Name: crawlerName}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫状态查询，如果不是“就绪”状态，则等待十秒后再次查询，直至成功或者超时。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;exports.handler = async event =&amp;gt; {
    response = await glue.getCrawler({Name: event.crawlerName}).promise();
    const state = response.Crawler.State;
    return state == "READY";
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;爬虫调用代替方案的其他两步可以利用状态机的“选择”和“等待”原生操作符完成。这里传入变量 next 作为爬虫轮询结束后的下一步操作。以下代码可作为爬虫调用的模版使用。若想提高响应速度可缩短等待时长。一个典型的爬虫任务需时数分钟。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCrawlerStep(next) {
    const crawlTask = new task.LambdaInvoke(this, "Crawl", {
        lambdaFunction: this.lambda("CrawlLambda", role, "../lambda/crawler/crawl"),
        payload: sf.TaskInput.fromObject({CrawlerTagName: "NF1-Airflow-Lab-RawGreenCrawler"}),
        payloadResponseOnly: true,
        resultPath: "$.crawlerName",
    });
    const checkCrawled = new task.LambdaInvoke(this, "Check if crawled", {
        lambdaFunction: this.lambda("CheckCrawledLambda", role, "../../lambda/crawler/check"),
        payloadResponseOnly: true,
        resultPath: "$.crawled",
    });
    const wait = 10;
    crawlTask.next(checkCrawled)
    .next(new sf.Choice(this, "Is crawled?")
        .when(sf.Condition.booleanEquals("$.crawled", true), next)
        .otherwise(new sf.Wait(this, `Wait for ${wait} Seconds`, {
            time: sf.WaitTime.duration(core.Duration.seconds(wait)),
        }).next(checkCrawled)));
    return crawlTask;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;保存结果&lt;/h3&gt; 
&lt;p&gt;状态机的跨服务集成尚未对 Redshift 提供支持，对保存结果需要替代方案。Airflow 提供 S3ToRedshiftOperator 操作符将数据从存储桶复制到 Redshift 表中。本质上是通过 Redshift 的 COPY 命令实现的。替代方案亦遵循此思路。利用亚马逊软件开发包的 RedshiftData 模块，可以执行 SQL 语言和数据操作命令。此处通过密码 ARN 获取密码，完全规避密码明文暴露的问题。此外 Glue 也提供应用接口支持直接把数据保存到 Redshift。在保存数据到数据仓库之前可多做一步，将目标表做清空操作（truncate 或 delete），避免因原表中有数据导致冗余。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;await data.executeStatement({
    ClusterIdentifier: event.ClusterIdentifier,
    Database: event.Database,
    SecretArn: event.SecretArn,
    Sql: event.Sql
}).promise();&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;状态机保存结果的替代方案可以一个 Lambda 函数实现。在生产环境，此处建议以更细粒度和最小化原则配置该函数所赋予的权限，夯实系统安全性。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createCopyS3ToRedshift(bucket, redshift) {
    const dir = bucket.s3UrlForObject("airflow/lab/data/aggregated");
    const sql = `copy nyc.green from '${dir}' iam_role '${redshift.role.roleArn}' format as parquet;`;

    return new task.LambdaInvoke(this, "Copy S3 to Redshift", {
        lambdaFunction: this.lambda("CopyToRedshiftLambda", role, "../lambda/redshift/execute"),
        payloadResponseOnly: true,
        payload: sf.TaskInput.fromObject({
            ClusterIdentifier: redshift.cluster.clusterName,
            Database: RedshiftStack.DB_NAME,
            SecretArn: redshift.cluster.secret.secretArn,
            Sql: sql,
        })
    });
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;监控文件&lt;/h3&gt; 
&lt;p&gt;最后还需要处理对存储桶文件的监控任务。Airflow 提供 S3PrefixSensor 来监控文件上传到某个桶，进而触发数据管道进行数据处理。此处有多种方式监控存储桶里面的文件。例如 S3 自带的事件通知功能。不过事件通知的目标不支持启动状态机，还需要 Lambda 辅助。或者可以通过 CloudTrail 跟踪桶写入操作，然后通过 EventBridge 的个规则来捕获事件进而触发状态机执行。跟踪只需要关注特定桶特定目录的写入即可。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createTrail(logBucket, monitorBucket) {
    const trail = new cloudtrail.Trail(this, 'CloudTrail', {
        bucket: logBucket,
        s3KeyPrefix: "data-trail",
    });
    trail.addS3EventSelector(
        [{bucket: monitorBucket, objectPrefix: "airflow/lab/data/raw"}],
        {readWriteType: cloudtrail.ReadWriteType.WRITE_ONLY});
    return trail;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;捕获规则和跟踪一样，只需要捕获特定桶特定目录的写入即可，此处利用 prefix 前缀操作符来限定。规则目标可以直接启动状态机，开启数据分析管道进程。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-js"&gt;createS3Event(machine, bucket) {
    new events.Rule(this, "S3StepFunctions", {
        description: "S3 invoke StepFunctions",
        eventPattern: {
            source: [ "aws.s3" ],
            detailType: [ "AWS API Call via CloudTrail" ],
            detail: {
                "eventSource": [ "s3.amazonaws.com" ],
                "eventName": [ "PutObject" ],
                "requestParameters": {
                    "bucketName": [ bucket.bucketName ],
                    "key": [{ "prefix": "airflow/lab/data/raw" }]
                }}},
        targets: [ new targets.SfnStateMachine(machine) ]
    });
}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h2&gt;方案对比&lt;/h2&gt; 
&lt;p&gt;至此云原生编排数据分析管道的改造宣告完成。回顾本文，重新审视和对比各项方案的利弊得失，可以更好的帮助读者选择更适合业务场景的方案。例如，如果在中国区新建数据分析管道项目，则建议使用状态机。如果从 Airflow 的老环境迁移上云，则建议使用 MWAA 或者自建 Airflow，这样可以复用积累的代码。亦可两者并行，对新的数据管道用云原生方案。&lt;/p&gt; 
&lt;table style="border-collapse: collapse;border: 3px solid grey" border="1"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;状态机&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MWAA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;自建 Airflow&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;编写语言&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;JSON 及云开发包支持的所有语言&lt;br&gt; (TypeScript, JavaScript, Python, Java, and C#)&lt;/td&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;支持中国区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;无服务器&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;托管服务&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;连接密码暴露&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;开源社区&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;部署时间（近似值）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;开箱即用&lt;/td&gt; 
   &lt;td&gt;一小时&lt;/td&gt; 
   &lt;td&gt;数小时到数天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Airflow &lt;/strong&gt;&lt;strong&gt;最新版本&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;（2021&lt;/strong&gt;&lt;strong&gt;年8&lt;/strong&gt;&lt;strong&gt;月）&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;不适用&lt;/td&gt; 
   &lt;td&gt;2.0.2&lt;/td&gt; 
   &lt;td&gt;2.1.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;服务调度集成&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;云原生&lt;/td&gt; 
   &lt;td&gt;通过操作符&lt;/td&gt; 
   &lt;td&gt;通过操作符&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;本文从 MWAA 的数据分析管道指导教程为引子，介绍利用云开发包快速搭建部署程序的方法，并以状态机为编排平台，尝试改造其为云原生编排的数据管道，辅以几个关键操作的替代方案介绍。本文初步探讨云原生编排数据分析管道的方法，借此抛砖引玉，供读者讨论。从“方案对比”一节可以看出，云原生的编排方案有诸多优势，尤其表现在零部署时间，无服务器化管理，多语言支持和增强安全性上。相信随着跨服务集成的深度和广度越来越高，云原生的编排优势会如虎添翼，成为数据分析管道编排平台的不二选择。&lt;/p&gt; 
&lt;h3&gt;工作展望&lt;/h3&gt; 
&lt;p&gt;有几个有趣的展开方向。首先就 Airflow 的诸多操作符，研究云原生改造方法，以期对所有 Airflow 有向无环图皆可支持改造，利于迁移。能自动化改造更佳。其次研究将 Airflow 的数据分析管道以 Glue 的蓝图和工作流为基础进行改造。Glue 蓝图的编排平台和状态机的编排平台是一对有趣的对比。再者就自建 Airflow 的方案如何高效搭建基础设施并降低运维难度亦值得关注。&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://amazon-mwaa-for-analytics.workshop.aws/en/"&gt;MWAA 数据分析管道指导教程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/clementy.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;袁文俊&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务部顾问。曾在亚马逊美国西雅图总部工作多年，就职于 Amazon Relational Database Service (RDS) 关系型数据库服务开发团队。拥有丰富的后端开发及运维经验。现负责业务持续性及可扩展性运行、企业应用及数据库上云迁移、云上灾难恢复管理系统等架构咨询、方案设计及项目实施工作。他拥有复旦大学理学学士学位和香港大学哲学硕士学位。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/xzhom.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;赵鑫&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技专业服务团队数据架构师，专注于生命科学、自动驾驶领域的数据架构与数据分析&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用托管节点组结合启动模板简化EKS升级与运维</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance/</link>
				<pubDate>Tue, 31 Aug 2021 04:09:59 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Containers]]></category>
		<category><![CDATA[Amazon EKS]]></category>
		<category><![CDATA[Amazon EKS Managed Node Group]]></category>
		<category><![CDATA[EC2 Launch Template]]></category>

		<guid isPermaLink="false">c7a2915de4f1e2f686bc64ad252f93fc8fe230e0</guid>
				<description>随着应用容器化不断流行与深入，采用Kubernetes（K8S）作为容器编排方式的应用也随之增加。作为亚马逊云科技的用户，在云上使用Amazon Web Service托管的K8S服务Elastic Kubernetes Service（EKS）服务的客户也在不断增加。同时根据K8S社区的发布规则K8S每年会有三个小版本的发布， 相应的EKS也会跟随上游K8S的版本发布3个版本，目前支持的版本以及相应终止支持的时间信息可以参考亚马逊EKS发布日历。</description>
								<content:encoded>&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;随着应用容器化不断流行与深入，采用Kubernetes（K8S）作为容器编排方式的应用也随之增加。作为亚马逊云科技的用户，在云上使用Amazon Web Service托管的K8S服务Elastic Kubernetes Service（EKS）服务的客户也在不断增加。同时根据K8S社区的发布规则K8S每年会有三个小版本的发布， 相应的EKS也会跟随上游K8S的版本发布3个版本，目前支持的版本以及相应终止支持的时间信息可以参考&lt;a href="https://docs.aws.amazon.com/zh_cn/eks/latest/userguide/kubernetes-versions.html"&gt;亚马逊EKS发布日历&lt;/a&gt;。每个上游的K8S版本都会有1年支持窗口加上2个月升级过渡窗口，为了保持与K8S社区版本的同步来获得社区的支持，客户每隔一段时间都要对现有的K8S或者EKS集群做升级，也就是说K8S与EKS的升级已经成为常态。&lt;/p&gt; 
&lt;p&gt;在EKS上这个升级主要涉及到控制平面升级、数据平面升级与插件组件升级。其中以数据平面的升级最为繁琐与复杂，所以本着减少无差别的繁重的运维工作为出发点，本文通过一个端到端的实验详细介绍通过使用托管节点组与启动模板简化客户的升级操作的过程与方法，从而为运维人员减负。并实现应用的平滑升级与灵活回退，进而保证应用与业务的稳定和可用性。&lt;/p&gt; 
&lt;p&gt;了解EKS的用户或者读者知道EKS的数据平面可以分为有服务器与无服务器两大类：有服务器即采用EC2的方式来运行K8S的应用；无服务器的方式即EKS Fargete，客户将工作负载部署在Fargate的环境而不是自己的VPC内，EKS节点对客户透明。有服务器EC2的节点管理方式又分为两种模式：&lt;a href="https://eksctl.io/usage/eks-managed-nodes/"&gt;托管节点组&lt;/a&gt;（Managed Node Group）与&lt;a href="https://eksctl.io/usage/nodegroup-upgrade/"&gt;非托管节点组&lt;/a&gt;（Unmanaged Node Group）。非托管节点组的命名来自于官方的EKS创建与维护工具eksctl.io文档中Unmanaged Node Group的中文直译，根据EKS官方文档， 非托管节点组模式被称为自行管理的节点（Self-managed nodes），为了简化与对比起见本文统一称为非托管节点组。托管节点组即将集群EC2节点的创建与生命周期管理由EKS服务来自动化管理，不需要客户干预。根据&lt;a href="https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability"&gt;eksctl对非托管节点组的设计原则&lt;/a&gt;，非托管节点组中的节点除了可以做扩缩容其他配置均不可变。下表列出了两种模式的主要区别：&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;项目&lt;/td&gt; 
   &lt;td width="198"&gt;托管节点组&lt;/td&gt; 
   &lt;td width="331"&gt;非托管节点组&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;升级方法&lt;/td&gt; 
   &lt;td width="198"&gt;原地升级&lt;/td&gt; 
   &lt;td width="331"&gt; &lt;p&gt;需要创建新的非托管节点组&lt;/p&gt; &lt;p&gt;（注：适用于通过eksctl创建的非托管节点组，其他方式可以通过更新CloudFormation&lt;/p&gt; &lt;p&gt;栈的方法更新AMI来升级，细节可以参考：&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/update-workers.html"&gt;官方文档&lt;/a&gt;）&lt;/p&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;EKS管理控制台可见&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;配置变更支持&lt;/td&gt; 
   &lt;td width="198"&gt; &lt;p&gt;是（可以变更的选项有：Min Size，Max Size，Desired Size, Kubernetes labels, taints, tags,&lt;/p&gt; &lt;p&gt;Maximum unavailable等配置，其他配置项变更需要通过切换启动模板版本实现。）&lt;/p&gt;&lt;/td&gt; 
   &lt;td width="331"&gt;否（除节点数量扩缩）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;支持关联启动模板&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="94"&gt;自定义AMI支持&lt;/td&gt; 
   &lt;td width="198"&gt;是&lt;/td&gt; 
   &lt;td width="331"&gt;是&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;考虑到EKS 1.17将于2021年11月终止支持，同时目前绝大部分客户使用的还是EC2的方式，并且因为非托管节点组相对于托管节点组的功能是更早发布，加上早期的托管节点组功能较少的原因，一部分客户还停留在非托管节点组的模式，所以本文的实验通过将非托管节点组转换为托管节点组结合启动模板的方式简化EKS 集群从1.17升级到1.18的升级过程（虽然本实验进行的的是1.17到1.18的升级，但过程和其中的方法对其他EKS版本的升级同样适用，比如从1.15升级到1.16或者1.18升级到1.19）。其中主要内容涵盖：控制平面升级、数据平面非托管节点组迁移到托管节点组、托管节点组升级与变更等。&lt;/p&gt; 
&lt;p&gt;在升级路径的选择上，也可以先将控制平面由1.17升级到1.18，然后创建托管节点组，再将工作负载由非托管节点组迁移到托管节点组，这样可以减少一次数据平面托管节点组的升级，加快集群整体升级的过程。因为本文的重点是介绍推广托管节点组结合启动模板的实践方法，先升级控制平面再创建托管节点组的做法，笔者测试下来对于文中简单的样例应用Nginx是可以的，遵从K8S官方的&lt;a href="https://kubernetes.io/releases/version-skew-policy/"&gt;Version Skew Policy&lt;/a&gt;：kubelet must not be newer than kube-apiserver, and may be up to two minor versions older。笔者尝试过将控制平面从1.17升级到1.18再连续升级到1.19，然后再创建托管节点组与迁移工作负载也是可以成功通过的，但如果集群中有对1.17到1.18/1.19版本变化敏感或者需要改造的应用，稳妥起见还是建议按照本实验的顺序来操作，并引入必要的测试。有兴趣的读者可以自行测试验证。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;本文目标读者：EKS运维与管理人员&lt;/p&gt; 
&lt;p&gt;实验所需时长：3小时&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;操作步骤&lt;/h2&gt; 
&lt;p&gt;前提：当前使用的用户具有Administrator Access权限&lt;/p&gt; 
&lt;h3&gt;准备Cloud9实验环境&lt;/h3&gt; 
&lt;p&gt;在AWS管理控制台中选择Cloud9服务，然后创建一个名称为：eksworkshop的环境，将Cost-saving setting选项设置为：After four hours，其他配置保持默认。创建完毕后关闭Welcome和底部的工作区页面，然后在主工作区中打开一个新的Terminal。&lt;/p&gt; 
&lt;p&gt;在IAM服务中，使用&lt;a href="https://console.aws.amazon.com/iam/home#/roles$new?step=type&amp;amp;commonUseCase=EC2%2BEC2&amp;amp;selectedUseCase=EC2&amp;amp;policies=arn:aws:iam::aws:policy%2FAdministratorAccess"&gt;链接&lt;/a&gt;创建一个名称为：eksworkshop-admin的角色，确认：AWS service和EC2被选中，点击下一步，确认AdministratorAccess策略被选中，点击下一步，跳过Tag选项，点击下一步在Review页面中输入eksworkshop-admin作为新角色的名称，点击创建角色完成创建。&lt;/p&gt; 
&lt;p&gt;点击&lt;a href="https://console.aws.amazon.com/ec2/v2/home?#Instances:tag:Name=aws-cloud9-eksworkshop;sort=desc:launchTime"&gt;链接&lt;/a&gt;在EC2服务中查看刚刚创建的Cloud9环境对应的EC2实例，选中该实例，然后在菜单选择：Actions / Security / Modify IAM Role，在IAM Role的下拉列表中选择eksworkshop-admin的角色，点击保存。&lt;/p&gt; 
&lt;p&gt;返回刚刚创建好的Cloud9环境，点击页面右上角的齿轮，打开首选项设置页面，然后选择AWS SETTINGS，关闭AWS managed temporary credentials单选框，最后关闭首选项设置页面。&lt;/p&gt; 
&lt;p&gt;在打开的终端中运行以下命令确认临时的秘钥凭证已经被删除干净，并验证在返回结果的ARN 中包含eksworkshop-admin。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;rm -vf ${HOME}/.aws/credentials&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws sts get-caller-identity&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列脚本安装实验所需的Kubernetes 工具：eksctl，kubectl，helm，jq，aws cli&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;# create a folder for the scripts
mkdir ~/environment/scripts
# tools script
cat &amp;gt; ~/environment/scripts/install-tools &amp;lt;&amp;lt;-"EOF"
#!/bin/bash -ex
sudo yum install -y jq gettext bash-completion

# install kubectl
sudo curl --silent --location -o /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.18.10/bin/linux/amd64/kubectl
sudo chmod +x /usr/local/bin/kubectl
echo 'source &amp;lt;(kubectl completion bash)' &amp;gt;&amp;gt;~/.bashrc
source ~/.bashrc
# install eksctl
curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv -v /tmp/eksctl /usr/local/bin
if ! [ -x "$(command -v jq)" ] || ! [ -x "$(command -v envsubst)" ] || ! [ -x "$(command -v kubectl)" ] || ! [ -x "$(command -v eksctl)" ] || ! [ -x "$(command -v ssm-cli)" ]; then
  echo 'ERROR: tools not installed.' &amp;gt;&amp;amp;2
  exit 1
fi
#pip install awscli --upgrade --user
# install aws cli v2
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
. ~/.bash_profile
# install helm 3
curl -sSL https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
helm version --short
helm repo add stable https://charts.helm.sh/stable
helm completion bash &amp;gt;&amp;gt; ~/.bash_completion
. /etc/profile.d/bash_completion.sh
. ~/.bash_completion
source &amp;lt;(helm completion bash)
helm repo update
EOF
chmod +x ~/environment/scripts/install-tools
~/environment/scripts/install-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;创建EKS集群（版本：1.17）&lt;/h3&gt; 
&lt;p&gt;配置创建集群需要的环境变量&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account)
export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r '.region')
export EKS_CLUSTER_NAME=eksworkshop
export EKS_UNMANAGED_NODEGROUP_NAME=ung-1
export EKS_MANAGED_NODEGROUP_NAME=mng-1
export AWS_DEFAULT_REGION=$AWS_REGION
echo "export ACCOUNT_ID=${ACCOUNT_ID}" &amp;gt;&amp;gt; ~/.bash_profile
echo "export AWS_REGION=${AWS_REGION}" &amp;gt;&amp;gt; ~/.bash_profile
echo "export AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}" &amp;gt;&amp;gt; ~/.bashrc
echo "export EKS_CLUSTER_NAME=${EKS_CLUSTER_NAME}" &amp;gt;&amp;gt; ~/.bashrc
echo "export EKS_MANAGED_NODEGROUP_NAME=${EKS_MANAGED_NODEGROUP_NAME}" &amp;gt;&amp;gt; ~/.bashrc
echo "export EKS_UNMANAGED_NODEGROUP_NAME=${EKS_UNMANAGED_NODEGROUP_NAME}" &amp;gt;&amp;gt; ~/.bashrc
aws configure set default.region ${AWS_REGION}
aws configure get default.region
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;运行下列命令创建EKS集群配置模板文件 eks-cluster.yml.template&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;cat &amp;gt; ~/environment/scripts/eks-cluster.yml.template &amp;lt;&amp;lt;-"EOF"
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: $EKS_CLUSTER_NAME
  region: $AWS_REGION
  version: "1.17"
nodeGroups:
  - name: $EKS_UNMANAGED_NODEGROUP_NAME
    minSize: 1
    maxSize: 3
    desiredCapacity: 2
    labels: {role: unmanaged-ng-worker}
    tags:
      Name: unmanaged-ng-worker
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;利用 &lt;a href="https://eksctl.io/"&gt;eksctl &lt;/a&gt;工具来创建 EKS 集群，运行下列命令创建一个 EKS 1.17 的集群，同时会创建一个新的 VPC，并且在该VPC中创建 一个含有2个节点的非托管节点组，整个过程大概需要 20 分钟左右（集群和节点组各10分钟左右）。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;envsubst &amp;lt; ~/environment/scripts/eks-cluster.yml.template &amp;gt; ~/environment/scripts/eks-cluster.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl create cluster -f ~/environment/scripts/eks-cluster.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在EKS服务界面上验证集群eksworkshop已经成功创建。运行下列命令验证 EKS 集群节点组ung-1已经成功创建&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl get nodegroup --cluster $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令测试 EKS 集群节点是否正常工作&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get nodes --show-labels&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令将当前登录管理控制台的用户加入到EKS集群管理员组中，这样使得当前登录用户可以在EKS服务界面上查看集群信息。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;c9builder=$(aws cloud9 describe-environment-memberships --environment-id=$C9_PID | jq -r '.memberships[].userArn')
if echo ${c9builder} | grep -q user; then
	rolearn=${c9builder}
        echo Role ARN: ${rolearn}
elif echo ${c9builder} | grep -q assumed-role; then
        assumedrolename=$(echo ${c9builder} | awk -F/ '{print $(NF-1)}')
        rolearn=$(aws iam get-role --role-name ${assumedrolename} --query Role.Arn --output text) 
        echo Role ARN: ${rolearn}
fi
eksctl create iamidentitymapping --cluster $EKS_CLUSTER_NAME --arn ${rolearn} --group system:masters --username admin
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们可以在EC2控制台看到新创建了2个名称为eksworkshop-ung-1-Node类型为m5.large 的EC2实例，也可以在管理控制台的EKS服务的集群列表中查看刚刚创建好的集群节点、网络和其他集群配置信息。因为我们刚刚创建的是一个非托管节点组，所以如下图所示在EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute界面查看托管节点组为空&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 同时，因为eksctl工具的底层实现是依赖CloudFormation服务的，所以可以再CloudFormation服务的管理界面查看为了创建集群而新建的2个CloudFormaiton模板：集群控制平面CloudFormaiton Stack、非托管节点组CloudFormaiton Stack。+&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;部署样例工作负载&lt;/h3&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;cat &amp;gt; ~/environment/scripts/nginx.yaml &amp;lt;&amp;lt;-"EOF"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 10
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: "nginx"
spec:
  selector:
    app: nginx
  type: ClusterIP
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
EOF
kubectl apply -f ~/environment/scripts/nginx.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;通过下列命令参考样例Nginx程序已经成功部署&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get deploy&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;创建启动模板&lt;/h3&gt; 
&lt;p&gt;进入EC2服务，选择Launch Templates &amp;gt; Create launch template，分别填入&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Launch template name：demo&lt;/li&gt; 
 &lt;li&gt;Instance type：large&lt;/li&gt; 
 &lt;li&gt;Security groups：在EKS集群管理控制台 EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Networking中显示Cluster security groupInfo的安全组ID&lt;/li&gt; 
 &lt;li&gt;Resource Tags Key: Name, Value: eksworkshop-mng-1, Resource types: Instances&lt;/li&gt; 
 &lt;li&gt;User Data: 如果某些客户在使用非托管节点组的配置YAML文件中有使用：preBootstrapCommands或者overrideBootstrapCommand之类的一些自定义命令，那么在转换到托管节点组加启动模板这种方式后将不再支持，如果继续使用会出现错误：cannot set instanceType, ami, …, preBootstrapCommands, overrideBootstrapCommand, placement in managedNodeGroup when a launch template is supplied。用户可以将这些选项中配置的SHELL命令迁移到User Data中。如果有使用自定义AMI，则必须在User Data中填入下列命令将节点加入到集群，否则会出现错误：node bootstrapping script (UserData) must be set when using a custom AMI。具体User Data输入的MIME格式要求请参考这里的&lt;a href="https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html"&gt;官方文档&lt;/a&gt;。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;#!/bin/bash&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/eks/bootstrap.sh cluster_name&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;点击Create launch template创建启动模板。在启动模板的版本列表中查看刚刚创建好的版本号为1的启动模板，因为启动模板的版本是不可变的，只能通过选择版本1后点击Actions &amp;gt; Modify template (Create new version)来创建新的版本。&lt;/p&gt; 
&lt;p&gt;如果在EKS集群中有使用自定义AMI，那么可以在创建模板过程中指定已经定义好的AMI。需要注意的是，根据&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html"&gt;EKS升级官方文档&lt;/a&gt;在升级控制平面之前要求自定义AMI的节点版本需要与控制平面的版本相同。在本实验中来说就是要求自定义AMI及kubelet版本必须是1.17。这样当控制平面升级到1.18以后就会导致托管节点组还停留在1.17版本，存在一个小版本的差异。这样在托管节点组升级到1.18之前是不能将控制平面升级到版本1.19，否则得到错误提示：Nodegroups xxx must be updated to match cluster version 1.1x before updating cluster version。如果自定义AMI的节点组比控制平面低一个版本，则不能直接在界面上通过点击“Update now”操作来升级节点组。如果后续有继续将版本从1.18升级到更高版本的需求则需要根据目标EKS版本的EKS优化AMI重新定义自己的AMI，通过创建新的启动模板版本来指定这个新的AMI，然后再托管节点组中切换启动模板版本即可完成升级。具体切换启动模板版本的流程可以参考下面的章节“切换启动模板版本”。&lt;/p&gt; 
&lt;h3&gt;创建托管节点组&lt;/h3&gt; 
&lt;p&gt;运行下列命令设置环境变量并创建托管节点组&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;export LT_ID=$(aws ec2 describe-launch-templates --launch-template-name demo --output json | jq -r '.LaunchTemplates[0].LaunchTemplateId')
cat &amp;gt; ~/environment/scripts/mng-1.yml.template &amp;lt;&amp;lt;-"EOF"
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: $EKS_CLUSTER_NAME
  region: $AWS_REGION
  version: "1.17"
managedNodeGroups:
  - name: $EKS_MANAGED_NODEGROUP_NAME
    minSize: 1
    maxSize: 3
    desiredCapacity: 2
    labels: {role: managed-ng-worker}
    launchTemplate:
      id: $LT_ID
      version: "1"
EOF
envsubst &amp;lt; ~/environment/scripts/mng-1.yml.template &amp;gt; ~/environment/scripts/mng-1.yml
eksctl create nodegroup -f ~/environment/scripts/mng-1.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;整个过程大概需要 3分钟左右。之后我们可以在EC2控制台看到新创建了2个名称为eksworkshop-mng-1类型为m5.large 的EC2实例。同时因为我们刚刚创建的是一个托管节点组，所以如下图所示在EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute界面可以查看到刚刚创建的托管节点组。&lt;/p&gt; 
&lt;p&gt;注意上述托管节点组的配置文件中设置的版本1.17是与控制平面一致的版本，如果托管节点组配置的版本与EKS集群控制平面不一致时，eksctl会自动使用控制平面版本。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 从选中的部分可以看出托管节点组mng-1对应的启动模本名称为demo版本为1。也可以运行下列命令验证 EKS 集群节点组mng-1已经成功创建&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl get nodegroup --cluster $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令测试 EKS 集群新加入的两个节点是否正常工作&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get nodes --show-labels&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;需要特别指出的是启动模板对于创建托管节点组是一个推荐的可选项。不预先配置启动模板，而是直接利用下列的配置文件也可以创建托管节点组。因为在配置中没有显示的配置启动模板，eksctl会根据配置自动生成一个名称为“eksctl-集群名称-nodegroup-托管节点组名称 (N)”的一个启动模板，这个启动模板是由eksctl创建、管理和维护，因此不建议手动创建新版本修改或者复用。这种方式下创建的每个托管节点组的启动模板都是独立的，不能复用，如果有统一配置的需求和后续针对单个节点组的修改需求就更加麻烦。同时因为没有在配置文件中显示的指定启动模板，需要根据命名规则或者在EKS的托管节点组控制界面上查询这个启动模板，所以这种方式不利于配置变更的跟踪。而显示的声明在多个托管节点组中可以共用一个启动模板，当出现不同的配置需求时又可以通过新建启动模板版本来解决，相对于隐式的方式更加灵活高效，所以在本实验中托管节点组采用的是显示的启动模板。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: eksworkshop
  region: us-east-1
  version: "1.17"
  availabilityZones: ["us-east-1a", "us-east-1b", "us-east-1c"]
managedNodeGroups:
- name: nodegroup
  minSize: 1
  maxSize: 3
  desiredCapacity: 3
  instanceType: m5.large
  ssh:
    enableSsm: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;h3&gt;迁移工作负载并删除非托管节点组&lt;/h3&gt; 
&lt;p&gt;因为非托管节点组的&lt;a href="https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability"&gt;不可变性&lt;/a&gt;，除了改变节点数量无法更改其配置，所以当遇到升级集群版本的情况是需要创建新的非托管节点组然后迁移负载再删除旧的节点组的方法来实现升级节点组。而托管节点组可以做到原地（In place）升级，所以本实验先将样例工作负载迁移到托管节点组再做集群的升级。&lt;/p&gt; 
&lt;p&gt;运行下列命令查验当前的nginx pod运行在非托管节点组的节点上&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令将在非托管节点组的节点上的工作负载驱逐到刚刚创建的托管节点组&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl drain nodegroup --cluster=$EKS_CLUSTER_NAME --name=$EKS_UNMANAGED_NODEGROUP_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行命令：&lt;code&gt;kubectl get no&lt;/code&gt;可以发现旧节点组的状态已经变为：Ready,SchedulingDisabled，重新运行下列命令查验当前的nginx pod运行在托管节点组的节点上&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get po -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令删除非托管节点组&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete nodegroup --cluster $EKS_CLUSTER_NAME --name $EKS_UNMANAGED_NODEGROUP_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;运行下列命令监视节点删除情况直至非托管节点组被完全删除。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get no -w&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;升级集群控制平面&lt;/h3&gt; 
&lt;p&gt;如下图所示在EKS集群控制台上点击Update Now升级集群控制平面，因为K8S需要逐个版本升级，所以只有1.18目标版本是可选状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 升级后如下图所示集群处于Updating状态，整个升级过程大约需要30~40分钟。这步升级操作也可以通过eksctl命令或者aws cli来完成，具体做法请参考&lt;a href="https://docs.amazonaws.cn/eks/latest/userguide/update-cluster.html"&gt;官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 升级成功后可以看到集群版本变为1.18。&lt;/p&gt; 
&lt;p&gt;需要注意的是如果有多个托管节点组，在升级控制平面之前，需要确认所有的托管节点组都已经升级到控制平面的版本，否则升级时会得到错误提示：Nodegroups xxx must be updated to match cluster version 1.1x before updating cluster version。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;升级托管节点组&lt;/h3&gt; 
&lt;p&gt;如下图所示进入EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Compute可以看到New AMI Release versios are avaiable for 1 Node Group的提示，并且在Node Groups中mng-1的AMI release version列的旁边出现了Update now的链接&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;点击Update now升级托管节点组到1.18&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在上面的弹出的对话框中可以看到Update Strategy设置为Rolling update，也即滚动更新，点击Update开始节点组升级更新，整个过程需要约20分钟。&lt;/p&gt; 
&lt;p&gt;其间可以在EC2控制台中查看新旧节点的变化情况，在新启动的实例细节信息里查验AMI name已经改为amazon-eks-node-1.18-v2021xxxx。通过运行命令：kubectl get no可以看到旧的节点被设置为SchedulingDisabled状态，Nginx Pod在被逐步迁移到新的节点上。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以通过如下图所示的编辑托管节点组 EKS &amp;gt; Clusters &amp;gt; eksworkshop &amp;gt; Node Group: mng-1 &amp;gt; Edit Node Group的Node Group update configuration来设置最大不可用节点数目或者比例数，从而控制滚动更新的颗粒度。当然也可以变更最小、最大、期望节点数，k8s labels，taints和tags等其他配置。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;相比之下，如果我们这里使用的依旧是非托管节点组，那么在这个步骤中我们就要重新创建一个与控制平面版本一致的1.18的新的非托管节点组，然后将工作负载从旧的1.17的节点组迁移到新的1.18的节点组再删除1.17的非托管节点组，这个过程相对于上述托管节点组的一键升级的流程复杂许多，而且存在一个新旧非托管节点组同时存在的时间窗口给集群的管理与维护增加了难度与不确定性。更令运维人员头疼的是，这个升级过程在后续的版本升级中（比如1.18到1.19）仍然需要重复一遍。对比可见数据平面的升级在托管节点组的支持下变得非常简单方便。&lt;/p&gt; 
&lt;h3&gt;切换启动模板版本&lt;/h3&gt; 
&lt;p&gt;在日常集群的维护中，我们经常会有一些变更需求，比如切换实例类型，修改各种资源比如EC2的名称等，这些在非托管节点组是无法实现的，而在配置了启动模板的托管节点组中可以轻松实现，下面将演示将节点组实例类型切换为m5.2xlarge的方法。&lt;/p&gt; 
&lt;p&gt;基于启动模板demo的版本1新创建一个新版本：version 2，将实例类型设置为m5.2xlarge同时保持其他选项不变。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;等待托管节点组mng-1升级到1.18完成后，可以看到节点组的AMI release version改为1.18.20-xxxx，同时因为我们增加了一个新的启动模板的版本，点击Change version将mng-1节点组切换到新创建的版本2从而修改节点组的实例类型到m5.2xlarge。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-managed-node-groups-combined-with-startup-templates-to-simplify-eks-upgrades-and-operation-and-maintenance13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 点击Update开始节点组滚动更新，类似的整个过程需要约20分钟。等待更新完毕后，按照相同的方法可以重新切换回版本1。启动模版的版本信息可以通过下列命令导出到yaml作为配置变更管理的一部分通过git等源代码版本管理工具来管理。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws ec2 describe-launch-template-versions --launch-template-name demo --output yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;需要注意的是在启动模板的不同版本间做切换目前不支持在有使用EKS优化AMI与自定义AMI的不同版本间切换。否则会得到错误：You cannot specify an image id within the launch template, since your nodegroup is configured to use an EKS optimized AMI（默认EKS优化版本改为自定义AMI版本）或者The request must contain the parameter ImageId（自定义AMI版本改为默认EKS优化版本）。如果有将默认AMI替换为自定义AMI的需求，可以通过创建一个新的托管节点组来引用配置有自定义AMI的启动模板的版本来解决。&lt;/p&gt; 
&lt;h3&gt;删除EKS集群和Cloud9环境&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;eksctl delete cluster --name $EKS_CLUSTER_NAME&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;最后，在AWS控制台的Cloud9服务的环境列表中删除eksworkshop。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;本文通过一个端到端的例子说明了将非托管节点组转换到托管节点组来实现工作负载的迁移。同时完成集群和托管节点组从 1.17到1.18的版本升级。最后通过在不同启动模板版本间切换的方法实现了节点组配置的灵活原地更新。需要特别指出虽然上述实验进行的的是1.17到1.18的升级，但过程对于其他EKS版本的升级同样适用，比如从1.18升级到1.19。&lt;/p&gt; 
&lt;p&gt;相比EKS集群的托管节点组，非托管节点组具有不可变性，所以必须通过新建节点组然后迁移工作负载的方式来更新。而托管节点组则可以通过改变启动模板的版本然后进行滚动更新来实现常用配置的变更，同时在出现失败的情况下支持回退，所以在日常变更管理与集群版本升级上更加简便。并且一个集群或者多个集群中的多个节点组可以共用一个启动模板，极大的简化了维护与管理的成本。另外将多项节点组配置选项转移到启动模板中，实现了节点组配置一定程度的解耦。最后因为启动模板支持多个版本，同一托管节点组可以在同一个启动模板的不同版本间灵活切换，也极大的方便了日常节点组的变更与维护。关于更多托管节点组的新功能请参考&lt;a href="https://aws.amazon.com/blogs/containers/catching-up-with-managed-node-groups-in-amazon-eks/"&gt;托管节点组最新动态博客&lt;/a&gt;与&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html"&gt;EKS官方文档&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;最后需要指出的是EKS升级的范畴远大于文中介绍的内容，鉴于篇幅所限，其他方面的升级方法请读者自行参考官方K8S升级手册与官方EKS升级文档。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考资料&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html&lt;/li&gt; 
 &lt;li&gt;https://eksctl.io/usage/managing-nodegroups/#nodegroup-immutability&lt;/li&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html&lt;/li&gt; 
 &lt;li&gt;https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html&lt;/li&gt; 
 &lt;li&gt;https://aws.amazon.com/blogs/containers/catching-up-with-managed-node-groups-in-amazon-eks/&lt;/li&gt; 
 &lt;li&gt;https://aws.amazon.com/blogs/containers/introducing-launch-template-and-custom-ami-support-in-amazon-eks-managed-node-groups/&lt;/li&gt; 
 &lt;li&gt;https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html&lt;/li&gt; 
 &lt;li&gt;https://www.eksworkshop.com/&lt;/li&gt; 
 &lt;li&gt;https://eksctl.io/usage/schema/&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/dapengt.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;田大鹏&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责帮助客户进行上云架构的设计和咨询。在电商及互联网行业有丰富的咨询和架构设计经验。加入 AWS 前曾于全球领先的存储和虚拟化企业，担任研发主管工程师及研发经理多种职位，负责在线存储及备份系统的多个子系统的高并发、高可用系统架构设计，应用微服务化等敏捷项目。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/guili.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;何归丽&lt;/h3&gt; 
  &lt;p&gt;AWS高级解决方案架构师，负责基于AWS的云计算方案架构的咨询和设计，同时致力于AWS云服务在国内的应用和推广。加入AWS之前在外企软件部门担任系统架构师，有十多年的软件研发和架构设计经验，在微服务架构和容器、企业应用信息安全、DevOps等领域有丰富的经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/panwenmi.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;潘文明&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责基于 AWS 的云计算方案的咨询与架构设计。专注于游戏行业，帮助客户利用AWS全球基础设施与强大的技术能力打造爆款游戏，降低游戏运行成本。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>如何将您的自定义容器镜像导入Amazon SageMaker Studio notebooks</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks/</link>
				<pubDate>Tue, 31 Aug 2021 03:41:59 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Amazon SageMaker Studio]]></category>

		<guid isPermaLink="false">75a8705bab975b942b359066fef42d5d15ceef5c</guid>
				<description>Amazon SageMaker Studio是第一套用于机器学习（ML）的全集成开发环境（IDE）。Amazon SageMaker Studio可帮助数据科学家们快速启动Studio notebooks以探索数据、构建模型、启动Amazon SageMaker训练作业并部署托管端点。Studio notebooks中随附一组预构建镜像，这些镜像由Amazon SageMaker Python SDK&amp;nbsp;与IPython运行时或内核的最新版本构成。凭借此项新功能，您可以轻松将自定义镜像导入Amazon SageMaker notebooks当中。在本文中，我们将具体探讨如何将自定义容器镜像导入Amazon SageMaker notebooks。</description>
								<content:encoded>&lt;p&gt;&lt;a href="https://aws.amazon.com/sagemaker/"&gt;Amazon SageMaker Studio&lt;/a&gt;是第一套用于机器学习（ML）的全集成开发环境（IDE）。Amazon SageMaker Studio可帮助数据科学家们快速启动Studio notebooks以探索数据、构建模型、启动Amazon SageMaker训练作业并部署托管端点。Studio notebooks中随附一组预构建镜像，这些镜像由&lt;a href="https://sagemaker.readthedocs.io/en/stable/"&gt;Amazon SageMaker Python SDK&lt;/a&gt;&amp;nbsp;与IPython运行时或内核的最新版本构成。凭借此项新功能，您可以轻松将自定义镜像导入Amazon SageMaker notebooks当中。在本文中，我们将具体探讨如何将自定义容器镜像导入Amazon SageMaker notebooks。&lt;/p&gt; 
&lt;p&gt;开发人员与数据科学家一般需要在以下几种不同用例内使用自定义镜像：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;访问流行机器学习框架（包括TensorFlow、MXNet以及PyTorch等）的特定或最新版本。&lt;/li&gt; 
 &lt;li&gt;将本地开发的自定义代码或算法引入Studio notebooks内以进行快速迭代及模型训练。&lt;/li&gt; 
 &lt;li&gt;通过API访问数据湖或本地数据存储，且管理员需要在镜像中添加相应驱动程序。&lt;/li&gt; 
 &lt;li&gt;访问后端运行时（也称内核）；除IPython之外，还有R、Julia或其它环境等。您也可以使用本文中概述的方法安装其他自定义内核。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在大型企业中，机器学习平台管理员往往需要保证安全团队预先批准第三方软件包及代码，而非直接通过互联网下载。在常见的工作流示例中，机器学习平台团队会批准一组要使用的软件包与框架，使用这些软件包构建自定义容器、测试容器中的漏洞，而后将核准后的镜像推送至私有容器注册表内，例如&lt;a href="https://aws.amazon.com/ecr/"&gt;Amazon Elastic Container Registry&lt;/a&gt;&amp;nbsp;(Amazon ECR)。现在，机器学习平台团队可以将经过核准的镜像直接附加至Studio域内（请参见以下工作流程图）。您只需在Studio中选定所需的获准自定义镜像即可。在当前版本中，单一Studio域最多可以包含30个自定义镜像，您可以根据需求添加新版本或删除镜像。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;现在，我们将逐步介绍如何使用此项功能将自定义容器镜像导入Amazon SageMaker Studio notebooks当中。这里主要演示在互联网上使用时的默认方法，您也可以对其稍加修改以配合&lt;a href="https://aws.amazon.com/vpc/"&gt;Amazon Virtual Private Cloud&lt;/a&gt;&amp;nbsp;(Amazon VPC)进行使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;先决条件&lt;/h2&gt; 
&lt;p&gt;在开始之前，大家需要满足以下先决条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;亚马逊云科技账户。&lt;/li&gt; 
 &lt;li&gt;确保用于访问Amazon SageMaker的角色拥有以下Amazon Web Services身份与访问管理（IAM）权限，使Amazon SageMaker Studio能够在Amazon ECR中以smstudio为前缀创建一个repo，并面向此repo进行镜像推送与提取。要使用现有repo，请将其中的Resource部分替换为您的repo ARN。要构建容器镜像，您可以使用本地Docker客户端，或者直接在Amazon SageMaker Studio中创建镜像。本文采用后一种方法。要在Amazon ECR内创建repo，Amazon SageMaker Studio需要使用&lt;a href="https://aws.amazon.com/codebuild/"&gt;Amazon CodeBuild&lt;/a&gt;；您还需要拥有使用CodeBuild的权限，具体如下所示。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
            "Effect": "Allow",
            "Action": [
                "ecr:CreateRepository",
                "ecr:BatchGetImage",
                "ecr:CompleteLayerUpload",
                "ecr:DescribeImages",
                "ecr:DescribeRepositories",
                "ecr:UploadLayerPart",
                "ecr:ListImages",
                "ecr:InitiateLayerUpload",
                "ecr:BatchCheckLayerAvailability",
                "ecr:GetDownloadUrlForLayer",
                "ecr:PutImage"
            ],
            "Resource": "arn:aws:ecr:*:*:repository/smstudio*"
        },
        {
            "Effect": "Allow",
            "Action": "ecr:GetAuthorizationToken",
            "Resource": "*"
           }
{
            "Effect": "Allow",
            "Action": [
                "codebuild:DeleteProject",
                "codebuild:CreateProject",
                "codebuild:BatchGetBuilds",
                "codebuild:StartBuild"
            ],
            "Resource": "arn:aws:codebuild:*:*:project/sagemaker-studio*"
}
{
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "arn:aws:iam::*:role/*",
            "Condition": {
                "StringLikeIfExists": {
                    "iam:PassedToService": "codebuild.amazonaws.com"
                }
            }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;您的Amazon SageMaker角色还应在Amazon CodeBuild中拥有信任策略，具体如下所示。关于更多详细信息，请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/"&gt;使用Amazon SageMaker Studio镜像构建CLI在Studio notebooks中构建容器镜像&lt;/a&gt;。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": [
          "codebuild.amazonaws.com"
        ]
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;在您的本地机器上安装Amazon Web Services命令行界面（Amazon CLI）。关于详尽操作说明，请参阅&lt;a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html"&gt;安装Amazon&lt;/a&gt; Web Services。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;准备一个SageMaker Studio域。要创建此域，请使用&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateDomain.html"&gt;CreateDomain&lt;/a&gt;&amp;nbsp;API或者&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/cli/latest/reference/sagemaker/create-domain.html"&gt;create-domain&lt;/a&gt;&amp;nbsp;CLI命令。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果您希望使用自有VPC以安全引入自定义容器，则需要完成以下操作：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;带有专有子网的VPC。&lt;/li&gt; 
 &lt;li&gt;用于以下服务的VPC端点： 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service&lt;/a&gt;&amp;nbsp;(Amazon S3)&lt;/li&gt; 
   &lt;li&gt;Amazon SageMaker&lt;/li&gt; 
   &lt;li&gt;Amazon ECR&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html"&gt;Amazon Security Token Service&lt;/a&gt;&amp;nbsp;(Amazon STS)&lt;/li&gt; 
   &lt;li&gt;用于构建Docker容器的CodeBuild&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;要设置上述资源，请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/securing-amazon-sagemaker-studio-connectivity-using-a-private-vpc/"&gt;使用专用VPC保护Amazon SageMaker Studio连接&lt;/a&gt;以及相关&lt;a href="https://github.com/aws-samples/amazon-sagemaker-studio-vpc-blog"&gt;GitHub repo&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;创建Dockerfile&lt;/h2&gt; 
&lt;p&gt;为了体现数据科学家使用最新框架进行试验的普遍性需求，我们在本次演练中使用以下Dockerfile，其选择最新的TensorFlow 2.3版本作为基础镜像。您也可以使用自己指定的Dockerfile进行替换。目前，Amazon SageMaker Studio已经能够支持多种基础镜像，例如Ubuntu、Amazon Linux 2等等。Dockerfile将安装运行Juypter notebooks所需要的IPython运行时，同时安装Amazon SageMaker Python SDK与boto3。&lt;/p&gt; 
&lt;p&gt;除了笔记本电脑之外，除了notebooks之外，数据科学家与机器学习工程师们还经常使用各种流行IDE（例如Visual Studio Code或者PyÇharm）在本地notebooks上进行迭代与试验。您可能希望将这些脚本引入云端，借此进行扩展化训练或数据处理。您可以将这些脚本打包进Docker容器之内，并在Amazon SageMaker Studio的本地存储中查看。在以下Dockerfile中，我们复制的train.py&amp;nbsp;脚本是一套用于在MNIST数据集上训练简单深度学习模型的基础脚本。您也可以使用自己的脚本或包含代码的软件包替换此脚本。&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;FROM tensorflow/tensorflow:2.3.0
RUN apt-get update 
RUN apt-get install -y git
RUN pip install --upgrade pip
RUN pip install ipykernel &amp;amp;&amp;amp; \
    python -m ipykernel install --sys-prefix &amp;amp;&amp;amp; \
    pip install --quiet --no-cache-dir \
    'boto3&amp;gt;1.0&amp;lt;2.0' \
    'sagemaker&amp;gt;2.0&amp;lt;3.0'&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;COPY train.py /root/train.py #可以替换为您的自定义脚本或软件包&lt;/p&gt; 
&lt;p&gt;以下代码为train.py脚本：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;import tensorflow as tf
import os 

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=1)
model.evaluate(x_test, y_test)&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;除了自定义脚本之外，您也可以添加其他文件，例如可通过&lt;a href="https://aws.amazon.com/secrets-manager/"&gt;Amazon Secrets Manage&lt;/a&gt;r 或&amp;nbsp;&lt;a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html"&gt;Amazon Systems Manager Parameter Store&lt;/a&gt;访问客户端secrets以及环境变量的Python文件、用于连接私有PyPi repo的config文件、或者其他软件包管理工具。您也可以使用自定义镜像复制脚本，但在这种情况下，Dockerfile中的一切ENTRYPOINT或CMD命令均无法运行。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;设置安装文件夹&lt;/h2&gt; 
&lt;p&gt;您需要在本地机器上创建一个文件夹，并向其中添加以下文件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在上一步中创建完成的Dockerfile。&lt;/li&gt; 
 &lt;li&gt;名为&amp;nbsp;app-image-config-input.json&amp;nbsp;的文件，具体内容如下：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;"AppImageConfigName": "custom-tf2",
    "KernelGatewayImageConfig": {
        "KernelSpecs": [
            {
                "Name": "python3",
                "DisplayName": "Python 3"
            }
        ],
        "FileSystemConfig": {
            "MountPath": "/root/data",
            "DefaultUid": 0,
            "DefaultGid": 0
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;我们将此Dockerfile的后端内核设置为IPython内核，并提供指向&lt;a href="https://aws.amazon.com/efs/"&gt;Amazon Elastic File System&lt;/a&gt;&amp;nbsp;(Amazon EFS)的挂载路径。Amazon SageMaker可以识别出Juypter定义的内核。例如，对于R内核，您可以将之前代码中的Name部分设置为ir。请注意保证其中的Uid、Gid以及内核名称与Docker镜像中的kernelspecs及用户信息相匹配。要获取这些值，请参阅本&lt;a href="https://github.com/aws-samples/sagemaker-studio-custom-image-samples/blob/main/DEVELOPMENT.md"&gt;文档&lt;/a&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用以下内容创建一个名为&amp;nbsp;default-user-settings.json&amp;nbsp;的文件。如果您需要添加多个自定义镜像，请直接将其添加至&amp;nbsp;CustomImages列表。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;{
  "DefaultUserSettings": {
    "KernelGatewayAppSettings": {
      "CustomImages": [
          {
                   "ImageName": "tf2kernel",
                   "AppImageConfigName": "custom-tf2"
                }
            ]
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;创建镜像并将其附加至您的Studio域&lt;/h2&gt; 
&lt;p&gt;如果您已经拥有现成的域，则直接使用新镜像进行更新即可。在本节中，我们将演示现有Studio用户如何进行镜像附加。关于启动新用户的说明，请参阅&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-iam.html"&gt;使用IAM登入Amazon SageMaker Studio&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;首先，我们使用Amazon SageMaker Studio Docker构建CLI构建Dockerfile，并将其推送至Amazon ECR。请注意，您也可以使用其他方法将容器推送至ECR，例如通过本地Docker客户端以及AWS CLI。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用您的用户信息登录至Studio。&lt;/li&gt; 
 &lt;li&gt;将您的Dockerfile、以及其他需要复制到容器当中的代码或依赖项上传至Studio域。&lt;/li&gt; 
 &lt;li&gt;导航至包含Dockerfile的文件夹。&lt;/li&gt; 
 &lt;li&gt;在终端窗口或notebook内 —&amp;gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;!pip install sagemaker-studio-image-build&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;导出一个名为IMAGE_NAME的变量，并将其设定为您在&amp;nbsp;default-user-settings.json当中所指定的值。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;sm-docker build . –repository smstudio-custom:IMAGE_NAME&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果要使用其他repo，请将以上代码中的smstudio-custom替换为您的repo名称。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Amazon SageMaker Studio将为您构建Docker镜像，将该镜像推送至Amazon ECR当中一个名为smstudio-custom的repo内，并为其标记适当的镜像名称。要进一步自定义此项功能（例如提供详细的文件路径或其他选项），请参阅&lt;a href="https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/"&gt;使用Amazon SageMaker Studio镜像构建CLI在Studio notebooks中构建容器镜像&lt;/a&gt;。要让以上pip命令在专用VPC环境下起效，您需要设置互联网路由或访问专用repo内的相应软件包。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在之前的安装文件夹中，创建一个名为&amp;nbsp;create-and-update-image.sh的新文件：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-python"&gt;ACCOUNT_ID=AWS ACCT ID # 替换为您的AWS账户ID
REGION=us-east-2 # 替换为您的区域
DOMAINID=d-####### # 替换为您的SageMaker Studio域名称
IMAGE_NAME=tf2kernel # 替换为您的镜像名称

# 使用Amazon SageMaker Studio
## 使用ECR中的镜像创建SageMaker镜像（根据需求修改镜像名称）
ROLE_ARN='The Execution Role ARN for the execution role you want to use'

aws --region ${REGION} sagemaker create-image \
    --image-name ${IMAGE_NAME} \
    --role-arn ${ROLE_ARN}

aws --region ${REGION} sagemaker create-image-version \
    --image-name ${IMAGE_NAME} \
    --base-image "${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/smstudio-custom:${IMAGE_NAME}"
    
## 为此镜像创建AppImageConfig（根据需要修改app-image-config-input.json中的AppImageConfigName与KernelSpecs参数）
aws --region ${REGION} sagemaker create-app-image-config --cli-input-json file://app-image-config-input.json

## 提供镜像与AppImageConfig以更新此域
aws --region ${REGION} sagemaker update-domain --domain-id ${DOMAINID} --cli-input-json file://default-user-settings.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;请参阅Amazon CLI以了解可在&amp;nbsp;&lt;a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker/create-image.html"&gt;create-image&lt;/a&gt;&amp;nbsp;API中使用的各项参数的详细信息。要检查当前状态，请导航至您的Amazon SageMaker控制台，并在导航面板中选择Amazon SageMaker Studio。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;使用Studio UI附加镜像&lt;/h2&gt; 
&lt;p&gt;您也可以通过UI完成将镜像附加至Studio域的最后一步。在此用例中，UI将处理镜像与镜像版本的创建操作，并使用附加的镜像完成域更新。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在Amazon SageMaker控制台上，选择Amazon SageMaker Studio。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在Control Panel页面上，可以看到已经置备完成的Studio域以及您所创建的所有用户配置。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Attach image&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;选择要附加新镜像，还是附加原有镜像。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ol&gt; 
   &lt;li style="list-style-type: none"&gt; 
    &lt;ol&gt; 
     &lt;li&gt;如果您选择Existing image，请从Amazon SageMaker镜像库中选择一个镜像。&lt;/li&gt; 
     &lt;li&gt;如果您选择New image，请提供Docker镜像的Amazon ECR注册表路径。此路径需要与Studio域处于同一区域内。ECR repo还需要与您的Studio域处于同一账户内；如果需要跨账户操作，则Studio必须具备相应权限。&lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Next&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;在&lt;/strong&gt;&lt;strong&gt;Image name&lt;/strong&gt;部分，输入名称。&lt;/li&gt; 
 &lt;li&gt;在&lt;strong&gt;Image display name&lt;/strong&gt;部分，输入描述性名称。&lt;/li&gt; 
 &lt;li&gt;在&amp;nbsp;&lt;strong&gt;Description&lt;/strong&gt;部分，输入标签定义。&lt;/li&gt; 
 &lt;li&gt;在IAM role部分，选择Amazon SageMaker用于向Amazon SageMaker镜像附加Amazon ECR镜像的IAM角色。&lt;/li&gt; 
 &lt;li&gt;此外，您也可以对镜像做出其他标记。&lt;/li&gt; 
 &lt;li&gt;选择&amp;nbsp;&lt;strong&gt;Next&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在Kernel name部分，输入Python 3。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Submit&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;绿色复选框代表镜像已被成功附加至域内。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker镜像存储将自动对镜像进行版本控制。您可以选择一个预先附加的镜像，而后选择Detach以分离该镜像及所有相关版本，或者选择Attach image以附加新版本。各镜像的版本数量或分离镜像的功能不受限制。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;自定义镜像用户体验&lt;/h2&gt; 
&lt;p&gt;下面，我们尝试Studio的实际用户体验。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用您的用户资料登录至Studio。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;要启动新活动，请选择&lt;/strong&gt;&lt;strong&gt;Launcher&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;在&lt;strong&gt;Select a SageMaker image to launch your activity&lt;/strong&gt;&lt;strong&gt;部分，选择&lt;/strong&gt;&lt;strong&gt;tf2kernel&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;strong&gt;Notebook&lt;/strong&gt;图标，使用自定义内核打开一个新notebook。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Notebook内核需要几分钟才能启动完成，之后即可开始使用！&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;在notebook中测试您的自定义容器&lt;/h2&gt; 
&lt;p&gt;在内核启动并开始运行之后，您即可在notebook中运行代码。首先，我们测试Dockerfile中指定的TensorFlow是否为正确版本。在以下截屏中，可以看到我们刚刚创建的notebook正在使用tf2kernel。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker notebooks还会显示本地CPU与内存使用量。&lt;/p&gt; 
&lt;p&gt;接下来，我们直接在notebook中使用自定义训练脚本。将训练脚本复制到notebook单元中并运行。此脚本会从tf.keras.datasets处下载mnist数据集，并将数据拆分为训练数据集与测试数据集，自定义一项定制化深度神经网络算法，在训练数据集上训练算法，并在测试数据集上测试算法。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要尝试使用TensorFlow 2.3框架，大家可能希望测试新发布的API，例如Keras中提供的预处理实用程序等新功能。在以下截屏中，我们导入了随TensorFlow 2.3版本发布的keras.layers.experimental&amp;nbsp;库，其中包含用于数据预处理的新API。我们加载其中一个API，而后在notebook中重新运行脚本。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Amazon SageMaker还能够在代码运行过程中动态修改CPU与内存使用率。通过引入自定义容器与训练脚本，此功能使您能够直接在Amazon SageMaker notebook中尝试自定义训练脚本与算法。如果您对Studio notebook中的试验结果感到满意，则可立即启动训练作业。&lt;/p&gt; 
&lt;p&gt;Docker file中所包含的、使用COPY命令的Python文件或其他自定义文件运行情况如何？Amazon SageMaker Studio会挂载app-image-config-input.json所提供的文件路径中的弹性文件系统，在本示例中我们将其设定为root/data。为了避免Studio覆盖掉需要包含的自定义文件，COPY命令会将train.py文件加载至路径/root当中。要访问此文件，请打开终端或notebook并运行以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;! cat /root/train.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;这时您应看到以下截屏所示的输出结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以看到train.py&amp;nbsp;文件位于指定位置。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;CloudWatch中的日志记录&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker Studio还会将内核指标发布至Amazon CloudWatch供您进行故障排查。这些指标将被捕捉至/aws/sagemaker/studio命名空间之内。&lt;/p&gt; 
&lt;p&gt;要访问日志，请在CloudWatch控制台上选择CloudWatch Logs。在Log groups页面中，输入命名空间以查看与Jupyter服务器及内核网关相关的日志记录。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks12.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;分离镜像或版本&lt;/h2&gt; 
&lt;p&gt;您可以从域中分离镜像或特定镜像版本。&lt;/p&gt; 
&lt;p&gt;要分离镜像及其全部版本，请在Custom images attached to domain表内选定该镜像，而后选择Detach。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks13.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;您还可以选择删除镜像及所有版本，这不会影响到Amazon ECR中的镜像。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-import-your-custom-container-image-into-amazon-sagemaker-studio-notebooks14.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要分离镜像的特定版本，请选定该镜像。在Image details页面上，从Image versions attached to domain表中选择目标镜像版本（一个或者多个版本），而后选择Detach。您会看到如上所示的警告及操作选项。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker Studio使您能够更轻松地对机器学习模型进行协作、实验、训练及部署。在这之前，数据科学家往往需要通过公共及私有代码repo以及软件包管理工具才能访问最新机器学习框架、自定义脚本以及软件包。现在，您可以将所有相关代码打包进自定义镜像之内，并使用Studio notebook启动这些镜像。这些镜像可供Studio域内的所有用户使用。您也可以使用此项功能使用Python之外的其他流行语言及运行时，包括R、Julia以及Scala等。您可以在&lt;a href="https://github.com/aws-samples/sagemaker-studio-custom-image-samples"&gt;GitHub repo&lt;/a&gt;中找到示例文件。关于此项功能的更多详细信息，请参阅&lt;a href="https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html"&gt;自带SageMaker镜像&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/stenatu.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Stefan Natu&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技公司高级机器学习专家。他致力于帮助金融服务客户在亚马逊云科技上构建端到端机器学习解决方案。在业余时间，他喜欢阅读机器学习技术博客、演奏吉他和探索纽约当地的各种美食。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/jaipreet.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Jaipreet Singh&lt;/h3&gt; 
  &lt;p&gt;Amazon SageMaker Studio团队高级软件工程师。他自2017年立项以来就一直从事Amazon SageMaker的开发工作，并为多个Jupyter开源项目做出贡献。业余时间，他喜欢远足和滑雪。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/huonguh.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Huong Nguyen&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技公司高级产品经理。她负责Amazon SageMaker Studio的用户体验工作。她在企业级及消费级领域拥有13年客户体验与数据驱动产品开发经验。在业余时间，她喜欢读书、享受自然风光和陪伴家人。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>如何注册成为亚马逊云科技 Marketplace海外区卖家</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace/</link>
				<pubDate>Tue, 31 Aug 2021 03:38:57 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Marketplace]]></category>

		<guid isPermaLink="false">6caba9bb2943867da8c579fee4e0fc54dae15eb7</guid>
				<description>亚马逊云科技Marketplace(以下简称Marketplace)是一个提供甄选的数字化产品的平台，分海外区和中国区，产品类型包括AMI映像，CloudFormation Template，SaaS，容器，SageMaker等。Marketplace海外区是中国ISV (Independent Software Vendor)触达亚马逊云科技庞大的海外用户群，拓展海外业务的绝佳选择。为了能够上架产品，首先需要注册成为Marketplace海外区卖家。本文将介绍注册成为卖家的具体流程。</description>
								<content:encoded>&lt;h2&gt;&lt;strong&gt;1. 概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;亚马逊云科技Marketplace(以下简称Marketplace)是一个提供甄选的数字化产品的平台，分海外区和中国区，产品类型包括AMI映像，CloudFormation Template，SaaS，容器，SageMaker，DataExchange，Professional Service等。Marketplace海外区是中国ISV (Independent Software Vendor)触达亚马逊云科技庞大的海外用户群，拓展海外业务的绝佳选择。为了能够上架产品，首先需要注册成为Marketplace海外区卖家。本文将介绍注册成为卖家的具体流程。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2. 注册只售卖免费产品的卖家&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果您的产品是完全免费的，不收取用户任何软件费用，您和用户之间没有资金往来，您可以注册成为只售卖免费产品的卖家。&lt;a href="https://aws.amazon.com/marketplace/search/results?PRICING_MODEL=FREE&amp;amp;filters=PRICING_MODEL"&gt;Marketplace上的免费产品&lt;/a&gt;包括操作系统，开源软件等。具体注册步骤如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;登录&lt;a href="https://aws.amazon.com/marketplace/partners/management-tour"&gt;Marketplace海外区主页&lt;/a&gt;，点击“Register Now”&lt;/li&gt; 
 &lt;li&gt;登录您用于注册卖家的亚马逊云科技账号&lt;/li&gt; 
 &lt;li&gt;登录后您会进入&lt;a href="https://aws.amazon.com/marketplace/management/homepage/"&gt;AWS Marketplace Management Portal(AMMP)&lt;/a&gt;，继续填写您的Public Profile，包括公司Logo，公司简称，主页，公司介绍等，这些信息将会对所有用户可见。&lt;/li&gt; 
 &lt;li&gt;提交后，即可完成注册。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3. 注册售卖收费产品的卖家&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果您的软件产品是Buy Your Own License(BYOL)或者在线收取用户的软件费用，都属于付费产品。要在Marketplace海外区售卖付费的产品，卖家的公司实体必须为以下&lt;a href="https://docs.aws.amazon.com/marketplace/latest/userguide/user-guide-for-sellers.html#eligible-jurisdictions"&gt;Eligible Location&lt;/a&gt;之一：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Australia&lt;/li&gt; 
 &lt;li&gt;Bahrain&lt;/li&gt; 
 &lt;li&gt;European Union (EU) member state&lt;/li&gt; 
 &lt;li&gt;Hong Kong SAR&lt;/li&gt; 
 &lt;li&gt;Japan&lt;/li&gt; 
 &lt;li&gt;New Zealand&lt;/li&gt; 
 &lt;li&gt;Norway&lt;/li&gt; 
 &lt;li&gt;Qatar&lt;/li&gt; 
 &lt;li&gt;Switzerland&lt;/li&gt; 
 &lt;li&gt;United Arab Emirates (UAE)&lt;/li&gt; 
 &lt;li&gt;United Kingdom (UK)&lt;/li&gt; 
 &lt;li&gt;United States (US)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;您在以下两个地方所设置的Location必须保持一致，且同时为以上Location之一。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Billing Console里的Location。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/marketplace/management/seller-settings/account"&gt;AWS Marketplace Management Portal&lt;/a&gt;里的location&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;3.1 设置Billing Console里的Location&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;基于用户在Billing Console里输入的信息，Amazon Web Service是基于以下逻辑来判断一个账号的location的：&lt;/p&gt; 
&lt;p&gt;如果您公司实体所在国家有TRN (Tax Registration Number)，则在Billing Console的Tax Setting里填写TRN。后台会根据TRN所在国家决定Location。假如所在国家没有TRN (例如美国，日本，中国等)，则根据优先级，按以下逻辑判断：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;如果Billing Address和所存档信用卡的location一致，则使用Billing Address的location。例如：绑定的美国信用卡，Billing Address也是在美国。那location就是美国。&lt;/li&gt; 
 &lt;li&gt;假如以上条件1不满足，且如果Contact Address和所存档信用卡的location一致，则使用Contact Address的location。&lt;/li&gt; 
 &lt;li&gt;假如以上条件1和2都不满足，则使用Billing Address的&lt;/li&gt; 
 &lt;li&gt;假如以上条件1、2和3都不满足，则使用Contact Address的&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;更多详细信息，请参考&lt;a href="https://aws.amazon.com/cn/tax-help/location/"&gt;https://aws.amazon.com/cn/tax-help/location/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1.1 设置TRN(Tax Registration Number) – 只对于有TRN的国家和地区适用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;美国、日本、中国和香港地区没有TRN，不能进行设置。如果您的公司实体在这些国家和地区，请通过设置Billing Address和Contract Address来完成对location的设置。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1.2 设置Billing Address&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;进入AWS控制台，点左侧导航栏的Payment Method，选中Billing Address，点Edit，修改地址为满足要求的location。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1.3 设置Contact Address&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;点击控制台右上方的My Account，在Contact Information部分，点击Edit，修改Contact Address为满足要求的location。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;3.2 设置AWS Marketplace Management Portal上的location&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;注册成为marketplace卖家过程中，需要在AWS Marketplace Management Portal(AMMP)里设置公司实体相关信息。公司实体所在国家或区域必须和Billing Console里的保持一致，且也是&lt;a href="https://docs.aws.amazon.com/marketplace/latest/userguide/user-guide-for-sellers.html#eligible-jurisdictions"&gt;Eligible Location&lt;/a&gt;之一。&lt;/p&gt; 
&lt;p&gt;以下是在AMMP中设置location的方法：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ol&gt; 
   &lt;li&gt;登录您海外区Amazon Web Service账户，打开AMMP主页: &lt;a href="https://aws.amazon.com/marketplace/management"&gt;https://aws.amazon.com/marketplace/management&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;点击上方的Setting&lt;/li&gt; 
   &lt;li&gt;点击Payment Information标签页&lt;/li&gt; 
   &lt;li&gt;设置Tax Information。在Tax Information中设置的国家,必须是&lt;a href="https://docs.aws.amazon.com/marketplace/latest/userguide/user-guide-for-sellers.html#eligible-jurisdictions"&gt;Eligible Location&lt;/a&gt; 之一，且和前面Billing Console中的国家或地区保持一致。&lt;/li&gt; 
   &lt;li&gt;查看下图框4中显示的business location是否正确，如果不正确，请返回AWS Billing Console，参考1节的内容进行设置。&lt;/li&gt; 
   &lt;li&gt;假如所有的设置都正确，在框五中，会显示“Publish paid and free products”。表示该卖家可以售卖付费产品。&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;3.3 在AWS Marketplace Management Portal里设置用于接收软件售卖款的美国银行账户&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;卖家需要设置一个银行账户，用于接收售卖软件所得款，Marketplace要求这个账号必须是美国银行账户。如果没有实体的美国银行账户，用户可以通过与Maketplace有合作关系的HyperWallet开通虚拟美国银行账户。在HyperWallet里绑定自己美国之外的银行账户，这样款会先进入HyperWallet的虚拟美国账户，然后再转给卖家在美国外的实体银行账户。具体开通方式如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;登录&lt;a href="https://aws.amazon.com/marketplace/management/homepage/"&gt;Amazon Marketplace Management Portal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;点Setting。点页面下端的Payment Information标签，点Complete Banking Information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;选项： Do you have a US bank account?&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;选：NO&lt;/li&gt; 
 &lt;li&gt;选项: Are you Register with HyperWallet Already?&amp;nbsp;&amp;nbsp;&amp;nbsp; 选: NO&lt;/li&gt; 
 &lt;li&gt;复制Pin Code, 点Sign Up For HyperWallet&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;跳转到hyperwallet，用pincode注册账号&lt;/li&gt; 
 &lt;li&gt;点add transfer method。选择从HyperWallet收款的银行账户所在国家。例如如果您有香港银行账户，请选 Hong Kong SAR China.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;填写Account Information: bank code, branch code, account number。&lt;/li&gt; 
 &lt;li&gt;下面的address会自动填写。&lt;/li&gt; 
 &lt;li&gt;注意：Account Holder的公司名，必须和Bank account的公司名是一样的。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;香港的银行账户请注意：account number应该是9位数字。如果您的account number是8位数字，多数是内部账号，请咨询开户银行获取外部的9位数account number。如果您的account number是12位，请确认前3位是否为branch code。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;点submit。成功的话，系统返回HyperWallet创建的virtual US account。把文件保存好。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;回到AMMP里的Payment Information 页面，填写US Bank Account&lt;/li&gt; 
 &lt;li&gt;填写HyperWallet里所填的银行账号地址，前面保存的文件里也有。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace10.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;填写HyperWallet虚拟美国账户信息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-register-as-an-overseas-seller-on-amazon-cloud-technology-marketplace11.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;点击提交即可&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当您完成以上设置后，您就可以在AMMP里创建相应的付费产品，开始产品上架流程了。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/hanliang.png" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;韩亮&lt;/h3&gt; 
  &lt;p&gt;AWS Marketplace技术客户经理&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>在 Amazon Kinesis Data Analytics Studio 中尝试的十大 Flink SQL 查询</title>
		<link>https://aws.amazon.com/cn/blogs/china/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio/</link>
				<pubDate>Tue, 31 Aug 2021 02:59:22 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Kinesis Data Analytics Studio]]></category>

		<guid isPermaLink="false">acb214406d1f4bb95baa1ee2f61dfc4b5983668f</guid>
				<description>通过 Amazon Kinesis Data Analytics Studio，您可以轻松地实时分析流数据并使用标准 SQL、Python 和 Scala 构建流处理应用程序。只需在亚马逊云科技管理控制台上单击几下，就可以启动无服务器笔记本来查询数据流，只需几秒钟即可获得结果。</description>
								<content:encoded>&lt;p&gt;通过&lt;a href="https://aws.amazon.com/kinesis/data-analytics/"&gt;&amp;nbsp;Amazon Kinesis Data Analytics Studio&lt;/a&gt;，您可以轻松地实时分析流数据并使用标准 SQL、Python 和 Scala 构建流处理应用程序。只需在&lt;a href="http://aws.amazon.com/console"&gt;亚马逊云科技管理控制台&lt;/a&gt;上单击几下，就可以启动无服务器笔记本来查询数据流，只需几秒钟即可获得结果。Kinesis Data Analytics 降低了构建和管理 Apache Flink 应用程序的复杂性。Apache Flink 是一个用于处理数据流的开源框架和引擎。它具有高可用性和可扩展性，为流处理应用程序提供了高吞吐量和低延迟。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/overview/"&gt;Apache Flink SQL&lt;/a&gt;&amp;nbsp;支持&lt;a href="https://calcite.apache.org/"&gt;&amp;nbsp;Apache Calcite&lt;/a&gt;，它执行 SQL 标准，使您能够编写简单的 SQL 语句来创建、转换数据并将其插入 Apache Flink 中定义的流数据表中。在本文中，我们将讨论一些可以在 Kinesis Data Analytics Studio 中运行的 Flink SQL 查询。&lt;/p&gt; 
&lt;p&gt;Flink SQL 接口可与&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/tableapi/"&gt;&amp;nbsp;Apache Flink Table API&lt;/a&gt; 以及 Apache Flink&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/datastream/overview/"&gt;&amp;nbsp;DataStream&lt;/a&gt;&amp;nbsp;和&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/dataset/overview/"&gt;&amp;nbsp;Dataset&lt;/a&gt;&amp;nbsp;API 无缝协作。为了以适合当前操作的方式处理流数据，流工作负载通常会在这些抽象层中切换。一个简单的过滤器模式可能需要 Flink SQL 语句，而涉及以对象为导向的状态控制的更复杂的聚合可能需要 DataStream API。工作负载可使用 DataStream API 从数据流中提取模式，然后使用 Flink SQL API 对模式进行分析、扫描、过滤和聚合。&lt;/p&gt; 
&lt;p&gt;有关 Flink SQL 和 Table API 的更多信息，请参阅&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/common/"&gt;概念和常见 API&lt;/a&gt;，尤其是关于解释器使用的不同计划器以及如何构建 Apache Flink SQL 或 Table API 程序的章节。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;在&lt;/strong&gt;&lt;strong&gt; Kinesis Data Analytics Studio 编写 Apache Flink SQL 应用程序&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;通过Amazon Kinesis Data Analytics Studio，您每秒可查询数百万条流记录，笔记本也可以得到相应的扩展。通过 Apache Flink 强大的Amazon Kinesis Data Analytics 功能，只需几个简单的 SQL 语句，您就能够拥有强大的 Apache Flink 应用程序或分析控制面板。&lt;/p&gt; 
&lt;p&gt;需要入门指导？&amp;nbsp;&lt;a href="https://aws.amazon.com/kinesis/data-analytics/getting-started/#It.E2.80.99s_easy_to_get_started_with_Amazon_Kinesis_Data_Analytics_Studio_"&gt;Amazon Kinesis Data Analytics Studio&lt;/a&gt;&amp;nbsp;很容易上手。在接下来的部分中，我们将介绍多种与传入数据流交互的方法 — 在Amazon Kinesis Data Analytics Studio 笔记本中查询、聚合、接收和处理数据。首先，为数据流创建一个内存表。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;为传入的数据创建一个内存表&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先使用 CREATE 语句注册内存表。您可以将这些语句配置为连接到&lt;a href="https://aws.amazon.com/kinesis/data-streams/"&gt;&amp;nbsp;Amazon Kinesis Data Streams&lt;/a&gt;、&lt;a href="https://aws.amazon.com/msk/"&gt;Amazon Managed Streaming for Apache Kafka&lt;/a&gt;&amp;nbsp;(Amazon MSK) 集群或 Apache Flink 中目前受支持的任何其他连接器，例如&lt;a href="http://aws.amazon.com/s3"&gt;&amp;nbsp;Amazon Simple Storage Service&lt;/a&gt;（Amazon S3）。&lt;/p&gt; 
&lt;p&gt;您需要在段落开头指出使用的是 Flink SQL 解释器，该解释器由&lt;a href="https://zeppelin.apache.org/docs/0.9.0/interpreter/flink.html"&gt;&amp;nbsp;Zeppelin&lt;/a&gt;&amp;nbsp;magic&amp;nbsp;%&amp;nbsp;指示，后跟&amp;nbsp;flink.ssql&amp;nbsp;和段落的类型。在大多数情况下是更新段落 type=update，会持续更新输出。如果查询的结果只有一行，可以使用&amp;nbsp;type=single；如果需要将查询的输出附加到现有结果后面，则可以使用&amp;nbsp;type=append。请参阅以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CREATE TABLE stock_table (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ticker VARCHAR(6),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;price DOUBLE,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;event_time TIMESTAMP(3),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;PARTITIONED BY (ticker)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WITH (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'connector' = 'kinesis',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'stream' = 'input-stream',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'aws.region' = 'us-east-1',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'scan.stream.initpos' = 'LATEST',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'format' = 'json',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'json.timestamp-format.standard' = 'ISO-8601')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此示例展示了创建一个名为&amp;nbsp;stock_table&amp;nbsp;的表，其中包含股票、价格和表示记录股票价格时间的&amp;nbsp;event_time&amp;nbsp;列。WATERMARK&amp;nbsp;子句根据&amp;nbsp;event_time&amp;nbsp;(row_time) 列定义了用于生成水位线的水位线策略。event_time&amp;nbsp;列被定义为&amp;nbsp;Timestamp(3)，是与水位线一起使用的顶级列。WATERMARK定义后面的语法 —&amp;nbsp;FOR event_time AS event_time – INTERVAL ‘5’ SECOND&amp;nbsp;— 声明水位线是根据&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/datastream/event-time/built_in/#fixed-amount-of-lateness"&gt;&amp;nbsp;bounded-out-of-orderness&lt;/a&gt; 策略发出的，允许&amp;nbsp;event_time&amp;nbsp;数据有 5 秒的延迟。该表使用 Kinesis 连接器从最新的流位置读取&amp;nbsp;us-east-1&amp;nbsp;区域中名为&amp;nbsp;input-stream&amp;nbsp;的 Kinesis 数据流。&lt;/p&gt; 
&lt;p&gt;在 Zeppelin 笔记本中运行此语句时，将会根据 CREATE 语句中的声明创建一个&lt;a href="https://aws.amazon.com/glue"&gt;&amp;nbsp;Amazon Glue&lt;/a&gt;&amp;nbsp;数据目录表，该表可立即用于来自 Kinesis Data Streams 的查询。&lt;/p&gt; 
&lt;p&gt;如果数据目录已包含该表，则无需完成此步骤。您可以如前文所述创建表，也可以使用现有的数据目录表。&lt;/p&gt; 
&lt;p&gt;以下屏幕截图展示了在 Amazon Glue 数据目录中创建的表。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;使用实时更新查询数据流&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;创建表后，可以通过编写 SELECT 语句来执行简单的数据流查询，该语句允许以表格形式或条形图、饼图等显示数据：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM stock_table;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;从不同图表中选择不同的可视化效果非常简单，可以直接从结果集的左上角选择。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要删除或重新创建此表，您可以导航到 Amazon Glue 控制台中的表目录，手动将其从数据目录中删除，也可以从Amazon Kinesis Data Analytics Studio 笔记本中显式地删除此表：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;DROP TABLE stock_table;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;过滤函数&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您可以使用关键字“WHERE”对数据流执行简单的过滤操作。在以下代码示例中，从所有股票代码记录过滤出以“AM”开头的流数据：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM stock_table WHERE ticker LIKE 'AM%'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio4.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;用户定义函数&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您可以在笔记本中注册用户定义函数 (UDF)，以便在我们的 Flink SQL 查询中使用。必须在表环境中注册才能供Amazon Kinesis Data Analytics Studio 应用程序中的 Flink SQL 使用。UDF 是可以在 Flink SQL 范围之外定义的函数，它们使用自定义逻辑或频繁的转换，通常这些内容不方便在 SQL 中表达出来。&lt;/p&gt; 
&lt;p&gt;UDF在Amazon Kinesis Data Analytics Studio 中是通过 Scala 实现的，其中 Python UDF 支持即将推出。UDF 可使用任意库处理数据。&lt;/p&gt; 
&lt;p&gt;让我们定义一个将股票符号转换为小写字母的 UDF 和一个将&amp;nbsp;event_time&amp;nbsp;转换为epoch seconds的 UDF：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;import java.time.LocalDateTime&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;import java.time.format.DateTimeFormatter._&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;import java.time.ZoneOffset&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;class DateTimeToEpoch extends ScalarFunction {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;def eval(datetime: LocalDateTime) = datetime.toEpochSecond(ZoneOffset.UTC)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;stenv.registerFunction("dt_to_epoch", new DateTimeToEpoch())&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;class ScalaLowerCase extends ScalarFunction {&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;def eval(str: String) = str.toLowerCase&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;stenv.registerFunction("to_lower", new ScalaLowerCase())&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在每个 UDF 定义的底部，Scala 中的&amp;nbsp;stenv(StreamingTableEnvironment) 用于注册指定名称的函数。&lt;/p&gt; 
&lt;p&gt;注册后，您只需在 Flink SQL 段落中调用 UDF 即可转换我们的数据：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT to_lower(ticker) as lowercase_ticker, price, dt_to_epoch(event_time) as epoch_time from stock_table;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio5.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;使用外部数据源（&lt;/strong&gt;&lt;strong&gt;join）来扩充数据&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;您可能需要使用存储在数据流之外的静态或参考数据来扩充流数据。例如，除了股票交易之外，公司地址和元数据可能流入到关系数据库或Amazon S3上的文件。为了扩充数据流，Flink SQL 允许您将参考数据连接到流数据源。这种扩充静态数据可能有或没有与之关联的时间元素。如果没有关联的时间元素，您可能需要向从外部读取的数据添加时间处理元素，以便将其与基于时间的流连接起来。这是为了避免得到过时的数据，在扩充数据时应注意这一点。&lt;/p&gt; 
&lt;p&gt;让我们定义一个扩充文件作为数据源，该文件位于 Amazon S3 中。存储桶包含一个 CSV 文件，其中包含股票代码和关联公司的元数据 — 全称、城市和州：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CREATE TABLE company_details_table (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; ticker_symbol VARCHAR(6),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; company_name VARCHAR,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; company_city VARCHAR,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; company_state_abbrev VARCHAR&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&amp;nbsp; WITH (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; 'connector' = 'filesystem',&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; 'path' = 's3a://interactive-applications/data-mapping-stock-enrichment.csv',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp; 'format' = 'csv'&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此 CSV 文件被一次性读取，且任务被标记为已完成。现在，您可以将它与现有的&amp;nbsp;stock_table&amp;nbsp;连接：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT ticker, price, company_name, event_time, company_city, company_state_abbrev FROM (SELECT CAST(event_time AS TIMESTAMP) as event_time, ticker, price from stock_table)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;JOIN company_details_table cd&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ON ticker=ticker_symbol;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在撰写本文时，Flink 存在一个&lt;a href="https://issues.apache.org/jira/browse/FLINK-10211"&gt;限制&lt;/a&gt;，它无法区分间隔连接（两个表都需要时间戳）和常规连接。因此，您需要将&amp;nbsp;rowtime&amp;nbsp;列 event_time 显式转换为常规时间戳，以免其被纳入常规连接中。如果两个表都有时间戳，理想的情况是将它们包含在连接语句的 WHERE 子句中。如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio6.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;滚动（&lt;/strong&gt;&lt;strong&gt;Tumbling）窗口&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;可将滚动窗口视为在不重叠的时间窗口中的小批次聚合。例如，计算 30 秒内的最高价格，或10 秒内的股票计数。要使用 Apache Flink SQL 执行此功能，请使用以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT ticker_symbol, COUNT(ticker_symbol) AS ticker_symbol_count&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;FROM stock_ticker_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;GROUP BY TUMBLE(processing_time, INTERVAL '10' second), ticker_symbol;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;以下截图显示了我们的输出。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio7.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;滑动（&lt;/strong&gt;&lt;strong&gt;Sliding）窗口&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;滑动窗口（也称为跳跃窗口）与滚动窗口基本相同，区别在于这些窗口可能会重叠。滑动窗口可以每隔 X 秒发出窗口大小为 Y 秒的数据。例如，对于上述使用案例，您可以每隔 5 秒发出一次 10 秒的数据统计：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT ticker_symbol, COUNT(ticker_symbol) AS ticker_symbol_count&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;FROM stock_ticker_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;GROUP BY HOP(processing_time, INTERVAL '5' second, INTERVAL '10' second), ticker_symbol;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;如下屏幕截图显示了结果。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio8.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;带过滤警报的滑动窗口&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;要过滤数据流中的记录，以触发某种警报或在下游使用它们，以下示例展示了如何将过滤出的滑动窗口插入聚合计数表中，该表的配置为写入数据流。之后可以使用&lt;a href="http://aws.amazon.com/cloudwatch"&gt;&amp;nbsp;Amazon CloudWatch&lt;/a&gt;&amp;nbsp;或其他触发机制来发出高交易率或其他指标的警报。&lt;/p&gt; 
&lt;p&gt;以下 CREATE TABLE 语句连接到 Kinesis 数据流，其后的插入语句将过滤出所有以&amp;nbsp;AM&amp;nbsp;开头的代码记录，其中 1 分钟间隔内有 750 条记录：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CREATE TABLE stock_ticker_count_table (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; ticker_symbol VARCHAR(4),&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; ticker_symbol_count INTEGER&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WITH (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'connector' = 'kinesis',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'stream' = 'output-stream',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'aws.region' = 'us-east-1',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'scan.stream.initpos' = 'LATEST',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'format' = 'json',&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;'json.timestamp-format.standard' = 'ISO-8601');&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;INSERT INTO&amp;nbsp; stock_ticker_count_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; (SELECT ticker_symbol, CAST(COUNT(ticker_symbol) AS INTEGER) AS ticker_symbol_count&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; FROM stock_ticker_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; WHERE ticker_symbol like 'AM%'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; GROUP BY HOP(processing_time, INTERVAL '30' second, INTERVAL '1' minute), ticker_symbol)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WHERE ticker_symbol_count &amp;gt; 750;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;事件时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果传入的数据包含时间戳信息，您的数据管道将使用事件时间而不是处理时间，从而更好地反映实际情况。这两种时间的区别在于，事件时间反映的是生成记录的时间，而处理时间指 Apache Flink 的Amazon Kinesis Data Analytics 收到记录的时间。&lt;/p&gt; 
&lt;p&gt;要在 Flink SQL 创建语句中指定事件时间，用于事件时间的元素必须为&amp;nbsp;TIMESTAMP(3)类型，并且必须伴随水位线策略表达式。如果事件时间列不是&amp;nbsp;TIMESTAMP(3)类型，也可以&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/create/#columns"&gt;计算出来&lt;/a&gt;。定义水位线策略表达式将事件时间字段标记为事件时间属性，并说明如何处理迟到的数据。&lt;/p&gt; 
&lt;p&gt;水位线策略表达式定义了水位线策略。计算为每条记录生成的水位线，并相应地处理数据的顺序。&lt;/p&gt; 
&lt;p&gt;流数据工作负载中的迟到数据很常见，大多数情况下是不可避免的。数据之所以迟到，可能是因为网络滞后、数据缓冲或处理速度缓慢以及介于它们之间的任何其他原因。对于可能引入迟到数据的升序的时间戳工作负载，您可以使用以下水位线策略：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL '0.001' SECOND&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此代码发出观察到的最大时间戳减去一条记录的水位线。时间戳早于或等于最大时间戳的行不会被视为迟到。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Bounded-out-of-orderness 时间戳&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;要发出观察到的最大时间戳减去指定延迟的水位线，可以通过Bounded-out-of-orderness时间戳定义允许的数据流中的记录延迟：&lt;/p&gt; 
&lt;p&gt;WATERMARK FOR rowtime_column AS rowtime_column – INTERVAL ‘3’ SECOND&lt;/p&gt; 
&lt;p&gt;上面的代码发出 3 秒延迟水位线。可以在本文的简介部分找到这个例子。水位线指示数据流处理迟到的数据。思考以下场景：股票代码每 5 秒钟用实时数据更新实时控制面板。如果数据延迟 10 秒（根据事件时间）到达数据流，我们会丢弃该数据，而不会反映在控制面板中。水位线指导 Apache Flink 处理迟到的数据。,&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;MATCH_RECOGNIZE&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;流数据中的一个常见模式是能够检测模式。Apache Flink 具有复杂的事件处理库，能够检测数据中的模式，而且 Flink SQL API 允许在关系查询语法中进行检测。&lt;/p&gt; 
&lt;p&gt;通过 Flink SQL 中的&amp;nbsp;MATCH_RECOGNIZE&amp;nbsp;查询能够实现逻辑分区并识别流表中的模式。以下示例演示了如何操作我们的股票表：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;%flink.ssql(type=update)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT *&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;FROM stock_table&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; MATCH_RECOGNIZE(&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; PARTITION BY ticker&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ORDER BY event_time&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; MEASURES&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; A.event_time AS initialPriceTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; C.event_time AS dropTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; A.price - C.price AS dropDiff,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; A.price as initialPrice,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; C.price as lastPrice&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ONE ROW PER MATCH&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; AFTER MATCH SKIP PAST LAST ROW&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; PATTERN (A B* C) WITHIN INTERVAL '10' MINUTES&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; DEFINE&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; B AS B.price &amp;gt; A.price - 500&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; )&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;在此查询中，我们识别了 10 分钟内某只下跌了 500 美元的股票。让我们将&amp;nbsp;MATCH_RECOGNIZE&amp;nbsp;查询细分为几个组件。&lt;/p&gt; 
&lt;p&gt;以下代码查询我们现有的&amp;nbsp;stock_table：&lt;/p&gt; 
&lt;p&gt;SELECT * FROM stock_table&lt;/p&gt; 
&lt;p&gt;MATCH_RECOGNIZE&amp;nbsp;关键字开始将模式与查询子句相匹配。这表示我们正在识别表中的模式。&lt;/p&gt; 
&lt;p&gt;下面的代码定义了表的逻辑分区，类似于 GROUP BY 表达式：&lt;/p&gt; 
&lt;p&gt;PARTITION BY ticker&lt;/p&gt; 
&lt;p&gt;以下代码定义了如何对传入数据进行排序。所有&amp;nbsp;MATCH_RECOGNIZE&amp;nbsp;模式都需要分区和排序方案才能识别模式。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ORDER BY event_time&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;MEASURES&amp;nbsp;定义了查询的输出。您可以将其视为 SELECT 语句，因为这是模式的最终结果。&lt;/p&gt; 
&lt;p&gt;在下面的代码中，我们从模式识别中选择要输出的行：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;A.event_time AS initialPriceTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;C.event_time AS dropTime,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;A.price - C.price AS dropDiff,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;A.price as initialPrice,&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;C.price as lastPrice&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;我们使用以下参数：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A.event_time&lt;/strong&gt;&amp;nbsp;— 记录在模式中的第一个时间，500 美元的价格从这个时间开始下跌&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C.event_time&lt;/strong&gt;&amp;nbsp;— 记录在模式中的最后一个时间，这个时间的价格比&amp;nbsp;A.price&amp;nbsp;下跌了至少 500 美元&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A.price – C.price&lt;/strong&gt;&amp;nbsp;— 记录在模式中的第一个时间到最后一个时间的价差&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A.price&lt;/strong&gt;&amp;nbsp;— 记录在模式中的第一个价格，500 美元的价格开始下跌&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C.price&lt;/strong&gt;&amp;nbsp;— 记录在模式中的最后一个价格，比&amp;nbsp;A.price&amp;nbsp;下跌了至少 500 美元&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ONE ROW PER MATCH&amp;nbsp;定义了输出模式 — 每找到一个匹配应发出多少行。从 Apache Flink 1.12 开始，这是唯一受支持的输出模式。有关当前不支持的替代方案，请参阅&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/match_recognize/#output-mode"&gt;输出模式&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;以下代码定义了匹配后策略&lt;strong&gt;：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;AFTER MATCH SKIP PAST LAST ROW&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;此代码指导 Flink SQL 在找到匹配后启动新的匹配过程。这个特定的定义跳过当前模式中的所有行，然后转到数据流中的下一行。这可以确保模式事件中不存在重叠。有关&amp;nbsp;AFTER MATCH SKIP&amp;nbsp;替代策略，请参阅&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/match_recognize/#after-match-strategy"&gt;匹配后策略&lt;/a&gt;。可将这种策略视为一种滚动窗口类型的聚合，因为模式的结果相互不重叠。&lt;/p&gt; 
&lt;p&gt;在下面的代码中，我们定义了模式&amp;nbsp;A B* C，表示我们将有一个序列的连接记录：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;PATTERN (A B* C) WITHIN INTERVAL '10' MINUTES&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;我们使用以下顺序：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A&lt;/strong&gt;&amp;nbsp;— 序列中的第一条记录&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;B*&lt;/strong&gt;&amp;nbsp;— 与 DEFINE 子句中定义的约束相匹配的零或多条记录&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C&lt;/strong&gt;&amp;nbsp;— 序列中的最后一条记录&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些变量的名称在 PATTERN 子句中得到定义，并遵循类似正则的语法。有关详细信息，请参见&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/match_recognize/#defining-a-pattern"&gt;定义模式&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在下面的代码中，我们将&amp;nbsp;B&amp;nbsp;模式变量定义为记录的价格，只要该价格大于模式中第一条记录减 500 的值：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;DEFINE&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; B AS B.price &amp;gt; A.price - 500&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;例如，假设我们有以下模式。&lt;/p&gt; 
&lt;table border="1"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;row&lt;/td&gt; 
   &lt;td width="88"&gt;ticker&lt;/td&gt; 
   &lt;td width="88"&gt;price&lt;/td&gt; 
   &lt;td width="88"&gt;event_time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;1&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;800&lt;/td&gt; 
   &lt;td width="88"&gt;10:00 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;2&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;400&lt;/td&gt; 
   &lt;td width="88"&gt;10:01 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;3&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;500&lt;/td&gt; 
   &lt;td width="88"&gt;10:02 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;4&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;350&lt;/td&gt; 
   &lt;td width="88"&gt;10:03 am&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="88"&gt;5&lt;/td&gt; 
   &lt;td width="88"&gt;AMZN&lt;/td&gt; 
   &lt;td width="88"&gt;200&lt;/td&gt; 
   &lt;td width="88"&gt;10:04 am&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;我们定义以下内容：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A&lt;/strong&gt;&amp;nbsp;— 第 1 行&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;B&lt;/strong&gt;&amp;nbsp;— 第 2—4 行，它们都匹配 DEFINE 子句中的条件&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C&lt;/strong&gt;&amp;nbsp;— 第 5 行，它打破了匹配 B 条件的模式，因此是模式中的最后一行&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以下屏幕截图展示了完整的例子。&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/top-10-flink-sql-queries-to-try-in-amazon-kinesis-data-analytics-studio9.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Top-N&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/topn/"&gt;Top-N 查询&lt;/a&gt;识别按列排序的 N 个最小值或最大值。例如，在需要识别数据流中前 10 个项目或最后 10 个项目的情况下，此查询非常有用。&lt;/p&gt; 
&lt;p&gt;Flink 可使用&amp;nbsp;OVER&amp;nbsp;窗口子句和筛选表达式的组合来生成 Top-N 查询。OVER / PARTITION&amp;nbsp;BY 子句还可以支持每组的 Top-N。请参阅以下代码：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;SELECT * FROM (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; SELECT *, ROW_NUMBER() OVER (PARTITION BY ticker_symbol ORDER BY price DESC) as row_num&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; FROM stock_table)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WHERE row_num &amp;lt;= 10;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;数据去重&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如果生成到数据流中的数据可能存在重复条目，有多种策略可消除这些条目。要实现这一目的，最简单的方法是&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/queries/deduplication/"&gt;数据去重&lt;/a&gt;，您可以在窗口中删除行，并根据时间戳仅保留第一个或最后一个元素。&lt;/p&gt; 
&lt;p&gt;Flink 可使用&amp;nbsp;ROW_NUMBER&amp;nbsp;来删除重复项，正如 Top-N 示例所展示的方法一样。只需编写&amp;nbsp;OVER / PARTITION&amp;nbsp;BY 查询，然后在 WHERE 子句中指定第一行的编号：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;SELECT * FROM (&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; SELECT *, ROW_NUMBER OVER (PARTITION BY ticker_symbol ORDER BY price DESC) as row_num&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; FROM stock_table)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;WHERE row_num = 1;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;最佳实践&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;与任何数据流工作负载一样，为了解工作负载的进展情况，您需要测试和监控策略。&lt;/p&gt; 
&lt;p&gt;以下是需要监控的关键领域：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;源&lt;/strong&gt;&amp;nbsp;— 确保源数据流具有足够的吞吐量，并且在使用Amazon Kinesis 的情况下，您没有收到&amp;nbsp;ThroughputExceededExceptions，或源系统的高内存或 CPU 使用率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;目标&lt;/strong&gt;&amp;nbsp;— 与数据源一样，确保 Flink SQL 应用程序的输出不会塞满下游系统。在使用Amazon Kinesis 的情况下，请确保您没有收到任何&amp;nbsp;ThroughputExceededExceptions。如果收到，应添加分片或者更均匀地分配数据。否则可能会对管道造成背压。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;扩缩&lt;/strong&gt;&amp;nbsp;— 在分配和扩缩Amazon Kinesis Data Analytics Studio 应用程序时，请确保数据管道有足够的Amazon Kinesis 处理单元。您可以启用基于 CPU 的自动扩缩功能，或者实施&lt;a href="https://github.com/aws-samples/kda-flink-app-autoscaling"&gt;自定义自动扩缩程序&lt;/a&gt;，以便在大量数据流入时扩展应用程序。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;测试&lt;/strong&gt;&amp;nbsp;— 在将新的数据管道部署到生产规模数据之前，先开展小规模的测试。如果可能，请使用真实的生产数据来测试管道，或者使用模拟生产数据来了解应用程序的反应，之后再将其部署到生产环境中。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;笔记本内存&lt;/strong&gt;&amp;nbsp;— 运行应用程序的 Zeppelin 笔记本受浏览器可用内存量的限制，因此，不要向控制台发出太多行，这会导致浏览器的内存冻结笔记本。虽然不会丢失数据和计算，但表示层会变得无法访问。相反，在将数据传到表示层之前，应尝试聚合数据，获取代表性样本，或者限制返回的记录量，以缓解笔记本内存不足的情况。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;只需几分钟，您就可以使用 Flink SQL 在Amazon Kinesis Data Analytics Studio 中查询数据流并创建数据管道。在本文中，我们讨论了多种不同的查询数据流的方法，&lt;a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/table/sql/overview/"&gt;Apache Flink SQL 文档&lt;/a&gt;还提供了大量的其他示例。&lt;/p&gt; 
&lt;p&gt;您可以将这些样本传入自己的Amazon Kinesis Data Analytics Studio 笔记本中，然后在自己的流数据上试用！ 务必让 AWS 了解您对这项新功能的体验，我们期待看到用户使用Amazon Kinesis Data Analytics Studio 从数据中获得见解。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/jdber.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Jeremy Ber&lt;/h3&gt; 
  &lt;p&gt;在过去 5 年中一直从事于遥测数据领域，担任软件工程师、机器学习工程师，最近还担任数据工程师。过去，Jeremy 支持并构建了每天流式传输 TB 级数据的系统，并实时处理复杂的机器学习算法。在 亚马逊云科技，他是解决方案架构师和流数据处理专家，为 Managed Streaming for Kafka (Amazon MSK) 和 Amazon Kinesis 提供支持。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>基于云的数据网格技术如何实现金融监管数据采集</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection/</link>
				<pubDate>Tue, 31 Aug 2021 02:42:10 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Data Exchange]]></category>
		<category><![CDATA[Amazon EMR]]></category>

		<guid isPermaLink="false">046f3ffc6e562813d8739670002e72b339163bd9</guid>
				<description>实践证明，现代云技术可以通过汇集数据并使用数据仓库和大数据工具进行分析，以经济高效的方式实现有价值的见解。例如，使用 Amazon EMR 之类的大数据分析工具整合来自证券交易的数据，以实现增强风险管理。对监管机构来说，面临的挑战在于能够通过以受控、高度灵活且经济高效的方式分析各种大型数据集来获取见解和有价值的信息。随着市场的演变和经济风险的变化，监管机构和中央银行的需求也将发生变化，因此监管生态系统必须继续适应所有参与者并具有成本效益。</description>
								<content:encoded>&lt;h2&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;中央银行和金融监管机构依赖于从银行和保险公司等受监管的金融机构获取高质量、最新的数据。这些受监管的实体拥有各种各样且不断变化的运营环境，每个机构都独立运营，但必须与监管机构协调交换相关数据。今天，银行支持监管机构提出的数据请求所产生的成本非常高。例如，&lt;a href="https://www.bankofengland.co.uk/-/media/boe/files/report/2019/future-of-finance-report.pdf?la=en&amp;amp;hash=59CEFAEF01C71AA551E7182262E933A699E952FC"&gt;英格兰银行提及了麦肯锡公司 2019 年的一项研究&lt;/a&gt;，该研究估计，英国银行在监管报告方面的每年的支出在 20 亿英镑至 45 亿英镑之间。&lt;/p&gt; 
&lt;p&gt;实践证明，现代云技术可以通过汇集数据并使用数据仓库和大数据工具进行分析，以经济高效的方式实现有价值的见解。例如，使用&amp;nbsp;&lt;a href="https://aws.amazon.com/emr/"&gt;Amazon EMR&lt;/a&gt;&amp;nbsp;之类的大数据分析工具整合来自证券交易的数据，以实现增强风险管理。对监管机构来说，面临的挑战在于能够通过以受控、高度灵活且经济高效的方式分析各种大型数据集来获取见解和有价值的信息。随着市场的演变和经济风险的变化，监管机构和中央银行的需求也将发生变化，因此监管生态系统必须继续适应所有参与者并具有成本效益。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;介绍数据网格&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 martinFowler.com 发表的一篇文章：“&lt;a href="https://martinfowler.com/articles/data-monolith-to-mesh.html"&gt;如何从单体数据湖迁移到分布式数据网格&lt;/a&gt;”中，Zhamak Dehghani 解释了需要对以数据为中心的系统采用新方法的一些原因。Dehghani 认为，每一代“数据平台”都导致了一个集中化的单体，却忽略了生产者（例如大型组织内的部门）在如何优化数据结构为业务目的服务的个性化需求。虽然单体数据湖对于具有直观业务模式的组织来说可以奏效，但随着数据血缘和治理问题管理难度的增加，这对于更复杂的企业而言变得越来越困难。对于参与监管报告和数据收集的独立实体的生态系统来说，问题更为严重。&lt;/p&gt; 
&lt;p&gt;与“数据网格”概念结合使用的云技术为解决监管报告问题提供了一种有希望的方法。数据网格可以自然地解决与联合监管生态系统相关的数据所有权、治理和血缘问题。在数据网格方法中，每个数据生产者（例如商业银行）都独立维护和更新其已发布的数据。只有当银行选择“发布”新版本的数据集时，订阅的数据消费者（例如 FSI 监管机构）才能看到更改。每个生产者都会控制每个已发布数据集的结构，此结构由数据模式描述。同时，数据消费者可能会从多个数据生产者（例如监管机构管辖下的每家银行）收集公布的数据。然后，数据消费者可以根据需要使用各种不同的云技术来填充数据湖或数据仓库。因此，以灵活而经济高效的方式，监管数据网格使受监管实体能够“弥合其人员、流程和生成数据的系统之间的差距”。&lt;/p&gt; 
&lt;p&gt;这种数据网格方法的一个关键推动因素是使用自我描述数据。我们可以设想一个基于集中定义的数据模式、包含多个数据生产者和消费者的数据生态系统。但是，鉴于数据生产者运营的内部 IT 系统种类繁多，保持所有参与者的数据严格同步是不现实的——这种方法的执行成本高昂，而且对持续变化非常脆弱。相反，解决此问题的办法是由每个生产者创建一个嵌入式数据模式，以描述每个已发布数据集的当前结构。在监管生态系统中，此元数据可以参考标准术语和监管机构定义的一组数据字段来描述数据，例如“银行综合报告词典”(BIRD) 和欧洲中央银行系统 (ESCB) 的综合报告框架 (IReF) 中定义的数据字段。只要他们遵守法定命名法并提供所有必填的数据字段，数据生产者就可以自由采用自己的数据架构。然后，每当生产者对数据集的内容或结构进行更改时，这些更改都会反映在嵌入式数据模式中。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;实施方法概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/data-exchange/"&gt;Amazon Data Exchange&lt;/a&gt;&amp;nbsp;为创建这些安全的多方数据网格环境提供了必要的基础。使用 Amazon Data Exchange “Private”（私有）发布选项，只有经生产者授权的特定数据消费者（例如监管机构）才能查看数据产品并订阅该数据产品。AWS Data Exchange 上发布的每个视图都开启了版本控制，因此，数据消费者可以使用可审计的数据更改记录。数据消费者可以访问此自描述数据，并使用工具（例如 AWS Glue）将其转换为通过数据仓库、数据库或数据湖进行下游处理所需的格式。&lt;/p&gt; 
&lt;p&gt;最近的博客&lt;a href="https://aws.amazon.com/blogs/apn/analyzing-covid-19-data-with-aws-data-exchange-amazon-redshift-and-tableau/"&gt;分析 COVID-19 数据&lt;/a&gt;展示了以这种方式使用 Amazon Data Exchange 的力量。在此示例中，亚马逊云科技与亚马逊云科技的合作伙伴 Salesforce、Tableau 和 MuleSoft 汇集了可信赖的 COVID-19 数据来源，使其能够通过 Amazon Data Exchange 与感兴趣的第三方共享。这使得数据消费者能够将相关数据提取到他们的分析数据湖中，并根据需要提取和转换数据。Amazon Data Exchange 内的相关数据生产者可以随时提供新版本的数据，并且这些新版本数据的可用性将传达给所有数据消费者。该资源可公开提供，用于支持组织的 COVID 救助工作。在其他使用案例中，也可以使用 Amazon Identity and Access Management 控件严格限制访问权限。&lt;/p&gt; 
&lt;p&gt;图 1 显示了联合监管报告数据网格环境的概念概述；其中每家受监管银行都是 AWS Data Exchange 数据生产者，每个监管机构都是 Amazon Data Exchange 数据消费者。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;em&gt;图&lt;/em&gt;&lt;em&gt; 1：监管机构报告数据网格&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;图 2 所示的这种环境的实施包括以下阶段：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;受监管银行（Amazon Data Exchange 数据生产者）策划和上传所需的数据构件，以创建其 Amazon Data Exchange 监管报告数据产品。请参阅 AWS Data Exchange 最佳实践。&lt;/li&gt; 
 &lt;li&gt;在适当或需要时，每个数据生产者都会发布其报告数据产品的新修订版本（例如监管数据）。这个新发布的修订版本可能只包括已更改的数据、所有数据或者所有数据和完整的更改历史记录。每个数据生产者可以随时创建和发布修订。&lt;/li&gt; 
 &lt;li&gt;监管机构（数据消费者）会收到更新通知，他们可以自行决定对更新采取行动，在需要时将修订内容纳入报告分析基础设施中。由于每个数据生产者的修订都是自我描述的，因此将这些不同来源映射到数据消费者的标准化数据结构中是一个简单的过程。&lt;/li&gt; 
 &lt;li&gt;可以使用一系列工具和技术对标准化数据进行分析，以搜索特定信息或提取见解。选项包括图关系分析 (Amazon Neptune)、AI/ML 模式识别 (Amazon SageMaker)、传统数据仓库搜索/查询（Amazon Redshift 或 Amazon Athena）和报告生成。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="text-align: center"&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-does-cloud-based-data-grid-technology-realize-financial-supervision-data-collection2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; &lt;em&gt;图&lt;/em&gt;&lt;em&gt; 2：联合监管报告数据网格环境的示例实施&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;机会和益处&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Amazon Data Exchange 方法可以用作高度自适应性和可扩展性的“常用输入层”的基础，监管机构认为这是一个理想的属性（例如，参见 2020 年 1 月发布的英格兰银行关于“&lt;a href="https://www.bankofengland.co.uk/-/media/boe/files/paper/2020/transforming-data-collection-from-the-uk-financial-sector.pdf?la=en&amp;amp;hash=6E6132B4F7AF681CCB425B0171B4CF43D82E7779"&gt;转型数据收集&lt;/a&gt;”的咨询意见）。该文讨论的考虑因素之一是，常用输入层是应采取“推送”还是“拉取”的方法（例如，受监管实体应按照要求向监管机构“推送”数据），或者在必要时，监管机构从每个受监管实体中“提取”数据。监管数据网格架构提供了这两种方法的优势。它为数据生产者提供了“推送”系统的益处，它可以抽象自己底层 IT 系统的复杂性以及更新的时间，而无需直接与监管机构协调。它还允许监管机构在需要时“拉取”所需数据，从而使每家银行免于根据监管机构的要求不断生成新报告或数据提取的负担。&lt;/p&gt; 
&lt;p&gt;它还为双方提供了进一步的优势。数据生产者有一个本地数据存储库，对于数据生产者来说，它具有作为参考数据存储的潜在价值，并且数据生产者不用承担必须根据监管机构的要求不断生成新报告或数据提取的负担。监管机构的优势是能够创建新的组合数据集并按需分析它们，而无需构建永久的集中式数据湖。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;监管机构为实现监管目标而需要收集的数据的数量、及时性和准确性给监管机构和受监管公司带来了挑战。但是，面临的许多业务问题有切实可行的解决方案，可以使用云技术来安全、经济高效且可扩展地开发这些解决方案。我们尤其相信，各方都可以从数据网格技术的应用中受益，以便能够以足够灵活的方式适应不断变化的需求，从而减轻大小型组织的数据收集负担。&lt;/p&gt; 
&lt;p&gt;基于云的数据网格技术还可以成功地应用于各种其他数据管理要求，从获取第三方和公共数据以帮助进行内部决策制定，到确保内部数据集之间的一致性。这只是云计算改变企业看待他们面临的一些最艰难的数据挑战的方式之一，从而帮助他们创建更敏捷和可持续的解决方案。&lt;/p&gt; 
&lt;p&gt;要了解有关云计算如何帮助改进监管报告和数据收集的更多信息，请联系：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/rcnic.png" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Richard Nicholson&lt;/h3&gt; 
  &lt;p&gt;Richard 是亚马逊云科技金融服务 EMEA 业务和市场开发团队的首席解决方案架构师。Richard 的工作领域非常广泛，比如前台风险系统架构和后台核心大型机迁移。在加入亚马逊云科技之前，Richard 在自己的公司工作了 18 年，专注于金融服务和工业 IoT 等不同行业的运行时自适应软件系统的开发和使用。作为一名经过培训的天体物理学家，Richard 于 1995 年进入金融服务行业，担任 Salomon Brothers 的基础设施系统管理员。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/rcaven.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Richard Caven&lt;/h3&gt; 
  &lt;p&gt;Richard Caven 是英国和爱尔兰以及北欧银行业领先的亚马逊云科技金融服务专家。他负责开发和执行战略计划，以帮助客户迁移到云并推动他们的数字化转型之旅。Richard 于 2018 年从 Barclays 加入亚马逊云科技，担任全球财资职能部门的总经理和首席运营官。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/dmmackei.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;David MacKeith&lt;/h3&gt; 
  &lt;p&gt;David MacKeith 负责亚马逊云科技欧洲、中东和非洲 (EMEA) 政府金融服务的业务开发。他在帮助世界各地的政府和金融服务组织转型其运营方式以更好地服务各自的客户和市场方面拥有 20 多年的经验。这包括帮助这些组织在数字货币、货币和市场分析、监管报告和数据收集自动化和优化以及财资管理职能转型等领域开发、试验和部署创新解决方案。在加入亚马逊云科技之前，MacKeith 先生曾在伦敦金融城担任商业交易律师。他拥有剑桥大学的物理学学位。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>如何使用数据网格创建现代包装消费品 (CPG)行业数据架构</title>
		<link>https://aws.amazon.com/cn/blogs/china/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture/</link>
				<pubDate>Tue, 31 Aug 2021 02:26:48 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Analytics]]></category>
		<category><![CDATA[Amazon Glue]]></category>
		<category><![CDATA[Amazon Lake Formation]]></category>

		<guid isPermaLink="false">a155373d52ed91a040fd538dc72cae34ccf05515</guid>
				<description>在本博客文章中，我们将深入探讨大规模管理数据的主题，并解释为什么 CPG 应考虑使用数据网格进行数据管理的新方法。</description>
								<content:encoded>&lt;p&gt;自新冠肺炎 (COVID-19) 疫情以来，我们看到世界各地都在向在线购物和直接面向消费者的销售进行翻天覆地的转变。可以说，包装消费品 (CPG) 行业比任何其他行业都更能感受到这种转变。根据统计，“零售网站&lt;a href="https://www.statista.com/statistics/1112595/covid-19-impact-retail-e-commerce-site-traffic-global/"&gt;在 2020 年 6 月创造了近 220 亿次访问量&lt;/a&gt;，而 2020 年 1 月，其全球访问量为 160.7 亿次。” 网站流量在 6 个月内大幅增长 27%，这加速了公司（特别是 CPG）需要管理的数据量。&lt;/p&gt; 
&lt;p&gt;历史上，大多数 CPG 并没有直接与消费者交流，因此数据很少，且主要代表了内部信息，例如与零售合作伙伴的订单和运输详情。现在，精明的消费品公司开始跟踪最终用户客户和外部数据，例如搜索分析和社交媒体情绪。在本博客文章中，我们将深入探讨大规模管理数据的主题，并解释为什么 CPG 应考虑使用数据网格进行数据管理的新方法。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;CPG 组织之间的数据流&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先，我们从数据生态系统的概述开始。由于数据已成为竞争差异化的一个重要点，因此，很多公司允许各个业务层面的人通过分析和机器学习来使用、转换和增强数据——将数据视为不断发展、不断扩展的资产。这对于利用数据推动产品开发和营销决策的 CPG 品牌经理尤其重要。&lt;/p&gt; 
&lt;p&gt;现代数据生态系统中有三个核心组：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;数据生产者&lt;/strong&gt;&amp;nbsp;– 拥有传入数据系统或来源（订单、发票、库存等）的领域专家。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据平台构建者&lt;/strong&gt;&amp;nbsp;– IT 团队的一部分，其成员拥有不同数据技能，其要求具体取决于公司的成熟度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据消费者&lt;/strong&gt;&amp;nbsp;– 使用数据优化业务、做出决策和定义策略的分析师和运营者。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;CPG 的数据湖面临的挑战和局限&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/?nc=sn&amp;amp;loc=2"&gt;数据湖&lt;/a&gt;通常用于管理数据的快速增长。该集中式存储库存储结构化和非结构化数据。您可以批量或通过实时流式传输来注入信息。但是，当具有大量数据源的数据扩展到 PB 级时，这种经过验证的技术就有一些局限性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安全挑战&lt;/strong&gt;&amp;nbsp;– 实现大规模精细安全性非常困难。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;通用方法&lt;/strong&gt;&amp;nbsp;– 一刀切的方法不允许您针对特定数据集优化数据湖。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完整性问题&lt;/strong&gt;&amp;nbsp;– 通常，数据输入数据湖后会丢失上下文。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;手动维护&lt;/strong&gt;&amp;nbsp;– 不同的，冲突的数据集需要人工操作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些限制会转化为较长的开发周期和瓶颈，从而无法将数据输入数据湖并从中提取有意义的信息，这意味着许多 CPG IT 部门都在努力地大规模维护和挖掘数据。同时，对于数据消费者来说，访问和分析企业数据可能非常复杂且令人沮丧。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture1.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在数据湖模型中，数据被摄取到企业数据湖中。中央平台团队负责管理安全性、摄取、转换、访问和数据可用性。数据生产者和消费者需要通过集中化团队来存储和访问数据。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;从整体到可管理：一种软件类比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由中央 IT 部门管理的数据湖类似于 20 世纪 90 年代的整体软件产品。刚性、相互依赖性和缓慢的开发周期是软件开发中的微服务革命背后的驱动力，它提供了可扩展性、更短的开发周期、隔离安全性和更轻松的管理。&lt;/p&gt; 
&lt;p&gt;那么我们如何将同样的微服务设计原则应用于数据呢？ 在CPG 行业（以及其他行业）的答案是数据网格。&lt;/p&gt; 
&lt;p&gt;数据网格是一种相对较新的架构设计，它解决了单体式数据湖架构的缺点，并提供了与软件设计中的微服务类似的益处。在数据网格中，数据本身就是产品，并且由与领域无关的自助式数据基础设施提供支持。数据网格通过以下方式打破了传统数据湖的单体性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;数据即产品&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;– 在典型的数据湖中，数据湖和数据管道就是产品。在数据网格中，数据以及收集和发布数据的领域和生产者专业知识是产品。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分散式所有权&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;– 与 IT 集中管理的数据湖不同，数据网格具有分散式所有权。不同的业务领域（数据生产者）负责策划、验证、发布、维护和生命周期管理他们拥有的数据。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;精细、可扩展的访问控制&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;– 由于数据被数据网格中的生产者所拥有，因此由他们指定访问、治理和保留策略以及基于数据粒度的任何自定义访问策略。这样一来，通过将责任和访问控制策略推送给数据所有者，消除了数据湖的集中访问控制瓶颈。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可扩展的数据发现&lt;/strong&gt;&amp;nbsp;– 数据网格允许消费者根据领域、粒度、质量、频率等发现、识别和订阅数据。这使可扩展的消费者可以访问和发现，并消除对集中式团队的依赖。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当生产者在数据网格中发布数据时，他们会使用以下属性创建不可变的数据契约：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;数据类型&lt;/li&gt; 
 &lt;li&gt;物理模式&lt;/li&gt; 
 &lt;li&gt;业务特点&lt;/li&gt; 
 &lt;li&gt;分发频率&lt;/li&gt; 
 &lt;li&gt;数据质量声明&lt;/li&gt; 
 &lt;li&gt;生命周期策略&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;数据契约是一种确保在整个企业中可以发现数据的机制。合同属性与数据的整个生命周期相关联，数据消费者可以发现和订阅特定的数据契约属性。&lt;/p&gt; 
&lt;p&gt;在网格架构中，数据可以存储在生成数据的位置。中央平台团队负责管理安全性，确保契约得到执行，并提供工具和自动化。数据生产者和消费者可以访问和查看整个企业中的所有数据，并可以彼此之间进行通信。&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture2.png" width="624" height="78"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;CPG 行业的数据网格参考架构和用法&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;以下是一种典型的数据网格实现的示例：&lt;br&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/how-to-use-data-grids-to-create-modern-consumer-packaged-goods-cpg-industry-data-architecture3.png" width="624" height="78"&gt;&lt;/a&gt;&lt;br&gt; 该设计使用&amp;nbsp;&lt;a href="https://aws.amazon.com/pub-sub-messaging/"&gt;pub/sub 模型&lt;/a&gt;。尽管该解决方案使用&lt;a href="https://aws.amazon.com/lake-formation"&gt;Amazon Lake Formation&lt;/a&gt;&lt;u&gt; 一种可以&lt;/u&gt;简化数据湖创建工作的服务，但您需要手动定义数据源、访问权限和安全策略。您可以使用&amp;nbsp;&lt;a href="https://aws.amazon.com/glue"&gt;Amazon Glue&lt;/a&gt;&amp;nbsp;发现数据目录中的数据，也可以使用契约中定义的属性发现元数据。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;用数据网格管理单独的微服务数据集&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;近年来，CPG 行业投入了大量资金，使用微服务和容器架构实现在线基础设施的现代化。在这种新的设计模式中，每项微服务都会创建单独的数据集（搜索、结账、排序、产品等），且新的不同数据会成倍增加。每个独特的数据流都由不同的数据生产者拥有，并且具有不同的质量、治理和生命周期属性。生产者可以配置数据流以实时或批量上传到数据平台。这种微服务设计能够自然地适合数据网格概念实施模式。&lt;/p&gt; 
&lt;p&gt;有关 CPG 行业微服务的更多信息，请务必阅读 Danny Yin 的博客文章《&lt;a href="https://aws.amazon.com/blogs/industries/use-this-success-strategy-to-move-to-a-microservice-architecture/"&gt;在 CPG 中迁移到微服务架构的成功策略&lt;/a&gt;》。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;将数据管家指定为&lt;/strong&gt;&lt;strong&gt; CPG 中的数据点人员&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;为了确保数据网格架构的可扩展性，组织通常会指定一名数据管家，他是一位对生产者生成数据的方式、数据本身的契约属性、用户访问控制、数据清洁度和预期的消费者使用模式有深入了解的专人。数据管家的任务是确保数据在整个生命周期中的契约完整性，并帮助管理任何契约修改。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;在数据清洁室中挖掘受限的&lt;/strong&gt;&lt;strong&gt; CPG 数据&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在这种新兴的使用案例中，清洁室包含原始数据，例如 PII 或 POS 交易数据，这些数据可能受到隐私限制的约束。在清洁室中，数据消费者可以通过充足的匿名化运行聚合查询。数据消费者还可以使用不受限制的数据联合匿名数据进行分析信息，同时遵守隐私要求。数据网格架构通过强制执行数据的契约限制去原生支持清洁室要求。&lt;/p&gt; 
&lt;p&gt;随着各国采用严格的数据隐私规则，例如&amp;nbsp;&lt;a href="http://www.oecd.org/"&gt;OECD&lt;/a&gt;&amp;nbsp;指南或欧盟《&lt;a href="https://www.consumersinternational.org/media/155133/gdpr-briefing.pdf"&gt;一般数据保护条例&lt;/a&gt;》，管理如何维护、保护、使用和处置数据的规则变得更加复杂。数据网格架构可以正确隔离数据、强制执行安全策略并授予对数据的访问权限。数据优先的设计和数据网格的精细访问控制提供了支持数据隐私要求的原生机制，而不需要昂贵的企业范围的数据项目。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;使用数据网格与&lt;/strong&gt;&lt;strong&gt; CPG 相关的供应商协作&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;很多 CPG 都在试图优化第三方提供商的运营，例如提供原材料和成品的供应链和物流供应商。数据网格是从头开始设计的，以在原生支持 CPG 和供应商之间的协作。内部和外部数据生产者和消费者可以通过商定的契约自由交换数据，而数据不可变性为多供应商系统的高效运行提供了完整性。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;数据网格架构是单体数据湖和数据仓库的现代化方法，从而使 CPG 行业能够大规模管理数据。询问亚马逊云科技如何支持您的数据转换。立即&lt;a href="https://pages.awscloud.com/GLOBAL-other-IND-CPG-Contact-Us-2021.html"&gt;联系&lt;/a&gt;您的 Amazon Web Services 账户团队以开始行动，或访问我们的&lt;a href="https://aws.amazon.com/cpg/"&gt;消费性包装品&lt;/a&gt;页面了解更多信息。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/ilanraab.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Ilan Raab&lt;/h3&gt; 
  &lt;p&gt;Ilan Raab 是亚马逊云科技消费性包装品 (CPG) 行业的全球技术领导者。Ilan 于 2019 年加入亚马逊云科技，负责定义和执行公司的 CPG 技术策略，其中包括在制造/移动/市场业务领域构建以 CPG 为重点的解决方案。他经常与亚马逊云科技CPG 客户合作，利用尖端的亚马逊云科技技术和思想领导力来帮助他们实现业务转型。在加入 AWS 之前，Ilan 是企业软件和网络领域多家初创公司的工程副总裁兼联合创始人。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/mchiapus.jpg" width="125"&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;Marco Chiapusso&lt;/h3&gt; 
  &lt;p&gt;Marco Chiapusso 于 2020 年 1 月加入亚马逊云科技，担任欧洲、中东和非洲的解决方案架构经理。他与全球企业客户合作，共享云如何帮助他们提高速度和敏捷性，同时让他们能把更多的时间花在客户身上的最佳实践、技术和策略。在加入亚马逊云科技之前，Marco 担任了多个高级技术职位，领导并共同领导了多项大规模计划，将组织转变为技术赋能型现代公司。其中包括开发和部署一个拥有超过 1PB 数据的现代数据平台，从而提高客户洞察力，并大规模增强机器学习能力。Marco 在 Adidas 的经验和任期涉及多个领域，包括架构、开发、支持、数据、创新（包括 AI 和 IoT）以及组织发展。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
	</channel>
</rss>