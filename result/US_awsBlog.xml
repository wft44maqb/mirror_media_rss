<?xml version="1.0" encoding="UTF-8" standalone="no"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" version="2.0">

<channel>
	<title>亚马逊AWS官方博客</title>
	<atom:link href="https://aws.amazon.com/cn/blogs/china/feed/" rel="self" type="application/rss+xml"/>
	<link>https://aws.amazon.com/cn/blogs/china/</link>
	<description>Just another AWS Brew Blogs  site</description>
	<lastBuildDate>Fri, 27 Aug 2021 09:31:39 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	
	<item>
		<title>基于AI技术的智能剪辑方案</title>
		<link>https://aws.amazon.com/cn/blogs/china/intelligent-editing-scheme-based-on-ai-technology/</link>
				<pubDate>Fri, 27 Aug 2021 09:31:38 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[Amazon DynamoDB]]></category>
		<category><![CDATA[Amazon Rekognition]]></category>
		<category><![CDATA[AWS Elemental MediaConvert]]></category>
		<category><![CDATA[AWS Lambda]]></category>
		<category><![CDATA[Media]]></category>

		<guid isPermaLink="false">ca4099e29b5c7c4211ff510b7c39fc6a512c0dee</guid>
				<description>本文描述了一种基于 AI 技术，针对人脸信息对视频文件进行智能剪辑的方案。</description>
								<content:encoded>&lt;p&gt;伴随着技术的发展，每天都有海量视频资料产生，但人们往往并不需要视频中的每一个片段。也许您只是想看到自己孩子出现的镜头，或者只关注自己喜欢的明星出演的节目，还可能需要用一些特定人员出现的镜头以制作新的视频。本文将介绍一种基于 AI 技术完成视频智能剪辑的方法。&lt;/p&gt; 
&lt;p&gt;通过这种方法，您可以从已有视频中快速剪辑出仅包含目标人物的内容。通过 AWS 所提供的托管服务，您无需了解复杂的人脸识别技术或视频编解码技术，甚至无需部署任何服务器资源。您只需要将精力集中在功能实现上。&lt;/p&gt; 
&lt;p&gt;本方案主要依赖两个核心功能。一，识别视频中的目标人物；二，针对目标任务进行剪辑。前者依赖于人脸识别技术（例如：Amazon Rekognition），后者则属于媒体行业中的视频合成技术（例如：AWS Elemental MediaConvert）。&lt;/p&gt; 
&lt;p&gt;此外，您需要预先了解 Amazon S3、Amazon DynamoDB、AWS Lambda、Amazon SNS、Amazon API Gateway 服务的基础功能。对这些服务的介绍不在本文范围内，您可以通过官方网站了解它们相关的进一步信息。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;关于人脸识别：&lt;/h2&gt; 
&lt;p&gt;Amazon Rekognition（下文简称 Rekognition）是 Amazon Web Services 提供的使用机器学习自动执行图像和视频分析的托管服务。Rekognition 提供高度精确的面孔分析和面孔搜索功能，我们将利用这个功能检测、分析并搜索视频中出现的特定面孔。&lt;/p&gt; 
&lt;h3&gt;面孔检测和分析&lt;/h3&gt; 
&lt;p&gt;为了实现特定人员的搜索，首先需要告诉 Rekognition 我们要搜索目标人脸特征是什么。这里我们无需了解诸如卷机神经网络、训练样本、迭代次数之类的技术细节，Rekognition 可以检测图像和视频中的人脸，自动提取并存储这些人脸的特征。所以我们需要做的只是向 Rekognition 提供一组目标人群的人脸照片即可。&lt;/p&gt; 
&lt;p&gt;首先，通过调用 create_collection API 在 Rekognition 中创建一个被称为“集合（以下称作：collection）“的对象，在 collection 中将会存储检测到的人脸特征。collection 只是一个逻辑上的容器，本身并不包含任何的人脸特征信息。所以接下来需要向 collection 中添加这些信息。&lt;/p&gt; 
&lt;p&gt;添加的过程需要调用 index_faces API，并提供一张保存在 Amazon S3 存储桶上的人脸照片，以及对应的 collection id。Rekognition 会完成人脸特征提取、信息保存的过程。在 collection 中不会保存完整的图片，只是保存人脸特征信息，例如：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-powershell"&gt;{
    &amp;quot;FaceModelVersion&amp;quot;: &amp;quot;5.0&amp;quot;,
    &amp;quot;Faces&amp;quot;: [
        {
            &amp;quot;BoundingBox&amp;quot;: {
                &amp;quot;Width&amp;quot;: 0.5216310024261475,
                &amp;quot;Top&amp;quot;: 0.3256250023841858,
                &amp;quot;Left&amp;quot;: 0.13394300639629364,
                &amp;quot;Height&amp;quot;: 0.3918749988079071
            },
            &amp;quot;FaceId&amp;quot;: &amp;quot;0040279c-0178-436e-b70a-e61b074e96b0&amp;quot;,
            &amp;quot;ExternalImageId&amp;quot;: &amp;quot;image1.jpg&amp;quot;,
            &amp;quot;Confidence&amp;quot;: 100.0,
            &amp;quot;ImageId&amp;quot;: &amp;quot;f976e487-3719-5e2d-be8b-ea2724c26991&amp;quot;
        }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;默认参数下，Rekognition 只提取这些人脸特征：BoundingBox、Confidence、Pose、Quality、和&amp;nbsp;Landmarks，对于本文中的应用场景已经足够。如果您还需要人脸的年龄、表情、眼睛状态、情绪等更细节的属性，可以在调用 index_faces API 时增加 DetectionAttributes=ALL 的参数设置。这可以满足更广泛的应用场景需求，当然所需要花费的处理时间也会更长。&lt;/p&gt; 
&lt;p&gt;在保存的参数中，ExternalImageId 是为当前人脸起一个便于记忆的名字。本文介绍的方法将会利用 ExternalImageId 作为在视频中搜索目标人物时使用到的标签名。每次调用 index_faces 时会向 colletion 中添加 1 张人脸信息。如果希望一次性添加多张人脸，需要自行编写代码实现多次调用。&lt;/p&gt; 
&lt;h3&gt;面孔搜索&lt;/h3&gt; 
&lt;p&gt;当建立好 collection 并向其中添加了 IndexFaces 后，就可以利用 collection 对视频进行检索。Rekognition Video 提供 start_face_search API 针对视频文件进行人脸信息检索。调用 API 时需提供视频文件存储的位置（视频需存储在 Amazon S3 存储桶中），以及所使用的 collectionId（即：需要针对哪一个人脸进行检索）。&lt;/p&gt; 
&lt;p&gt;注意，start_face_search API将搜索视频文件中所有的人脸信息。如果搜索到的人脸信息包含在 collection 中，返回结果将包含该人脸的 ExternalImageId。这是一个异步的人脸检测操作，处理时间与 collection 中包含的信息数量以及待处理的视频长度相关。API 调用成功后仅返回生成的 jobId。在调用 API 进行处理时，可以指定 Amazon SNS Topic。这样，当 Rekognition Video 完成视频检索后将会自动向 SNS Topic 发送消息进行提示。&lt;/p&gt; 
&lt;p&gt;当检索完成后，可以调用 get_face_search API 查看特定 jobId 的检索结果。返回结果示意如下：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-powershell"&gt;{
    &amp;quot;JobStatus&amp;quot;: &amp;quot;SUCCEEDED&amp;quot;,
    &amp;quot;NextToken&amp;quot;: &amp;quot;cbV9RaFdm…&amp;quot;,
    &amp;quot;VideoMetadata&amp;quot;: {
        &amp;quot;Codec&amp;quot;: &amp;quot;h264&amp;quot;,
        &amp;quot;DurationMillis&amp;quot;: 1800000,
        &amp;quot;Format&amp;quot;: &amp;quot;QuickTime / MOV&amp;quot;,
        &amp;quot;FrameRate&amp;quot;: 25.0,
        &amp;quot;FrameHeight&amp;quot;: 480,
        &amp;quot;FrameWidth&amp;quot;: 856
    },
    &amp;quot;Persons&amp;quot;: [
        {
            &amp;quot;Timestamp&amp;quot;: 4480,
            &amp;quot;Person&amp;quot;: {…},
	&amp;quot;FaceMatches&amp;quot;: [
                {
                    &amp;quot;Similarity&amp;quot;: 99.99900817871094,
                    &amp;quot;Face&amp;quot;: {…},
                        &amp;quot;ImageId&amp;quot;: &amp;quot;15681d6b-&amp;quot;,
                        &amp;quot;ExternalImageId&amp;quot;: &amp;quot;xxxxxx&amp;quot;,
                        &amp;quot;Confidence&amp;quot;: 99.99849700927734
                    }
                }
            ]
        },
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;返回结果中包含如下主要信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;视频的元数据信息（视频时长、帧率等）；&lt;/li&gt; 
 &lt;li&gt;人脸出现的时间戳（以毫秒为单位）；&lt;/li&gt; 
 &lt;li&gt;人脸匹配信息（ExternalImageId，Confidence等）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在单次调用 get_face_search API 时，最多只返回 1000 条信息，这显然无法满足长视频的识别需要。因此对于超过 1000 条信息的检索，get_face_search API 在返回结果中会包含 NextToken字段，这是一个指向后 1000 条检索信息的 hash 指针。通过在循环调用 get_face_search API 中逐条包含 NextToken 字段可顺序获得全部检索结果。&lt;/p&gt; 
&lt;p&gt;本文中所涉及到的场景将会利用检索结果中的如下信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;视频文件的帧率；&lt;/li&gt; 
 &lt;li&gt;人脸出现的时间戳；&lt;/li&gt; 
 &lt;li&gt;人脸的 ExternalImageId。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;关于视频合成：&lt;/h2&gt; 
&lt;p&gt;现在我们已经获得了视频文件中所有人脸出现时的时间码信息，接下来的工作将是基于这些信息进行新的视频合成。这将用到 Amazon Elemental MediaConvert（下文简称 MediaConvert）服务。MediaConvert 是一款具有广播级功能的基于文件的视频转码服务。借助该服务，您能够轻松创建视频点播 (VOD) 内容，实现大规模的广播和多屏幕传输。&lt;/p&gt; 
&lt;p&gt;在这里我们将使用 MediaConvert 所提供的视频合成功能。我们只需要在创建 MediaConvert 任务时指定好每段视频的起、止时间帧，MediaConvert 将按顺序将所有时间段串行合并为一个新的视频。&lt;/p&gt; 
&lt;p&gt;Rekognition Video 返回的结果中已经包含了 ExternalImageId，基于这个标记我们直接可以选择要检索出来的人员在哪些时间点出现。然而仍然有两个细节工作需要注意。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Rekognition Video 返回的结果以毫秒为单位，而 MediaConvert 在视频处理时以帧（HH:MM:SS:FF）为单位。这就需要根据视频原始帧率，在“毫秒”与“帧”之间进行转换。&lt;/li&gt; 
 &lt;li&gt;Rekognition Video 返回的是所有时间点，而不是某个人在视频中出现的时间段。从“时间点”到“时间段”的转换需要使用者通过代码自行时间。例如：当返回结果中两个相邻的 Timestamp 之间间隔大于 1 秒时，我们就可以认为这是两段不同的时间段，如果小于 1 秒则是一段连续时间段中的不同时间点。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;完成好时间段和视频帧的转换后，可以通过调用 MediaConvert 的 create_job API 创建视频合成任务。&lt;/p&gt; 
&lt;p&gt;如前文所提到的，MediaConvert 是一款广播级功能的视频转码服务，可设置的参数、可实现的功能非常丰富。下图展示了 MediaConvert 在输出选项组中可设置的部分参数：&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 输出参数设置（部分截图）&lt;/p&gt; 
&lt;p&gt;所有参数均和可以在调用 create_job API 时进行设置，或通过指定 JSON 文件的方式传入。对于 job 所需要的 JSON 文件，使用者不必从零开始编写，只需要在控制台界面中根据自己的需要设置好各项参数，然后选择控制台界面中的“显示作业JSON”选项，将自动生成的内容复制出来生成新的 JSON 文件即可。&lt;/p&gt; 
&lt;p&gt;为实现本文所涉及的场景，只需要设置基本的输入（待处理视频位置）、输出（处理后视频位置、视频片段起止时间、输出视频名称）参数即可。需要注意的是，在输出选项中“速率控制模式”参数是必填项，支持可变比特率（VBR）、恒定比特率（CBR）以及质量定义的可变比特率（QVBR）三种模式。推荐使用 QVBR 方式，不同分辨率下 QVBR 的推荐参数值可以参考 &lt;a href="https://docs.aws.amazon.com/mediaconvert/latest/ug/cbr-vbr-qvbr.html#qvbr-guidelines"&gt;官方文档&lt;/a&gt; 中的介绍。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;整体设计架构：&lt;/h2&gt; 
&lt;p&gt;为了进一步提升整体方案的自动化程度，以及对中间数据持久化，本方案中还使用到了 Amazon DynamoDB、AWS Lambda、Amazon SNS、Amazon API Gateway 服务。方案的整体架构如下图所示：&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/intelligent-editing-scheme-based-on-ai-technology2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;方案架构图&lt;/p&gt; 
&lt;p&gt;方案中使用了如下服务：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/rekognition/"&gt;Amazon Rekognition&lt;/a&gt;：图像和视频分析服务；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/mediaconvert/"&gt;Amazon Elemental MediaConvert&lt;/a&gt;：具有广播级功能的基于文件的视频转码服务；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/api-gateway/"&gt;Amazon API Gateway&lt;/a&gt;：一种完全托管的服务，可以帮助开发人员轻松创建、发布、维护、监控和保护任意规模的 API；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/lambda/"&gt;Amazon Lambda&lt;/a&gt;：一种无服务器的计算服务，让您无需预置或管理服务器、创建可感知工作负载的集群扩展逻辑、维护事件集成或管理运行时，即可运行代码；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/dynamodb/"&gt;Amazon DynamoDB&lt;/a&gt;：是一个键/值和文档数据库，可以在任何规模的环境中提供个位数的毫秒级性能；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/s3/"&gt;Amazon S3&lt;/a&gt;：对象存储服务，提供行业领先的可扩展性、数据可用性、安全性和性能；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/cloudfront/"&gt;Amazon CloudFront&lt;/a&gt;：快速内容分发网络 (CDN) 服务，可以安全地以低延迟和高传输速度向全球客户分发数据、视频、应用程序和 API；&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/sns/"&gt;Amazon SNS&lt;/a&gt;：一项用于应用与应用之间 (A2A) 以及应用与人之间 (A2P) 通信的完全托管型消息收发服务。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;方案通过 Amazon API Gateway 对外暴露 3 个 REST API：collection-create、faces-search、video-clip。&lt;/p&gt; 
&lt;p&gt;3 个 API 分别对应后端的 3 个 Amazon Lambda 函数。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Collection：创建 collection，并从指定的 S3 目录中读取照片，将照片中的人脸信息逐一添加到 collection，以照片的文件名作为人脸信息的 ExternalImageId。需调用 Rekognition 服务的 create_collection 和 index_faces API。&lt;/li&gt; 
 &lt;li&gt;Faces Search：根据指定的 collectionid，对保存在 S3 存储桶中的视频文件进行人脸检索。需调用 Rekognition 服务的 start_face_search API。&lt;/li&gt; 
 &lt;li&gt;Media Clipping：创建 MediaConvert Job，按照指定的 ExternalImageId 合成剪辑后的视频。需调用 MediaConvert 服务的 create_job API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如之前所描述的，在调用 start_face_search API 时处理时间较长，一方面需要注意将 Lambda 函数的处理时间适当增加（例如：1分钟），另一方面需要进行自动化的设置以便触发下一步的 Lambda 函数。在自动化设置方面，start_face_search API 支持设置 SNS topic，当作业完成后直接发送消息给对应的 SNS topic，通过这个 topic 触发下一步的操作。以 python 为例，调用 start_face_search API 注意进行如下设置：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-powershell"&gt;reko_client.start_face_search(
        Video={
            'S3Object': {
                'Bucket': BUCKET,
                'Name': OBJECT
            }
        },
        CollectionId=collectionId,
        NotificationChannel={
            'SNSTopicArn': snsTopic,
            'RoleArn': roleARN
        }
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;Lambda 函数 Result Save 被 SNS topic 触发，根据 NextToken 循环调用 Rekognition 的 get_face_search API 获取完整的 face_search 结果，并生成 JSON 文件保存到 S3 存储桶。&lt;/p&gt; 
&lt;p&gt;上述过程中所生成的 collectionid、jobid 等中间信息均保存在 DynamoDB Table 中。在方案架构图中显示有两个 DynamoDB Table，一个用于保存 collection 信息，另一个用于保存 face_search 的结果信息。您也可以根据自己的需要进行设置。&lt;/p&gt; 
&lt;p&gt;最后，剪辑好的视频会保存在 S3 存储桶中。为了进一步降低方案的整体成本，剪辑好的视频会通过 cloudfront 进行下载（这将降低在云上产生的流量成本）。在向 S3 存储桶中保存视频时会产生一个事件，这个事件会触发负责通知的 Lambda 函数，生成下载视频时所需要用到的 cloudfront 链接，并向 SNS topic 发送消息，通过 SNS 向订阅者发送 email 进行通知。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结：&lt;/h2&gt; 
&lt;p&gt;本文描述了一种基于 AI 技术，针对人脸信息对视频文件进行智能剪辑的方案。在使用该方案时，您可以：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;无需部署服务器资源，整个方案使用 Amazon Web Services 托管服务；&lt;/li&gt; 
 &lt;li&gt;利用 AI 技术，自动识别目标任务；&lt;/li&gt; 
 &lt;li&gt;无需准备海量训练样本，无需掌握复杂的机器学习技能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如您希望了解该方案原型的部署细节，可以从这里获得方案源代码及架构详细说明。https://github.com/weiping-bj/Smart-Cutting-using-AWS&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/lweiping.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;刘伟平&lt;/h3&gt; 
  &lt;p&gt;AWS APN 合作伙伴解决方案架构师，主要负责 AWS (中国)合作伙伴的技术支持工作，同时致力于 AWS 云服务在国内的应用及推广。加入 AWS 前，在 HP（HPE）服务超过7年，历任存储售前工程师、电信行业售前工程师、NFV 解决方案架构师，熟悉传统企业 IT 架构、私有云及混合云部署。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用 AWS Backup Audit Manager 监控、评估和证明备份合规性</title>
		<link>https://aws.amazon.com/cn/blogs/china/monitor-evaluate-and-demonstrate-backup-compliance-with-aws-backup-audit-manager/</link>
				<pubDate>Fri, 27 Aug 2021 06:46:01 +0000</pubDate>
		<dc:creator><![CDATA[Steve Roberts]]></dc:creator>
				<category><![CDATA[Security, Identity, & Compliance]]></category>

		<guid isPermaLink="false">706a282d09cd87aa5e8c3dbb3bc555d58a002413</guid>
				<description>今天，我很高兴地宣布推出 AWS Backup Audit Manager，它是 AWS Backup 的一项新功能，可帮助您监控和评估备份的合规性状态，以满足业务和法规要求，并使您能够生成有助于向审计员和监管机构证明合规性的报告。</description>
								<content:encoded>&lt;p&gt;今天，我很高兴地宣布推出 &lt;strong&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager&lt;/strong&gt;，它是 &lt;strong&gt;&lt;a title="" href="https://aws.amazon.com/backup/"&gt;AWS Backup&lt;/a&gt;&lt;/strong&gt; 的一项新功能，可帮助您监控和评估备份的合规性状态，以满足业务和法规要求，并使您能够生成有助于向审计员和监管机构证明合规性的报告。&lt;/p&gt; 
&lt;p&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt; 是一项完全托管式服务，可启动策略驱动的 &lt;span title=""&gt;AWS&lt;/span&gt; 应用程序备份和恢复，能够简化大规模保护数据的流程，而无需自定义脚本和手动流程。但是，客户仍需使用自己的工具来验证备份策略是否得到执行，而且为了向审计员证明合规性，还需要解析备份记录，将其转换为可审计的报告。&lt;/p&gt; 
&lt;p&gt;现在，您可以通过 &lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 持续自动地跟踪备份活动，例如备份计划或备份保管库的变更，并自动生成每日报告。&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 内置了可自定义的合规性控件。简而言之，控件是具有备份策略参数（例如备份频率或保留期）的过程，这些参数与您的业务合规性和法规要求保持一致。&lt;/p&gt; 
&lt;p&gt;您可以创建一个框架，以账户和区域为范围，然后向其添加所需的控件。根据控件跟踪备份活动，自动检测违反定义的数据保护策略的情况，使您能够快速采取纠正措施。为跟踪备份活动，&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 要求您通过 &lt;a title="" href="https://aws.amazon.com/config/"&gt;AWS Config&lt;/a&gt; 监控备份计划（&lt;code&gt;AWS። Backup። BackupPlan&lt;/code&gt; 资料类型）、备份选择（&lt;code&gt;AWS። Backup። BackupSelection&lt;/code&gt;）、保管库（&lt;code&gt;AWS። Backup። BackupVault&lt;/code&gt;）、恢复点（&lt;code&gt;AWS። Backup። RecoveryPoint&lt;/code&gt;）和&lt;span title=""&gt; AWS Config&lt;/span&gt; 资源合规性（&lt;code&gt;AWS::Config::ResourceCompliance&lt;/code&gt;）。您可以使用&lt;strong&gt;框架&lt;/strong&gt;页面的&lt;strong&gt;资源跟踪&lt;/strong&gt;部分，在 &lt;a title="" href="https://aws.amazon.com/backup/"&gt;AWS Backup&lt;/a&gt; 控制台中查看这些资源的记录状态。&lt;/p&gt; 
&lt;p&gt;将所需的控件添加到框架后，就可以进行部署。如果要满足不同的内部或监管标准，可以创建和部署其他控件框架。部署框架后，您可以设置自动生成备份活动的每日报告。这些信息将显示在控制面板中，您需要时可随时请求报告。您还可以将结果导入 &lt;a title="AWS Audit Manager" href="https://aws.amazon.com/audit-manager/"&gt; 中&lt;/a&gt;，这是我于 &lt;a title="" href="https://reinvent.awsevents.com/"&gt;AWS re:Invent&lt;/a&gt; 2020 大会期间&lt;a href="https://aws.amazon.com/blogs/aws/aws-audit-manager-simplifies-audit-preparation/" target="_blank" rel="noopener noreferrer"&gt;在此新闻博客文章&lt;/a&gt;中介绍过的一项服务。&lt;/p&gt; 
&lt;p&gt;此短视频简要概述了新的&lt;span title=""&gt; AWS Backup&lt;/span&gt; Audit Manager 功能。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;可用的控件和备份报告&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 提供了五种备份治理控件模板和备份活动报告，涵盖备份任务、复制任务和还原任务。这些报告提高了对单个账户和区域备份活动的可见性，帮助您监控运营状况并确定可能需要采取进一步行动的故障。&lt;/p&gt; 
&lt;p&gt;创建框架时，您需要提供名称、可选描述，然后选择是否使用提供的 &lt;span title=""&gt;AWS Backup&lt;/span&gt; 框架类型（包括五个预定义控件），也可以选择自定义框架。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-create-framework.png"&gt;&lt;img class="alignnone size-full wp-image-54157" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-create-framework.png" alt="创建 AWS Backup Audit Manager 框架" width="900" height="564" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;选择&lt;strong&gt;自定义框架&lt;/strong&gt;将展开面板，显示可用控件、它们的参数以及将它们纳入框架或从框架中排除的选项。五种可用控件的标题分别是：&lt;strong&gt;受备份计划保护的备份资源&lt;/strong&gt;、&lt;strong&gt;备份计划最低频率和最低保留期&lt;/strong&gt;、&lt;strong&gt;备份以防恢复点手动删除&lt;/strong&gt;、&lt;strong&gt;加密的备份恢复点&lt;/strong&gt;和&lt;strong&gt;备份恢复点最短保留期限&lt;/strong&gt;。在每个控件标题的右侧，您将找到一个&lt;strong&gt;信息&lt;/strong&gt;链接，描述了控件评估的内容、频率以及资源符合控件的含义。&lt;/p&gt; 
&lt;p&gt;让我们来看看几个控件。&lt;strong&gt;受备份计划保护的备份资源&lt;/strong&gt;控件使您可以选择所有受支持的资源，或者由标签、类型或特定资源识别的资源。此控件有助于识别备份覆盖范围中的缺口。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-resoures-control.png"&gt;&lt;img class="size-full wp-image-54158 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-resoures-control.png" alt="受备份计划保护的备份资源控制资源选择" width="755" height="562" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;备份计划最低频率和最低保留期&lt;/strong&gt;控件包含的参数决定了备份计划的备份频率以及恢复点的维持时间。原定设置要求每小时进行一次备份，恢复点应保留一个月，但您可以自定义设置，以满足业务合规性要求。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-frequency-control.png"&gt;&lt;img class="size-full wp-image-54159 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-backup-frequency-control.png" alt="设置备份频率和保留期控件" width="768" height="421" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;完成关于其余控件的选择，纳入控件并根据需要设置适当的参数值，或者将它们从框架中排除，然后单击&lt;strong&gt;创建框架&lt;/strong&gt;来完成这个过程。将创建和部署新框架，这需要几分钟的时间。如果需要，您随时可以返回并编辑框架中的控件和参数。&lt;/p&gt; 
&lt;p&gt;部署后，框架中的控件将开始评估合规性，您可以通过选择框架在控制台中检查合规性状态。摘要部分根据您部署的控制定义，报告框架的总体合规性状态以及框架中合规或不合规控件的数量。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-compliance-summary.png"&gt;&lt;img class="size-full wp-image-54162 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-compliance-summary.png" alt="框架和控件合规性摘要" width="909" height="325" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;您可以在摘要下方找到一份列表，其中包含框架中每个控件的合规性详细信息，可以按状态筛选。每个控件都详细说明了它是否合规，以及控件所监控的不合规资源的数量。单击控件标题将直接转到&lt;span title=""&gt; AWS Config&lt;/span&gt; 控制面板，您可以查看有关控件标识的资源的更多详细信息。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-control-compliance.png"&gt;&lt;img class="alignnone size-full wp-image-54163" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-framework-control-compliance.png" alt="控件合规性详情" width="910" height="612" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;自动生成的备份活动报告可用于向审计员和监管机构证明合规性。要设置报告，首先单击导航工具栏上的&lt;strong&gt;报告&lt;/strong&gt;条目，然后单击&lt;strong&gt;创建报告计划&lt;/strong&gt;。系统将要求您选择报告模板。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-template.png"&gt;&lt;img class="alignnone size-full wp-image-54169" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-template.png" alt="选择审计报告模板" width="884" height="543" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;选择模板（我选择了&lt;strong&gt;备份任务报告&lt;/strong&gt;）后，您可以填写名称和可选描述，选择要将报告传送到 &lt;a title="" href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt; 存储桶的哪个位置以及报告的文件格式，然后单击&lt;strong&gt;创建报告计划&lt;/strong&gt;。报告将每 24 小时更新一次，您随时可以按需运行报告。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-settings.png"&gt;&lt;img class="alignnone size-full wp-image-54171" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-settings.png" alt="编辑报告设置" width="861" height="1097" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;自动或按需运行报告后，要查看报告数据，可以在&lt;strong&gt;报告计划&lt;/strong&gt;列表中选择报告，然后单击&lt;strong&gt;查看报告&lt;/strong&gt;。 将直接转到选定的报告文件的&lt;span title=""&gt; S3&lt;/span&gt; 位置，您可以按所选的文件类型查看一个对象（报告）。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-list.png"&gt;&lt;img class="alignnone size-full wp-image-54172" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-reports-list.png" alt="选择要查看的报告" width="901" height="466" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-files.png"&gt;&lt;img class="alignnone size-full wp-image-54173" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-files.png" alt="Amazon S3 中的报告文件" width="901" height="378" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下载文件会显示资源评估的时间段、备份任务详细信息、故障或完成状态、状态消息、资源类型和备份计划等。下面，我在电子表格中打开了 CSV 格式文件。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-csv.png"&gt;&lt;img class="alignnone size-full wp-image-54174" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/20/backup_audit_manager-report-csv.png" alt="备份报告数据" width="899" height="180" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration: underline"&gt;与 Raven Launch 建立合作伙伴关系&lt;/span&gt;&lt;br /&gt; &lt;/strong&gt;通过此次发布，我们很高兴&lt;a href="https://aws.amazon.com/marketplace/pp/prodview-2yil74chd7ihg?ref_=srh_res_product_title" target="_blank" rel="noopener noreferrer"&gt; Open Raven&lt;/a&gt; 成为&lt;span title=""&gt; AWS Backup&lt;/span&gt; 的合作伙伴。Open Raven 是一个云原生数据安全平台，专为保护现代数据湖和仓库而构建。通过从查找所有数据位置到主动识别暴露的各种方法，该平台可解决组织在使用大量基于云的数据时通常会面临的各种问题。&lt;/p&gt; 
&lt;p&gt;Open Raven 首席技术官 Mark Curphey 谈到了新的&lt;span title=""&gt; AWS Backup&lt;/span&gt; 功能：“要成功地从勒索软件攻击中恢复，组织需要完成两项基础任务来提前规划，即确定关键数据和系统并根据组织要求对它们进行备份，使它们得到保护且能够恢复。&lt;span title=""&gt;AWS Backup&lt;/span&gt; Audit Manager 与 Open Raven 的结合简化了这项工作，消除了猜测和数小时的手动工作。”&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;立即开始使用&lt;span title=""&gt; AWS Backup&lt;/span&gt; Audit Manager&lt;/strong&gt;&lt;/span&gt;&lt;br /&gt; &lt;a title="" href="https://aws.amazon.com/backup/"&gt;AWS Backup&lt;/a&gt; Audit Manager 现已在美国东部（弗吉尼亚北部、俄亥俄州）、美国西部（加利福尼亚北部、俄勒冈）、加拿大（中部）、欧洲（法兰克福、爱尔兰、伦敦、巴黎、斯德哥尔摩）、南美洲（圣保罗）、亚太地区（香港、孟买、首尔、新加坡、 悉尼、东京) 和中东（巴林）地区推出。&lt;/p&gt; 
&lt;p&gt;有关 &lt;span title=""&gt;Backup&lt;/span&gt; Audit Manager 的更多信息，请参阅&lt;span title=""&gt; AWS Backup&lt;/span&gt;&lt;a href="https://docs.aws.amazon.com/aws-backup/latest/devguide/" target="_blank" rel="noopener noreferrer"&gt; 开发人员指南&lt;/a&gt;中的&lt;a href="https://docs.aws.amazon.com/aws-backup/latest/devguide/aws-backup-audit-manager.html" target="_blank" rel="noopener noreferrer"&gt;此部分&lt;/a&gt;。&lt;strong&gt;要开始使用，请访问&lt;a href="https://console.aws.amazon.com/backup"&gt;&lt;span title=""&gt; AWS Backup&lt;/span&gt; 控制台。&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a title="Steve 的 Twitter" href="https://twitter.com/bellevuesteve"&gt; – Steve&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>Amazon EC2！15 岁生日快乐！</title>
		<link>https://aws.amazon.com/cn/blogs/china/happy-15th-birthday-amazon-ec2/</link>
				<pubDate>Fri, 27 Aug 2021 06:37:53 +0000</pubDate>
		<dc:creator><![CDATA[Jeff Barr]]></dc:creator>
				<category><![CDATA[News]]></category>

		<guid isPermaLink="false">8278615799a7821a1b794611f1bd4a139c2db943</guid>
				<description>十五年前的今天，我通过博文宣布发布 Amazon EC2 测试版。我记得，那时发布迫在眉睫，我们还在努力敲定功能集、定价模式和无数其他细节。最终确定了发布日期，但时间恰好与我计划已久的前往墨西哥卡波圣卢卡斯的家庭旅行重叠。但我很淡定，选择带上了手提电脑去度假，记得在撰写博文时，还不得不用毛巾盖住手提电脑，因为只有这样才能看清楚屏幕。我不是 100% 确定，但我相信我是在坐在泳池旁边的躺椅上点击发布按钮的！ 在那个星期剩下的时间里，我都处于离线状态，完全不知道这次发布引起了怎样的轰动。</description>
								<content:encoded>&lt;p&gt;&lt;img style="float: right;margin-left: 8px;margin-bottom: 8px" src="https://media.amazonwebservices.com/blog/2021/ec2_15_1.png" /&gt;十五年前的今天，我通过博文宣布发布 &lt;a href="https://aws.amazon.com/blogs/aws/amazon_ec2_beta/"&gt;Amazon EC2 测试版&lt;/a&gt;。我记得，那时发布迫在眉睫，我们还在努力敲定功能集、定价模式和无数其他细节。最终确定了发布日期，但时间恰好与我计划已久的前往墨西哥卡波圣卢卡斯的家庭旅行重叠。但我很淡定，选择带上了手提电脑去度假，记得在撰写博文时，还不得不用毛巾盖住手提电脑，因为只有这样才能看清楚屏幕。我不是 100% 确定，但我相信我是在坐在泳池旁边的躺椅上点击&lt;strong&gt;发布&lt;/strong&gt;按钮的！ 在那个星期剩下的时间里，我都处于离线状态，完全不知道这次发布引起了怎样的轰动。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;准备发布&lt;/strong&gt;&lt;/span&gt;&lt;br /&gt; 在 Andy Jassy 组建这个 AWS 小组，并开始撰写叙述的时候，他给我看了一份文档，其中提议打造 Amazon Execution Service，并询问我，开发人员是否会觉得有用，以及他们是否愿意为它付费。我饶有兴趣地阅读了这份文档，阅毕很是欢欣鼓舞，对他的两个问题的回答都是肯定的。在职业生涯的早期，我曾构建并运行过多个托管在主机托管站点的项目，对于长期合约和难以按需扩展再熟悉不过了。提议的服务将解决这两个基本问题，并能够让像我这样的开发人员更容易应对需求的大幅波动。&lt;/p&gt; 
&lt;p&gt;EC2 团队必须做出大量决策，才能构建可满足开发人员、企业家和更大组织需求的服务。虽然我不参与决策，但在我看来，他们至少需要在三个主要方面做出决策：功能、定价和详细程度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt; – 让我们首先回顾 EC2 发布时提供的功能。当时只有一种实例类型，一个区域（&lt;span title=""&gt;美国东部（弗吉尼亚北部）&lt;/span&gt;），并且我们还没有公开可用区的概念。只有为数不多的预构建 Linux 内核可供选择，并在实例启动时分配 IP 地址。所有存储都是暂时的，并且与实例具有相同的生命周期。没有数据块存储，根磁盘镜像 (AMI) 存储在 S3 捆绑中。现在看来，这些功能中的任何一个或所有功能都是发布时所必须提供的，但事实上并没有，而我们的客户马上就开始使用 EC2 了。多年来，我已经采用这样的策略，即创建最小但有用的服务，这使我们能够快速发布并快速迭代（以及添加新功能）以响应客户的反馈。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;定价&lt;/strong&gt; – 我们肯定是要对 EC2 的使用收费，但要决定收费依据的单位并不容易。最终，我们确定按实例小时数收费。与直接购买服务器并在 3 或 5 年期限内折旧，或作为年度合约的一部分每月支付的旧模式相比，这是向前迈出的一大步。即便如此，我们的客户仍有可以从更精细计费方式受益的使用案例，因此我们在 2017 年&lt;a href="https://aws.amazon.com/blogs/aws/new-per-second-billing-for-ec2-instances-and-ebs-volumes/"&gt;针对 EC2 和 EBS 推出了按秒计费&lt;/a&gt;的方式。在背后，AWS 团队还必须构建基础设施，来对客户的使用情况进行测量、跟踪、制表和计费。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;详细程度&lt;/strong&gt; – 这可能不像前两个那么显而易见，但这是我在撰写博文时经常考虑的问题。在发布时，我分享了一个事实，即 EC2 实例（我们后来称为 &lt;strong&gt;m1.small&lt;/strong&gt;）提供了相当于 1.7 GHz Intel Xeon 处理器的计算能力，但我并没有分享实际型号或其他细节。我分享了我们在 &lt;a href="https://www.cl.cam.ac.uk/research/srg/netos/projects/archive/xen/"&gt;Xen&lt;/a&gt; 上构建 EC2 的事实。随着时间的推移，客户告诉我们他们想利用一些专门的处理器功能，因此，我们开始分享这些信息。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;一些令人难忘的 EC2 发布&lt;/strong&gt;&lt;/span&gt;&lt;br /&gt; 回顾过去的 15 年，我认为我们做对了很多事情，我们也为该服务的发展留下了很大的空间。每一次发布都很重要，但这里我说说让我记忆犹新的几次：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/blogs/aws/amazon_ec2_beta/"&gt;EC2 发布&lt;/a&gt;（2006年）&lt;/strong&gt; – 这是一切的开始。早期较为重要的扩展成功案例之一发生在 2008 年初，当时 &lt;a href="https://animoto.com/"&gt;Animoto&lt;/a&gt; 在一周内将其使用量从不到 100 个实例扩展到了 3400 个实例（请阅读 &lt;a href="https://aws.amazon.com/blogs/aws/animoto-scali/"&gt;Animoto – 通过爆炸式增长进行扩展&lt;/a&gt;以获取完整故事）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/blogs/aws/amazon-elastic/"&gt;Amazon Elastic Block Store&lt;/a&gt;（2008 年）&lt;/strong&gt; – 此次发布使我们的客户能够将 EC2 和持久性数据块存储结合使用。如果您看一看那篇文章，您会看到曾经流行的适用于 Firefox 的扩展 ElasticFox 的一些历史屏幕截图。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/blogs/aws/new-aws-load-balancing-automatic-scaling-and-cloud-monitoring-services/"&gt;Elastic Load Balancing/Auto Scaling/CloudWatch&lt;/a&gt;（2009 年）&lt;/strong&gt; – 此次发布使我们的客户能够更轻松地构建可扩展且高度可用的应用程序。引用我自己的话，“Amazon CloudWatch 可监控 Amazon EC2 容量，Auto Scaling 可根据需求动态扩展它，而 Elastic Load Balancing 可在一个或多个可用区中的多个实例之间分配负载。”&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/blogs/aws/introducing-amazon-virtual-private-cloud-vpc/"&gt;Virtual Private Cloud/VPC&lt;/a&gt;（2009 年）&lt;/strong&gt; – 此次发布使我们的客户能够创建逻辑隔离的 EC2 实例集，并通过 IPsec VPN 连接将它们连接到现有网络。它为我们的客户提供了对网络寻址和路由的额外控制，并为未来几年许多额外的联网功能打开了大门。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/blogs/aws/amazon-ec2-update-additional-instance-types-nitro-system-and-cpu-options/"&gt;Nitro 系统&lt;/a&gt;（2017 年）&lt;/strong&gt; – 多年来，我们一直努力重新构想和重建我们的虚拟化基础架构，以追求更高的性能和安全性，此次发布是我们多年工作的结晶（&lt;a href="https://aws.amazon.com/ec2/nitro/"&gt;阅读更多内容&lt;/a&gt;）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/blogs/aws/new-ec2-instances-a1-powered-by-arm-based-aws-graviton-processors/"&gt;Graviton&lt;/a&gt;（2018 年）&lt;/strong&gt; – 此次发布标志着 Amazon 设计的定制 CPU 的诞生，这些 CPU 专为成本敏感的横向扩展工作负载而设计。自那次发布以来，我们继续在这条进化路线上前进，推出采用 Graviton2 处理器的通用型、计算优化、内存优化和可突增实例。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/ec2/instance-types/"&gt;实例类型&lt;/a&gt;（2006 年至今）&lt;/strong&gt; – 在发布之初，我们只提供一种实例类型，而如今则提供超过四百种实例类型，每一种都旨在让我们的客户能够满足特定使用案例的需求。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;与我们一同庆祝&lt;/strong&gt;&lt;/span&gt;&lt;br /&gt; 为了庆祝过去 15 年来我们在客户身上看到的令人难以置信的创新，我们将于 8 月 23 日至 24 日举办一场&lt;a href="https://aws.amazon.com/ec2/15th-birthday-event/"&gt;为期两天的现场活动&lt;/a&gt;，涵盖一系列主题。我们将于太平洋夏令时间今天上午 9 点拉开此次活动的序幕，届时 Amazon EC2 副总裁 Dave Brown 将发表主题演讲“15 年创新的经验教训”。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;活动日程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;table style="border: 2px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border-bottom: 1px solid black;background-color: #e0e0e0"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;width: 50%"&gt;&lt;strong&gt;8 月 23 日&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;&lt;strong&gt;8 月 24 日&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;15 年创新的经验教训&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;AWS 无所不在：关于混合云的炉边谈话&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;AWS 芯片创新 15 年&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;深入了解真实世界的 AWS 混合示例&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;为正确的工作负载选择正确的实例&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;AWS Outposts：扩展 AWS 本地部署以获得真正一致的混合体验&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;针对成本和容量优化计算&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;使用混合连接解决方案将您的网络连接到 AWS&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;Amazon Virtual Private Cloud 的演变&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;在 AWS 上加速 ADAS 和自驾车的开发&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;使用 AWS ML 基础设施服务加速 AI/ML 创新&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;使用 AWS ML 芯片加速 AI/ML 的采用&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;使用机器学习和 HPC 加速产品设计&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px"&gt;数字孪生：连接物理与数字世界&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/ec2/15th-birthday-event/"&gt;在此处注册&lt;/a&gt;并在太平洋时间上午 9 点加入我们，以了解有关 EC2 的更多信息，并与我们一起庆祝吧！&lt;/p&gt; 
&lt;p&gt;— &lt;a href="https://twitter.com/jeffbarr"&gt;Jeff&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>推出 Amazon MemoryDB for Redis — 一款与 Redisis 兼容、持久的内存数据库服务</title>
		<link>https://aws.amazon.com/cn/blogs/china/introducing-amazon-memorydb-for-redis-a-redis-compatible-durable-in-memory-database-service/</link>
				<pubDate>Fri, 27 Aug 2021 06:31:31 +0000</pubDate>
		<dc:creator><![CDATA[Danilo Poccia]]></dc:creator>
				<category><![CDATA[News]]></category>

		<guid isPermaLink="false">e53b0dca6f1ce3aa74c21432627cdb39a7339673</guid>
				<description>交互式应用程序需要非常快速地处理请求并做出响应，这一要求延伸到架构的所有组件。如果您采用了微服务，并且您的架构由许多相互通信的小型独立服务组成，这一点就更加重要了。</description>
								<content:encoded>&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;交互式应用程序需要非常快速地处理请求并做出响应，这一要求延伸到架构的所有组件。如果您采用了微服务，并且您的架构由许多相互通信的小型独立服务组成，这一点就更加重要了。&lt;/p&gt; 
&lt;p&gt;因此，数据库性能对应用程序的成功至关重要。为了将读取延迟减少到微秒，可以在持久数据库之前放置内存缓存。在缓存方面，许多开发人员使用&lt;a href="https://redis.io/"&gt; Redis&lt;/a&gt;，它是一种开源的内存数据结构存储。事实上，根据&lt;a href="https://insights.stackoverflow.com/survey/2021#section-most-loved-dreaded-and-wanted-databases"&gt; Stack Overflow 2021 年开发者调查&lt;/a&gt;，Redis 是五年来最受喜爱的数据库。&lt;/p&gt; 
&lt;p&gt;要在 AWS 上实施此设置，您可以使用&lt;a href="https://aws.amazon.com/elasticache/redis/"&gt; Amazon ElastiCache for Redis&lt;/a&gt;，它是一项完全托管式内存缓存服务，提供了持久数据库服务（如&lt;a title="" href="https://aws.amazon.com/rds/aurora/"&gt; Amazon Aurora&lt;/a&gt; 或&lt;a title="" href="https://aws.amazon.com/dynamodb/"&gt; Amazon DynamoDB&lt;/a&gt;）之前的低延迟缓存，可最大限度地减少数据丢失。但是，此设置要求您在应用程序中引入自定义代码，使缓存与数据库保持同步。此外，运行缓存和数据库会产生费用。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;推出 Amazon MemoryDB for Redis&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;今天，我很高兴地宣布正式发布&lt;a href="https://aws.amazon.com/memorydb"&gt; Amazon MemoryDB for Redis&lt;/a&gt;，它是一款新的与 Redis 兼容、持久的内存数据库。MemoryDB 让您可以轻松且经济高效地构建需要&lt;strong&gt;微秒读取&lt;/strong&gt;和&lt;strong&gt;个位数毫秒写入&lt;/strong&gt;性能且具备&lt;strong&gt;数据持久性&lt;/strong&gt;和&lt;strong&gt;高可用性&lt;/strong&gt;的应用程序。&lt;/p&gt; 
&lt;p&gt;现在，您可以简化架构并将 MemoryDB 作为单一的&lt;strong&gt;主数据库&lt;/strong&gt;，而无需在持久数据库之前使用低延迟缓存。使用 MemoryDB 之后，所有数据都存储在内存中，从而实现低延迟和高吞吐量的数据访问。MemoryDB 使用跨多个&lt;a href="https://aws.amazon.com/about-aws/global-infrastructure/regions_az/#Availability_Zones"&gt;可用区 (AZ)&lt;/a&gt; 存储数据的分布式&lt;a href="https://en.wikipedia.org/wiki/Transaction_log"&gt;事务日志&lt;/a&gt;，可实现高持久性的快速故障转移、数据库恢复和节点重启。&lt;/p&gt; 
&lt;p&gt;MemoryDB 维持与开源 Redis 的兼容性，并支持您熟悉的同一组 Redis 数据类型、参数和命令。这意味着您目前与开源 Redis 一起使用的代码、应用程序、驱动程序和工具可以与 MemoryDB 一起使用。作为开发人员，您可以立即访问许多数据结构，例如字符串、哈希、列表、集合、包含范围查询的排序集合、位图、&lt;a href="https://en.wikipedia.org/wiki/HyperLogLog"&gt;超日志&lt;/a&gt;、地理空间索引和流。您还可以访问高级功能，例如内置复制、最近最少使用 (LRU) 的移出、事务和自动分区。MemoryDB 与 Redis 6.2 兼容，并将支持在开源中发布的较新版本。&lt;/p&gt; 
&lt;p&gt;此时，您可能有一个疑问，即 MemoryDB 与 ElastiCache 相比如何，因为这两种服务都可以让您访问 Redis 数据结构和 API：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="padding-bottom: 0.5em"&gt;MemoryDB 可成为应用程序的安全的主数据库，因为它提供了数据持久性、微秒读取和个位数毫秒写入延迟。MemoryDB 使您无需在数据库之前添加缓存，即可实现交互式应用程序和微服务架构所需的低延迟。&lt;/li&gt; 
 &lt;li&gt;另一方面，ElastiCache 为读取和写入提供了微秒延迟。它非常适合用于缓存您希望加快从现有数据库访问数据的工作负载。对于可能接受数据丢失的用例（例如，您可以从另一个源快速重建数据库），ElastiCache 也可用作主数据存储。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;创建 Amazon MemoryDB 集群&lt;/strong&gt;&lt;/span&gt;&lt;br /&gt; 在&lt;a href="https://console.aws.amazon.com/memorydb/home"&gt; MemoryDB 控制台&lt;/a&gt;中，我使用左侧导航窗格中的链接转到&lt;strong&gt;集群&lt;/strong&gt;部分，然后选择&lt;strong&gt;创建集群&lt;/strong&gt;。这将打开&lt;strong&gt;集群设置&lt;/strong&gt;，我在其中输入集群的名称和描述。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-create-cluster.png"&gt;&lt;img class="aligncenter size-large wp-image-53887" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-create-cluster-1024x752.png" alt="控制台屏幕截图。" width="1024" height="752" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;所有 MemoryDB 集群都在&lt;a href="https://docs.aws.amazon.com/vpc/latest/userguide/how-it-works.html#how-it-works-subnet"&gt;虚拟私有云 (VPC)&lt;/a&gt; 中运行。在&lt;strong&gt;子网组&lt;/strong&gt;中，我选择我的一个 VPC 并提供子网列表（集群将使用此列表分配其节点），从而创建子网组。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-subnet-group-vpc.png"&gt;&lt;img class="aligncenter size-large wp-image-53889" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-subnet-group-vpc-1024x568.png" alt="控制台屏幕截图。" width="1024" height="568" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;集群设置&lt;/strong&gt;中，我可以更改网络端口、控制节点和集群的运行时属性的参数组、节点类型、分片数量以及每个分片的副本数量。存储在集群中的数据在分片之间进行分区。分片数量和每个分片的副本数量决定了我的集群中的节点数量。考虑到每个分片都有一个主节点及其副本，我预计这个集群将有八个节点。&lt;/p&gt; 
&lt;p&gt;为实现&lt;strong&gt;与 Redis 版本的兼容性&lt;/strong&gt;，我选择 6.2。我将所有其他选项保留为默认值，然后选择&lt;strong&gt;下一步&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-cluster-settings.png"&gt;&lt;img class="aligncenter size-large wp-image-53890" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-cluster-settings-1024x908.png" alt="控制台屏幕截图。" width="1024" height="908" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;高级设置&lt;/strong&gt; 的&lt;strong&gt;安全&lt;/strong&gt;部分，我为用于子网组的 VPC 添加&lt;code&gt;默认&lt;/code&gt;安全组，然后选择我之前创建的访问控制列表 (ACL)。MemoryDB ACL 基于&lt;a href="https://redis.io/topics/acl"&gt; Redis ACL&lt;/a&gt;，并提供用于连接到集群的用户凭证和权限。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-security.png"&gt;&lt;img class="aligncenter size-large wp-image-53891" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-security-1024x806.png" alt="控制台屏幕截图。" width="1024" height="806" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;快照&lt;/strong&gt;部分，我保留默认值，使 MemoryDB 自动创建每日快照，并选择 7 天的保留期。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-snapshot.png"&gt;&lt;img class="aligncenter size-large wp-image-53892" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-snapshot-1024x478.png" alt="控制台屏幕截图。" width="1024" height="478" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;对于&lt;strong&gt;维护&lt;/strong&gt;，我保留默认值，然后选择&lt;strong&gt;创建&lt;/strong&gt;。在这一部分，我还可以提供 &lt;a title="" href="https://aws.amazon.com/sns/"&gt;Amazon Simple Notification Service (SNS)&lt;/a&gt; 主题，以便收到重要集群事件的通知。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-maintenance.png"&gt;&lt;img class="aligncenter size-large wp-image-53893" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/08/11/amazon-memorydb-redis-maintenance-1024x804.png" alt="控制台屏幕截图。" width="1024" height="804" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;几分钟后，集群运行，我可以使用&lt;a href="https://redis.io/topics/rediscli"&gt; Redis 命令行界面&lt;/a&gt;或任何&lt;a href="https://redis.io/clients"&gt; Redis 客户端&lt;/a&gt;进行连接。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;使用 Amazon MemoryDB 作为主数据库&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;管理客户数据是许多业务流程的关键组件。为测试我的新 Amazon MemoryDB 集群的持久性，我想将其用作客户数据库。为简单起见，让我们在 Python 中构建一个简单的微服务，使我能够使用&lt;a href="https://en.wikipedia.org/wiki/Representational_state_transfer"&gt; REST&lt;/a&gt; API 从 Redis 集群中创建、更新、删除和获取一个或所有客户数据。&lt;/p&gt; 
&lt;p&gt;这是我的 &lt;code&gt;server.py&lt;/code&gt; 实现的代码：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-python"&gt;from flask import Flask, request
from flask_restful import Resource, Api, abort
from rediscluster import RedisCluster
import logging
import os
import uuid

host = os.environ['HOST']
port = os.environ['PORT']
db_host = os.environ['DBHOST']
db_port = os.environ['DBPORT']
db_username = os.environ['DBUSERNAME']
db_password = os.environ['DBPASSWORD']

logging.basicConfig(level=logging.INFO)

redis = RedisCluster(startup_nodes=[{&amp;quot;host&amp;quot;: db_host, &amp;quot;port&amp;quot;: db_port}],
            decode_responses=True, skip_full_coverage_check=True,
            ssl=True, username=db_username, password=db_password)

if redis.ping():
    logging.info(&amp;quot;Connected to Redis&amp;quot;)

app = Flask(__name__)
api = Api(app)


class Customers(Resource):

    def get(self):
        key_mask = &amp;quot;customer:*&amp;quot;
        customers = []
        for key in redis.scan_iter(key_mask):
            customer_id = key.split(':')[1]
            customer = redis.hgetall(key)
            customer['id'] = customer_id
            customers.append(customer)
            print(customer)
        return customers

    def post(self):
        print(request.json)
        customer_id = str(uuid.uuid4())
        key = &amp;quot;customer:&amp;quot; + customer_id
        redis.hset(key, mapping=request.json)
        customer = request.json
        customer['id'] = customer_id
        return customer, 201


class Customers_ID(Resource):

    def get（自我，ustomer_id）：
        key = &amp;quot;customer:&amp;quot; + customer_id
        customer = redis.hgetall(key)
        print(customer)
        if customer:
            customer['id'] = customer_id
            return customer
        else:
            abort(404)

    def put(self, customer_id):
        print(request.json)
        key = &amp;quot;customer:&amp;quot; + customer_id
        redis.hset(key, mapping=request.json)
        return '', 204

    def delete(self, customer_id):
        key = &amp;quot;customer:&amp;quot; + customer_id
        redis.delete(key)
        return '', 204


api.add_resource(Customers, '/customers')
api.add_resource(Customers_ID, '/customers/&amp;lt;customer_id&amp;gt;')


if __name__ == '__main__':
    app.run(host=host, port=port)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这是&lt;code&gt; requirements.txt&lt;/code&gt; 文件，它列出了应用程序所需的 Python 模块：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;redis-py-cluster
Flask
Flask-RESTful&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;同样的代码适用于 MemoryDB、ElastiCache 或任何 Redis 集群数据库。&lt;/p&gt; 
&lt;p&gt;我在 MemoryDB 集群所在的 VPC 中启动 &lt;a title="" href="https://aws.amazon.com/ec2/"&gt;Amazon Elastic Compute Cloud (Amazon EC2)&lt;/a&gt; 实例。为了能够连接到 MemoryDB 集群，我分配了&lt;code&gt;默认&lt;/code&gt;安全组。我还添加了另一个安全组，为我提供了对实例的 SSH 访问权限。&lt;/p&gt; 
&lt;p&gt;我将&lt;code&gt; server.py&lt;/code&gt; 和&lt;code&gt; requirements.txt&lt;/code&gt; 文件复制到实例中，然后安装依赖项：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;pip3 install --user -r requirements.txt&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;现在，我开始微服务：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;python3 server.py&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在另一个终端连接中，我使用&lt;a href="https://curl.se/"&gt; curl&lt;/a&gt; 在我的数据库中创建一个客户，并在&lt;code&gt; /customers&lt;/code&gt; 资源中使用 HTTP POST：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;curl -i --header &amp;quot;Content-Type: application/json&amp;quot; --request POST \
     --data '{&amp;quot;name&amp;quot;: &amp;quot;Danilo&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;Somewhere in London&amp;quot;,
              &amp;quot;phone&amp;quot;: &amp;quot;+1-555-2106&amp;quot;,&amp;quot;email&amp;quot;: &amp;quot;danilop@example.net&amp;quot;, &amp;quot;balance&amp;quot;: 1000}' \
     http://localhost:8080/customers&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;结果确认数据已存储并且已向字段添加了唯一 ID（由 Python 代码生成的&lt;a href="https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)"&gt; UUIDv4&lt;/a&gt;）：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;HTTP/1.0 201 CREATED
Content-Type: application/json
Content-Length: 172
Server: Werkzeug/2.0.1 Python/3.7.10
Date: Wed, 11 Aug 2021 18:16:58 GMT

{&amp;quot;name&amp;quot;: &amp;quot;Danilo&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;Somewhere in London&amp;quot;,
 &amp;quot;phone&amp;quot;: &amp;quot;+1-555-2106&amp;quot;, &amp;quot;email&amp;quot;: &amp;quot;danilop@example.net&amp;quot;,
 &amp;quot;balance&amp;quot;: 1000, &amp;quot;id&amp;quot;: &amp;quot;3894e683-1178-4787-9f7d-118511686415&amp;quot;}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;所有字段都存储在 Redis Hash 中，密钥是 &lt;code&gt;customer:&amp;lt;id&amp;gt;&lt;/code&gt;。&lt;/p&gt; 
&lt;p&gt;我重复几次上一个命令，以创建三个客户。客户数据是相同的，但每个数据都有一个唯一 ID。&lt;/p&gt; 
&lt;p&gt;现在，我获得了一份列表，列出了所有具有到 &lt;code&gt;/customers&lt;/code&gt; 资源 HTTP GET 的客户：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;curl -i http://localhost:8080/customers&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在代码中，有一个使用&lt;a href="https://redis.io/commands/scan"&gt; SCAN&lt;/a&gt; 命令的匹配键上的 iterator。&amp;nbsp;在响应中，我看到了三位客户的数据：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;HTTP/1.0 200 OK
Content-Type: application/json
Content-Length: 526
Server: Werkzeug/2.0.1 Python/3.7.10
Date: Wed, 11 Aug 2021 18:20:11 GMT

[{&amp;quot;name&amp;quot;: &amp;quot;Danilo&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;Somewhere in London&amp;quot;,
&amp;quot;phone&amp;quot;: &amp;quot;+1-555-2106&amp;quot;, &amp;quot;email&amp;quot;: &amp;quot;danilop@example.net&amp;quot;,
&amp;quot;balance&amp;quot;: &amp;quot;1000&amp;quot;, &amp;quot;id&amp;quot;: &amp;quot;1d734b6a-56f1-48c0-9a7a-f118d52e0e70&amp;quot;},
{&amp;quot;name&amp;quot;: &amp;quot;Danilo&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;Somewhere in London&amp;quot;,
&amp;quot;phone&amp;quot;: &amp;quot;+1-555-2106&amp;quot;, &amp;quot;email&amp;quot;: &amp;quot;danilop@example.net&amp;quot;,
&amp;quot;balance&amp;quot;: &amp;quot;1000&amp;quot;, &amp;quot;id&amp;quot;: &amp;quot;89bf6d14-148a-4dfa-a3d4-253492d30d0b&amp;quot;},
{&amp;quot;name&amp;quot;: &amp;quot;Danilo&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;Somewhere in London&amp;quot;,
&amp;quot;phone&amp;quot;: &amp;quot;+1-555-2106&amp;quot;, &amp;quot;email&amp;quot;: &amp;quot;danilop@example.net&amp;quot;,
&amp;quot;balance&amp;quot;: &amp;quot;1000&amp;quot;, &amp;quot;id&amp;quot;: &amp;quot;3894e683-1178-4787-9f7d-118511686415&amp;quot;}]&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;其中一位客户花费了所有余额。我用包含 ID (&lt;code&gt;/customers/&amp;lt;id&amp;gt;&lt;/code&gt;) 的客户资源 URL 上的 HTTP PUT 更新该字段：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;curl -i --header &amp;quot;Content-Type: application/json&amp;quot; \
     --request PUT \
     --data '{&amp;quot;balance&amp;quot;: 0}' \
     http://localhost:8080/customers/3894e683-1178-4787-9f7d-118511686415&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;该代码正在使用请求数据更新 Redis Hash 的字段。在这种情况下，它将&lt;code&gt;余额&lt;/code&gt;设置为零。我按 ID 获取客户数据，从而验证更新：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;curl -i http://localhost:8080/customers/3894e683-1178-4787-9f7d-118511686415&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;在响应中，我看到余额已更新：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre class="unlimited-height-code"&gt;&lt;code class="lang-bash"&gt;HTTP/1.0 200 OK
Content-Type: application/json
Content-Length: 171
Server: Werkzeug/2.0.1 Python/3.7.10
Date: Wed, 11 Aug 2021 18:32:15 GMT

{&amp;quot;name&amp;quot;: &amp;quot;Danilo&amp;quot;, &amp;quot;address&amp;quot;: &amp;quot;Somewhere in London&amp;quot;,
&amp;quot;phone&amp;quot;: &amp;quot;+1-555-2106&amp;quot;, &amp;quot;email&amp;quot;: &amp;quot;danilop@example.net&amp;quot;,
&amp;quot;balance&amp;quot;: &amp;quot;0&amp;quot;, &amp;quot;id&amp;quot;: &amp;quot;3894e683-1178-4787-9f7d-118511686415&amp;quot;}&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;这就是 Redis 的力量！ 我只需几行代码就能够创建微服务的框架。最重要的是，MemoryDB 为我提供了生产环境中所需的持久性和高可用性，而无需在后端添加另一个数据库。&lt;/p&gt; 
&lt;p&gt;根据我的工作负载，我可以通过添加或删除节点来横向扩展我的 MemoryDB 集群，或者通过移动到更大或更小的节点类型进行纵向扩展。MemoryDB 支持使用分片进行写入扩展以及通过添加副本进行读取扩展。我的集群将继续保持在线状态，并在调整运维期间支持读取和写入操作。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;可用性和定价&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;&lt;a href="https://aws.amazon.com/memorydb"&gt;Amazon MemoryDB for Redis&lt;/a&gt; 现已在美国东部（弗吉尼亚北部）、欧洲（爱尔兰）、亚太地区（孟买）和南美洲（圣保罗）推出，而且即将在更多 AWS 区域推出。&lt;/p&gt; 
&lt;p&gt;您可以使用&lt;a title="" href="https://console.aws.amazon.com"&gt; AWS 管理控制台&lt;/a&gt;、&lt;a title="" href="https://aws.amazon.com/cli/"&gt;AWS 命令行界面 (CLI) &lt;/a&gt;或 &lt;a title="" href="https://aws.amazon.com/tools/"&gt;AWS 开发工具包&lt;/a&gt;在几分钟内创建 MemoryDB 集群。即将提供&lt;a title="" href="https://aws.amazon.com/cloudformation/"&gt; AWS CloudFormation&lt;/a&gt; 支持。对于节点，MemoryDB 目前支持 R6g &lt;a href="https://aws.amazon.com/ec2/graviton/"&gt;Graviton2&lt;/a&gt; 实例。&lt;/p&gt; 
&lt;p&gt;要从 ElastiCache for Redis 迁移到 MemoryDB，您可以备份 ElastiCache 集群并将其还原到 MemoryDB 集群。您还可以从存储在 &lt;a title="" href="https://aws.amazon.com/s3/"&gt;Amazon Simple Storage Service (Amazon S3)&lt;/a&gt; 上的 &lt;a href="https://redis.io/topics/persistence"&gt;Redis Database Backup (RDB)&lt;/a&gt; 文件创建新集群。&lt;/p&gt; 
&lt;p&gt;通过 MemoryDB，您可以根据每个节点的按需实例小时数、写入集群的数据量以及快照存储为实际使用量付费。&amp;nbsp;有关更多信息，请参阅 &lt;a href="https://aws.amazon.com/memorydb/pricing"&gt;MemoryDB 定价页面&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;了解详情&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;观看以下视频，获得快速概述。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/memorydb"&gt;&lt;strong&gt;立即将 Amazon MemoryDB for Redis 作为您的主数据库。&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;– &lt;a title="Danilo 的 Twitter" href="https://twitter.com/danilop"&gt;Danilo&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>关于Amazon EKS中Service和Ingress深入分析和研究</title>
		<link>https://aws.amazon.com/cn/blogs/china/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks/</link>
				<pubDate>Wed, 25 Aug 2021 03:16:09 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Containers]]></category>
		<category><![CDATA[Amazon Elastic Kubernetes Service]]></category>
		<category><![CDATA[Amazon elastic load balancer]]></category>

		<guid isPermaLink="false">f55b4bf47866bdab1e857be08eff6e59ddfbea66</guid>
				<description>在使用Amazon EKS的过程中，暴露容器化的服务(各种类型的协议),经常会碰到Kubernetes Service和Ingress。它们具体适用的场景和特点是什么了？比如IoT场景下的服务暴露，使用那种方式比较适合了？这里和业务场合相关，也和Service和Ingress技术实现有很大关联。那细节上它们具体是如何实现的了？本文将主要讨论Amazon EKS中Service和Ingress的具体实现细节。知道这些细节后，我们能做出更好的取舍。</description>
								<content:encoded>&lt;h2&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在使用Amazon EKS的过程中，暴露容器化的服务(各种类型的协议),经常会碰到Kubernetes Service和Ingress。它们具体适用的场景和特点是什么了？比如IoT场景下的服务暴露，使用那种方式比较适合了？这里和业务场合相关，也和Service和Ingress技术实现有很大关联。那细节上它们具体是如何实现的了？本文将主要讨论Amazon EKS中Service和Ingress的具体实现细节。知道这些细节后，我们能做出更好的取舍。&lt;/p&gt; 
&lt;p&gt;这里有一个典型的场景，对于一些应用的某些部分，比如常说的前端，可能希望将其暴露给 Amazon EKS集群外部的IP地址，Kubernetes Service和Ingress是常见的两种方式。对于Kubernetes Service允许指定你所需要的Service Tyeps(类型)。Service Types的可能的选项以及具体的特性如下：&lt;/p&gt; 
&lt;p&gt;(1) ClusterIP: 通过集群的内部IP(虚拟IP/VIP)暴露服务，选择此选项时服务只能够在集群内部访问。 这也是默认的Service类型。&lt;/p&gt; 
&lt;p&gt;(2) NodePort: 通过每个节点(worker node)上的IP和静态端口(NodePort)暴露服务。 NodePort服务会路由到自动创建的ClusterIP服务。 通过请求&amp;lt;节点 IP&amp;gt;:&amp;lt;节点端口&amp;gt;，你可以从集群的外部访问一个NodePort服务。&lt;/p&gt; 
&lt;p&gt;(3)LoadBalancer: 使用云提供商的负载均衡器向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的NodePort服务和 ClusterIP 服务上。&lt;/p&gt; 
&lt;p&gt;(4) ExternalName：通过返回CNAME和对应值，可以将服务映射到externalName字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理。&lt;/p&gt; 
&lt;p&gt;说明：你需要使用kube-dns 1.7及以上版本或者 oreDNS 0.0.8 及以上版本才能使用 ExternalName 类型。&lt;/p&gt; 
&lt;p&gt;另外，你也可以使用 Ingress 来暴露服务。 Ingress 不是一种Service Tyeps(类型)，但它充当集群提供的服务的入口。 它可以将路由规则整合到一个资源中，因为它可以在同一IP地址下公开多个服务。&lt;/p&gt; 
&lt;p&gt;上面对Service Tyeps(类型)和Ingress做了大致的介绍，但是你理解它具体是如何实现的吗？又如何根据他的特点来选择和配置呢？接下来我们来讨论Service (ClusterIP, NodePort, LoadBalancer)和Ingress。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;二、准备知识&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在分析和研究Service 和Ingress之前，让我们先温顾一下ISO OSI 7层模型和TCP/IP 4层模型。另外还有就是Linux的network stack以及netfilter 和iptables。因为这些都是我们来分析和研究Service和Ingress的前提知识。&lt;/p&gt; 
&lt;h3&gt;1) ISO OSI 7层模型和TCP/IP 4层模型&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 开放系统互连模型（ISO OSI 7层模型）是一个概念模型，它对电信或计算系统的通信功能进行了描述和标准化，不考虑其潜在的内部结构和技术。它的目标是使不同的通信系统与标准通信协议具有互操作性。&lt;/p&gt; 
&lt;p&gt;传输控制协议/互联网协议模型(TCP/IP 4层模型)是指一套管理像以太网这样的IP网络中设备之间通信的规则。它是以一系列的层来实现的。为什么要分层？层允许我们处理复杂的系统，将问题分离成各个组成部分，然后以模块化的方式处理它。这种模块化使系统能够被维护和更新，而不会给系统的其他部分带来麻烦。&lt;/p&gt; 
&lt;p&gt;ISO OSI 7层模型和TCP/IP 4层模型有如上图的的对应关系。如上各层的信息，可以参考以下的link:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/OSI_model"&gt;https://en.wikipedia.org/wiki/OSI_model&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2) Linux Network Stack&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 上图主要反映Linux Network Stack的层次结构。Linux内核由几个重要部分组成,其中包括进程管理、内存管理、硬件设备驱动、文件系统驱动、网络管理和其他各种部分。其中最大的特性之一是它的网络堆栈(Network Stack)，它最初起源于BSD的网络堆栈，有一个非常简洁的界面，而且组织良好。它的接口范围从与协议无关的层（如一般套接字层接口或设备层）到各种网络协议的特定层。请注意其中的Netfilter层。&lt;/p&gt; 
&lt;p&gt;下图是详细的发送者和接受者之间的数据传输路径(图片来之 &lt;a href="https://www.cs.cornell.edu/~qizhec/paper/tcp_2021.pdf"&gt;https://www.cs.cornell.edu/~qizhec/paper/tcp_2021.pdf&lt;/a&gt; )&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 3) netfilter 和iptables&lt;/h3&gt; 
&lt;p&gt;netfilter官网对netfilter 和iptables有很好介绍和说明，具体如下：&lt;/p&gt; 
&lt;p&gt;什么是netfilter项目？&lt;/p&gt; 
&lt;p&gt;netfilter项目是一个社区驱动的协作性的FOSS(开源免费软件)项目，为Linux 2.4.x及以后的内核系列提供包过滤软件。netfilter项目通常与iptables和它的后继者nftables有关。&lt;/p&gt; 
&lt;p&gt;netfilter项目实现了数据包过滤、网络地址[和端口]转换（NA[P]T）、数据包记录、用户空间数据包排队和其他数据包处理。&lt;/p&gt; 
&lt;p&gt;iptables是一个通用的防火墙软件，允许你定义规则集。iptables内的每个规则由一些分类器(iptables匹配)和一个连接动作(action)或iptables目标(target)组成。留意这里的action和target.&lt;/p&gt; 
&lt;p&gt;netfilter主要特点&lt;/p&gt; 
&lt;p&gt;(1)无状态数据包过滤(IPv4和IPv6)&lt;/p&gt; 
&lt;p&gt;(2)有状态数据包过滤（IPv4和IPv6&lt;/p&gt; 
&lt;p&gt;(3)各种网络地址和端口转换，如NAT/NAPT（IPv4和IPv6）。&lt;/p&gt; 
&lt;p&gt;(4)灵活和可扩展的基础设施&lt;/p&gt; 
&lt;p&gt;(5)用于第三方扩展的多层次的API&lt;/p&gt; 
&lt;p&gt;根据如上的内容，netfilter提供的是一个数据包过滤的框架，而iptables只是通过定义的规则集来调用这个框架的工具。所以我们经常使用的工具为iptables。&lt;/p&gt; 
&lt;p&gt;在netfilter框架中过滤的流程图，来至于&lt;a href="https://en.wikipedia.org/wiki/Netfilter"&gt;https://en.wikipedia.org/wiki/Netfilter&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 上面是详细版本数据包流程图，下面给一个笔者制作的简易易于理解的流程图：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 当我们说iptables，什么是链和表了？经常会说道四表五链。那具体是什么了？如上图&lt;/p&gt; 
&lt;p&gt;从数据包的角度，进入到Linux Network Stack中的netfilter环节，扮演成网络防火墙的netfilter会根据设定规则来过滤这些数据包，比如拒绝掉ping请求(ICMP包)。这些规则就组织成了形如链的结构–“规则链”。这些链用预定义的标题来命名，五链包括PREROUTING, INPUT, OUTPUT, FORWARD和POSTROUTING。这些链的标题有助于描述netfilter堆栈中的位置和起源。例如，数据包的接收属于PREROUTING，而INPUT代表本地交付的数据，转发的流量则属于FORWARD链。本地产生的输出通过OUTPUT链，而要发送出去的数据包则在POSTROUTING链。另外，链中规则还可以执行自己定义的规则(放置于自定义链中)，这就使额外的处理和迭代成为可能。Kubernetes Service中大量使用了自定义链。&lt;/p&gt; 
&lt;p&gt;但一条链上有了太多的规则后，如何对这些规则进行管理是个问题。我们可以将具有相同功能的规则集合放在一起，这里就形成了表。iptables已经默认定义了四张表。它们分别是filter, nat, raw, mangle。每个表的引入都是为了服务于一个特定的目的, 就netfilter而言，它以特定的顺序相对于其他表运行一个特定的表，比如上图中的PREROUTING链中表的执行顺序就是raw,mangle和nat。这四表的功能如下：&lt;/p&gt; 
&lt;p&gt;(1)filter表：负责过滤功能，防火墙；内核模块：iptables_filter&lt;/p&gt; 
&lt;p&gt;(2)nat表：network address translation，网络地址转换功能；内核模块：iptable_nat&lt;/p&gt; 
&lt;p&gt;(3)mangle表：拆解报文，做出修改，并重新封装 的功能；内核模块：iptable_mangle&lt;/p&gt; 
&lt;p&gt;(4)raw表：关闭nat表上启用的连接追踪机制；内核模块：iptable_raw&lt;/p&gt; 
&lt;p&gt;因为iptables中表和链的关系刚接触理解起来是比较繁琐的，所以建议看如下的博客，写的比较通俗易懂 &lt;a href="https://www.zsythink.net/archives/tag/iptables/page/2"&gt;https://www.zsythink.net/archives/tag/iptables/page/2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;三、&lt;/strong&gt;&lt;strong&gt;Service和Ingress分析和研究&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;1) 准备实验环境&lt;/h3&gt; 
&lt;p&gt;此处使用亚马逊云科技的宁夏区域，使用如下的yaml文件，通过eksctl创建EKS集群，具体创建步骤方法可以参考github链接 — &lt;a href="https://github.com/jerryjin2018/AWS-China-EKS-Workshop-2021/blob/main/Lab1:%20Create%20an%20EKS%20cluster%20through%20eksctl.md"&gt;https://github.com/jerryjin2018/AWS-China-EKS-Workshop-2021/blob/main/Lab1:%20Create%20an%20EKS%20cluster%20through%20eksctl.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;本次分析和研究用的yaml文件在如下的连接中&lt;a href="https://github.com/jerryjin2018/service_ingress/tree/main/code"&gt;https://github.com/jerryjin2018/service_ingress/tree/main/code&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;eksgo05-cluster.yaml&lt;/code&gt;&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: eksgo05
  region: cn-northwest-1 
  version: &amp;quot;1.19&amp;quot;

managedNodeGroups:
  - name: ng-eksgo05-01
    instanceType: t3.xlarge
    instanceName: ng-eksgo05
    desiredCapacity: 3
    minSize: 1
    maxSize: 8 
    volumeSize: 100
    ssh:
      publicKeyName: your_key_pair
      allow: true
      enableSsm: true 
    iam:
      withAddonPolicies:
        ebs: true
        fsx: true
        efs: true&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;查看新建集群的状态：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get nodes&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 2) 检查每个worker node上iptables中四表的状态&lt;/h3&gt; 
&lt;p&gt;因为iptables命令就是按照参数-t[表名]来展示规则的。默认是filter表。登陆到其中一台worker node上&lt;/p&gt; 
&lt;p&gt;2.1)检查filter表&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t filter -vnL | grep ^Chain &amp;amp;&amp;amp; iptables -t filter -vnL | grep ^Chain | wc -l&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; filter表处理有默认的链，还有自定义的链，如KUBE-SERVICES等。共12条链。&lt;/p&gt; 
&lt;p&gt;2.2)检查nat表&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL | grep ^Chain &amp;amp;&amp;amp; iptables -t nat -vnL | grep ^Chain | wc -l&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks8.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; nat表处理有默认的链，还有自定义的链，如KUBE-SERVICES等。共32条链。&lt;/p&gt; 
&lt;p&gt;2.3)检查raw表&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t raw -vnL | grep ^Chain &amp;amp;&amp;amp; iptables -t raw -vnL | grep ^Chain | wc -l&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks9.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; raw表处理有默认的链。&lt;/p&gt; 
&lt;p&gt;2.4)检查mangle表&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t mangle -vnL | grep ^Chain &amp;amp;&amp;amp; iptables -t mangle -vnL | grep ^Chain | wc -l&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks10.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; mangle表处理有默认的链，还有自定义的链，如KUBE-PROXY-CANARY等。共7条链。&lt;/p&gt; 
&lt;p&gt;2.5)给node group中增加一个node，看新的node上的iptables中四表的状态&lt;/p&gt; 
&lt;p&gt;查看目前node group中node的数量&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws eks describe-nodegroup&amp;nbsp; --cluster-name eksgo05 --nodegroup-name ng-eksgo05-01 | jq .nodegroup.scalingConfig&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks11.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 增加一个node&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws eks update-nodegroup-config --cluster-name eksgo05 --nodegroup-name ng-eksgo05-01 --scaling-config minSize=1,maxSize=8,desiredSize=4&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks12.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 再次检查node group的&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws eks describe-nodegroup&amp;nbsp; --cluster-name eksgo05 --nodegroup-name ng-eksgo05-01 | jq .nodegroup.scalingConfig&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks13.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;code&gt;kubectl get nodes&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks14.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 登陆到这个新增加的worker node上，我们会发现iptables的四张表中的链，包括自定义链（在准备知识中已经解释了）的数量和名称都是一样的，也就是说，默认情况下，所有worker node上的iptables的规则定义是一样，这个和笔者以前了解的分布式的SDN的实现方式是一致的。&lt;/p&gt; 
&lt;p&gt;将node group仍然调整为3个nodes，具体命令为&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;aws eks update-nodegroup-config --cluster-name eksgo05 --nodegroup-name ng-eksgo05-01 --scaling-config minSize=1,maxSize=8,desiredSize=3&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;3) 分析Service类型是ClusterIP的场景&lt;/h3&gt; 
&lt;p&gt;3.1)创建类型为ClusterIP的Service和测试的Deployment, testenv_clusterip.yaml&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;---
apiVersion: v1
kind: Namespace
metadata:
  name: net-test
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: net-test
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-net
  template:
    metadata:
      labels:
        app: nginx-net
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-clusterip
  namespace: net-test
spec:
  type: ClusterIP
  selector:
    app: nginx-net
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 80
:
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;code&gt;kubectl apply -f testenv_cluster.yaml &amp;amp;&amp;amp; kubectl get service -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;3.2)检查ClusterIP的Service和对应的nat表中的链&lt;/p&gt; 
&lt;p&gt;查看创建的类型为ClusterIP的Service对应deployment中的pod&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks15.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks15.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; nat表中的链有iptable默认定义的链(PREROUTING,INPUT,OUTPUT,POSTROUTING)&lt;/p&gt; 
&lt;p&gt;在测试机器上执行kubectl,我们可以看到我们刚刚创建的名为nginx-service-clusterip 的service，目前为ClusterIP的类型(TYPE)，而且它的CLUSTER-IP地址为10.100.87.207，端口为8080/TCP，也就是通过 nginx-service(10.100.87.207)的8080端口可以访问到target(pod的80端口）&lt;/p&gt; 
&lt;p&gt;再查看service名为nginx-service-clusterip中的细节以及endpoints和endpointslices clusterip&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl describe service/nginx-service-clusterip -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get endpoints -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl describe service/nginx-service-clusterip -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl describe endpointslices.discovery.k8s.io/nginx-service-clusterip-kzkhp -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks16.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks16.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 登陆到其中一台worker node上查看iptables 规则，其实在3个worker node上的iptables -t nat -vnL结果基本一样，只是Chain KUBE-SERVICES中具体的规则的顺序不一样&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks17.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks17.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks18.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks18.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks19.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks19.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;nat表中的链有iptable默认定义的链(PREROUTING,INPUT,OUTPUT,POSTROUTING)，来检查CLUSTER IP — 10.100.87.207。我们会发现10.100.87.207 在自定义链 KUBE-SERVICES中定义一条规则，具体如下，并且应用的target/action是KUBE-SVC-7QI22HNU2ECHCQD4&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL&amp;nbsp; | grep -i &amp;quot;10.100.87.207&amp;quot; -B 8&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks20.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks20.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 那我们来检查自定义链 KUBE-SERVICES 和 KUBE-SVC-7QI22HNU2ECHCQD4&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL&amp;nbsp; | grep -i &amp;quot;Chain KUBE-SVC-7QI22HNU2ECHCQD4 &amp;quot; -A 5&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks21.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks21.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 此处需要介绍一下 iptables statistic 模块&lt;a href="https://ipset.netfilter.org/iptables-extensions.man.html"&gt;https://ipset.netfilter.org/iptables-extensions.man.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks22.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks22.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 很显然，通过 statistic 模块达到负载均衡的效果，但是这里是3个worker node，如果是4个或是10个pod，情况会是如何的了？那我们先将pod扩展到4个。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get deployments.apps&amp;nbsp; -n net-test -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get pod&amp;nbsp; -n net-test -o wide&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl scale deployments.apps/nginx-deployment --replicas=4 -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get deployments.apps/nginx-deployment -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks23.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks23.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 再来看看iptables 自定义链 KUBE-SVC-7QI22HNU2ECHCQD4。正如你所见到的，自定义链 KUBE-SVC-7QI22HNU2ECHCQD4的条目发生了变化，它根据增加的pod，而调整了statistic模块 mode random probability后面的值。&lt;/p&gt; 
&lt;p&gt;扩展到4个pod的情况&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL&amp;nbsp; | grep -i &amp;quot;Chain KUBE-SVC-7QI22HNU2ECHCQD4 &amp;quot; -A 5&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks24.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks24.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 扩展到10个pod的情况&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL&amp;nbsp; | grep -i &amp;quot;Chain KUBE-SVC-7QI22HNU2ECHCQD4 &amp;quot; -A 12&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks25.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks25.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 总结下来，当你扩展pod副本的数量后，Amazon EKS /K8S 会在自定义链 KUBE-SVC-7QI22HNU2ECHCQD4 中定义n条额外的自定义链，n的数量等于pod replicas的数量，每一条自定义链后面的statistic模块 mode random probability后面的值的规律是:&lt;/p&gt; 
&lt;p&gt;1/n&lt;/p&gt; 
&lt;p&gt;1/(n-1)&lt;/p&gt; 
&lt;p&gt;1/(n-2)&lt;/p&gt; 
&lt;p&gt;…&lt;/p&gt; 
&lt;p&gt;1/3&lt;/p&gt; 
&lt;p&gt;1/2&lt;/p&gt; 
&lt;p&gt;先缩回3个pod，继续分析自定义链 — KUBE-SEP-GFX4GQVKUQKLDQSC, KUBE-SEP-7DVRGHMVAU4TLNCL, KUBE-SEP-OR4TYVRLHR7Z5F7F&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks26.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks26.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 扩展到10个pod的情况&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL&amp;nbsp; | grep -i &amp;quot;Chain KUBE-SEP-GFX4GQVKUQKLDQSC&amp;quot; -A 4&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL&amp;nbsp; | grep -i &amp;quot;Chain KUBE-SEP-7DVRGHMVAU4TLNCL&amp;quot; -A 4&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL&amp;nbsp; | grep -i &amp;quot;Chain KUBE-SEP-OR4TYVRLHR7Z5F7F&amp;quot; -A 4&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks27.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks27.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 那DNAT和MARK target/action意义是什么了？如下的官方文档的介绍。DNAT就是对数据包中的目的地址做NAT(地址转换)，也就是访问到CLUSTER-IP地址10.100.87.207后，会被负载均衡到后端的pod上,而MARK则是给指定的数据包做标识&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks28.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks28.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks29.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks29.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 到这里，对于Service类型是ClusterIP的场景分析结束，ClusterIP就是通过Cluster-IP的虚拟IP(VIP)，结合iptables中的自定义链加上statistic模块和DNAT来做轻量的负载均衡。结合之前的数据包流程图：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks30.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks30.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 这里，你可能会问为什么没有走nat表，而不是走raw表或是mangle表。其实还是这里主要需要实现地址转换(NAT)。数据包在netfilter/iptables中nat表走的链如下:&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks31.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks31.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 4) 分析Service类型是NodePort的场景&lt;/h3&gt; 
&lt;p&gt;4.1)创建类型为NodePort的Service和测试的Deployment, testenv_nodeport.yaml&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;---
apiVersion: v1
kind: Namespace
metadata:
  name: net-test
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: net-test
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-net
  template:
    metadata:
      labels:
        app: nginx-net
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-nodeport
  namespace: net-test
spec:
  type: NodePort
  selector:
    app: nginx-net
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 80
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;4.2)检查NodePort的Service和对应的nat表中的链&lt;/p&gt; 
&lt;p&gt;nat表中的链有iptable默认定义的链(PREROUTING,INPUT,OUTPUT,POSTROUTING)&lt;/p&gt; 
&lt;p&gt;在测试机器上执行kubectl,我们可以看到我们刚刚创建的名为nginx-service-nodeport 的service，目前为NodePort的类型(TYPE)，而且它的CLUSTER-IP地址为10.100.127.14，对的它也有CLUSTER-IP，它的端口是8080:32060/TCP。也就是通过 nginx-service-nodeport(worker node)的32060端口可以访问到target(pod的80端口）&lt;/p&gt; 
&lt;p&gt;再查看service名为nginx-service- nodeport中的细节以及endpoints和endpointslices&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get service -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get endpoints -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get endpointslices.discovery.k8s.io -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl describe service/nginx-service-nodeport -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks32.png" width="624" height="78" /&gt;&lt;/p&gt; 
&lt;p&gt;大家很容易想到使用Node Port，为了确保能访问到pod，一定是发生了nat(网络地址翻译)，所以我们来查看nat表。nat表中的链有iptable默认定义的链(PREROUTING,INPUT,OUTPUT,POSTROUTING)，逻辑上数据包进入到linux network stack，是先到PREROUTING链，再结合 iptables -t nat -vnL 输出中在4条链(PREROUTING,INPUT,OUTPUT,POSTROUTING)内容的观察，也会直接查看PREROUTING链的规则。PREROUTING链的target/action还是自定义链 KUBE-SERVICES。接下来还是查看自定义链 KUBE-SERVICES中定义一条规则，具体如下:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL | grep PREROUTING -A 3&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL | grep &amp;quot;Chain KUBE-SERVICES&amp;quot; -A 10&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks33.png" width="624" height="78" /&gt;&lt;/p&gt; 
&lt;p&gt;尽管其中有一个条规则，它的destination 是10.100.127.14，但是我们现在创建的service的类型是nodeport，也就意味一定是通过worker node的端口(port)进入到worker node，也就是一定通过了worker node的ip地址,不论是primary ip,还是secondary ip.&lt;/p&gt; 
&lt;p&gt;这里有一个iptables的addrtype模块，具体功能如下:&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks34.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks34.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;netstat -ntupl| head -n 2 &amp;amp;&amp;amp; netstat -ntupl | grep -i 32060&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks35.png" width="624" height="78" /&gt;我们可以看到worker node的端口32060是被kube-proxy监听，而且是监听了worker node上所有的ip地址。所以进入到worker node的端口32060的数据包匹配的是 KUBE-SERVICES 中 KUBE-NODEPORTS 自定义链。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL | grep &amp;quot;Chain KUBE-NODEPORTS&amp;quot; -A 4&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;iptables -t nat -vnL | grep &amp;quot;Chain KUBE-SVC-NUUJACZKM4EFI6UZ&amp;quot; -A 5&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks36.png" width="624" height="78" /&gt;&lt;/p&gt; 
&lt;p&gt;那KUBE-NODEPORTS 自定义链包含的具体规则是什么了？如大家可以看到的，自定义链 KUBE-MARK-MASQ 对数据包mark。另外的自定义链 KUBE-SVC-NUUJACZKM4EFI6UZ ，让我们记住这个自定义链 KUBE-SVC-NUUJACZKM4EFI6UZ&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks37.png" width="624" height="78" /&gt;&lt;/p&gt; 
&lt;p&gt;到这里，大家又看到类似ClusterIP又做了负载均衡。&lt;/p&gt; 
&lt;p&gt;我们来看看自定义链 KUBE-SERVICES 中destination 是10.100.127.14的规则, 它的target/action也是自定义链 KUBE-SVC-NUUJACZKM4EFI6UZ。所以在iptables 的规则的角度，NodePort变相的使用了ClusterIP(的规则)，而不是直接使用ClusterIP的ip地址。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks38.png" width="624" height="78" /&gt;&lt;/p&gt; 
&lt;p&gt;至此，对于Service类型是NodePort的场景分析结束，NodePort就是通过worker node上的kube-proxy将流量引入iptables,结合addrtype模块将数据包再次转到ClusterIP的处理规则上来。进而在结合statistic模块和DNAT来做轻量的负载均衡。具体的在iptables中nat表走的链如下:&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks39.png" width="624" height="78" /&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;5) 分析Service类型是LoadBalancer的场景&lt;/h3&gt; 
&lt;p&gt;Service类型是LoadBalancer的场景，根据yaml文件中Service参数的不同，会创建不同类型的Amazon ELB&lt;/p&gt; 
&lt;p&gt;5.1)创建类型为LoadBalancer(CLB模式)&lt;/p&gt; 
&lt;p&gt;创建类型为LoadBalancer的Service和测试的Deployment, testenv_lb_1.yaml, 注意创建Service的部分没有annotation字段&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;---
apiVersion: v1
kind: Namespace
metadata:
  name: net-test
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: net-test
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-net
  template:
    metadata:
      labels:
        app: nginx-net
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-lb
  namespace: net-test
#There is no any annotation
spec:
  type: LoadBalancer
  selector:
    app: nginx-net
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 80&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;5.2)检查LoadBalancer的Service(CLB模式)&lt;/p&gt; 
&lt;p&gt;在测试机器上执行kubectl,我们可以看到我们刚刚创建的名为nginx-service-lb-1 的service，目前为LoadBalancer的类型(TYPE)，而且它的CLUSTER-IP地址为10.100.115.16，对的它也有CLUSTER-IP，它的端口是8080:32052/TCP。也就是通过 nginx-service-lb-1(也就是Amazon ELB)将数据包分发到 worker node的32052端口可以访问到target(pod的80端口)。注意到这里的EXTERNAL-IP就是Amazon ELB的地址。&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks40.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks40.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;再查看service名为nginx-service-lb-1中的细节以及endpoints和endpointslices&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl describe service/nginx-service-lb-1 -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get endpoints -n net-test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;kubectl get endpointslices.discovery.k8s.io -n net-test&lt;/code&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks41.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks41.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;我们再到亚马逊云科技的console查看ELB,可以看到在这里创建的是CLB(Classic Load Balancer)&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks42.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks42.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks43.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks43.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 其实当数据包由亚马逊云科技的CLB转发到3个worker node的端口，数据包处理的逻辑和过程和NodePort没有什么本质的差别。此处不再赘述。&lt;/p&gt; 
&lt;p&gt;5.3) 创建类型为LoadBalancer(NLB instance模式)&lt;/p&gt; 
&lt;p&gt;创建类型为LoadBalancer的Service和测试的Deployment, testenv_lb_2.yaml, 注意创建Service的部分的annotation字段&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;---
apiVersion: v1
kind: Namespace
metadata:
  name: net-test
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: net-test
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-net
  template:
    metadata:
      labels:
        app: nginx-net
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-lb-2
  namespace: net-test
 #There is an important annotation
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
spec:
  type: LoadBalancer
  selector:
    app: nginx-net
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 80
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks44.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks44.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;其实这次创建的名为nginx-service-lb-2的service和之前创建的nginx-service-lb-1 的service很相似。显示内容基本相同，只是在亚马逊云科技的console查看ELB是显示为NLB。&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks45.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks45.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks46.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks46.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks47.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks47.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 其实这次创建的名为nginx-service-lb-2的service和之前创建的nginx-service-lb-1 的service很相似。显示内容基本相同，只是在亚马逊云科技的console查看ELB是显示为NLB。这里就是NLB的instance模式。当数据包由亚马逊云科技的NLB转发到3个worker node的端口，数据包处理的逻辑和过程和NodePort没有什么本质的差别。此处也不再描述&lt;/p&gt; 
&lt;p&gt;5.4) 创建类型为LoadBalancer(NLB ip模式)&lt;/p&gt; 
&lt;p&gt;创建类型为LoadBalancer的Service和测试的Deployment, testenv_lb_3.yaml, 注意创建Service的部分的annotation字段&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;---
apiVersion: v1
kind: Namespace
metadata:
  name: net-test
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: net-test
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-net
  template:
    metadata:
      labels:
        app: nginx-net
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-lb-3
  namespace: net-test
 #There is an important annotation
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb-ip
spec:
  type: LoadBalancer
  selector:
    app: nginx-net
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 80
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;而这次创建的名为nginx-service-lb-3的service和之前创建的nginx-service-lb-2 的service也很相似。也只是在亚马逊云科技的console查看ELB也显示为NLB。但是这里为ip 模式。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks49.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks49.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks50.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks50.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks51.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks51.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;这里是直接将数据包发到pod的ip地址，因为此处EKS的service的类型为LoadBalancer(IP 模式)。而且pod也具有vpc cidr range内分配的IP 地址，直接arp获得pod对应的内网ip地址的mac，流量就直接转到承载此pod的worker node上。&lt;/p&gt; 
&lt;h3&gt;6) 分析Ingress&lt;/h3&gt; 
&lt;p&gt;Ingress 公开了从集群外部到集群内服务的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源上定义的规则控制。&lt;/p&gt; 
&lt;p&gt;Ingress 规则，每个 HTTP 规则都包含以下信息：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;可选的&lt;/strong&gt;&lt;strong&gt; host&lt;/strong&gt;: 该规则适用于通过指定 IP 地址的所有入站 HTTP 通信。 如果提供了 host（例如 foo.bar.com），则 rules 适用于该 host。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;路径列表&lt;/strong&gt;&lt;strong&gt; paths&lt;/strong&gt;: （例如，/testpath）,每个路径都有一个由 serviceName 和 servicePort 定义的关联后端。 在负载均衡器将流量定向到引用的服务之前，主机和路径都必须匹配传入请求的内容。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;backend（后端）&lt;/strong&gt;: 是 Service 文档中所述的服务和端口名称的组合。 与规则的 host 和 path 匹配的对 Ingress 的 HTTP（和 HTTPS ）请求将发送到列出的 backend。&lt;/p&gt; 
&lt;p&gt;通常在 Ingress 控制器中会配置 defaultBackend（默认后端），以服务于任何不符合规约中 path 的请求。&lt;/p&gt; 
&lt;p&gt;6.1)创建ingress和相应的Deployment&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;---
apiVersion: v1
kind: Namespace
metadata:
  name: net-test
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: net-test
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-net
  template:
    metadata:
      labels:
        app: nginx-net
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-clusterip
  namespace: net-test
spec:
  type: ClusterIP
  selector:
    app: nginx-net
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 80
---
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  namespace: net-test
  name: nginx-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
spec:
  rules:
    - http:
        paths:
          - path: /*
            backend:
              serviceName: nginx-service-clusterip
              servicePort: 8080

&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks52.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks52.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 正如你在kubernetes官方页面( &lt;a href="https://kubernetes.io/docs/concepts/services-networking/ingress"&gt;https://kubernetes.io/docs/concepts/services-networking/ingress&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;)中看到的那样, Ingress就扮演一个连接器的角色，它将http/https流量引入到Service.但我们可以看到为这个Ingress创建的ALB仍然使用的IP模式。也就是意味着Ingress也会如Service的LoadBalancer类型中的NLB IP模式，流量直接引入到pod的ip地址,因为pod也具有vpc cidr range内分配的IP地址。直接arp获得pod对应的内网ip地址的mac，流量就直接转到承载此pod的worker node上。&lt;/p&gt; 
&lt;p&gt;另外，尽管此处Service为ClusterIP,其实不论是NodePort还是LoadBalancer,效果也一样，这一点完全体现了Ingress就扮演一个连接器的角色，它将流量直接引入到pod，借助了ALB中的IP模式的优势。&lt;/p&gt; 
&lt;p&gt;这里可以通过查看 ALB ( k8s-nettest-nginxing-2893a9a207-569319061.cn-northwest-1.elb.amazonaws.com.cn )的target group。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks53.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks53.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks54.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks54.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks55.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/in-depth-analysis-and-research-on-service-and-ingress-in-amazon-eks55.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;h2&gt;&lt;strong&gt;四、总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在使用Amazon EKS的过程中，Service和Ingress是主要两种服务暴露方式。通过以上的深入分析和研究，我们可以看到Service的ClusterIP，NodePort和LoadBalancer的技术实现，在使用iptables的情况下，都是重度依赖kube-proxy对iptables的规则的操作。这其中ClusterIP是最关键最基础，NodePort又利用了ClusterIP的实现方式，LoadBalancer(CLB和NLB的instance模式)又使用了NodePort提供的功能。对于Service的NLB的ip模式和ingress又是主要利用的就是ALB的ip模式。&lt;/p&gt; 
&lt;p&gt;根据如上的特性，我们可以在不同的业务场景下选择不同的方式来暴露服务。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考材料:&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://blogs.cisco.com/cloud/an-osi-model-for-cloud"&gt;https://blogs.cisco.com/cloud/an-osi-model-for-cloud&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.cisco.com/c/dam/global/fi_fi/assets/docs/SMB_University_120307_Networking_Fundamentals.pdf"&gt;https://www.cisco.com/c/dam/global/fi_fi/assets/docs/SMB_University_120307_Networking_Fundamentals.pdf&lt;/a&gt;&lt;br /&gt; &lt;a href="https://en.wikipedia.org/wiki/OSI_model"&gt;https://en.wikipedia.org/wiki/OSI_model&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.cisco.com/E-Learning/bulk/public/tac/cim/cib/using_cisco_ios_software/linked/tcpip.htm"&gt;https://www.cisco.com/E-Learning/bulk/public/tac/cim/cib/using_cisco_ios_software/linked/tcpip.htm&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.cisco.com/c/en/us/support/docs/ip/routing-information-protocol-rip/13769-5.html"&gt;https://www.cisco.com/c/en/us/support/docs/ip/routing-information-protocol-rip/13769-5.html&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.netfilter.org/"&gt;https://www.netfilter.org/&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.netfilter.org/projects/iptables/index.html"&gt;https://www.netfilter.org/projects/iptables/index.html&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.zsythink.net/archives/tag/iptables/"&gt;https://www.zsythink.net/archives/tag/iptables/&lt;/a&gt;&lt;br /&gt; &lt;a href="https://ipset.netfilter.org/iptables-extensions.man.html"&gt;https://ipset.netfilter.org/iptables-extensions.man.html&lt;/a&gt;&lt;br /&gt; &lt;a href="https://aws.amazon.com/premiumsupport/knowledge-center/eks-kubernetes-services-cluster/"&gt;https://aws.amazon.com/premiumsupport/knowledge-center/eks-kubernetes-services-cluster/&lt;/a&gt;&lt;br /&gt; &lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/"&gt;https://kubernetes.io/docs/concepts/services-networking/service/&lt;/a&gt;&lt;br /&gt; &lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/network-load-balancing.html"&gt;https://docs.aws.amazon.com/eks/latest/userguide/network-load-balancing.html&lt;/a&gt;&lt;br /&gt; &lt;a href="https://en.wikipedia.org/wiki/OSI_model"&gt;https://en.wikipedia.org/wiki/OSI_model&lt;/a&gt;&lt;br /&gt; &lt;a href="https://en.wikipedia.org/wiki/List_of_network_protocols_(OSI_model)"&gt;https://en.wikipedia.org/wiki/List_of_network_protocols_(OSI_model)&lt;/a&gt;&lt;br /&gt; &lt;a href="https://codilime.com/blog/how-to-drop-a-packet-in-linux-in-more-ways-than-one"&gt;https://codilime.com/blog/how-to-drop-a-packet-in-linux-in-more-ways-than-one&lt;/a&gt;&lt;br /&gt; &lt;a href="http://www.jsevy.com/network/Linux_network_stack_walkthrough.html"&gt;http://www.jsevy.com/network/Linux_network_stack_walkthrough.html&lt;/a&gt;&lt;br /&gt; &lt;a href="https://openwrt.org/docs/guide-developer/networking/praxis"&gt;https://openwrt.org/docs/guide-developer/networking/praxis&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.cs.cornell.edu/~qizhec/paper/tcp_2021.pdf"&gt;https://www.cs.cornell.edu/~qizhec/paper/tcp_2021.pdf&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.netfilter.org/"&gt;https://www.netfilter.org/&lt;/a&gt;&lt;br /&gt; &lt;a href="https://en.wikipedia.org/wiki/Netfilter"&gt;https://en.wikipedia.org/wiki/Netfilter&lt;/a&gt;&lt;br /&gt; &lt;a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/"&gt;https://kubernetes.io/zh/docs/concepts/services-networking/service/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/zhongmij.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;金忠敏&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，现在专注于云计算解决方案和架构的工作。具有超过15年的IT从业经验，曾从事软件开发，售后支持，系统交付，售前等工作。参与过很多大型项目架构设计和实施交付。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/dongshic.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;董仕超&lt;/h3&gt; 
  &lt;p&gt;AWS 解决方案架构师。负责基于 AWS 的云计算方案架构的咨询和设计，致力于 AWS 云服务在国内和全球的应用和推广，在加入 AWS 前，拥有多年外企售前及运营商 IT 架构、运维经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>游戏公司多账号管理(一)</title>
		<link>https://aws.amazon.com/cn/blogs/china/game-company-multi-account-management/</link>
				<pubDate>Tue, 24 Aug 2021 03:14:56 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Industries]]></category>
		<category><![CDATA[AWS Config]]></category>
		<category><![CDATA[AWS Organization]]></category>
		<category><![CDATA[AWS Single Sign-On]]></category>

		<guid isPermaLink="false">5de028d6e8d5c4b0459f9ae924d001252fb3be6f</guid>
				<description>通常游戏发行公司每年都要发行数款新游戏，这些游戏可能由公司内部不同的项目组开发，也可能是由其他游戏公司开发。为了实现不同游戏之间的互相独立以及方便的核算每款游戏所使用云计算资源的成本，在AWS上我们推荐为每一款游戏使用单独的账户，这样做的好处是每个游戏都有独立的明细账单，并且不同账户互相独立，有非常好的隔离性。</description>
								<content:encoded>&lt;p&gt;通常游戏发行公司每年都要发行数款新游戏，这些游戏可能由公司内部不同的项目组开发，也可能是由其他游戏公司开发。为了实现不同游戏之间的互相独立以及方便的核算每款游戏所使用云计算资源的成本，在AWS上我们推荐为每一款游戏使用单独的账户，这样做的好处是每个游戏都有独立的明细账单，并且不同账户互相独立，有非常好的隔离性。&lt;/p&gt; 
&lt;p&gt;对于稍大规模的游戏公司来说有十几款、甚至几十款游戏同时在运行中是很常见的，那么为每一款游戏使用单独账户的方式，会给游戏公司带来管理与安全方面的挑战。在和不同的游戏公司交流之后，我总结了一下几点挑战：&lt;/p&gt; 
&lt;p&gt;（1）如何快速为每个游戏单独创建账户并组织这些账户&lt;/p&gt; 
&lt;p&gt;（2）如何集中式的用户管理与权限分配&lt;/p&gt; 
&lt;p&gt;（3）如何方便的查看、管理多账户下的资源&lt;/p&gt; 
&lt;p&gt;（4）如何实现多账户下用户操作的统一审计&lt;/p&gt; 
&lt;p&gt;（5）如何减少新账户初始化配置工作&lt;/p&gt; 
&lt;p&gt;（6）如何限制某个账户或者用户资源使用量&lt;/p&gt; 
&lt;p&gt;由于涉及的服务和内容较多，本篇Blog将先解决前面三个挑战，在后续的博客中再介绍剩下部分的内容。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;（1）如何快速为每个游戏单独创建账户并组织这些账户&lt;/h2&gt; 
&lt;p&gt;为了保持每款游戏的独立性，建议采用每款游戏一个独立账户的方式，那么首先要解决的就是如何方便快速创建账户。创建AWS账户有两种方式，第一种方式是通过&lt;a href="https://portal.aws.amazon.com/billing/signup#/start"&gt;注册页面&lt;/a&gt;，这种方式需要填写的信息较多，适合公司第一次注册使用AWS；第二种方式就是通过AWS Organizations来创建账户，&lt;a href="https://aws.amazon.com/cn/organizations/"&gt;AWS Organizations&lt;/a&gt;本身的功能介绍以及如何启用请参考官方文档，这里不再赘述。&lt;/p&gt; 
&lt;p&gt;需要注意的是启用AWS Organizations服务的账户被称为管理账户，下面的操作都是在管理账号下完成的。下面介绍如何在AWS Organizations中创建并组织账户&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;从AWS控制台进入&lt;em&gt;AWS Organizations&lt;/em&gt;&lt;em&gt;服务&lt;/em&gt;，点击&amp;nbsp;&lt;em&gt;AWS &lt;/em&gt;&lt;em&gt;账户&lt;/em&gt;，再点击&amp;nbsp;&lt;em&gt;添加&lt;/em&gt;&lt;em&gt;AWS&lt;/em&gt;&lt;em&gt;账户&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;输入&lt;em&gt;AWS &lt;/em&gt;&lt;em&gt;账户名和电子邮箱地址&lt;/em&gt;后，点击&lt;em&gt;创建&lt;/em&gt;&lt;em&gt;AWS&lt;/em&gt;&lt;em&gt;账户&lt;/em&gt;即可&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;除了新建账户外，还可以把现有的账户通过邀请的方式加入到组织中来。点击&amp;nbsp;&lt;em&gt;邀请&lt;/em&gt;，再点击&lt;em&gt;邀请&lt;/em&gt;&lt;em&gt;AWS账户&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;输入现有其他AWS账户的&lt;em&gt;12&lt;/em&gt;&lt;em&gt;位数字或者邮箱&lt;/em&gt;，点击&lt;em&gt;发送邀请&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;把所有游戏账户都加到组织之后，接下来我们要组织这些账户，以区分哪些账号属于哪款游戏，哪些游戏属于哪个项目组，哪些游戏是第三方开发商开发的等等。比如，我们按游戏项目组组织所有的账户&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在AWS账户下，选中&lt;em&gt;Root&lt;/em&gt;，点击&lt;em&gt;操作&lt;/em&gt;下拉列表，再点击&lt;em&gt;新建&lt;/em&gt;。通过这种方式我们就可以建立多个项目组&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在AWS账户下，选中某个账户，点击&lt;em&gt;操作&lt;/em&gt;下拉列表，再点击&lt;em&gt;移动&lt;/em&gt;，可移动到任意组织下。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;更多详细操作说明请参考以下文档&lt;a href="https://docs.aws.amazon.com/zh_cn/organizations/latest/userguide/orgs_manage_ous.html"&gt;https://docs.aws.amazon.com/zh_cn/organizations/latest/userguide/orgs_manage_ous.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;（2）如何集中式的用户管理与权限分配&lt;/h2&gt; 
&lt;p&gt;在用户管理与权限方面，我看到大部分游戏公司都是在每个账户下面单独创建用户并分配权限，在账户少的情况下还可以应付，随着账号增加用户与权限管理的难度越来越大。&lt;/p&gt; 
&lt;p&gt;通过AWS Organizations解决了游戏账户申请和组织之后，我们就可以利用AWS Single Sign-On (SSO)这个服务，集中管理多个 AWS 账户的访问与权限，并为用户提供单点登录访问他们的所拥有权限的账户。下面介绍如何在SSO内创建用户、用户组、分配权限以及和Organization组织绑定&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;使用Organization管理账户，从AWS控制台进入AWS SSO服务，点击左边的&lt;em&gt;用户&lt;/em&gt;，然后点击&lt;em&gt;添加用户&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;我们还可以创建用户组，点击左边的 &lt;em&gt;组&lt;/em&gt;，然后点击 &lt;em&gt;创建组&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management8.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;将用户加入到某个用户组，点击某个组&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management9.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;点击 &lt;em&gt;添加用户&lt;/em&gt;，将用户加到某个用户组&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management10.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;创建完用户之后，下面来介绍创建权限集合，首先点击 &amp;nbsp;&lt;em&gt;AWS&lt;/em&gt;&lt;em&gt;账户&lt;/em&gt;，再点击&lt;em&gt;权限集合&lt;/em&gt;，最好&lt;em&gt;创建权限集合&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management11.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;用户、用户组、权限集合都已经有了，现在为organization的组织指定用户、用户组和分配权限&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management12.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management13.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management14.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;那么我们如何通过SSO来到登录某个账户呢？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;首先我们要找到SSO的门户URL，点击 &lt;em&gt;设置&lt;/em&gt;，我们就可以看到用户&lt;em&gt;门户&lt;/em&gt;&lt;em&gt;URL&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management15.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management15.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;打开浏览器，输入url，用户名，点击Next，输入密码&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management16.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management16.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;登录后我们即可看到有权限登录的账户都会显示出来&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management17.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management17.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 使用SSO后不再需要到每个账户下去创建用户、用户组、分配权限，只需要在SSO中集中创建用户、分配权限，再把用户和Organization组织做一个绑定。AWS SSO除了支持在SSO中创建用户外，还可以和你的AD或者通过SAML2.0的方式集成。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;（3）如何方便的查看、管理多账户下的资源&lt;/h2&gt; 
&lt;p&gt;通过SSO可以很方便的登录到每一个账户下面去做相应的操作以及查看资源，但是随着账号越来越多，这依然是一个很费时费力的工作。因此我们需要一个更简单的方式帮我们汇总每个账户下所有区域的资源到一个集中地方进行查看和分析。下面介绍两种方式来汇总资源：第一种是通过AWS Resource Groups，Resource Groups可以查看单个账户下所有区域的资源；另一种方式是通过AWS Config这个服务加上Organization可以实现统一查看组织下所有账户的资源情况。下面我们来看一下具体如何操作&lt;/p&gt; 
&lt;p&gt;第一种通过AWS Resource Groups的方式&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;从AWS控制台进入&lt;em&gt;Resource Groups &amp;amp; Tag Editor&lt;/em&gt;服务，点击&lt;em&gt;Tag Editor&lt;/em&gt;，选择&lt;em&gt;所有区域&lt;/em&gt;，资源类型选择&lt;em&gt;AWS::EC2::Instance&lt;/em&gt;，点击 &lt;em&gt;搜索资源&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management18.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management18.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;各个区域的EC2资源如下&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management19.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management19.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;当然也可以指定Tag来进行资源查找&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;注意：虽然选择了所有的区域，但是由于某些区域还不支持，所以并不是所有的区域资源都能看到&lt;/p&gt; 
&lt;p&gt;第二种通过Organizations加上AWS Config的方式&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;使用organization管理账户从AWS控制台进入AWS Config服务，首先我们要确认config记录功能已打开，如果没打开的话首先要打开。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management20.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management20.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;点击左边的 &lt;em&gt;聚合器&lt;/em&gt;，再点击 &lt;em&gt;创建聚合器&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management21.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management21.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;勾上允许 AWS Config 将数据从源账户复制到聚合器账户，输入聚合器名称，选择添加我们的组织，选择想要聚合区域，点击创建聚合器&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management22.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management22.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;这样我们一个聚合器就创建完成了，等待一段时间后（大概10分钟）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;查询所有账号下的资源&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management23.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management23.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management24.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management24.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;查看所有账号下的EC2 Instances&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management25.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management25.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="list-style-type: none"&gt; 
  &lt;ul&gt; 
   &lt;li&gt;查看所有账号下的RDS Instances&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management26.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/game-company-multi-account-management26.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在本篇博客中介绍了在AWS上如何快速为每个游戏单独创建账户并组织这些账户；如何集中式的用户管理与权限分配；如何方便的查看、管理多账户下的资源等挑战，在下一篇博客中将进一步介绍多账号下的安全合规、资源合规、成本等内容。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/panwenmi.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;潘文明&lt;/h3&gt; 
  &lt;p&gt;AWS解决方案架构师，负责基于 AWS 的云计算方案的咨询与架构设计。专注于游戏行业，帮助客户利用AWS全球基础设施与强大的技术能力打造爆款游戏，降低游戏运行成本。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>使用 Step Functions 编排从数据库到数据仓库的数据ETL</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse/</link>
				<pubDate>Tue, 24 Aug 2021 02:50:38 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Serverless]]></category>
		<category><![CDATA[Amazon Redshift]]></category>
		<category><![CDATA[AWS Glue]]></category>
		<category><![CDATA[AWS Step Functions]]></category>

		<guid isPermaLink="false">072eb0625cf677b6e06ae9b28901f4a81f197b19</guid>
				<description>数据仓库是信息的中央存储库。业务分析师、数据工程师、数据科学家和决策者通过商业智能 (BI) 工具、SQL 客户端和其他分析应用程序访问数据。数据和分析已然成为各大企业保持竞争力所不可或缺的部分。企业用户依靠报告、控制面板和分析工具从其数据中获得洞察力、监控企业绩效以及更明智地决策。</description>
								<content:encoded>&lt;p&gt;数据仓库是信息的中央存储库。业务分析师、数据工程师、数据科学家和决策者通过商业智能 (BI) 工具、SQL 客户端和其他分析应用程序访问数据。数据和分析已然成为各大企业保持竞争力所不可或缺的部分。企业用户依靠报告、控制面板和分析工具从其数据中获得洞察力、监控企业绩效以及更明智地决策。&lt;/p&gt; 
&lt;p&gt;通常，数据定期从事务系统、关系数据库和其他来源流入数据仓库。这个流入的过程，被称作ETL(Extract-Transform-Load)。在数据爆炸的今天，开发者经常需要通过Hadoop/Spark 集群，配合一些开源组件，如sqoop, Hive, Airflow等实现对海量数据的处理和迁移。除了集群本身的维护，如虚机的配置，操作系统的升级，安全管理，存储的扩展等，还要考虑如性能监控，日志，错误处理等诸多支撑性功能的实现。&lt;/p&gt; 
&lt;p&gt;本文介绍一个通过亚马逊云Serverless(无服务器)服务提供ETL的方案。它包含了亚马逊云Step Function, Glue, Lambda等组件，实现从mysql 数据库到亚马逊云Redshift 数仓的数据迁移以及迁移后的处理功能。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;架构设计&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;① &amp;nbsp;通过定期执行的源数据爬虫任务，读取业务数据库和数据仓库的源数据。&lt;/p&gt; 
&lt;p&gt;②&amp;nbsp; 通过Glue服务的ETL Job完成从业务数据库到数据仓库的数据拉取，转化和加载。&lt;/p&gt; 
&lt;p&gt;③&amp;nbsp; 调用Lambda函数，对数仓中的数据进行进一步的加工，满足企业对数据分层等进一步处理的要求。&lt;/p&gt; 
&lt;p&gt;这其中，第2步和第3步都是通过Step Function来调度执行，实现可视化的作业管理。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;环境准备&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，在环境中分别创建一个mysql 实例和一个redshift 数仓实例来模拟企业的场景。这里我们设置redshift数据库为“dev”:&lt;/li&gt; 
 &lt;li&gt;另外，需要创建s3和redshift-data的两个Endpoint 服务，用于VPC内程序的访问&lt;/li&gt; 
 &lt;li&gt;之后，创建一个SNS topic,用于在出现问题时进行通知&lt;/li&gt; 
 &lt;li&gt;最后，我们需要为redshift创建一个secret manager 密钥，用于安全访问redshift&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在这些基础框架建设完毕后，可以分别连接到数仓和数据库中，通过&lt;a href="https://github.com/sun-biao/step-function-etl-redshift/blob/main/sql.script"&gt;https://github.com/sun-biao/step-function-etl-redshift/blob/main/sql.script&lt;/a&gt;&amp;nbsp;中的建表语句，分别创建两个表，table1和table2。 另外在资源中还有一个创建存储过程的语句，可以在redshift中执行，这个存储过程用来模拟企业内部数仓中的执行程序。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;环境搭建&lt;/h2&gt; 
&lt;h3&gt;第一步： 源数据管理&lt;/h3&gt; 
&lt;p&gt;一 在AWS Glue/数据库/连接 中，创建两个JDBC连接，分别指向数据库和数仓。&lt;/p&gt; 
&lt;p&gt;二 在AWS Glue/爬网程序 中点击“创建爬网程序”，分别为库和仓创建两个爬网程序&lt;/p&gt; 
&lt;p&gt;三 选中爬网程序，点击“运行爬网程序”。在真实场景中，可以设置为定期触发方式，这里我们手动执行。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;四 执行完毕后，点击 AWS Glue/数据库/表 查看添加后的源数据信息。注意这里的表名会根据数据库的名称不同而不同。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;第二步: 创建ETL Job&lt;/h3&gt; 
&lt;p&gt;一 点击AWS Glue/ETL/作业，点击“添加作业”&lt;/p&gt; 
&lt;p&gt;二 在“配置作业属性”页面中，输入“名称”并选择一个“角色”。如果角色中为空，参照链接创建一个新的角色：&lt;a href="https://docs.aws.amazon.com/zh_cn/glue/latest/dg/create-service-policy.html"&gt;https://docs.aws.amazon.com/zh_cn/glue/latest/dg/create-service-policy.html&lt;/a&gt;&amp;nbsp;并点击下一步&lt;/p&gt; 
&lt;p&gt;三 在“选择一个数据源”页面，选中mysql 数据库的table2,点击“下一步”&lt;/p&gt; 
&lt;p&gt;四 在“选择转换类型”页面，点击“下一步”&lt;/p&gt; 
&lt;p&gt;五 在“选择一个数据目标”页面，选中redshift数据库的table2，点击“下一步”&lt;/p&gt; 
&lt;p&gt;六 检查字段mapping后点击“保存作业并编辑脚本”。&lt;/p&gt; 
&lt;p&gt;七 在最后作业脚本页面，点击“保存”并“运行作业”。如无异常，作业会执行，数据会进入redshift&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;八 在redshift中可以通过“编辑器”对table2进行查询&lt;/p&gt; 
&lt;p&gt;九 重复上面1-8，创建一个新的作业，选择table1作为源和目标。这样我们就有了两个作业，分别对应table1和table2&lt;/p&gt; 
&lt;h3&gt;第三步： 创建lambda程序&lt;/h3&gt; 
&lt;p&gt;一 在AWS Lambda中选择“创建函数”&lt;/p&gt; 
&lt;p&gt;二 函数名为callredshift, “运行时”选择python3.8。&lt;/p&gt; 
&lt;p&gt;三 点击“高级设置”，在“VPC”中选择redshift 所在VPC, 安全组选择可以访问Redshift的安全组&lt;/p&gt; 
&lt;p&gt;四在“配置/常规配置”中，将超时时间设置为25秒。&lt;/p&gt; 
&lt;p&gt;五 在“配置/权限”中，为当前角色附加 “AdministratorAccess”策略&lt;/p&gt; 
&lt;p&gt;六 将下列代码粘贴到lambda_function.py中&lt;/p&gt; 
&lt;pre&gt;&lt;code class="lang-python"&gt;import json
import boto3
import time

client = boto3.client('redshift-data')
def lambda_handler(event, context):
    print('start.....')
    try:
        response = client.execute_statement(
            ClusterIdentifier='redshift-cluster-1',
            Database='dev',
            SecretArn=‘&amp;lt;redshit的Secret Manager ARN&amp;gt;',
            Sql='call test_sp1(1000000)',
            # Sql='select count(*) from table1',
            StatementName='get result'
        )
    except Exception as e:
        subject = &amp;quot;Error:&amp;quot; + &amp;quot;:&amp;quot; + str(e)
        print(subject)
        raise
    query_id = response[&amp;quot;Id&amp;quot;]
    done = False
    while not done:
        time.sleep(1)
        status = status_check(client, query_id)
        if status in (&amp;quot;STARTED&amp;quot;, &amp;quot;FAILED&amp;quot;, &amp;quot;FINISHED&amp;quot;):
            print(&amp;quot;status is: {}&amp;quot;.format(status))
            break
    print(response)
    desc = client.describe_statement(Id=response[&amp;quot;Id&amp;quot;])
    result = client.get_statement_result(Id=response[&amp;quot;Id&amp;quot;])
    print(result)
    return str(result)
def status_check(client, query_id):
    desc = client.describe_statement(Id=query_id)
    status = desc[&amp;quot;Status&amp;quot;]
    if status == &amp;quot;FAILED&amp;quot;:
        raise Exception('SQL query failed:' + query_id + &amp;quot;: &amp;quot; + desc[&amp;quot;Error&amp;quot;])
    return status.strip('&amp;quot;')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;七 保存后点击“Test”，创建一个“测试事件”后，再次点击”Test“，查看输出结果&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;第四步： 创建Step Functions 状态机&lt;/h3&gt; 
&lt;p&gt;一 选择“Step Functions/状态机”，点击“创建状态机”&lt;/p&gt; 
&lt;p&gt;二 使用默认选项，在下面定义中，删除原Json文件，拷贝如下内容：&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-json"&gt;{
  &amp;quot;Comment&amp;quot;: &amp;quot;This is your state machine&amp;quot;,
  &amp;quot;StartAt&amp;quot;: &amp;quot;Parallel&amp;quot;,
  &amp;quot;States&amp;quot;: {
    &amp;quot;Parallel&amp;quot;: {
      &amp;quot;Type&amp;quot;: &amp;quot;Parallel&amp;quot;,
      &amp;quot;Branches&amp;quot;: [
        {
          &amp;quot;StartAt&amp;quot;: &amp;quot;Table1 Job&amp;quot;,
          &amp;quot;States&amp;quot;: {
            &amp;quot;Table1 Job&amp;quot;: {
              &amp;quot;Type&amp;quot;: &amp;quot;Task&amp;quot;,
              &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:states:::glue:startJobRun.sync&amp;quot;,
              &amp;quot;Parameters&amp;quot;: {
                &amp;quot;JobName&amp;quot;: “&amp;lt;Table1 Job&amp;gt;&amp;quot;
              },
              &amp;quot;OutputPath&amp;quot;: &amp;quot;$.JobRunState&amp;quot;,
              &amp;quot;End&amp;quot;: true
            }
          }
        },
        {
          &amp;quot;StartAt&amp;quot;: &amp;quot;Table2 Job&amp;quot;,
          &amp;quot;States&amp;quot;: {
            &amp;quot;Table2 Job&amp;quot;: {
              &amp;quot;Type&amp;quot;: &amp;quot;Task&amp;quot;,
              &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:states:::glue:startJobRun.sync&amp;quot;,
              &amp;quot;Parameters&amp;quot;: {
                &amp;quot;JobName&amp;quot;: &amp;quot;&amp;lt;Table2 Job&amp;gt;&amp;quot;
              },
              &amp;quot;OutputPath&amp;quot;: &amp;quot;$.JobRunState&amp;quot;,
              &amp;quot;End&amp;quot;: true
            }
          }
        }
      ],
      &amp;quot;Next&amp;quot;: &amp;quot;Choice&amp;quot;
    },
    &amp;quot;Choice&amp;quot;: {
      &amp;quot;Type&amp;quot;: &amp;quot;Choice&amp;quot;,
      &amp;quot;Choices&amp;quot;: [
        {
          &amp;quot;And&amp;quot;: [
            {
              &amp;quot;Variable&amp;quot;: &amp;quot;$[0]&amp;quot;,
              &amp;quot;StringMatches&amp;quot;: &amp;quot;SUCCEEDED&amp;quot;
            },
            {
              &amp;quot;Variable&amp;quot;: &amp;quot;$[1]&amp;quot;,
              &amp;quot;StringMatches&amp;quot;: &amp;quot;SUCCEEDED&amp;quot;
            }
          ],
          &amp;quot;Next&amp;quot;: &amp;quot;Call redshift&amp;quot;
        }
      ],
      &amp;quot;Default&amp;quot;: &amp;quot;SNS Publish&amp;quot;
    },
    &amp;quot;Call redshift&amp;quot;: {
      &amp;quot;Type&amp;quot;: &amp;quot;Task&amp;quot;,
      &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:states:::lambda:invoke&amp;quot;,
      &amp;quot;OutputPath&amp;quot;: &amp;quot;$.Payload&amp;quot;,
      &amp;quot;Parameters&amp;quot;: {
        &amp;quot;Payload.$&amp;quot;: &amp;quot;$&amp;quot;,
        &amp;quot;FunctionName&amp;quot;: &amp;quot;arn:aws:lambda:&amp;lt;Region的名字，如ap-northeast-1&amp;gt;:&amp;lt;12位账号&amp;gt;:function:callredshift:$LATEST&amp;quot;
      },
      &amp;quot;Retry&amp;quot;: [
        {
          &amp;quot;ErrorEquals&amp;quot;: [
            &amp;quot;Lambda.ServiceException&amp;quot;,
            &amp;quot;Lambda.AWSLambdaException&amp;quot;,
            &amp;quot;Lambda.SdkClientException&amp;quot;
          ],
          &amp;quot;IntervalSeconds&amp;quot;: 2,
          &amp;quot;MaxAttempts&amp;quot;: 6,
          &amp;quot;BackoffRate&amp;quot;: 2
        }
      ],
      &amp;quot;End&amp;quot;: true
    },
    &amp;quot;SNS Publish&amp;quot;: {
      &amp;quot;Type&amp;quot;: &amp;quot;Task&amp;quot;,
      &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:states:::sns:publish&amp;quot;,
      &amp;quot;Parameters&amp;quot;: {
        &amp;quot;Message.$&amp;quot;: &amp;quot;$&amp;quot;,
        &amp;quot;TopicArn&amp;quot;: &amp;quot;arn:aws:sns:&amp;lt;Region的名字，如ap-northeast-1&amp;gt;:&amp;lt;12位账号&amp;gt;:&amp;lt;SNS 主题名&amp;gt;&amp;quot;
      },
      &amp;quot;End&amp;quot;: true
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;三 保存后，修改当前状态机的权限为管理员，执行该状态机并查看状态。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;四 点击“图表检查器”中最后一步“Call redshift”,查看右侧步骤输出，确认redshift中的程序被正确调用。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-step-functions-to-orchestrate-data-etl-from-database-to-data-warehouse7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;一 整个流程中没有除了数据仓库，没有使用任何需要维护的计算资源，实现了“零运维”。&lt;/p&gt; 
&lt;p&gt;二 Step Functions状态机的每次执行，都提供了完备的流程日志，每个步骤都有详细的输入输出信息，方便调试。&lt;/p&gt; 
&lt;p&gt;三 依照Step Functions提供逻辑处理功能，通过判断，循环等可以实现客户复杂的逻辑。&lt;/p&gt; 
&lt;p&gt;四 Step Functions提供强大的服务整合能力，通过整合其它服务，提供诸如报警，数据，计算等等功能。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/UserGuide/CHAP_GettingStarted.CreatingConnecting.MySQL.html"&gt;https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/UserGuide/CHAP_GettingStarted.CreatingConnecting.MySQL.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/rs-gsg-sample-data-load-create-cluster.html"&gt;https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/rs-gsg-sample-data-load-create-cluster.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/vpc/latest/privatelink/vpce-interface.html#create-interface-endpoint"&gt;https://docs.aws.amazon.com/zh_cn/vpc/latest/privatelink/vpce-interface.html#create-interface-endpoint&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/sns/latest/dg/sns-getting-started.html"&gt;https://docs.aws.amazon.com/zh_cn/sns/latest/dg/sns-getting-started.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/zh_cn/secretsmanager/latest/userguide/tutorials_basic.html"&gt;https://docs.aws.amazon.com/zh_cn/secretsmanager/latest/userguide/tutorials_basic.html&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/biaosun.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;孙标&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技资深解决方案架构师。拥有多年金融，移动互联网研发及数字货币交易所架构经验。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
		<item>
		<title>新增 — 由最新一代英特尔至强可扩展处理器提供支持的 Amazon EC2 M6i 实例</title>
		<link>https://aws.amazon.com/cn/blogs/china/new-amazon-ec2-m6i-instances-powered-by-the-latest-generation-intel-xeon-scalable-processors/</link>
				<pubDate>Thu, 19 Aug 2021 03:45:32 +0000</pubDate>
		<dc:creator><![CDATA[Danilo Poccia]]></dc:creator>
				<category><![CDATA[News]]></category>

		<guid isPermaLink="false">1425ca3ea8c449b55feefccc5d9e1f4e19205b61</guid>
				<description>去年，我们推出了由 AWS 设计的 Graviton2 处理器支持的第六代 EC2 实例。我们现在正在扩展我们的第六代产品功能，以包括基于 x86 的实例，为依赖 x86 指令的工作负载提供性价比优势。 今天，我很高兴地宣布推出全新通用型 Amazon EC2 M6i 实例，与同类的第五代实例相比，它的性价比提高了 15%。新实例由最新一代英特尔至强可扩展处理器（代号为 Ice Lake）提供支持，全核涡轮频率为 3.5 GHz。</description>
								<content:encoded>&lt;p&gt;去年，我们推出了由 &lt;a href="https://aws.amazon.com/ec2/graviton/"&gt;AWS 设计的 Graviton2&lt;/a&gt; 处理器支持的第六代 EC2 实例。我们现在正在扩展我们的第六代产品功能，以包括&lt;strong&gt;基于 x86 的实例&lt;/strong&gt;，为依赖 x86 指令的工作负载提供性价比优势。&lt;/p&gt; 
&lt;p&gt;今天，我很高兴地宣布推出全新通用型 &lt;a href="https://aws.amazon.com/ec2/instance-types/m6i/"&gt;&lt;strong&gt;Amazon EC2 M6i 实例&lt;/strong&gt;&lt;/a&gt;，与同类的第五代实例相比，它的性价比提高了 &lt;strong&gt;15%&lt;/strong&gt;。新实例由最新一代英特尔至强可扩展处理器（代号为 Ice Lake）提供支持，全核涡轮频率为 &lt;strong&gt;3.5 GHz&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;您可能已经注意到，我们现在正在使用实例类型中的“&lt;strong&gt;i&lt;/strong&gt;”后缀来指定实例使用的是&lt;a href="https://aws.amazon.com/intel/"&gt;英特尔处理器&lt;/a&gt;。我们已经使用后缀“&lt;strong&gt;a&lt;/strong&gt;”指代 &lt;a href="https://aws.amazon.com/ec2/amd/"&gt;AMD 处理器&lt;/a&gt;（例如，M5a 实例），对于 &lt;a href="https://aws.amazon.com/ec2/graviton/"&gt;Graviton 处理器&lt;/a&gt;（例如，M6g 实例），我们使用后缀“&lt;strong&gt;g&lt;/strong&gt;”。&lt;/p&gt; 
&lt;p&gt;与使用英特尔处理器的 M5 实例相比，这种新的实例类型提供：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;更大的实例大小（&lt;strong&gt;m6i.32xlarge&lt;/strong&gt;），具有 128 个 vCPUs 和 512 GiB 内存，这使得整合工作负载和纵向扩展应用程序变得更轻松、更具成本效益。&lt;/li&gt; 
 &lt;li&gt;计算性价比提高了 &lt;strong&gt;15％&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;内存带宽高达 &lt;strong&gt;20％&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;a title="" href="https://aws.amazon.com/ebs/"&gt;Amazon Elastic Block Store (EBS)&lt;/a&gt; 最高 &lt;strong&gt;40 Gbps&lt;/strong&gt;，联网最高速度可达 &lt;strong&gt;50 Gbps&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;始终开启的&lt;strong&gt;内存加密&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;M6i 实例非常适合运行通用工作负载，例如 Web 和应用程序服务器、&lt;a href="https://aws.amazon.com/containers/"&gt;容器化&lt;/a&gt;应用程序、&lt;a href="https://aws.amazon.com/microservices/"&gt;微服务&lt;/a&gt;和小型数据存储。更高的内存带宽对于 &lt;a href="https://aws.amazon.com/sap/solutions/saphana/"&gt;SAP HANA&lt;/a&gt; 等企业应用程序和&lt;a href="https://aws.amazon.com/hpc/"&gt;高性能计算 (HPC) 工作负载（&lt;/a&gt;如计算&lt;a href="https://aws.amazon.com/hpc/cfd/"&gt;流体动力学 (CFD)）&lt;/a&gt;的帮助尤其明显。&lt;/p&gt; 
&lt;p&gt;M6i 实例也 &lt;strong&gt;经过了 SAP 认证&lt;/strong&gt;。八年来，SAP 客户一直依赖 Amazon EC2 M 系列实例来处理其任务关键型 SAP 工作负载。相较于 M5 实例，使用 M6i 实例可以让客户的 SAP 应用程序性价比提高多达 &lt;strong&gt;15%&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;m6i 实例有&lt;strong&gt;九种大小&lt;/strong&gt;可供选择（&lt;strong&gt;m6i.metal&lt;/strong&gt; 大小即将推出）：&lt;/p&gt; 
&lt;table style="border: 2px solid black;border-collapse: collapse;margin-left: auto;margin-right: auto"&gt; 
 &lt;tbody&gt; 
  &lt;tr style="border-bottom: 1px solid black;background-color: #e0e0e0"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;名称&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;vCPU 数量&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;内存&lt;br /&gt; (GiB)&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;网络带宽&lt;br /&gt; (Gbps)&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;EBS 吞吐量&lt;br /&gt; (Gbps)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.large&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;2&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;8&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 12.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;4&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;16&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 12.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.2xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;8&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;32&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 12.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.4xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;16&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;64&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 12.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;高达 10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.8xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;32&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;128&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;12.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.12xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;48&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;192&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;18.75&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.16xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;64&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;256&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;25&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;20&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.24xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;96&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;384&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;37.5&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;30&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-bottom: 1px solid black"&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;&lt;strong&gt;m6i.32xlarge&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;128&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;512&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;50&lt;/td&gt; 
   &lt;td style="border-right: 1px solid black;padding: 4px;text-align: center"&gt;40&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;新实例基于 &lt;a href="https://aws.amazon.com/ec2/nitro/"&gt;AWS Nitro System&lt;/a&gt; 打造，该系统是构建数据块的集合，将许多传统&lt;strong&gt;虚拟化&lt;/strong&gt;功能转移到专用&lt;strong&gt;硬件&lt;/strong&gt;上，从而提供高性能、高可用性以及高度安全的云实例。&lt;/p&gt; 
&lt;p&gt;为了在这些新实例上获得最佳联网性能，请将 Elastic Network Adapter (ENA) 驱动程序升级到版本 3。有关更多信息，请参阅本文介绍&lt;a href="https://aws.amazon.com/premiumsupport/knowledge-center/migrate-to-gen6-ec2-instance/"&gt;如何在第六代 EC2 实例上获得最大网络性能&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;M6i 实例支持 &lt;strong&gt;m6i.32xlarge&lt;/strong&gt; 大小的 &lt;a href="https://aws.amazon.com/hpc/efa/"&gt;Elastic Fabric Adapter (EFA)&lt;/a&gt;，适用于受益于较低网络延迟的工作负载，例如 HPC 和视频处理。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;可用性和定价&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;&lt;a href="https://aws.amazon.com/ec2/instance-types/m6i/"&gt;EC2 M6i 实例&lt;/a&gt;现已在&lt;span title=""&gt;美国东部（弗吉尼亚北部）&lt;/span&gt;、&lt;span title=""&gt;美国西部（俄勒冈）&lt;/span&gt;、&lt;span title=""&gt;美国东部（俄亥俄）&lt;/span&gt;、&lt;span title=""&gt;欧洲（爱尔兰）&lt;/span&gt;、&lt;span title=""&gt;欧洲（法兰克福）&lt;/span&gt;和&lt;span title=""&gt;亚太地区（新加坡）&lt;/span&gt;这六个 AWS 区域推出。像往常的 EC2 实例一样，您将按使用量付费。有关更多信息，请参阅 &lt;a href="https://aws.amazon.com/ec2/pricing/"&gt;EC2 定价页面&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;– &lt;a title="Danilo 的 Twitter" href="https://twitter.com/danilop"&gt;Danilo&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>面向 Amazon Redshift 的跨账户数据共享</title>
		<link>https://aws.amazon.com/cn/blogs/china/cross-account-data-sharing-for-amazon-redshift/</link>
				<pubDate>Thu, 19 Aug 2021 03:42:08 +0000</pubDate>
		<dc:creator><![CDATA[Martin Beeby]]></dc:creator>
				<category><![CDATA[Announcements]]></category>

		<guid isPermaLink="false">2bc7ac320fda29261084e669eff74ef29f1ee084</guid>
				<description>为了在当今快速变化的市场环境中取得成功，企业需要快速分析数据并采取有意义的行动。我们的许多客户都接受了这一概念，因此转型成为数据驱动型组织。 数据驱动型组织将数据视为资产，利用数据提高洞察力并制定更完善的决策。他们使用安全系统来收集、存储和处理数据，并与组织中的人员共享数据，从而充分发挥数据的作用。有些组织甚至将数据和分析作为服务提供给客户、合作伙伴和外部各方，以创造新的收入来源。</description>
								<content:encoded>&lt;p&gt;为了在当今快速变化的市场环境中取得成功，企业需要快速分析数据并采取有意义的行动。我们的许多客户都接受了这一概念，因此转型成为数据驱动型组织。&lt;/p&gt; 
&lt;p&gt;数据驱动型组织将数据视为资产，利用数据提高洞察力并制定更完善的决策。他们使用安全系统来收集、存储和处理数据，并与组织中的人员共享数据，从而充分发挥数据的作用。有些组织甚至将数据和分析作为服务提供给客户、合作伙伴和外部各方，以创造新的收入来源。&lt;/p&gt; 
&lt;p&gt;所有利益相关者都希望共享和使用与单一事实来源同等准确的数据。他们希望能够并发查询数据的实时视图，同时不会出现性能降低，并在需要时准确访问正确的信息。&lt;/p&gt; 
&lt;p&gt;&lt;a title="" href="https://aws.amazon.com/redshift/"&gt;Amazon Redshift&lt;/a&gt; 是第一款面向云构建的数据仓库组件，其已受到市场的普遍欢迎，成为许多客户数据架构的数据仓库组件。&lt;/p&gt; 
&lt;p&gt;&lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 用户&lt;a href="https://docs.aws.amazon.com/redshift/latest/dg/datashare-overview.html"&gt;可以与 AWS 账户中的用户共享数据&lt;/a&gt;，但为了与其他 AWS 账户共享和协作处理数据，他们需要从一个系统中提取数据并将其加载到另一个系统中。&lt;/p&gt; 
&lt;p&gt;为了实现此目标，他们需要执行大量的手动工作来构建和维护不同的提取、转换与加载作业。随着数据共享规模的扩大以及越来越多的利益相关者需要数据，复杂性也随之增加。因此，持续执行保障数据安全所需的监控、合规性和安全最佳实践可能变得困难。&lt;/p&gt; 
&lt;p&gt;这种共享方式也无法提供完整和最新的数据视图，因为手动流程会导致延迟和数据不一致，从而产生过时的数据、低质量的业务结果以及缓慢的客户响应。&lt;/p&gt; 
&lt;p&gt;这就是我们为 &lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 创建跨账户数据共享的原因所在。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;为 &lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 引入跨账户数据共享&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;这项新功能为您提供了一种简单而安全的方式，可以与跨 AWS 账户的任意数量利益相关者共享 Amazon Redshift 数据仓库中全新、完整且一致的数据。它可让您跨组织共享数据并与外部各方协作，同时满足合规性和安全要求。&lt;/p&gt; 
&lt;p&gt;&lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 使用 IAM 集成、系统表和 &lt;a title="" href="https://aws.amazon.com/cloudtrail/"&gt;AWS CloudTrail&lt;/a&gt; 提供全面的安全控制和审计功能。这可让客户控制和监控消费者之间的数据共享权限和使用情况，并在必要时立即撤消访问权限。&lt;/p&gt; 
&lt;p&gt;您可以在多个级别 (包括数据库、架构、表、视图、列和用户定义的函数) 共享数据，以提供针对需要访问 &lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 数据的用户和企业量身定制的精细访问控制。&lt;/p&gt; 
&lt;p&gt;下面详细了解跨账户数据共享的工作原理。&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;跨两个账户共享数据&lt;br /&gt; &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;跨账户数据共享是两个步骤的过程。第一步是，生产者群集管理员创建数据共享，添加对象，以及授予对消费者账户的访问权限。第二步是，生产者账户管理员授权共享指定消费者的数据。您可以从 &lt;a title="" href="https://aws.amazon.com/redshift/"&gt;Amazon Redshift&lt;/a&gt; 控制台执行此操作。&lt;/p&gt; 
&lt;p&gt;首先，在 &lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 控制台中，我创建一个 &lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 集群，然后导入一些示例数据。当集群可用时，我导航到集群详细信息页面，从中选择&lt;strong&gt;数据共享&lt;/strong&gt;选项卡，然后选择&lt;strong&gt;创建数据共享&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter wp-image-53695" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/demo-1.jpg" alt="" width="800" height="507" /&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在&lt;strong&gt;创建数据共享&lt;/strong&gt;页面上，我输入数据共享名称，然后选择数据库。在“公开访问”下，我选择&lt;strong&gt;启用&lt;/strong&gt;，因为我希望将数据共享提供给可公开访问的集群。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter wp-image-53698" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/demo-3-1.jpg" alt="" width="800" height="558" /&gt;&lt;/p&gt; 
&lt;p&gt;然后，我从数据库中选择想要包含在数据共享中的对象。对于选择与他人共享的内容，我拥有精细控制权。为简单起见，我将共享所有表。但实际上，您可以选择一个或多个表、视图或用户定义的函数。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-53699" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/demo-4.jpg" alt="" width="801" height="814" /&gt;&lt;/p&gt; 
&lt;p&gt;我需要做的最后一件事就是向数据共享添加一个 AWS 账户。我添加自己的第二个 AWS 账户 ID，然后选择&lt;strong&gt;创建数据共享&lt;/strong&gt;。&lt;br /&gt; &lt;img class="aligncenter size-full wp-image-53700" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/demo-5.jpg" alt="" width="807" height="443" /&gt;&lt;/p&gt; 
&lt;p&gt;为了授权刚创建的数据使用者，我在控制台的&lt;strong&gt;数据共享&lt;/strong&gt;部分中选择&lt;strong&gt;授权&lt;/strong&gt;。&lt;strong&gt;消费者状态&lt;/strong&gt;将从&lt;strong&gt;等待授权&lt;/strong&gt;更改为&lt;strong&gt;已授权&lt;/strong&gt;。现在数据共享已设置完毕，我将切换到自己的辅助账户，向您展示如何在消费者 AWS 账户中使用数据共享。值得注意的是，我需要在辅助账户中使用同一个区域，因为跨账户数据共享不能跨区域运作。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter wp-image-53704" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/demo-auth0.jpg" alt="" width="800" height="497" /&gt;&lt;/p&gt; 
&lt;p&gt;与生产者类似，数据使用有着相应的流程。首先，您需要将数据共享与消费者账户中的一个或多个集群关联起来。您还可以将数据共享与整个消费者账户关联，以便消费者账户中的当前和未来集群均可以访问该共享。&lt;/p&gt; 
&lt;p&gt;我登录自己的辅助账户，然后转到控制台的&lt;strong&gt;数据共享&lt;/strong&gt;部分。&amp;nbsp;我选择&lt;strong&gt;从其他账户&lt;/strong&gt;选项卡，然后选择从生产者 AWS 账户共享的 news_blog_datashred。接下来，我选择&lt;strong&gt;关联&lt;/strong&gt;以将数据共享与我账户中的集群关联。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-53703" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/demo-asso.jpg" alt="" width="807" height="418" /&gt;&lt;/p&gt; 
&lt;p&gt;在集群的详细信息页面上，我选择&lt;strong&gt;从数据共享创建数据库&lt;/strong&gt;，然后输入新数据库的名称。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-53708" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/2021-07-31_12-30-54.jpg" alt="" width="807" height="312" /&gt;&lt;/p&gt; 
&lt;p&gt;在查询编辑器中，我选择自己的数据库并对作为数据共享一部分提供的所有对象运行查询。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-53711" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/run_query.jpg" alt="" width="807" height="448" /&gt;&lt;/p&gt; 
&lt;p&gt;当我选择&lt;strong&gt;运行&lt;/strong&gt;时，将从查询中返回数据。务必记住，这是数据的实时视图。生产者数据库中的任何更改都将反映在我的查询中。不需要复制或手动转移数据。&lt;/p&gt; 
&lt;p&gt;&lt;img class="aligncenter size-full wp-image-53712" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/07/31/rows.jpg" alt="" width="675" height="388" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="text-decoration: underline"&gt;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;以下是关于跨账户数据共享的几点有趣的事实：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;安全性&lt;/strong&gt; – 授权和关联操作所需的所有权限均通过 &lt;a title="" href="https://aws.amazon.com/iam/"&gt;AWS Identity and Access Management (IAM)&lt;/a&gt; 进行管理，因此您可以创建 IAM 策略来控制每个用户可以执行哪些操作。有关安全考虑事项，请参阅&lt;a href="https://docs.aws.amazon.com/redshift/latest/dg/control-access.html"&gt;控制跨账户数据集的访问权限&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加密&lt;/strong&gt; – 生产者和消费者群集必须在同一 AWS 区域中进行加密。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;区域&lt;/strong&gt; – 跨账户数据共享功能现已在以下区域面向所有 Amazon Redshift &lt;a href="https://aws.amazon.com/redshift/pricing/"&gt;RA3 节点类型&lt;/a&gt;推出：美国东部 (弗吉尼亚北部)、美国东部 (俄亥俄)、美国西部 (加利福尼亚北部)、美国西部 (俄勒冈)、亚太地区 (孟买)、亚太地区 (首尔)、亚太地区 (新加坡)、亚太地区 (悉尼)、亚太地区 (东京)、加拿大 (中部)、欧洲 (法兰克福)、欧洲 (爱尔兰)、欧洲 (伦敦)、欧洲 (巴黎)、欧洲 (斯德哥尔摩) 以及南美洲 (圣保罗)。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;定价&lt;/strong&gt; – 跨账户数据共享可以跨位于同一区域的集群之间进行。共享数据没有成本。客户只需为参与共享的 Redshift 集群付费。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aws.amazon.com/redshift/features/data-sharing/"&gt;&lt;strong&gt;立即试用针对 &lt;span title=""&gt;Amazon Redshift&lt;/span&gt; 的跨账户数据共享。&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;这项新功能现已推出，何不现在就创建集群并进行跨账户数据共享？ 有关如何开始使用的信息，请参阅&lt;a href="https://docs.aws.amazon.com/redshift/latest/dg/across-account.html"&gt;跨 AWS 账户共享数据&lt;/a&gt;。不要忘记告诉我们您是如何取得进展的。&lt;/p&gt; 
&lt;p&gt;快乐共享！&lt;/p&gt; 
&lt;p&gt;&lt;a title="Martin 的 Twitter" href="https://twitter.com/thebeebs"&gt; – Martin&lt;/a&gt;&lt;/p&gt;</content:encoded>
										</item>
		<item>
		<title>在AWS上使用AlphaFold进行蛋白质结构预测</title>
		<link>https://aws.amazon.com/cn/blogs/china/use-alphafold-for-protein-structure-prediction-on-aws/</link>
				<pubDate>Tue, 17 Aug 2021 03:26:52 +0000</pubDate>
		<dc:creator><![CDATA[AWS Team]]></dc:creator>
				<category><![CDATA[Industries]]></category>
		<category><![CDATA[Amazon CloudWatch]]></category>
		<category><![CDATA[Amazon EC2]]></category>

		<guid isPermaLink="false">be2652ecb75d41386e4c43a8ad2c23fb0bc32f02</guid>
				<description>AlphaFold是一个能根据蛋白质序列预测构象的深度学习模型，2021年7月，DeepMind开源了升级版本AlphaFold v2.0，本文简要描述了如何在AWS上使用AlphaFold进行蛋白质结构预测。</description>
								<content:encoded>&lt;p&gt;AlphaFold是一个能根据蛋白质序列预测构象的深度学习模型，2021年7月，DeepMind开源了升级版本AlphaFold v2.0，本文简要描述了如何在AWS上使用AlphaFold进行蛋白质结构预测。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;EC2实例设置&lt;/h2&gt; 
&lt;p&gt;运行AlphaFold需要安装Docker和NVIDIA Container Toolkit，我们可以启动一台运行ECS GPU-optimized AMI的EC2实例，以省去这些工具的安装操作：&lt;/p&gt; 
&lt;p&gt;启动EC2实例，搜索AMI: amzn2-ami-ecs-gpu-hvm-2.0.2021，选择最新的日期的版本(也可以从https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html查询对于区域的最新Amazon Linux（GPU）AMI ID)&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws1.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws1.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如果要使用NVIDIA A100则实例类型可选择p4d.24xlarge，本例测试选择具有4块NVIDIA V100 GPU的p3.8xlarge&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws2.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws2.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 系统卷100G，增加一个3T的数据卷，卷类型均为gp3&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws3.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws3.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;实例创建完成后登录系统，格式化并挂载3T的数据盘到/data，具体操作参考该&lt;a href="https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ebs-using-volumes.html"&gt;文档&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws4.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws4.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;数据库下载&lt;/h2&gt; 
&lt;p&gt;1.安装依赖&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;sudo rpm http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;sudo yum install aria2 rsync git vim wget -y&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;2.修改/data目录权限&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;sudo chown ec2-user:ec2-user -R /data&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;3.克隆AlphaFold 代码库并进入alphafold目录&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;git clone https://github.com/deepmind/alphafold.git&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;4.下载数据到/data，因为数据下载加解压可能需要十几个小时的时间，所以使用nohup让下载任务在后台执行&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nohup scripts/download_all_data.sh /data &amp;amp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;完成之后在下载目录会有如下文件生成&lt;/p&gt; 
&lt;div class="hide-language"&gt; 
 &lt;pre&gt;&lt;code class="lang-powershell"&gt;$DOWNLOAD_DIR/                          # Total: ~ 2.2 TB (download: 438 GB)
    bfd/                                   # ~ 1.7 TB (download: 271.6 GB)
        # 6 files.
    mgnify/                                # ~ 64 GB (download: 32.9 GB)
        mgy_clusters_2018_12.fa
    params/                                # ~ 3.5 GB (download: 3.5 GB)
        # 5 CASP14 models,
        # 5 pTM models,
        # LICENSE,
        # = 11 files.
    pdb70/                                 # ~ 56 GB (download: 19.5 GB)
        # 9 files.
    pdb_mmcif/                             # ~ 206 GB (download: 46 GB)
        mmcif_files/
            # About 180,000 .cif files.
        obsolete.dat
    small_fbd/                             # ~ 17 GB (download: 9.6 GB)
        bfd-first_non_consensus_sequences.fasta
    uniclust30/                            # ~ 86 GB (download: 24.9 GB)
        uniclust30_2018_08/
            # 13 files.
    uniref90/                              # ~ 58 GB (download: 29.7 GB)
        uniref90.fasta
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;运行AlphaFold&lt;/h2&gt; 
&lt;p&gt;1.创建输出目录&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;mkdir -p /tmp/alphafold&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;2.将docker/run_docker.py中的DOWNLOAD_DIR修改为包含下载数据库目录的路径/data, output_dir设置为上一步创建的输出目录&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws5.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws5.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 3.构建Docker镜像&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;docker build -f docker/Dockerfile -t alphafold .&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;完成后查看&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws6.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws6.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 4.安装依赖&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip3 install -r docker/requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;5.测试文件&lt;/p&gt; 
&lt;p&gt;打开https://www.predictioncenter.org/casp14/target.cgi?target=T1050，复制Sequence的文本到T1050.fasta文件中&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws7.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws7.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws8.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws8.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 6.运行可能需要几个小时时间，可以同样使用nohup命令让任务在后台执行&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nohup python3 docker/run_docker.py --fasta_paths=T1050.fasta --max_template_date=2020-05-14 &amp;amp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;一个任务只能使用一块GPU，如果计算实例具有多块GPU，可以利用–gpu_devices参数将多个任务投递到不同的GPU上进行计算，如：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nohup python3 docker/run_docker.py --fasta_paths=T1050-1.fasta --max_template_date=2020-05-14 --gpu_devices=0 &amp;amp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nohup python3 docker/run_docker.py --fasta_paths=T1050-2.fasta --max_template_date=2020-05-14 --gpu_devices=1 &amp;amp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;7.完成之后在之前设置的/tmp/alphafold目录下会有结果输出&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws9.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws9.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;监控配置&lt;/h2&gt; 
&lt;p&gt;我们可以通过CloudWatch来监控CPU、内存和GPU的使用率，其中CPU监控指标CloudWatch默认就支持，内存监控指标需要通过CloudWatch Agent来实现，GPU监控需要通过一个python程序来实现&lt;/p&gt; 
&lt;h3&gt;IAM角色&lt;/h3&gt; 
&lt;p&gt;新建一个具有ClooudWatchAgentServerPolicy权限的角色，取名CW-Role&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws10.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws10.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;将它附加到EC2实例上&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws11.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws11.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;CloudWatch Agent&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws12.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws12.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 1.安装&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;sudo yum install collectd amazon-cloudwatch-agent -y&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;2.执行如下命令并按提示进行配置，详见附录&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-config-wizard&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;3.重新启动agent&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -s -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;GPU监控&lt;/h3&gt; 
&lt;p&gt;1. 下载python脚本&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;wget https://s3.amazonaws.com/aws-bigdata-blog/artifacts/GPUMonitoring/gpumon.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;2. vim gpumon.py&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;修改&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;### 选择区域 ####&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;EC2_REGION = 'us-east-1'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;#在此处选择命名空间参数，名字可以随意取###&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;my_NameSpace = 'AlphaFold'&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;### 选择推送间隔 ####&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;sleep_interval = 10&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;### 选择存储精度 (在 1-60 之间) ####&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;store_reso = 60&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;3. 安装python2的依赖&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;wget &lt;a href="https://bootstrap.pypa.io/pip/2.7/get-pip.py"&gt;https://bootstrap.pypa.io/pip/2.7/get-pip.py&lt;/a&gt;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python get-pip.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install nvidia-ml-py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install boto3&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;执行&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nohup python gpumon.py &amp;amp;&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;CloudWatch&lt;/h3&gt; 
&lt;p&gt;在CloudWatch的指标中可以发现CWAgent和AlphaFold两个命名空间，其中包含了我们所需要的内存和GPU监控指标&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws13.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws13.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws14.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws14.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;br /&gt; 创建一个控制面板来统一监控这些指标&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws15.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws15.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;测试结果分析&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;python3 docker/run_docker.py --fasta_paths=T1050.fasta --max_template_date=2020-05-14&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;结果如下：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws16.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws16.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;只有在模型的推理阶段才会用到GPU，而且只用到了4块GPU中的一块，其余阶段都是用的CPU（https://github.com/deepmind/alphafold/issues/67）&lt;/p&gt; 
&lt;p&gt;投递两个任务&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nohup python3 docker/run_docker.py --fasta_paths=T1050-1.fasta --max_template_date=2020-05-14 --gpu_devices=0 &amp;gt; a.out &amp;amp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nohup python3 docker/run_docker.py --fasta_paths=T1050-2.fasta --max_template_date=2020-05-14 --gpu_devices=1 &amp;gt; b.out &amp;amp;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;结果如下：&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws17.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws17.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;可以看到用到了2块GPU&lt;/p&gt; 
&lt;h3&gt;&lt;/h3&gt; 
&lt;h2&gt;参考&lt;/h2&gt; 
&lt;p&gt;更详细的AlphaFold使用请参考：https://github.com/deepmind/alphafold&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;附录&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws18.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws18.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CloudWatch Agent配置示例&lt;br /&gt; &lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws19.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws19.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws20.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws20.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;a href="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws21.jpg"&gt;&lt;img class="aligncenter size-medium" src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-alphafold-for-protein-structure-prediction-on-aws21.png" width="624" height="78" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;本篇作者&lt;/h2&gt; 
&lt;footer&gt; 
 &lt;div class="blog-author-box"&gt; 
  &lt;div class="blog-author-image"&gt;
   &lt;img src="https://s3.cn-north-1.amazonaws.com.cn/awschinablog/Author/suliang.jpg" width="125" /&gt;
  &lt;/div&gt; 
  &lt;h3 class="lb-h4"&gt;孙亮&lt;/h3&gt; 
  &lt;p&gt;亚马逊云科技解决方案架构师，硕士毕业于浙江大学计算机系。在加入亚马逊云科技之前，拥有多年软件行业开发经验。目前在Public Sector部门主要服务于生命科学和医疗健康相关的行业客户，致力于提供有关HPC、无服务器、数据安全等各类云计算解决方案的咨询与架构设计。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/footer&gt;</content:encoded>
										</item>
	</channel>
</rss>